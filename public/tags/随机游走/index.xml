<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>随机游走 on bitJoy</title>
    <link>http://localhost:1313/tags/%E9%9A%8F%E6%9C%BA%E6%B8%B8%E8%B5%B0/</link>
    <description>Recent content in 随机游走 on bitJoy</description>
    <generator>Hugo -- 0.148.2</generator>
    <language>en</language>
    <lastBuildDate>Tue, 23 Aug 2016 18:59:57 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/%E9%9A%8F%E6%9C%BA%E6%B8%B8%E8%B5%B0/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>随机矩阵及其特征值</title>
      <link>http://localhost:1313/posts/2016-08-23-the-eigenvalue-of-stochastic-matrix/</link>
      <pubDate>Tue, 23 Aug 2016 18:59:57 +0800</pubDate>
      <guid>http://localhost:1313/posts/2016-08-23-the-eigenvalue-of-stochastic-matrix/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Stochastic_matrix&#34;&gt;随机矩阵&lt;/a&gt;是这样一类方阵，其元素为非负实数，且行和或列和为1。如果行和为1，则称为行随机矩阵；如果列和为1，则称为列随机矩阵；如果行和和列和都为1，则称为双随机矩阵。&lt;/p&gt;
&lt;p&gt;前面我们介绍的&lt;a href=&#34;https://bitjoy.net/posts/2016-08-04-googles-pagerank-and-beyond/&#34;&gt;谷歌矩阵&lt;/a&gt;和&lt;a href=&#34;https://bitjoy.net/posts/2016-08-20-introduction-to-hmm-1/&#34;&gt;HMM中的转移矩阵&lt;/a&gt;都属于随机矩阵，所以随机矩阵也称为概率矩阵、转移矩阵、或马尔可夫矩阵。&lt;/p&gt;
&lt;p&gt;随机矩阵有一个性质，就是其所有特征值的绝对值小于等于1，且其最大特征值为1。下面通过两种方法证明这个结论。&lt;/p&gt;
&lt;p&gt;首先，随机矩阵A肯定有特征值1，即&lt;/p&gt;
$$\begin{equation}A\vec 1=1\times\vec 1\end{equation}$$&lt;p&gt;其中的单位向量\(\vec 1=(\frac{1}{n},…,\frac{1}{n})^T\)，因为A的行和为1，所以上述等式成立。即1是A的特征值。&lt;/p&gt;
&lt;h1 id=&#34;反证法&#34;&gt;&lt;a href=&#34;https://mikespivey.wordpress.com/2013/01/17/eigenvalue-stochasti/&#34;&gt;反证法&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;假设存在大于1的特征值\(\lambda\)，则有\(A\vec x=\lambda\vec x\)。令\(x_k\)是\(\vec x\)中最大的元素。又因为A的元素非负，且行和为1，所以\(\lambda\vec x\)中的每个元素都是\(\vec x\)中元素的凸组合，所以\(\lambda\vec x\)中的每个元素都小于等于\(x_k\)。&lt;/p&gt;
$$\begin{equation}a_{i1}x_1+a_{i2}x_2+…+a_{in}x_n=\lambda x_i\leq x_k\end{equation}$$&lt;p&gt;但是如果\(\lambda&gt;1\)，则\(\lambda x_k&gt;x_k\)，和(2)式矛盾，所以\(\lambda\leq 1\)。又因为(1)式，所以A的最大特征值为1。&lt;/p&gt;
&lt;h1 id=&#34;常规证法&#34;&gt;常规证法&lt;/h1&gt;
&lt;p&gt;设&lt;strong&gt;对称随机矩阵A&lt;/strong&gt;的特征值\(\lambda\)对应的特征向量为\(x\)（为了简便，以下省略向量符号），则有\(Ax=\lambda x\)，即\(x^TAx=\lambda x^Tx\)，欲证明\(|\lambda|\leq 1\)，只需证明&lt;/p&gt;
$$\begin{equation}\lambda=\frac{&lt; x, Ax &gt;}{&lt; x, x &gt;}\leq 1\end{equation}$$&lt;p&gt;根据定义有：&lt;/p&gt;
$$\begin{equation}&lt; x, Ax &gt;=\sum_{i=1}^na_{ii}x_i^2+2\sum_{i &lt; j, i\sim j}a_{ij}x_ix_j\end{equation}$$&lt;p&gt;对于\(i &lt; j, i\sim j\)，有：&lt;/p&gt;
$$\begin{equation}a_{ij}(x_i-x_j)^2=a_{ij}x_i^2-2a_{ij}x_ix_j+a_{ij}x_j^2\end{equation}$$&lt;p&gt;两边求和并移项得到：&lt;/p&gt;
$$
\begin{equation}
\begin{array}
\displaystyle{2\sum_{i &lt; j}}a_{ij}x_ix_j &amp; = &amp; \displaystyle{\sum_{i &lt; j}a_{ij}x_i^2+\sum_{i &lt; j}a_{ij}x_j^2-\sum_{i &lt; j}a_{ij}(x_i-x_j)^2}\\
&amp; = &amp; \displaystyle{\sum_{i &lt; j}a_{ij}x_i^2+\sum_{i &lt; j}a_{ji}x_j^2-\sum_{i &lt; j}a_{ij}(x_i-x_j)^2}\\ &amp; = &amp; \displaystyle{\sum_{i &lt; j}a_{ij}x_i^2+\sum_{i &gt; j}a_{ij}x_i^2-\sum_{i &lt; j}a_{ij}(x_i-x_j)^2}\\
&amp; = &amp; \displaystyle{\sum_i(\sum_{j\neq i}a_{ij}x_i^2)-\sum_{i &lt; j}a_{ij}(x_i-x_j)^2}\\
&amp; = &amp; \displaystyle{\sum_i(x_i^2(1-a_{ii}))-\sum_{i &lt; j}a_{ij}(x_i-x_j)^2}
\end{array}
\end{equation}
$$&lt;p&gt;第2、3个等号都是因为A是对称矩阵，所以可以把\(a_{ij}\)替换为\(a_{ji}\)，然后互换\(i,j\)下标。最后一个等号是因为A的行和为1。&lt;/p&gt;</description>
    </item>
    <item>
      <title>马尔可夫聚类算法</title>
      <link>http://localhost:1313/posts/2016-08-22-the-markov-cluster-algorithm/</link>
      <pubDate>Mon, 22 Aug 2016 18:41:45 +0800</pubDate>
      <guid>http://localhost:1313/posts/2016-08-22-the-markov-cluster-algorithm/</guid>
      <description>&lt;p&gt;马尔可夫聚类算法（The Markov Cluster Algorithm, MCL）是一种快速可扩展的基于图的聚类算法。它的基本思想为：在一个稀疏图G中，如果某个区域A是稠密的（是一个聚类），则在A中随机游走k步，还在A内的概率很大，也就是说，A内的k步路径（k-length path）很多。所以我们可以在图中随机游走k步，如果某个区域连通的概率很大，则该区域是一个聚类。随机游走的下一步只和当前所处节点有关，也就是说这是一个马尔可夫的随机游走过程。&lt;/p&gt;
&lt;p&gt;我们用一个例子来演示马尔可夫聚类算法的过程。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;mcl-1&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/posts/2016-08-22-the-markov-cluster-algorithm/mcl-1.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;上图是一个很小的网络，我们用肉眼大概能看出有三个聚类，分别是左边的{1,6,7,10}，中间的{2,3,5}和右边的{4,8,9,11,12}。我们用MCL看看结果如何。&lt;/p&gt;
&lt;p&gt;为了随机游走，我们常用邻接矩阵来表示图，如果i,j有边，则N[i][j]=1，否则N[i][j]=0。又随机游走可能有自回路，所以加上单位矩阵I，得到矩阵N+I。&lt;/p&gt;
&lt;p&gt;MCL有两个关键的步骤，分别是Expansion和Inflation。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Expansion&lt;/strong&gt;就是不断对矩阵进行幂次运算，相当于随机游走。假设随机游走了2步，则得到如下图的关联矩阵\((N+I)^2\)，第1行第10列为4，说明1到10的2-length path有4条：1→6→10，1→7→10，1→1→10，1→10→10。随机游走k步之后，\((N+I)^k[i][j]\)越大，说明\(i\)和\(j\)之间的连通性越强。&lt;/p&gt;
$$\begin{equation}Expand(M)=M^k\end{equation}$$&lt;p&gt;&lt;img alt=&#34;mcl-2&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/posts/2016-08-22-the-markov-cluster-algorithm/mcl-2.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Inflation&lt;/strong&gt;是为了增强更强的连接，减弱更弱的连接，只有这样才能得到边界比较明确的聚类。MCL的做法是对元素做幂次运算，然后按列归一化，公式为：&lt;/p&gt;
$$\begin{equation}(\Gamma_rM)_{pq}=\frac{(M_{pq})^r}{\sum_{i=1}^k(M_{iq})^r}\end{equation}$$&lt;p&gt;参数经验值是\(k=r=2\)。不断做Expansion和Inflation操作，直到算法收敛，得到若干个聚类。&lt;a href=&#34;http://localhost:1313/posts/2016-08-22-the-markov-cluster-algorithm/mcl-3.pdf&#34;&gt;中间过程请点此查看&lt;/a&gt;，下图为最终结果。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;mcl-4&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/posts/2016-08-22-the-markov-cluster-algorithm/mcl-4.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;从图中可以看出，和1有边的只剩下6,7,10了，所以得到聚类{1,6,7,10}，同理能得到聚类{2,3,5}和{4,8,9,11,12} ，和我们肉眼得到的结果是一致的。&lt;/p&gt;
&lt;p&gt;MCL算法的原理很简单，得到的聚类效果也不错。下面总结一下MCL的算法过程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;给定无向图G，Expansion和Inflation的参数\(k\)和\(r\)&lt;/li&gt;
&lt;li&gt;生成G的邻接矩阵\(N\)&lt;/li&gt;
&lt;li&gt;添加自回路，得到矩阵\(N+I\)&lt;/li&gt;
&lt;li&gt;循环对\(N+I\)做Expansion和Inflation操作，即计算公式(1)和(2)，直到收敛&lt;/li&gt;
&lt;li&gt;根据最终得到的矩阵，进行划分聚类&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;此算法是我在上《生物信息学中的算法设计》课上是学到的，当时觉得这个算法真是神奇，如此简单，但又如此有效，实在高明。查阅文献得知，此为&lt;a href=&#34;http://www.micans.org/mcl/&#34;&gt;Stijn van Dongen的博士论文&lt;/a&gt;，本博客的图片均来自其博士论文，想深入了解图聚类算法，请&lt;a href=&#34;http://micans.org/mcl/lit/svdthesis.pdf.gz&#34;&gt;下载他的论文&lt;/a&gt;。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
