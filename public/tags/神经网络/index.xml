<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>神经网络 on bitJoy</title>
    <link>http://localhost:1313/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</link>
    <description>Recent content in 神经网络 on bitJoy</description>
    <generator>Hugo -- 0.148.2</generator>
    <language>en</language>
    <lastBuildDate>Sun, 07 Apr 2019 18:34:01 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Neural Networks and Deep Learning（四）图解神经网络为什么能拟合任意函数</title>
      <link>http://localhost:1313/posts/2019-04-07-neural-networks-and-deep-learning-4-why-nn-can-compute-any-function/</link>
      <pubDate>Sun, 07 Apr 2019 18:34:01 +0800</pubDate>
      <guid>http://localhost:1313/posts/2019-04-07-neural-networks-and-deep-learning-4-why-nn-can-compute-any-function/</guid>
      <description>&lt;p&gt;我们应该都听说过神经网络强大到能拟合任意一个函数，但细究起来很少有人能论证这个观点，这一章就用通俗易懂的图解方式来证明神经网络为什么能拟合任意一个函数。&lt;/p&gt;
&lt;p&gt;开始介绍之前，有两点需要注意：&lt;/p&gt;
&lt;p&gt;并不是说神经网络可以精确计算任意一个函数&lt;/p&gt;
$$f(x)$$&lt;p&gt;，而是说当隐藏层神经元增加时，可以无限逼近&lt;/p&gt;
$$f(x)$$&lt;p&gt;，比如对于任何一个输入&lt;/p&gt;
$$x$$&lt;p&gt;，网络的输出&lt;/p&gt;
$$g(x)$$&lt;p&gt;和正确值&lt;/p&gt;
$$f(x)$$&lt;p&gt;的差小于某个阈值，&lt;/p&gt;
$$|g(x) – f(x)| &lt; \epsilon$$&lt;p&gt;；
神经网络拟合的是连续函数，而不是那种不连续、离散、急剧变化的函数。
假设给定一个下图的连续函数，函数形式未知，本章将用图解的方式来证明，一个单隐层的神经网络就可以很好的拟合这个未知函数。&lt;/p&gt;
&lt;p&gt;首先，假设我们的隐藏层只有两个神经元，激活函数使用Sigmoid，并且我们暂时只关注上面那个神经元的参数和输出。则通过调整该神经元的&lt;/p&gt;
$$w$$&lt;p&gt;和&lt;/p&gt;
$$b$$&lt;p&gt;，可以得到不同形状的Sigmoid函数形式。&lt;/p&gt;
&lt;p&gt;极端情况下，如果&lt;/p&gt;
$$w$$&lt;p&gt;很大而&lt;/p&gt;
$$b$$&lt;p&gt;很小，则可以用Sigmoid函数模拟阶梯函数：&lt;/p&gt;
&lt;p&gt;如果令&lt;/p&gt;
$$s = -b/w$$&lt;p&gt;，则只用一个&lt;/p&gt;
$$s$$&lt;p&gt;就可以确定Sigmoid的函数图像：&lt;/p&gt;
&lt;p&gt;如果把隐藏层下面那个神经元也考虑进来，并且令隐藏层的两个神经元和输出层的神经元的连接权重互为相反数，则输出层未激活值&lt;/p&gt;
$$z=w_1 a_1 + w_2 a_2$$&lt;p&gt;的函数图像变成了一个神奇的鼓包，这个鼓包就是我们后续拟合任意函数的基本单元。根据严格的函数形式，还可以知道&lt;/p&gt;
$$w_1$$&lt;p&gt;和&lt;/p&gt;
$$w_2$$&lt;p&gt;的绝对值控制着鼓包的高度，&lt;/p&gt;
$$s_1$$&lt;p&gt;和&lt;/p&gt;
$$s_2$$&lt;p&gt;的值控制着鼓包的位置和宽度。大家可以去原始网页上体验一下作者给出的可交互版本，很有意思。&lt;/p&gt;
&lt;p&gt;有了这个基本单元之后，我们可以通过增加隐藏层神经元的个数来增加鼓包的个数，比如再增加一对隐层神经元，可增加一个鼓包。虽然下图的例子中两个鼓包相互独立，但通过调整4个&lt;/p&gt;
$$s$$&lt;p&gt;，可以让两个鼓包相连甚至交错，大家可以去原网页试一试。&lt;/p&gt;
&lt;p&gt;继续增加隐层神经元个数，则可以继续增加鼓包的数量，如下图所示。&lt;/p&gt;
&lt;p&gt;到这里想必大家马上知道了为什么神经网络能拟合任何一个函数了，如果隐层神经元足够多，则右图的小鼓包可以足够密，通过调整每个鼓包的高度，则无穷多个鼓包的顶点连线可以拟合任意一个函数。这和我们求函数积分（函数下方面积）时使用多个小矩形近似是一个道理！&lt;/p&gt;
&lt;p&gt;所以对于本章开头的未知函数，我们通过调整不同鼓包的高度，可以使得小矩形面积之和与真实积分的差在&lt;/p&gt;
$$ \epsilon=0.4$$&lt;p&gt;以内。如果无限增加隐层神经元个数，则可以无限逼近真实值。这就说明神经网络确实可以拟合任意一个函数。&lt;/p&gt;
&lt;p&gt;上述推导稍微需要注意的一点是，右图的输出是未激活函数值&lt;/p&gt;
$$\sum_j w_j a_j$$&lt;p&gt;，而网络真正的输出是激活值&lt;/p&gt;
$$\sigma(\sum_j w_j a_j + b)$$&lt;p&gt;。这没有太大的关系，因为上面已经说明未激活输出能拟合任意函数，激活函数也是一个函数。增加激活函数就要求右图需要拟合激活函数和真实函数的嵌套函数。既然未激活输出能拟合任意函数，肯定能拟合这个嵌套函数&lt;/p&gt;
$$\sigma^{-1} \circ f(x)$$&lt;p&gt;，再用激活函数作用一下&lt;/p&gt;
$$\sigma\circ\sigma^{-1} \circ f(x)$$&lt;p&gt;，激活函数抵消了，正好得到&lt;/p&gt;
$$f(x)$$&lt;p&gt;。&lt;/p&gt;
&lt;p&gt;如果输入是多维，或者输出是多维，都是类似的道理。这就说明神经网络确实可以拟合任意函数，真的很强大哦。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Neural Networks and Deep Learning（三·二）过拟合与正则化</title>
      <link>http://localhost:1313/posts/2019-03-24-neural-networks-and-deep-learning-3-2-overfitting-and-regularization/</link>
      <pubDate>Sun, 24 Mar 2019 12:14:22 +0800</pubDate>
      <guid>http://localhost:1313/posts/2019-03-24-neural-networks-and-deep-learning-3-2-overfitting-and-regularization/</guid>
      <description>&lt;h1 id=&#34;过拟合介绍&#34;&gt;过拟合介绍&lt;/h1&gt;
&lt;p&gt;首先介绍一下神经网络中不同数据集的功能，包括训练集、验证集和测试集。&lt;/p&gt;
&lt;p&gt;训练集是用来训练网络参数的。当觉得在训练集上训练得差不多时，就可以在验证集上进行测试，如果验证集上的性能不好，则需要调整网络结构或者超参数，重新在训练集上训练。所以本质上验证集指导训练过程，也参与了训练和调参。为了防止网络对验证集过拟合，当网络在训练集和验证集上表现都不错时，就可以在测试集上进行测试了。测试集上的性能代表了模型的最终性能。&lt;/p&gt;
&lt;p&gt;当然如果发现网络在测试集上性能不好，可能还会反过来去优化网络，重新训练和验证，这么说测试集最终也变相参与了调优。如果一直这么推下去的话，就没完没了了，所以一般还是认为用验证集对模型进行优化，用测试集对模型性能进行测试。&lt;/p&gt;
&lt;p&gt;过拟合的含义就是网络在训练集上性能很好，但是在验证集（或者测试集）上的性能较差，这说明网络在训练集上训练过头了，对训练集产生了过拟合。为了便于叙述，本文没有验证集，直接使用测试集作为验证集对模型进行调优，所以主要考察网络在训练集和测试集上的性能表现。&lt;/p&gt;
&lt;p&gt;判断网络是否过拟合的方法就是观察网络在训练集和测试集上的accuracy和loss的变化曲线。对于accuracy，如果训练集的accuracy很高接近100%且收敛了，但测试集上的accuracy和训练集上的accuracy相差较大也收敛了（如下图收敛到82%左右），说明网络过拟合了。对于loss，如果训练集的loss一直在下降，但测试集的loss先下降后又上升，也说明网络过拟合了。这两种现象，虽然指标不同，但含义是一样的，即网络在训练集上的性能一直在提高甚至到完美水平，但在测试集上的性能提高到一定水平后不再变化甚至下降了。&lt;/p&gt;
&lt;p&gt;不过下面几张图反应的过拟合epoch时间可能不一样，比如对于测试集上的accuracy，可能在280左右过拟合，但是对于测试集上的loss，在15和280左右都可以认为是过拟合了，尤其是15，loss最低，之后loss反升，可以认为是一个合理的过拟合的点。具体哪个epoch之后过拟合，取决于问题本身关注哪个指标，比如MNIST分类问题，可能关注分类accuracy，所以可重点关注测试集上的accuracy那个图，认为是280左右过拟合，因为200~280的accuracy还一直有提升，虽然提升很有限。&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://i0.wp.com/neuralnetworksanddeeplearning.com/images/overfitting4.png&#34;&gt;&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://i0.wp.com/neuralnetworksanddeeplearning.com/images/overfitting2.png&#34;&gt;&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://i0.wp.com/neuralnetworksanddeeplearning.com/images/overfitting1.png&#34;&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://i0.wp.com/neuralnetworksanddeeplearning.com/images/overfitting3.png&#34;&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;应对过拟合最好的方法就是增加训练数据，如果能把所有可能的数据都收集到，对所有数据产生过拟合，那相当于对所有数据都能预测得很好，那问题本质上已经解决了。&lt;/p&gt;
&lt;p&gt;但是，在实际应用场景中，不可能收集到所有数据，而且数据往往是严重不足的，此时，应对过拟合主要有三种方法：正则化、Dropout和数据增强，下面分别介绍这三个部分。&lt;/p&gt;
&lt;h1 id=&#34;正则化&#34;&gt;正则化&lt;/h1&gt;
&lt;p&gt;正则化的思路就是修改损失函数，使损失函数考虑模型复杂度。考虑正则化的损失函数的通用公式如下：&lt;/p&gt;
$$\begin{eqnarray} C = C_0(w,x,y) + \lambda\Omega(w)\tag{1}\end{eqnarray}$$&lt;p&gt;其中\(C_0\)为原始的没有正则化项的损失函数，比如MSE或者交叉熵损失等，\(\Omega(w)\)表示正则化项，即用来惩罚模型复杂度的，\(\lambda\)表示正则化参数，用来平衡\(C_0\)和\(\Omega(w)\)的重要性。&lt;/p&gt;
&lt;p&gt;正则化又分为L2正则和L1正则，它们很类似，先详细介绍下L2正则。&lt;/p&gt;
&lt;p&gt;举个例子，L2正则化后的损失函数如下：&lt;/p&gt;
$$\begin{eqnarray} C = C_0 + \frac{\lambda}{2n}\sum_w w^2,\tag{2}\end{eqnarray}$$&lt;p&gt;前半部分就是普通的损失函数（比如MSE或者交叉熵损失），后半部分就是L2正则。L2正则是对网络中的所有权重\(w\)求平方和（\(\vec w\)的L2范数，所以叫L2正则），然后除以\(2n\)，其中\(n\)是训练样本数，除以2应该是为了后面求导方便。&lt;/p&gt;
&lt;p&gt;(2)式的直观含义是，\(\min C\)的过程中，我不但希望损失函数本身\(C_0\)足够小，还希望网络的权重\(w\)也比较小，最好不要出现很大的\(w\)。如果\(\lambda\)越大，表示正则化越厉害，对大的\(w\)惩罚越严重。&lt;/p&gt;
&lt;p&gt;加入L2正则后的梯度也很容易计算，如下：&lt;/p&gt;
$$\begin{eqnarray}\frac{\partial C}{\partial w} &amp; = &amp; \frac{\partial C_0}{\partial w} + \frac{\lambda}{n} w \tag{3}\\ \frac{\partial C}{\partial b} &amp; = &amp; \frac{\partial C_0}{\partial b}.\tag{4}\end{eqnarray}$$&lt;p&gt;对应的参数更新公式如下：&lt;/p&gt;
$$\begin{eqnarray}b &amp; \rightarrow &amp; b -\eta \frac{\partial C_0}{\partial b}.\tag{5}\end{eqnarray}$$$$\begin{eqnarray} w &amp; \rightarrow &amp; w-\eta \frac{\partial C_0}{\partial w}-\frac{\eta \lambda}{n} w \tag{6}\\ &amp; = &amp; \left(1-\frac{\eta \lambda}{n}\right) w -\eta \frac{\partial C_0}{\partial w}. \tag{7}\end{eqnarray}$$&lt;p&gt;由(5)可知，偏移量\(b\)的梯度更新和没有正则化时是一样的，因为正则化并没有惩罚\(b\)，这个后面会解释为什么。由(7)可知，对\(w\)的梯度更新和没有正则化时很类似，只不过需要先对\(w\)进行缩放，缩放因子为\(1-\frac{\eta\lambda}{n}\)，因为训练样本\(n\)往往很大，所以缩放因子在(0,1)，即先对\(w\)进行缩小，然后正常梯度下降，这种操作也被称为权值衰减。\(\lambda\)最好根据\(n\)的大小进行调整，如果\(n\)非常大的话，\(\lambda\)最好也大一些，否则权值衰减因子就会很小，正则化效果就不明显。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Neural Networks and Deep Learning（二）BP网络</title>
      <link>http://localhost:1313/posts/2018-12-14-neutral-networks-and-deep-learning-2-bp/</link>
      <pubDate>Fri, 14 Dec 2018 12:18:07 +0800</pubDate>
      <guid>http://localhost:1313/posts/2018-12-14-neutral-networks-and-deep-learning-2-bp/</guid>
      <description>&lt;p&gt;这一讲介绍误差反向传播（backpropagation）网络，简称BP网络。&lt;/p&gt;
&lt;p&gt;以上一讲介绍的MNIST手写数字图片分类问题为研究对象，首先明确输入输出：输入就是一张28×28的手写数字图片，展开后可以表示成一个长度为784的向量；输出可以表示为一个长度为10的one-hot向量，比如输入是一张“3”的图片，则输出向量为(0,0,0,1,0,0,0,0,0,0,0)。&lt;/p&gt;
&lt;p&gt;然后构造一个如下的三层全连接网络。第一层为输入层，包含784个神经元，正好对应输入的一张28×28的图片。第二层为隐藏层，假设隐藏层有15个神经元。第三层为输出层，正好10个神经元，对应该图片的one-hot结果。&lt;/p&gt;
&lt;p&gt;全连接网络表示上一层的每个神经元都和下一层的每个神经元有连接，即每个神经元的输入来自上一层所有神经元的输出，每个神经元的输出连接到下一层的所有神经元。每条连边上都有一个权重w。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://i0.wp.com/neuralnetworksanddeeplearning.com/images/tikz12.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;每个神经元执行的操作非常简单，就是把跟它连接的每个输入乘以边上的权重，然后累加起来。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://i0.wp.com/neuralnetworksanddeeplearning.com/images/tikz0.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;比如上面的一个神经元，它的输出就是：&lt;/p&gt;
$$\begin{eqnarray}\mbox{output} = \left\{ \begin{array}{ll}0 &amp; \mbox{if} \sum_j w_j x_j \leq \mbox{ threshold} \\1 &amp; \mbox{if} \sum_j w_j x_j &gt; \mbox{threshold}\end{array}\right.\tag{1}\end{eqnarray}$$&lt;p&gt;其中的threshold就是该神经元激活的阈值，如果累加值超过threshold，则该神经元被激活，输出为1，否则为0。这就是最原始的感知机网络。感知机网络也可以写成如下的向量形式，用激活阈值b代替threshold，然后移到左边。神经网络中，每条边具有权重w，每个神经元具有激活阈值b。&lt;/p&gt;
$$\begin{eqnarray}\mbox{output} = \left\{ \begin{array}{ll} 0 &amp; \mbox{if } w\cdot x + b \leq 0 \\1 &amp; \mbox{if } w\cdot x + b &gt; 0\end{array}\right.\tag{2}\end{eqnarray}$$&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://upload.wikimedia.org/wikipedia/commons/d/d9/Dirac_distribution_CDF.svg&#34;&gt;
&lt;img loading=&#34;lazy&#34; src=&#34;https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg&#34;&gt;&lt;/p&gt;
&lt;p&gt;但是感知机网络的这种激活方式不够灵活，它在threshold左右有一个突变，如果输入或者某个边上的权重稍微有一点变化，输出结果可能就千差万别了。于是后来人们提出了用sigmoid函数来当激活函数，它在0附近的斜率较大，在两边的斜率较小，能达到和阶梯函数类似的效果，而且函数光滑可导。sigmoid的函数形式如下，其中\(z\equiv w \cdot x + b\)为神经元激活之前的值。&lt;/p&gt;
$$\begin{eqnarray} \sigma(z) \equiv \frac{1}{1+e^{-z}}\tag{3}\end{eqnarray}$$&lt;p&gt;sigmmoid函数还有一个优点就是它的导数很好计算，可以用它本身来表示：&lt;/p&gt;
$$\begin{eqnarray}\sigma&#39;(z)=\sigma(z)(1-\sigma(z))\tag{4}\end{eqnarray}$$&lt;p&gt;BP网络的参数就是所有连线上的权重w和所有神经元中的激活阈值b，如果知道这些参数，给定一个输入x，则可以很容易的通过正向传播（feedforward）的方法计算到输出，即不断的执行\(w \cdot x + b\)操作，然后用sigmoid激活，再把上一层的输出传递给下一层作为输入，直到最后一层。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;
&lt;table style=&#34;border-spacing:0;padding:0;margin:0;border:0;&#34;&gt;&lt;tr&gt;&lt;td style=&#34;vertical-align:top;padding:0;margin:0;border:0;&#34;&gt;
&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code&gt;&lt;span style=&#34;white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;1
&lt;/span&gt;&lt;span style=&#34;white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;2
&lt;/span&gt;&lt;span style=&#34;white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;3
&lt;/span&gt;&lt;span style=&#34;white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;4
&lt;/span&gt;&lt;span style=&#34;white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td style=&#34;vertical-align:top;padding:0;margin:0;border:0;;width:100%&#34;&gt;
&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;feedforward&lt;/span&gt;(self, a):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Return the output of the network if ``a`` is input.&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; b, w &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;biases, self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;weights):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;		a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sigmoid(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dot(w, a)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;b)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; a
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;同时，网络的误差可以用均方误差（mean squared error, MSE）表示，即网络在最后一层的激活值（即网络的输出值）\(a\)和对应训练集输入\(x\)的正确答案\(y(x)\)的差的平方。有\(n\)个输入则误差取平均，\(\dfrac{1}{2}\)是为了后续求导方便。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Neural Networks and Deep Learning（一）MNIST数据集介绍</title>
      <link>http://localhost:1313/posts/2018-11-25-neutral-networks-and-deep-learning-1-mnist-dataset/</link>
      <pubDate>Sun, 25 Nov 2018 11:33:45 +0800</pubDate>
      <guid>http://localhost:1313/posts/2018-11-25-neutral-networks-and-deep-learning-1-mnist-dataset/</guid>
      <description>&lt;p&gt;最近开始学习神经网络和深度学习，使用的是网上教程：&lt;a href=&#34;http://neuralnetworksanddeeplearning.com/&#34;&gt;http://neuralnetworksanddeeplearning.com/&lt;/a&gt;，这是学习心得第一讲，介绍经典的MNIST手写数字图片数据集。&lt;/p&gt;
&lt;p&gt;MNIST（Modified National Institute of Standards and Technology database）数据集改编自美国国家标准与技术研究所收集的更大的NIST数据集，该数据集来自250个不同人手写的数字图片，一半是人口普查局的工作人员，一半是高中生。该数据集包括60000张训练集图片和10000张测试集图片，训练集和测试集都提供了正确答案。每张图片都是28×28=784大小的灰度图片，也就是一个28×28的矩阵，里面每个值是一个像素点，值在[0,1]之间，0表示白色，1表示黑色，(0,1)之间表示不同的灰度。下面是该数据集中的一些手写数字图片，可以有一个感性的认识。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://i0.wp.com/neuralnetworksanddeeplearning.com/images/digits_separate.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;MNIST数据集可以在Yann LeCun的网站上下载到：&lt;a href=&#34;http://yann.lecun.com/exdb/mnist/&#34;&gt;http://yann.lecun.com/exdb/mnist/&lt;/a&gt;，但是他提供的MNIST数据集格式比较复杂，需要自己写代码进行解析。目前很多深度学习框架都自带了MNIST数据集，比较流行的是转换为pkl格式的版本：&lt;a href=&#34;http://deeplearning.net/data/mnist/mnist.pkl.gz&#34;&gt;http://deeplearning.net/data/mnist/mnist.pkl.gz&lt;/a&gt;，该版本把原始的60000张训练集进一步划分成了50000张小训练集和10000张验证集，下面以这个版本为例进行介绍。&lt;/p&gt;
&lt;p&gt;pkl是python内置的一种格式，可以将python的各种数据结构序列化存储到磁盘中，需要时又可以读取并反序列化到内存中。mnist.pkl.gz做了两次操作，先pkl序列化，再gz压缩存储，所以要读取该文件，需要先解压再反序列化，在python3中，读取mnist.pkl.gz的方式如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;
&lt;table style=&#34;border-spacing:0;padding:0;margin:0;border:0;&#34;&gt;&lt;tr&gt;&lt;td style=&#34;vertical-align:top;padding:0;margin:0;border:0;&#34;&gt;
&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code&gt;&lt;span style=&#34;white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;1
&lt;/span&gt;&lt;span style=&#34;white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;2
&lt;/span&gt;&lt;span style=&#34;white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;3
&lt;/span&gt;&lt;span style=&#34;white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;4
&lt;/span&gt;&lt;span style=&#34;white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td style=&#34;vertical-align:top;padding:0;margin:0;border:0;;width:100%&#34;&gt;
&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pickle
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; gzip
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;f &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; gzip&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;open(&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;‘&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;../&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;mnist&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pkl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gz&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;’&lt;/span&gt;, &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;‘&lt;/span&gt;rb&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;’&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;training_data, validation_data, test_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pickle&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load(f, encoding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;’&lt;/span&gt;bytes&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;’&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;f&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;close()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这样就得到了训练集、验证集和测试集。将数据集序列化到文件中的方法也很简单，需要注意的是pickle在序列化和反序列化时有不同的协议，可以用protocol参数进行设置。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;
&lt;table style=&#34;border-spacing:0;padding:0;margin:0;border:0;&#34;&gt;&lt;tr&gt;&lt;td style=&#34;vertical-align:top;padding:0;margin:0;border:0;&#34;&gt;
&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code&gt;&lt;span style=&#34;white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;1
&lt;/span&gt;&lt;span style=&#34;white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;2
&lt;/span&gt;&lt;span style=&#34;white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;3
&lt;/span&gt;&lt;span style=&#34;white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td style=&#34;vertical-align:top;padding:0;margin:0;border:0;;width:100%&#34;&gt;
&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dataset&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[training_data, validation_data, test_data]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;f&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;gzip&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;open(&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;‘&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;../&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;mnist3&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pkl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gz&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;’&lt;/span&gt;,&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;’&lt;/span&gt;wb&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;’&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pickle&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dump(dataset,f,protocol&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;f&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;close()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;我们从mnist.pkl.gz读取到的training_data, validation_data, test_data这三个数据的结构是一样的，每个都是一个二维的tuple。以training_data为例，training_data[0]是训练样本，是一个50000×784的矩阵，表示有50000个训练样本，每个训练样本是一个784的一维数组，784就是把一张28×28的图片展开reshape成的一维数组；training_data[1]是训练样本对应的类标号，大小为50000的一维数组，每个值为0~9中的某个数，表示对应样本的数字标号。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
