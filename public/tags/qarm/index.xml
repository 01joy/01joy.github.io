<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>QARM on bitJoy</title>
    <link>http://localhost:1313/tags/qarm/</link>
    <description>Recent content in QARM on bitJoy</description>
    <generator>Hugo -- 0.148.2</generator>
    <language>en</language>
    <lastBuildDate>Sat, 04 Oct 2025 18:24:40 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/qarm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>论文阅读：QARM: Quantitative Alignment Multi-Modal Recommendation at Kuaishou</title>
      <link>http://localhost:1313/posts/2025-10-04-qarm-paper-reading/</link>
      <pubDate>Sat, 04 Oct 2025 18:24:40 +0800</pubDate>
      <guid>http://localhost:1313/posts/2025-10-04-qarm-paper-reading/</guid>
      <description>&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/posts/2025-10-04-qarm-paper-reading/QARM-paper-cover.png&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;基本信息&#34;&gt;基本信息&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;论文标题：QARM: Quantitative Alignment Multi-Modal Recommendation at Kuaishou&lt;/li&gt;
&lt;li&gt;作者单位：快手&lt;/li&gt;
&lt;li&gt;论文链接：&lt;a href=&#34;https://arxiv.org/pdf/2411.11739&#34;&gt;https://arxiv.org/pdf/2411.11739&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;来源：CIKM 2025&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;motivation论文要解决的问题是什么&#34;&gt;Motivation：论文要解决的问题是什么&lt;/h1&gt;
&lt;p&gt;多模态emb在搜推场景应用时通常采用如下图的两阶段方式，先预训练多模态emb，然后作为一个冻结特征放到搜推模型中。这种方式存在2个问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;表征不对齐&lt;/strong&gt;：多模态emb预训练的任务通常是图片分类或者文本的MLM，和下游搜推任务不对齐&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;表征不更新&lt;/strong&gt;：多模态emb在搜推任务中作为冻结特征，没有更新&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本文的方法就是想要解决上述2个问题。
&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/posts/2025-10-04-qarm-paper-reading/QARM-fig1.png&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;对齐搜推任务的多模态emb预训练&#34;&gt;对齐搜推任务的多模态emb预训练&lt;/h1&gt;
&lt;p&gt;为了解决多模态emb表征不对齐的问题，本文提出的多模态emb预训练任务直接对齐搜推场景，使用U2I和I2I召回模型，挖掘出相似item pair，然后通过对比学习微调多模态大模型。&lt;/p&gt;
&lt;p&gt;具体来说，通过U2I和I2I模型，能够拿到item emb；然后用每一个target item emb去行为流中检索出最相似的商品，作为trigger item emb。&amp;lt;trigger, target&amp;gt;构成一对正样本，然后进行对比学习训练。&lt;/p&gt;
&lt;p&gt;通过召回模型构造的训练样本，和搜推场景的协同信号对齐了，解决了开头提到的第一个问题，即表征不对齐的问题。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/posts/2025-10-04-qarm-paper-reading/QARM-fig3.png&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;semantic-id生产方法&#34;&gt;Semantic id生产方法&lt;/h1&gt;
&lt;p&gt;Semantic id的生产方法如上图右半部分所示，有两种方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;VQ&lt;/strong&gt;：直接圈定一定数量（如N）的item emb作为底池，编号1~N，然后任意来一个item emb，通过对底池emb进行KNN搜索，找出top-k相似商品，假设是(a,b,&amp;hellip;,k)，则VQ编码的semantic id就是(a,b,&amp;hellip;,k)。文中取k=25，感觉挺大的。。。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RQ-Kmeans&lt;/strong&gt;：对圈定的N个item emb不断进行Kmeans聚类、求残差、残差继续Kmeans聚类的过程。文中取迭代次数为L=6，但是没说每次聚到多少个类。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注意：文中的RQ-Kmeans方法和RQ-VAE还不一样，RQ-Kmeans没有训练过程，也没有重构loss，纯粹是每次进行聚类，然后选聚类中心作为码本的过程。文中也没有对比过为啥不用RQ-VAE。&lt;/p&gt;
&lt;p&gt;产出两套semantic id之后，直接在下游排序任务中进行端到端更新，解决开头提到的表征不更新的问题。具体建模方法比较常规，不是本文的重点，略讲。&lt;/p&gt;
&lt;h1 id=&#34;评论&#34;&gt;评论&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;可借鉴
&lt;ul&gt;
&lt;li&gt;多模态emb预训练任务是i2i的，直接和下游搜推任务对齐&lt;/li&gt;
&lt;li&gt;semantic id有两种产出方式，VQ和RQ-Kmeans，尽可能多地保留原始多模态emb的信息&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;可改进
&lt;ul&gt;
&lt;li&gt;多模态emb预训练和下游任务对齐，在2025年不算新鲜事了，常规操作。而且文中i2i的构造过程依赖U2I和I2I召回模型，有外部依赖，不够漂亮&lt;/li&gt;
&lt;li&gt;VQ的方法，k=25这也太长了吧，相当于一个小型行为流了，会导致下游任务的特征处理更复杂&lt;/li&gt;
&lt;li&gt;为什么用RQ-Kmeans而不是RQ-VAE，没有任何说明与对比&lt;/li&gt;
&lt;li&gt;从pretrain emb量化成semantic id的过程中，存在严重的信息丢失，这在&lt;a href=&#34;https://bitjoy.net/posts/2025-10-04-mme-sid-paper-reading/&#34;&gt;Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs&lt;/a&gt;论文中有讨论&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
  </channel>
</rss>
