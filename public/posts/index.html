<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>Posts | bitJoy</title>
<meta name="keywords" content="">
<meta name="description" content="Posts - bitJoy">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:1313/posts/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.36819bea596090d8b48cf10d9831382996197aa7e4fc86f792f7c08c9ca4d23b.css" integrity="sha256-NoGb6llgkNi0jPENmDE4KZYZeqfk/Ib3kvfAjJyk0js=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="http://localhost:1313/posts/index.xml">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
    
    
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>
  MathJax = {
    tex: {
      displayMath: [['\\[', '\\]'], ['$$', '$$']],  
      inlineMath: [['\\(', '\\)']]                  
    },
    loader:{
      load: ['ui/safe']
    },
  };
</script>
    
</head>

<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="bitJoy (Alt + H)">bitJoy</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/categories" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/archives" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/about" title="About">
                    <span>About</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main"> 
<header class="page-header">
  <h1>
    Posts
  </h1>
</header>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">解决Hugo的Giscus评论系统出现URI_TOO_LONG的问题
    </h2>
  </header>
  <div class="entry-content">
    <p>本博客使用的评论系统是Giscus，日常使用没啥问题，但是当博客内容很长的时候，就会出现URI_TOO_LONG的问题：
An error occurred URI_TOO_LONG hkg1:: 例如下面两篇博客：
2017年国庆旅行——郑州、杭州 伪·2018届校招面经 正常Giscus评论 异常Giscus评论 针对这个问题，网上搜URI_TOO_LONG说的都是网页请求的URI太长导致的，但都没找到和Giscus相关的内容。
后来在Giscus的Github Issue里找到一个相同的问题：https://github.com/giscus/giscus/issues/1340，里面一个人提到和Hugo所用的主题有关，另一个人提到和博客的meta name=&#34;description&#34;内容太长有关。但都蜻蜓点水，说的不是很详细，也没有给出一个通用的解决办法。
后来怀疑这个报错可能是在加载Giscus评论系统的时候，发起的URI请求太长有关。因此针对出问题的博客，通过Chrome右键检查，找到Giscus模块出现的URI链接，如下图所示。
光这么看看不出来这个URI的长度，可以把这个URI拷贝出来，粘贴到Word中，你会发现这个URI真的非常非常长，而且包含了完整的博客正文！进一步分析发现是URI中的description字段非常长，包含完整的博客正文。
定位到问题之后，解决办法就很简单了，目标就是如何缩短博客html代码中的description字段长度。这里有很多种方法，最简单的方法就是，在每篇博客的头信息区域，增加自定义配置的description内容，简短一点就行，我就直接复用了博客标题。通过这种方法就缩短了Giscus发起URI中的description字段长度了。
此外，还可以在主题中搜一下meta name=&#34;description&#34;出现的位置，把里面的代码改掉或者注释掉，都能解决这个问题。
</p>
  </div>
  <footer class="entry-footer"><span title='2025-11-09 13:08:18 +0800 CST'>November 9, 2025</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to 解决Hugo的Giscus评论系统出现URI_TOO_LONG的问题" href="http://localhost:1313/posts/2025-11-09-resolve-the-uri-too-long-error-of-giscus-in-hugo/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">论文阅读：Enhancing Embedding Representation Stability in Recommendation Systems with Semantic ID
    </h2>
  </header>
  <div class="entry-content">
    <p>
基本信息 论文标题：Enhancing Embedding Representation Stability in Recommendation Systems with Semantic ID 作者单位：Meta 论文链接：https://arxiv.org/pdf/2504.02137 来源：RecSys 2025 Motivation：论文要解决的问题是什么 搜推广的模型严重依赖于item id embedding的表征质量，但在工业场景下，搜推广的id表征存在如下挑战：
id量级非常大，常常是数十亿甚至是百亿的规模。因此，通常不可能给每个id一个单独的embedding（即文中的individual embedding, IE），IE的成本太高 id分布非常不均匀，马太效应严重。文中统计：0.1%的头部item占据了25%的曝光量；5.5%的腰部item占据了50%的曝光量；94.4%的尾部item只占据了25%的曝光量 id分布漂移严重：搜推广场景中item的变化非常频繁，无时无刻不在发生着新id的产生和旧id的退出，而且不同id存活的时间周期也不尽相同，所以id的准入准出策略很难完美适配所有item 针对上述问题，常见的做法是对item id采用hash然后查emb的方式（即文中的random hash，RH），将所有id hash到一个固定大小的空间，然后查emb。但是RH方式有如下缺点：
存在hash冲突，把不相关的id hash到一个桶里，导致语义混乱，学习效果不佳 无法解决id分布漂移的问题，比如hash到同一个桶的A、B两个id，如果B出现频率变高，则会带偏A的分布，影响了A的效果 无法进行知识共享，例如新出了商品iphone15，iphone15无法共享到老的iphone14的emb知识，iphone15的id emb必须完全重新学习。针对这种情况，作者做了一个更加极端的AA实验，就是copy一个完全相同的商品，只换item id，如果是IE或者RH策略，则新商品由于id emb是随机初始化的，效果不佳，这是id-based的通病 基于前缀n-gram的semantic id表征方法 针对上述问题，作者沿用了semantic id的思路，首先使用内容理解团队产出的文本、图片等多模态emb，然后基于过去3个月的item多模态emb，训练RQ-VAE模型，并产出所有item的semantic id。
上述过程都是常规操作，重点在于如何基于semantic id得到item emb表征。假设semantic id是L层，每层的codebook size是K：
最常规的做法：每层都初始化一个K*d的emb table，每层sid查各自的emb table，然后把L层的sid emb加起来。但是本文完全没有提这种方法，也没有和这种方法比较，非常奇怪。 为了比较，我个人再详细描述下这种常规做法。比如老item A的sid是(c1,c2,c3)；新来一个item B，它的sid是(c1,c2,c4)。用常规方法，A的emb是c1&#43;c2&#43;c3，B的emb是c1&#43;c2&#43;c4。两者c1、c2是可以共享的，所以常规方法也能起到一定的知识共享的效果，共享项有2项：c1、c2。但是因为RQ-VAE的沙漏问题，c2很有可能是沙漏瓶颈，信息量不足。 作者对比了Table 1中的几种方法： Trigram和Fourgram差不多，如果L=3用Trigram、L=4用Fourgram的话，本质上是把L个sid映射成了一个无冲突的int。但是这种方法映射出来的int数量太多了，是\(K^L\)。如果K=1024、L=3，则\(K^L\)就已经超过10亿了，这和直接无冲突的IE方法一样了，而且存在新id无法共享老id学到的知识的问题 All bigrams，就是所有的sid的2-gram。还是上面的例子，A的emb相当于\(c_1c_2&#43;c_2c_3\)，B的emb相当于\(c_1c_2&#43;c_2c_4\)，两者可共享\(c_1c_2\)项，相比于常规方法，虽然共享项数变少了，但粒度更精细了，孰好孰坏未可知。由Table 2可知，All bigrams的效果至少比Trigram和Fourgram好很多了，而且如果层数L越大，可共享项越多 Prefix-ngram（简称Prefix-SID方法），本文提出的新方法，把所有前缀组合成新id查emb，然后所有emb再求和。还是上面的例子，A的emb相当于\(c_1&#43;c_1c_2&#43;c_1c_2c_3&#43;c_2&#43;c_2c_3&#43;c_3\)，B的emb相当于\(c_1&#43;c_1c_2&#43;c_1c_2c_4&#43;c_2&#43;c_2c_4&#43;c_4\)，两者可共享\(c_1, c_1c_2, c_2\)三项，比之前的所有方法可共享的信息都多，而且如果层数L越大，可共享项越多，因此这种方法的效果最好，训练也最稳定 实验结果很丰富，做了很多分析，Prefix-SID方法有如下优势：
相比于IE和RH方法，Prefix-SID方法对中长尾item的提升尤其显著，因为新id和老id的表征有了知识共享 对id分布漂移问题更不敏感：由于电商模型训练时消费数据的顺序是和数据的时间一致的，比如一个月的数据，按照1号、2号、…31号这样的时间先后顺序依次训练，理论上4号的模型在4号的测试集上的效果是最好的。作者做了一个实验，分别用20号和4号的模型都在4号的测试集上进行评测，看看20号的模型指标相比4号降低了多少。作者发现，使用Prefix-SID方法和IE方法，两者的指标降低幅度都差不多，都比较小。首先IE方法由于不存在hash冲突，所以20号的模型仍然能比较好地预测4号的数据；其次，Prefix-SID方法虽然有hash冲突，但是因为冲突的item都是语义相似的，可以进行新老item的知识共享，所以这个冲突反而是好事，对模型效果无影响。但是作者发现RH方法的20号的模型在4号数据上评测指标下降比较多，因为有hash冲突，而且冲突是随机的，20号的分布已经变化很大了，导致在4号数据上效果不佳。Table 4的指标越小越好。 基于Prefix-SID方法虽然也有hash冲突，但是冲突到同一个semantic id的item表征更相似，而RH冲突到同一个桶里的item是完全随机的，相似度差。作者以IE为base，把Prefix-SID和RH都各自都冲突到同一个桶的IE emb提取出来，计算类内相似度和类间相似度，发现基于Prefix-SID的类内相似度方差小，类间距离大，说明Prefix-SID确实能把相似item聚到一起。 评论 可借鉴 基于Prefix-SID方法确实能提高新item和老item的信息共享数量，方法值得借鉴 论文实验分析很丰富 可改进 基于Prefix-SID方法居然没有和最常规的加和方法比较，是本文最大的不足 </p>
  </div>
  <footer class="entry-footer"><span title='2025-10-09 18:17:16 +0800 CST'>October 9, 2025</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to 论文阅读：Enhancing Embedding Representation Stability in Recommendation Systems with Semantic ID" href="http://localhost:1313/posts/2025-10-09-meta-prefix-ngram-sid-paper-reading/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">论文阅读：VL-CLIP: Enhancing Multimodal Recommendations via Visual Grounding and LLM-Augmented CLIP Embeddings
    </h2>
  </header>
  <div class="entry-content">
    <p>
基本信息 论文标题：VL-CLIP: Enhancing Multimodal Recommendations via Visual Grounding and LLM-Augmented CLIP Embeddings 作者单位：沃尔玛 论文链接：https://arxiv.org/pdf/2507.17080 来源：RecSys 2025 Motivation：论文要解决的问题是什么 多模态q2i召回通常使用CLIP的对比学习方式进行训练，在电商场景下存在2个问题：
CLIP这种方式通常是对图片整体的表征，缺乏细粒度的目标检测能力，尤其在电商场景，比如fig1，卖衣服场景，传统CLIP只能识别整张图片是一件T恤，难以关注T恤上的图案等细节特征；另外，电商图片往往存在很多附加背景、道具、模特等元素，会影响主体物体的表征 电商标题、属性等文本描述通常参差不齐，存在错误、堆砌、图文不符等问题，导致CLIP训练时图文对齐效果不佳 VL-CLIP解决方案 针对图片的处理：
将图片和商品类型（product type）输入到开源模型Grounding DINO中，让模型进行目标检测，将可信度超过某个阈值且可信度最高的区域抠出来，输入到CLIP的图像encoder中。通过这步预处理，相当于对电商图片进行了关键主体识别和提取，只提取和商品最相关的主体进行图像表征。文中使用的图像编码器是ViT-B/32。 针对文本的处理：
将商品的类型、标题、描述、性别、年龄等文本描述以及图片本身输入到Summarizer多模态大模型，让大模型产出精简、准确的文本描述\(q_0\) 将\(q_0\)和商品图文信息输入到Evaluator多模态大模型，让大模型对\(q_0\)的质量进行评判，如果\(q_0\)质量很好，则直接输出&lt;STOP&gt;；否则指出\(q_0\)的问题所在，并说明改进方法 如果第2步输出不是&lt;STOP&gt;，则将第2步的输出再输入到Refiner大模型，让大模型根据第2步的结果继续调整并输出更优的文本描述\(q_i\) 不断重复第2、3步，直到输出&lt;STOP&gt;，或者最多重复5遍 将产出的精准的文本描述q输入到CLIP的文本encoder中，文中使用的是BERT系列。产出的emb维度是512 上述Summarizer、Evaluator、Refiner都是VLM，文中使用的是GPT-4o，三个任务的prompt设计参考论文附录Table 9 上述对图片和文本的处理本质上是去噪，提取图片的主体物品、让文本描述更加精准。
产出多模态emb之后，后续的操作就是常规的召回流程了，使用HNSW进行ANN召回。
评论 可借鉴 使用Grounding DINO对图片进行主体识别，值得借鉴 使用VLM对商品标题、描述等文本信息进行去噪，值得借鉴 但如果商品量级很大的话，这两个步骤估计会很耗时 可改进 如果是q2i场景，直接用query文本是不是更真实，更接近搜索日子的真实数据分布？ </p>
  </div>
  <footer class="entry-footer"><span title='2025-10-08 23:31:54 +0800 CST'>October 8, 2025</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to 论文阅读：VL-CLIP: Enhancing Multimodal Recommendations via Visual Grounding and LLM-Augmented CLIP Embeddings" href="http://localhost:1313/posts/2025-10-08-vl-clip-paper-reading/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">论文阅读：Generative Recommendation with Semantic IDs: A Practitioner’s Handbook
    </h2>
  </header>
  <div class="entry-content">
    <p>
基本信息 论文标题：Generative Recommendation with Semantic IDs: A Practitioner’s Handbook 作者单位：Snap 论文链接：https://arxiv.org/pdf/2507.22224 来源：CIKM 2025 这是CIKM 2025的一篇resource文章，比较简单。核心内容是开源了一个基于semantic id的生成式推荐框架GRID，可以很方便地做各种消融对比实验。
主要内容 主要结论如下：
对于semantic id生成算法，简单的RQ-KMeans效果反而是最好的，好于R-VQ和RQ-VAE 生产pretrain emb的LLM模型参数量越大，效果越好，但是提升幅度有限 生产semantic id的codebook size和网络层数并不是越大越好，常规的3层，每层256个id效果反而最好 生成式推荐时，是否需要在用户行为序列基础上增加一个user id，实验发现增加user id效果反而变差，不增加user id效果最好 生成式网络结构encoder-decoder对比decoder-only，发现前者效果更好，因为前者能充分学习到行为序列完整的信息 对行为流进行滑动窗口数据增强能提升模型的泛化能力 当semantic id到item存在映射冲突时，随机选一个item的效果和对冲突item追加一个区分标识（digit），两者效果差不多 在生成式beam search的时候，限制只输出合法semantic id和不增加限制，两者效果差不多 评论 看这篇文章主要是想看看不同semantic id生产方法的对比，发现RQ-KMeans居然比RQ-VAE更好。个人感觉这两个方法效果应该差不多，后者应该更好点才对。首先，RQ-VAE的量化loss本质上和KMeans聚类是一个意思；其次，RQ-VAE还增加了一个重构loss，感觉产出来的semantic id和原始emb的信息损失应该更少。
此外，本文的所有实验都是基于亚马逊的公开数据集，数据量肯定不能和真正的工业数据集相提并论，所以文中很多结论有可能只适用于本文的设定，换一个场景估计结论就变了，所以看看就好。
最后，文中很多结论只写了现象，要是能增加原因分析就好了。
</p>
  </div>
  <footer class="entry-footer"><span title='2025-10-07 12:09:43 +0800 CST'>October 7, 2025</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to 论文阅读：Generative Recommendation with Semantic IDs: A Practitioner’s Handbook" href="http://localhost:1313/posts/2025-10-07-grid-paper-reading/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">论文阅读：Progressive Semantic Residual Quantization for Multimodal-Joint Interest Modeling in Music Recommendation
    </h2>
  </header>
  <div class="entry-content">
    <p>
基本信息 论文标题：Progressive Semantic Residual Quantization for Multimodal-Joint Interest Modeling in Music Recommendation 作者单位：网易云音乐 论文链接：https://arxiv.org/pdf/2508.20359 来源：CIKM 2025 Motivation：论文要解决的问题是什么 多模态emb在搜推的应用方式，通常是先将多模态emb转换成semantic id，然后把semantic id用到搜推模型中，这种方式有如下两个问题：
模态内语义退化：多模态emb转换成semantic id通常使用RQ-VAE或者RQ-KMeans的方法，这种方法在不断残差的过程中，后续残差聚类结果已经不能反映初始emb的聚类效果了。其实就是semantic id的沙漏问题，具体可以看这篇文章，后续有空再分享这个问题。 简单来说，如下图所示，初始有DJ、Rock、Lullaby、Choir四个类，但是对残差emb（即RQ-VAE的第二层）聚类的话，初始的四个类的item就打散了，会聚到不同的簇中，也就是RQ-VAE的后续层的聚类效果已经和初始emb的聚类效果很不一样了，这就是文中说的语义退化问题 模态间建模差异：搜推场景的item通常有多种模态特征，比如文本、图像、音频等，传统方法在多模态融合方面比较简单，不能很好地捕捉多模态之间的关系。 PSRQ生产semantic id 本文是音乐推荐场景，主要用到两种模态：text和audio，分别用百川和MERT提取text和audio的模态emb。
生产semantic id的方法如下图所示：
fig2a是传统的RQ-KMeans的方法，每一层都用上一层的残差进行聚类。如上文所述，由于沙漏问题，会导致后续层次的semantic id存在语义退化问题 fig2b是本文新提出的PSRQ量化方法，在RQ-KMeans基础上，每一层除了有上一层的残差向量，还会concat上初始emb减去残差emb后的向量。这样就能区分出残差相似，但初始emb不同的item了，也就避免了RQ方法的沙漏问题，后续semantic id也能保留初始emb的语义信息。fig1d能看出来第二层semantic id仍然能够反映初始emb的分类效果。 Semantic id在下游的应用方法 如下图所示：
每个item有两套多模态emb：text和audio，但是有三套semantic id，除了text和audio各自产一套semantic id之外，还会把text和audio的emb concat起来，再产一套semantic id，相当于多模态融合的semantic id semantic id的emb在排序模型中随机初始化，然后端到端训练 semantic id在用户建模时，使用DIN模型，query用的是多模态融合的semantic id emb，行为流分别用text和audio的semantic id emb。作者说这种方法既能捕捉到单模态细粒度的信息，又能建模跨模态的交互信息 评论 可借鉴 PSRQ的semantic id生产方法确实很有意思，在每一层都用上原始emb，这样不同簇的item在每一层都能分开，不会出现沙漏问题，使得每一层的semantic id都能保留原始emb的语义聚类信息 产了多套semantic id，单模态semantic id是常规操作；多模态emb concat后也产一套semantic id，是个创新点 用户建模时query用多模态semantic id，行为流用单模态semantic id，也是个创新点，虽然论文说这种方法效果最好，但是有点存疑 论文有个实验结果对比了不同semantic id量化方法的效果，结论是：PSRQ &gt; RQ-KMeans = RQ-VAE &gt; VQ &gt; PQ 可改进 pretrain emb和semantic id的生产都没有对齐协同信号 semantic id在下游应用时直接端到端训练，而没有使用codebook初始化，会不会丢失信息比较多？ 产semantic id的过程中，模态内语义退化的问题，描述了现象，但是没有用定量的指标来说明问题，感觉可以借鉴【论文阅读：Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs】的方法，定量说明后续层的semantic id的聚类效果或者说区分能力相比初始emb已经相差甚远了 fig2b中，第一层的codebook的dim=d，后续层的codebook的dim=2d，那么后续层的残差dim也是2d，那么初始emb怎么和后续的残差emb相减呢，维度对不上啊？我理解可能是这样的，后续层聚类的时候用的是concat的dim=2d的emb，但是算聚类中心的时候只用了残差本身的emb，这样就能解释得通了，但是文中对这部分的细节没有解释。 </p>
  </div>
  <footer class="entry-footer"><span title='2025-10-06 21:01:25 +0800 CST'>October 6, 2025</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to 论文阅读：Progressive Semantic Residual Quantization for Multimodal-Joint Interest Modeling in Music Recommendation" href="http://localhost:1313/posts/2025-10-06-psrq-paper-reading/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">论文阅读：DAS: Dual-Aligned Semantic IDs Empowered Industrial Recommender System
    </h2>
  </header>
  <div class="entry-content">
    <p>
基本信息 论文标题：DAS: Dual-Aligned Semantic IDs Empowered Industrial Recommender System 作者单位：快手 论文链接：https://arxiv.org/pdf/2508.10584 来源：CIKM 2025 Motivation：论文要解决的问题是什么 Semantic id生产时，要么没有和协同信号对齐（fig2(1)），要么是两阶段对齐方式（fig2(2)）：
例如LETTER先生成协同emb，然后和semantic id对齐 或者例如QARM，先协同对齐emb，再生产semantic id 把协同对齐和生产semantic id分成两个阶段，天然有信息损失，不是最优的。本文的目的就是把生产协同emb，以及semantic id的协同对齐放到一个模型中联合训练完成，尽量减少信息损失（fig2(3)）。
主模型 主模型如上图所示，中间的ICDM是user和item的双塔模型，用于学习user和item的协同id-based emb；两边分别是生产user和item的semantic id的量化模型。
中间的ICDM就是经典的召回双塔模型，使用点击样本进行训练，唯一不同的是，在user和item塔都有流行度去偏模块，用于学习user和item的无偏emb，后续user和item的semantic id协同对齐用的也是无偏的emb。
两边分别是user和item的semantic id量化模型，两者比较类似，以item为例：
先把item的各种信息，如title、desc、ocr等信息用文本构造成prompt，输入到LLM，借助LLM的summary和reasoning能力，产出item的详细描述 然后把LLM产出的描述再输入到一个预训练的embedding模型PLM，文中用的是bge m3模型，得到item emb 后续就是标准的RQ-VAE过程了 需要注意的是，上述前两步，分别用到了LLM和PLM两个大模型，而且看图上这两个模型都是freeze的，也就是说并不微调这两个大模型。后续协同对齐用的emb是RQ-VAE重构emb的中间层结果，即图中的item quantized emb。
semantic id的协同对齐方面，有三大类对齐任务：
U2I对齐：量化user emb和协同item emb对齐、量化item emb和协同user emb对齐 U2U和I2I对齐：量化user emb和协同user emb对齐、量化item emb和协同item emb对齐 U2U和I2I的共现对齐：点击相同item的两个量化user emb对齐、同一个user点击的两个item的量化item emb对齐 由于fig3中的协同模型和semantic id模型是联合训练的，总共有3大类loss：
中间的ICDM的双塔召回模型的loss 两边的产semantic id的loss 三个模块的对齐loss 评论 可借鉴 把semantic id的生产和协同信号对齐统一成一阶段的模式，信息损失更少 中间的ICDM模型生产协同emb时进行了去偏，协同对齐的时候用的是去偏的emb，这是其他论文很少提到的 可改进 太复杂了！3个模块，3大类loss，每类loss又有很多个小loss，总loss数量加起来有十多个。。。 任务太多，各种去偏、对齐loss，真的不会互相影响吗？ 中间的ICDM模块有必要吗？我理解ICDM本质是为了训练产出协同emb，但是因为训练样本本身是点击样本，样本本身已经包含了搜推场景的协同信号，也就是ICDM本身没必要存在了，直接用相同的样本训练两边的semantic id量化模型就行了，也能实现在训练semantic id的过程中，完成协同信号的对齐 生产semantic id的emb来自LLM和PLM，但是这两个大模型都是freeze的，如果把这两个模型也sft，效果会不会更好？其实我原本以为的一阶段就是这样的，这也是我在【论文阅读：Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs】中提到的一阶段方法。 </p>
  </div>
  <footer class="entry-footer"><span title='2025-10-05 20:26:43 +0800 CST'>October 5, 2025</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to 论文阅读：DAS: Dual-Aligned Semantic IDs Empowered Industrial Recommender System" href="http://localhost:1313/posts/2025-10-05-das-paper-reading/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">论文阅读：QARM: Quantitative Alignment Multi-Modal Recommendation at Kuaishou
    </h2>
  </header>
  <div class="entry-content">
    <p>
基本信息 论文标题：QARM: Quantitative Alignment Multi-Modal Recommendation at Kuaishou 作者单位：快手 论文链接：https://arxiv.org/pdf/2411.11739 来源：CIKM 2025 Motivation：论文要解决的问题是什么 多模态emb在搜推场景应用时通常采用如下图的两阶段方式，先预训练多模态emb，然后作为一个冻结特征放到搜推模型中。这种方式存在2个问题：
表征不对齐：多模态emb预训练的任务通常是图片分类或者文本的MLM，和下游搜推任务不对齐 表征不更新：多模态emb在搜推任务中作为冻结特征，没有更新 本文的方法就是想要解决上述2个问题。 对齐搜推任务的多模态emb预训练 为了解决多模态emb表征不对齐的问题，本文提出的多模态emb预训练任务直接对齐搜推场景，使用U2I和I2I召回模型，挖掘出相似item pair，然后通过对比学习微调多模态大模型。
具体来说，通过U2I和I2I模型，能够拿到item emb；然后用每一个target item emb去行为流中检索出最相似的商品，作为trigger item emb。&lt;trigger, target&gt;构成一对正样本，然后进行对比学习训练。
通过召回模型构造的训练样本，和搜推场景的协同信号对齐了，解决了开头提到的第一个问题，即表征不对齐的问题。
Semantic id生产方法 Semantic id的生产方法如上图右半部分所示，有两种方式：
VQ：直接圈定一定数量（如N）的item emb作为底池，编号1~N，然后任意来一个item emb，通过对底池emb进行KNN搜索，找出top-k相似商品，假设是(a,b,…,k)，则VQ编码的semantic id就是(a,b,…,k)。文中取k=25，感觉挺大的。。。 RQ-Kmeans：对圈定的N个item emb不断进行Kmeans聚类、求残差、残差继续Kmeans聚类的过程。文中取迭代次数为L=6，但是没说每次聚到多少个类。 注意：文中的RQ-Kmeans方法和RQ-VAE还不一样，RQ-Kmeans没有训练过程，也没有重构loss，纯粹是每次进行聚类，然后选聚类中心作为码本的过程。文中也没有对比过为啥不用RQ-VAE。
产出两套semantic id之后，直接在下游排序任务中进行端到端更新，解决开头提到的表征不更新的问题。具体建模方法比较常规，不是本文的重点，略讲。
评论 可借鉴 多模态emb预训练任务是i2i的，直接和下游搜推任务对齐 semantic id有两种产出方式，VQ和RQ-Kmeans，尽可能多地保留原始多模态emb的信息 可改进 多模态emb预训练和下游任务对齐，在2025年不算新鲜事了，常规操作。而且文中i2i的构造过程依赖U2I和I2I召回模型，有外部依赖，不够漂亮 VQ的方法，k=25这也太长了吧，相当于一个小型行为流了，会导致下游任务的特征处理更复杂 为什么用RQ-Kmeans而不是RQ-VAE，没有任何说明与对比 从pretrain emb量化成semantic id的过程中，存在严重的信息丢失，这在Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs论文中有讨论 </p>
  </div>
  <footer class="entry-footer"><span title='2025-10-04 18:24:40 +0800 CST'>October 4, 2025</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to 论文阅读：QARM: Quantitative Alignment Multi-Modal Recommendation at Kuaishou" href="http://localhost:1313/posts/2025-10-04-qarm-paper-reading/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">论文阅读：Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs
    </h2>
  </header>
  <div class="entry-content">
    <p>
基本信息 论文标题：Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs 作者单位：香港城市大学&amp;腾讯 论文链接：https://arxiv.org/pdf/2509.02017 来源：CIKM 2025 Motivation：论文要解决的问题是什么 LLM4SR的基本范式如下，即用LLM直接来做搜推的范式（这种方式在学术界常见，但在工业界不常见）。由于LLM的输入词表范围是有限的（通常比较小），因此其token emb dim通常比较大，比如2048或者4096；而搜推场景的item量级很大，而且在不断更新，因此工业界经典的id-based的搜推模型的item emb dim通常比较小，比如64或128。经典的id-based的搜推模型能比较好地学习到搜推场景的协同信号，为了让LLM模型也能感知这种信息，LLM4SR范式通常会先预训练一个id-based的经典搜推模型，然后将其中的item id emb通过下图的Linear Projection的映射层，映射到LLM token emb的空间，让LLM也能感知搜推的协同信号。
上述LLM4SR范式存在两个问题：
维度坍缩：id-based训出来的id emb dim比较小（如64），LLM token emb dim比较大（如4096），在由id emb通过Linear Projection映射到toen emb的过程中，虽然64映射到4096空间了，但扩维后的矩阵存在低秩问题，即还是只利用了4096中的64维的空间。
论文中，作者分两种情况进行了分析，如果Linear Projection只是一个线性层的话，通过公式推导能得出上述结论；如果Linear Projection包含非线性变换，作者通过实验分析也发现了维度坍缩的现象。 灾难遗忘：除了使用id-based模型产出的id emb，LLM4SR也常用多模态模型产出item emb表征，然后转换成semantic id输入到LLM4SR中。在这种情况下，产出的semantic id通过会遗忘多模态item emb的信息，导致下游LLM4SR的效果不佳。
论文中，作者用公式9来衡量semantic id保留pretrain多模态emb的信息量。具体来说，如果行为流中的商品序列是{A,B,C,D}，target item是E。使用pretrain多模态emb能计算出E和A~D的相似度，例如相似度&lt;E,A&gt; &gt; &lt;E,B&gt;。如果将pretrain多模态emb转换成semantic id，然后由semantic id恢复出新的A~E的emb之后，再计算E和A~D的相似度，如果仍然有&lt;E,A&gt; &gt; &lt;E,B&gt;，则认为一致（concordant），否则不一致（disconcordant）。这个分析方法挺好的，通过这个指标能估算出转换成semantic id之后，仍然保留原有pretrain多模态emb对搜推场景的序关系的保留程度。 作者发现，转换成semantic id之后，信息只保留了37.14%；进一步，如果semantic id是在下游任务中端到端训练的，则信息只保留了5.5%，也就是说94.5%的pretrain emb的序的信息都丢掉了，也就是灾难遗忘。 Semantic id构建方法 3套emb来源，一套id-based经典搜推模型产出的包含协同信号的emb，另外两套是LLM2CLIP产出的多模态文本和图片emb。作者提到传统CLIP对长文本处理能力较弱，所以升级到LLM2CLIP，能更好地处理长文本。 Semantic id构建方法是经典的RQ-VAE的方法，但有如下两个改进点： 将emb的重构loss由MSE升级成MMD (maximum mean discrepancy)，MSE是计算原始emb和重构emb的欧式距离的误差，而MMD是计算两个分布的diff，实验表明能MMD比MSE能保留更多的pretrain多模态emb信息（即上述公式9），保留44.36% 对量化后的emb做了对齐，因为LLM2CLIP本身进行了图文模态的对齐，所以文中只新增了id emb分别和文本、图片模态的对齐 此外，还有一点论文没提但可能和常规RQ-VAE不同之处，就是原始emb在进行RQ-VAE之前，有一个Encoder升维的操作，在重构loss前对应有一个Decoder降维的操作，而semantic id量化恢复emb是Decoder之前的那个。这一升一降，估计也有助于缓解维度坍缩。 ...</p>
  </div>
  <footer class="entry-footer"><span title='2025-10-04 11:10:11 +0800 CST'>October 4, 2025</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to 论文阅读：Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs" href="http://localhost:1313/posts/2025-10-04-mme-sid-paper-reading/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">公告
    </h2>
  </header>
  <div class="entry-content">
    <p>博客数据恢复中，敬请期待！
测试图片： 测试代码：
1 2 3 4 5 6 7 8 9 10 11 12 13 // Necessary header files for input output functions #include &lt;iostream&gt; using namespace std; // main() function: where the execution of // C&#43;&#43; program begins int main() { // This statement prints &#34;Hello World&#34; cout &lt;&lt; &#34;Hello World&#34;; return 0; } 测试数学公式： This is an inline \(a^*=x-b^*\) equation.
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-08-15 22:03:06 +0800 CST'>August 15, 2025</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to 公告" href="http://localhost:1313/posts/2025-08-15-announcement/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">“蛋白质结构预测”问题描述
    </h2>
  </header>
  <div class="entry-content">
    <p>相信很多学CS的同学之前都没听说过“蛋白质结构预测”这个问题，直到2018年12月初，一则劲爆消息瞬间引爆了CSer的朋友圈，那就是Google Deepmind团队开发的AlphaFold一举拿下当年的CASP比赛冠军，而且远远甩开了第二名。我当时就转载过类似的公众号文章，大家可以阅读并想象当时朋友圈的欢呼声：阿尔法狗再下一城 | 蛋白结构预测AlphaFold大胜传统人类模型。
当时，很多同学也转载过类似的文章，但其实很少有人真正明白“蛋白质结构预测”这个问题是什么，它的难度有多大，CASP是个什么比赛，以及AlphaFold的内部原理是什么。当然，对于这一连串的问题，我当时也是懵逼的。不过自己好歹也是个跟蛋白质有关的PhD，如此热点事件，自然是要关注的。不过之后一直没时间，直到今年相关顶级文章再次爆出，我就借着准备文献讲评的机会了解了相关的知识，在这里跟大家分享一下。
https://upload.wikimedia.org/wikipedia/commons/a/a9/Protein_folding.png
蛋白质结构分为四级，分别是一级结构、二级结构、三级结构和四级结构，下面分别描述。
一级结构 蛋白质的一级结构可以理解为一条线性的字符串，比如MSFIKTFSGKHFYYDKINKDDIVINDIAVSLSNICR。其基本组成单元是一个个的氨基酸，即一个个的字母。氨基酸有单字母表示和三字母表示，为了简洁，本文使用单字母表示，下图的例子是三字母表示。常见的氨基酸只有20种，所以一级结构的字符串通常只包含20种字母，不包含的6种字母是BJOUXZ。
http://oregonstate.edu/instruct/bb450/450material/schedule450s17e.html 本文大部分蛋白质基础知识都来源于此
20种氨基酸的结构符合一个通式，如下图所示，中间的碳原子称为Cα碳原子，表示它处在α位；左边连了一个氨基-NH2，称为N端；右边连了一个羧基-COOH，称为C端。20种不同氨基酸的差别就在于Cα上连接的侧链基团R，具体的差别网上一搜就能查到。 https://upload.wikimedia.org/wikipedia/commons/c/ce/AminoAcidball.svg
20种氨基酸连接的方式为脱水缩合，即一个氨基酸的羧基-COOH和另一个氨基酸的氨基-NH2反应，丢掉一个H2O，形成一个肽键-CO-NH-，如下图所示。丢掉了羧基和氨基的氨基酸被称为氨基酸残基，这个名词很形象，氨基酸缺胳膊少腿，所以变成了“残”基。 二级结构 二级结构就是在一级结构的字符串的基础上，肽链怎样进行盘旋、折叠等变换，形成一种局部的三维结构，这种局部的三维结构通常由氢键支撑。常见的二级结构有α螺旋和β折叠，如下图所示。其中α螺旋的每个残基的-NH的H和临近的第4个残基的-CO的O形成氢键，由此支撑α螺旋的结构稳定性，如下图的箭头所指虚线。β折叠则是两条肽链，平行排列，对应残基的-NH的H和-CO的O形成氢键，由此形成两股β折叠的结构，多股β折叠形成类似手风琴的样子。β折叠分为平行和反平行排列，我们前面介绍到肽段分为N端和C端，如果形成β折叠的两股链都是从N到C（或从C到N），则称为平行排列，否则是反平行排列。每股β折叠都有一个大箭头表示其方向。
细分的话，蛋白质的二级结构总共有8种，包括转角、无规则卷曲等。目前常采用DSSP的分类方法，有些文献会把8种结构粗分为α螺旋、β折叠和转角这三种结构。
由上图可知，蛋白质的二级结构极大的决定了其三级结构（下面介绍），所以有很多工作是研究怎样准确预测蛋白质的二级结构的，即预测每个氨基酸残基处于哪一种二级结构中。形式化表示就是，对于一个蛋白质一级结构字符串\(A_1A_2A_3A_4A_5…\)，输出\(a_1a_2a_3a_4a_5…\)，其中\(a_i\)∈{α螺旋，β折叠，转角}。所以，蛋白质的二级结构是一个端到端的问题，很像机器翻译，目前很多文章都会用深度学习NLP的方法来预测蛋白质的二级结构。
三级结构 简单理解，三级结构就是把多个二级结构拼接到一起，折叠成一个完整的蛋白质三维结构，如下图所示。维持蛋白质三级结构的力比较多样，除了氢键之外，还有二硫键、金属键等。
四级结构 简单理解，四级结构就是多个三级结构分子组合成一个复合物，就是四级结构。
https://en.wikipedia.org/wiki/Protein_quaternary_structure
对于CSer来说，由于四级结构仅仅是多个三级结构组合到一起，我们常说的蛋白质三维结构预测问题，通常是指预测蛋白质的三级结构。问题是，构成蛋白质链的原子非常多，我们怎样形式化描述一条蛋白质的三维结构呢？这还要从最原始的一级结构说起。
蛋白质结构预测问题 前面提到，两个氨基酸通过脱水缩合的方式形成肽键从而连接到一起形成一级结构（本文图四），肽键虽然是单键，但它具有类似双键的特点，即难以旋转（比如羧基中的-C=O键就是双键，无法旋转）。所以，由肽键及周围的6个原子形成了一个固定的肽键平面，这6个原子分别是-C-CO-NH-C-，如下图所示，箭头所指的红色键就是肽键，它周围画出了一个平面，就是肽键平面。
肽键平面的存在极大的简化了蛋白质结构，可以认为这6个原子的相对位置是固定的了！另一方面，跟这个平面相连的左右两个C原子的两个键是单键，所以他们可以旋转，旋转的角度称为扭转角ϕ和ψ，为了更直观的感受肽链的肽键平面和两个扭转角，可以看下面的动画：K0045879-Rotation_around_amide_bonds_in_protein.mp4（来自https://www.sciencephoto.com/media/639617/view）
事实上，扭转角ϕ和ψ并不是在360°范围内随机均匀分布的，1963年就有科学家统计过扭转角ϕ和ψ的分布，他们发现稳定的蛋白质结构的ϕ和ψ通常只分布在一小部分区域，如下图的拉氏图所示，这些区域正好对应了常见的α螺旋和β折叠的结构。
最后，我们还需要介绍一个角度，那就是ω。前面提到，虽然肽键具有双键的特点，难以旋转，但它在少数情况下还是可以旋转的。假设通常情况下，肽键的角度定义为ω=0°，如下图所示，红色的键即为肽键，这种结构的好处是它能让形成肽键的两个残基的侧链R（图中黑色基团）离得尽量的远，这样能保持比较稳定的结构。如果肽键旋转为ω=180°，变为下图的样子，则两个侧链R很靠近，就产生位阻效应，就不稳定，所以这种情况比较少见。但不管怎么说，肽键的扭转角ω也是一个变量因素。
综上所述，对于一条肽链，如果知道每个残基的三个扭转角ϕ、ψ和ω，则可以重构出肽链的主干部分的三维结构，这就像将极坐标转换为直角坐标一样容易。需要提醒的是，本文提到的蛋白质三维结构预测问题，对蛋白质的结构进行了简化，包括：1. 仅预测蛋白质或肽链的主干结构，不考虑侧链R的结构；2. 假设肽链主干中每个键的长度是固定的；3. 不考虑键的角度，比如对于上图的肽键，仅考虑肽键绕肽键轴本身的旋转，不考虑肽键绕着某一端原子的旋转，比如固定左边的蓝色小球，肽键和右边的红色小球旋转出平面了。 下图的肽键平面，详细的标识出了各个相对固定的值。
Figure 8-1 from Fundamentals of Biochemistry
所以，对于CSer来说，蛋白质的三维结构预测问题，就可以看成一个端到端的学习问题，输入是一个字符串，输出是每个字符（残基）对应的三个扭转角ϕ、ψ和ω，问题看起来非常的简洁漂亮。而且，这个问题和NLP中的序列标注、机器翻译等问题很像，所以很多NLP的技术可以用来预测蛋白质的三维结构。下图的插画就是最近发表在Cell Sytems上的一篇用LSTM预测蛋白质三维结构的文章，我会在下一篇博客中和大家分享这篇文章。
https://www.sciencedirect.com/science/article/pii/S2405471219300766?via%3Dihub
有关“蛋白质结构预测”本身的最后一个问题是，为什么能仅仅通过一级结构的序列信息，预测得到其三级结构呢？也就是说蛋白质结构预测这个问题是否可解，如果蛋白质的三级结构还由其他因素决定，那么即使Deeplearning玩出花了，在生物上也是不可行的。所以，每遇到一个新问题，都要自问一下，这个问题从原理上是否可解。对于“蛋白质结构预测”这个问题，最开始也有人进行了类似的自问，得到的答案是可行的：
1965年，安芬森（Anfinsen）基于还原变性的牛胰RNase在不需其他任何物质帮助下，仅通过去除变性剂和还原剂就使其恢复天然结构的实验结果，提出了“多肽链的氨基酸序列包含了形成其热力学上稳定的天然构象所必需的全部信息”的“自组装学说”，随后这个学说又得到一些补充。这些学说表明：氨基酸序列确定其空间构象，从而为蛋白质结构预测提供了可行性。
http://chinaxiv.org/user/download.htm?id=6478
CASP比赛 提到蛋白质三级结构预测，不得不提的是CASP这个比赛。CASP的全称是The Critical Assessment of protein Structure Prediction (CASP)，即蛋白质结构预测的关键评估，被誉为蛋白质结构预测的奥林匹克竞赛。CASP从1994年开始举办，每两年一届，最近的一届是2018年的CASP13。
每一届CASP比赛，都会提供大约100条未知结构的蛋白质序列，让所有参赛者进行结构预测，比赛结束之后，主办方会通过生化方法测定这些蛋白质的三维结构，然后和参赛者预测的结果进行比对，然后给出预测得分。提供的蛋白质序列分为两类：一类序列和PDB数据库中已有结构的序列有相似性，由此可以基于模板预测，准确度比较高，这类算法称为Template-Based Modeling；另一类序列和PDB库已知结构的序列相似度很低，可以认为是全新的蛋白质，因为无法利用已有模板信息，需要进行从头测序（De novo或ab initio或Free Modeling），目前的准确率比较低。参赛选手也分为两组，一组是servers only，即仅允许算法参赛，给定3天的时间；另一组是human and servers，即允许人和算法合作，共同预测蛋白质结构，给定3周的时间。
CASP同时提供多种比赛项目，比如常规的结构预测（Regular targets）、数据辅助预测（Data-Assisted targets）和蛋白质接触面预测（Contact predictions）等，其中数据辅助预测中提供了核磁数据（NMR）、交联数据（XLMS）等，对的，交联数据就是我目前研究的pLink处理的数据。
...</p>
  </div>
  <footer class="entry-footer"><span title='2019-05-25 22:32:54 +0800 CST'>May 25, 2019</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to “蛋白质结构预测”问题描述" href="http://localhost:1313/posts/2019-05-25-introduction-to-protein-structure-prediction/"></a>
</article>
<footer class="page-footer">
  <nav class="pagination">
    <a class="next" href="http://localhost:1313/posts/page/2/">Next&nbsp;2/8&nbsp;»
    </a>
  </nav>
</footer>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">bitJoy</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
