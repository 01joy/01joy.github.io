<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>Posts | bitJoy</title>
<meta name="keywords" content="">
<meta name="description" content="Posts - bitJoy">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:1313/posts/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.36819bea596090d8b48cf10d9831382996197aa7e4fc86f792f7c08c9ca4d23b.css" integrity="sha256-NoGb6llgkNi0jPENmDE4KZYZeqfk/Ib3kvfAjJyk0js=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="http://localhost:1313/posts/index.xml">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
    
    
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>
  MathJax = {
    tex: {
      displayMath: [['\\[', '\\]'], ['$$', '$$']],  
      inlineMath: [['\\(', '\\)']]                  
    },
    loader:{
      load: ['ui/safe']
    },
  };
</script>
    
</head>

<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="bitJoy (Alt + H)">bitJoy</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/categories" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/archives" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/about" title="About">
                    <span>About</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main"> 
<header class="page-header">
  <h1>
    Posts
  </h1>
</header>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">论文阅读：Enhancing Embedding Representation Stability in Recommendation Systems with Semantic ID
    </h2>
  </header>
  <div class="entry-content">
    <p>
基本信息 论文标题：Enhancing Embedding Representation Stability in Recommendation Systems with Semantic ID 作者单位：Meta 论文链接：https://arxiv.org/pdf/2504.02137 来源：RecSys 2025 Motivation：论文要解决的问题是什么 搜推广的模型严重依赖于item id embedding的表征质量，但在工业场景下，搜推广的id表征存在如下挑战：
id量级非常大，常常是数十亿甚至是百亿的规模。因此，通常不可能给每个id一个单独的embedding（即文中的individual embedding, IE），IE的成本太高 id分布非常不均匀，马太效应严重。文中统计：0.1%的头部item占据了25%的曝光量；5.5%的腰部item占据了50%的曝光量；94.4%的尾部item只占据了25%的曝光量 id分布漂移严重：搜推广场景中item的变化非常频繁，无时无刻不在发生着新id的产生和旧id的退出，而且不同id存活的时间周期也不尽相同，所以id的准入准出策略很难完美适配所有item 针对上述问题，常见的做法是对item id采用hash然后查emb的方式（即文中的random hash，RH），将所有id hash到一个固定大小的空间，然后查emb。但是RH方式有如下缺点：
存在hash冲突，把不相关的id hash到一个桶里，导致语义混乱，学习效果不佳 无法解决id分布漂移的问题，比如hash到同一个桶的A、B两个id，如果B出现频率变高，则会带偏A的分布，影响了A的效果 无法进行知识共享，例如新出了商品iphone15，iphone15无法共享到老的iphone14的emb知识，iphone15的id emb必须完全重新学习。针对这种情况，作者做了一个更加极端的AA实验，就是copy一个完全相同的商品，只换item id，如果是IE或者RH策略，则新商品由于id emb是随机初始化的，效果不佳，这是id-based的通病 基于前缀n-gram的semantic id表征方法 针对上述问题，作者沿用了semantic id的思路，首先使用内容理解团队产出的文本、图片等多模态emb，然后基于过去3个月的item多模态emb，训练RQ-VAE模型，并产出所有item的semantic id。
上述过程都是常规操作，重点在于如何基于semantic id得到item emb表征。假设semantic id是L层，每层的codebook size是K：
最常规的做法：每层都初始化一个K*d的emb table，每层sid查各自的emb table，然后把L层的sid emb加起来。但是本文完全没有提这种方法，也没有和这种方法比较，非常奇怪。 为了比较，我个人再详细描述下这种常规做法。比如老item A的sid是(c1,c2,c3)；新来一个item B，它的sid是(c1,c2,c4)。用常规方法，A的emb是c1&#43;c2&#43;c3，B的emb是c1&#43;c2&#43;c4。两者c1、c2是可以共享的，所以常规方法也能起到一定的知识共享的效果，共享项有2项：c1、c2。但是因为RQ-VAE的沙漏问题，c2很有可能是沙漏瓶颈，信息量不足。 作者对比了Table 1中的几种方法： Trigram和Fourgram差不多，如果L=3用Trigram、L=4用Fourgram的话，本质上是把L个sid映射成了一个无冲突的int。但是这种方法映射出来的int数量太多了，是\(K^L\)。如果K=1024、L=3，则\(K^L\)就已经超过10亿了，这和直接无冲突的IE方法一样了，而且存在新id无法共享老id学到的知识的问题 All bigrams，就是所有的sid的2-gram。还是上面的例子，A的emb相当于\(c_1c_2&#43;c_2c_3\)，B的emb相当于\(c_1c_2&#43;c_2c_4\)，两者可共享\(c_1c_2\)项，相比于常规方法，虽然共享项数变少了，但粒度更精细了，孰好孰坏未可知。由Table 2可知，All bigrams的效果至少比Trigram和Fourgram好很多了，而且如果层数L越大，可共享项越多 Prefix-ngram（简称Prefix-SID方法），本文提出的新方法，把所有前缀组合成新id查emb，然后所有emb再求和。还是上面的例子，A的emb相当于\(c_1&#43;c_1c_2&#43;c_1c_2c_3&#43;c_2&#43;c_2c_3&#43;c_3\)，B的emb相当于\(c_1&#43;c_1c_2&#43;c_1c_2c_4&#43;c_2&#43;c_2c_4&#43;c_4\)，两者可共享\(c_1, c_1c_2, c_2\)三项，比之前的所有方法可共享的信息都多，而且如果层数L越大，可共享项越多，因此这种方法的效果最好，训练也最稳定 实验结果很丰富，做了很多分析，Prefix-SID方法有如下优势：
相比于IE和RH方法，Prefix-SID方法对中长尾item的提升尤其显著，因为新id和老id的表征有了知识共享 对id分布漂移问题更不敏感：由于电商模型训练时消费数据的顺序是和数据的时间一致的，比如一个月的数据，按照1号、2号、…31号这样的时间先后顺序依次训练，理论上4号的模型在4号的测试集上的效果是最好的。作者做了一个实验，分别用20号和4号的模型都在4号的测试集上进行评测，看看20号的模型指标相比4号降低了多少。作者发现，使用Prefix-SID方法和IE方法，两者的指标降低幅度都差不多，都比较小。首先IE方法由于不存在hash冲突，所以20号的模型仍然能比较好地预测4号的数据；其次，Prefix-SID方法虽然有hash冲突，但是因为冲突的item都是语义相似的，可以进行新老item的知识共享，所以这个冲突反而是好事，对模型效果无影响。但是作者发现RH方法的20号的模型在4号数据上评测指标下降比较多，因为有hash冲突，而且冲突是随机的，20号的分布已经变化很大了，导致在4号数据上效果不佳。Table 4的指标越小越好。 基于Prefix-SID方法虽然也有hash冲突，但是冲突到同一个semantic id的item表征更相似，而RH冲突到同一个桶里的item是完全随机的，相似度差。作者以IE为base，把Prefix-SID和RH都各自都冲突到同一个桶的IE emb提取出来，计算类内相似度和类间相似度，发现基于Prefix-SID的类内相似度方差小，类间距离大，说明Prefix-SID确实能把相似item聚到一起。 评论 可借鉴 基于Prefix-SID方法确实能提高新item和老item的信息共享数量，方法值得借鉴 论文实验分析很丰富 可改进 基于Prefix-SID方法居然没有和最常规的加和方法比较，是本文最大的不足 </p>
  </div>
  <footer class="entry-footer"><span title='2025-10-09 18:17:16 +0800 CST'>October 9, 2025</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to 论文阅读：Enhancing Embedding Representation Stability in Recommendation Systems with Semantic ID" href="http://localhost:1313/posts/2025-10-09-meta-prefix-ngram-sid-paper-reading/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">论文阅读：VL-CLIP: Enhancing Multimodal Recommendations via Visual Grounding and LLM-Augmented CLIP Embeddings
    </h2>
  </header>
  <div class="entry-content">
    <p>
基本信息 论文标题：VL-CLIP: Enhancing Multimodal Recommendations via Visual Grounding and LLM-Augmented CLIP Embeddings 作者单位：沃尔玛 论文链接：https://arxiv.org/pdf/2507.17080 来源：RecSys 2025 Motivation：论文要解决的问题是什么 多模态q2i召回通常使用CLIP的对比学习方式进行训练，在电商场景下存在2个问题：
CLIP这种方式通常是对图片整体的表征，缺乏细粒度的目标检测能力，尤其在电商场景，比如fig1，卖衣服场景，传统CLIP只能识别整张图片是一件T恤，难以关注T恤上的图案等细节特征；另外，电商图片往往存在很多附加背景、道具、模特等元素，会影响主体物体的表征 电商标题、属性等文本描述通常参差不齐，存在错误、堆砌、图文不符等问题，导致CLIP训练时图文对齐效果不佳 VL-CLIP解决方案 针对图片的处理：
将图片和商品类型（product type）输入到开源模型Grounding DINO中，让模型进行目标检测，将可信度超过某个阈值且可信度最高的区域抠出来，输入到CLIP的图像encoder中。通过这步预处理，相当于对电商图片进行了关键主体识别和提取，只提取和商品最相关的主体进行图像表征。文中使用的图像编码器是ViT-B/32。 针对文本的处理：
将商品的类型、标题、描述、性别、年龄等文本描述以及图片本身输入到Summarizer多模态大模型，让大模型产出精简、准确的文本描述\(q_0\) 将\(q_0\)和商品图文信息输入到Evaluator多模态大模型，让大模型对\(q_0\)的质量进行评判，如果\(q_0\)质量很好，则直接输出&lt;STOP&gt;；否则指出\(q_0\)的问题所在，并说明改进方法 如果第2步输出不是&lt;STOP&gt;，则将第2步的输出再输入到Refiner大模型，让大模型根据第2步的结果继续调整并输出更优的文本描述\(q_i\) 不断重复第2、3步，直到输出&lt;STOP&gt;，或者最多重复5遍 将产出的精准的文本描述q输入到CLIP的文本encoder中，文中使用的是BERT系列。产出的emb维度是512 上述Summarizer、Evaluator、Refiner都是VLM，文中使用的是GPT-4o，三个任务的prompt设计参考论文附录Table 9 上述对图片和文本的处理本质上是去噪，提取图片的主体物品、让文本描述更加精准。
产出多模态emb之后，后续的操作就是常规的召回流程了，使用HNSW进行ANN召回。
评论 可借鉴 使用Grounding DINO对图片进行主体识别，值得借鉴 使用VLM对商品标题、描述等文本信息进行去噪，值得借鉴 但如果商品量级很大的话，这两个步骤估计会很耗时 可改进 如果是q2i场景，直接用query文本是不是更真实，更接近搜索日子的真实数据分布？ </p>
  </div>
  <footer class="entry-footer"><span title='2025-10-08 23:31:54 +0800 CST'>October 8, 2025</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to 论文阅读：VL-CLIP: Enhancing Multimodal Recommendations via Visual Grounding and LLM-Augmented CLIP Embeddings" href="http://localhost:1313/posts/2025-10-08-vl-clip-paper-reading/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">论文阅读：Generative Recommendation with Semantic IDs: A Practitioner’s Handbook
    </h2>
  </header>
  <div class="entry-content">
    <p>
基本信息 论文标题：Generative Recommendation with Semantic IDs: A Practitioner’s Handbook 作者单位：Snap 论文链接：https://arxiv.org/pdf/2507.22224 来源：CIKM 2025 这是CIKM 2025的一篇resource文章，比较简单。核心内容是开源了一个基于semantic id的生成式推荐框架GRID，可以很方便地做各种消融对比实验。
主要内容 主要结论如下：
对于semantic id生成算法，简单的RQ-KMeans效果反而是最好的，好于R-VQ和RQ-VAE 生产pretrain emb的LLM模型参数量越大，效果越好，但是提升幅度有限 生产semantic id的codebook size和网络层数并不是越大越好，常规的3层，每层256个id效果反而最好 生成式推荐时，是否需要在用户行为序列基础上增加一个user id，实验发现增加user id效果反而变差，不增加user id效果最好 生成式网络结构encoder-decoder对比decoder-only，发现前者效果更好，因为前者能充分学习到行为序列完整的信息 对行为流进行滑动窗口数据增强能提升模型的泛化能力 当semantic id到item存在映射冲突时，随机选一个item的效果和对冲突item追加一个区分标识（digit），两者效果差不多 在生成式beam search的时候，限制只输出合法semantic id和不增加限制，两者效果差不多 评论 看这篇文章主要是想看看不同semantic id生产方法的对比，发现RQ-KMeans居然比RQ-VAE更好。个人感觉这两个方法效果应该差不多，后者应该更好点才对。首先，RQ-VAE的量化loss本质上和KMeans聚类是一个意思；其次，RQ-VAE还增加了一个重构loss，感觉产出来的semantic id和原始emb的信息损失应该更少。
此外，本文的所有实验都是基于亚马逊的公开数据集，数据量肯定不能和真正的工业数据集相提并论，所以文中很多结论有可能只适用于本文的设定，换一个场景估计结论就变了，所以看看就好。
最后，文中很多结论只写了现象，要是能增加原因分析就好了。
</p>
  </div>
  <footer class="entry-footer"><span title='2025-10-07 12:09:43 +0800 CST'>October 7, 2025</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to 论文阅读：Generative Recommendation with Semantic IDs: A Practitioner’s Handbook" href="http://localhost:1313/posts/2025-10-07-grid-paper-reading/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">论文阅读：Progressive Semantic Residual Quantization for Multimodal-Joint Interest Modeling in Music Recommendation
    </h2>
  </header>
  <div class="entry-content">
    <p>
基本信息 论文标题：Progressive Semantic Residual Quantization for Multimodal-Joint Interest Modeling in Music Recommendation 作者单位：网易云音乐 论文链接：https://arxiv.org/pdf/2508.20359 来源：CIKM 2025 Motivation：论文要解决的问题是什么 多模态emb在搜推的应用方式，通常是先将多模态emb转换成semantic id，然后把semantic id用到搜推模型中，这种方式有如下两个问题：
模态内语义退化：多模态emb转换成semantic id通常使用RQ-VAE或者RQ-KMeans的方法，这种方法在不断残差的过程中，后续残差聚类结果已经不能反映初始emb的聚类效果了。其实就是semantic id的沙漏问题，具体可以看这篇文章，后续有空再分享这个问题。 简单来说，如下图所示，初始有DJ、Rock、Lullaby、Choir四个类，但是对残差emb（即RQ-VAE的第二层）聚类的话，初始的四个类的item就打散了，会聚到不同的簇中，也就是RQ-VAE的后续层的聚类效果已经和初始emb的聚类效果很不一样了，这就是文中说的语义退化问题 模态间建模差异：搜推场景的item通常有多种模态特征，比如文本、图像、音频等，传统方法在多模态融合方面比较简单，不能很好地捕捉多模态之间的关系。 PSRQ生产semantic id 本文是音乐推荐场景，主要用到两种模态：text和audio，分别用百川和MERT提取text和audio的模态emb。
生产semantic id的方法如下图所示：
fig2a是传统的RQ-KMeans的方法，每一层都用上一层的残差进行聚类。如上文所述，由于沙漏问题，会导致后续层次的semantic id存在语义退化问题 fig2b是本文新提出的PSRQ量化方法，在RQ-KMeans基础上，每一层除了有上一层的残差向量，还会concat上初始emb减去残差emb后的向量。这样就能区分出残差相似，但初始emb不同的item了，也就避免了RQ方法的沙漏问题，后续semantic id也能保留初始emb的语义信息。fig1d能看出来第二层semantic id仍然能够反映初始emb的分类效果。 Semantic id在下游的应用方法 如下图所示：
每个item有两套多模态emb：text和audio，但是有三套semantic id，除了text和audio各自产一套semantic id之外，还会把text和audio的emb concat起来，再产一套semantic id，相当于多模态融合的semantic id semantic id的emb在排序模型中随机初始化，然后端到端训练 semantic id在用户建模时，使用DIN模型，query用的是多模态融合的semantic id emb，行为流分别用text和audio的semantic id emb。作者说这种方法既能捕捉到单模态细粒度的信息，又能建模跨模态的交互信息 评论 可借鉴 PSRQ的semantic id生产方法确实很有意思，在每一层都用上原始emb，这样不同簇的item在每一层都能分开，不会出现沙漏问题，使得每一层的semantic id都能保留原始emb的语义聚类信息 产了多套semantic id，单模态semantic id是常规操作；多模态emb concat后也产一套semantic id，是个创新点 用户建模时query用多模态semantic id，行为流用单模态semantic id，也是个创新点，虽然论文说这种方法效果最好，但是有点存疑 论文有个实验结果对比了不同semantic id量化方法的效果，结论是：PSRQ &gt; RQ-KMeans = RQ-VAE &gt; VQ &gt; PQ 可改进 pretrain emb和semantic id的生产都没有对齐协同信号 semantic id在下游应用时直接端到端训练，而没有使用codebook初始化，会不会丢失信息比较多？ 产semantic id的过程中，模态内语义退化的问题，描述了现象，但是没有用定量的指标来说明问题，感觉可以借鉴【论文阅读：Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs】的方法，定量说明后续层的semantic id的聚类效果或者说区分能力相比初始emb已经相差甚远了 fig2b中，第一层的codebook的dim=d，后续层的codebook的dim=2d，那么后续层的残差dim也是2d，那么初始emb怎么和后续的残差emb相减呢，维度对不上啊？我理解可能是这样的，后续层聚类的时候用的是concat的dim=2d的emb，但是算聚类中心的时候只用了残差本身的emb，这样就能解释得通了，但是文中对这部分的细节没有解释。 </p>
  </div>
  <footer class="entry-footer"><span title='2025-10-06 21:01:25 +0800 CST'>October 6, 2025</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to 论文阅读：Progressive Semantic Residual Quantization for Multimodal-Joint Interest Modeling in Music Recommendation" href="http://localhost:1313/posts/2025-10-06-psrq-paper-reading/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">论文阅读：DAS: Dual-Aligned Semantic IDs Empowered Industrial Recommender System
    </h2>
  </header>
  <div class="entry-content">
    <p>
基本信息 论文标题：DAS: Dual-Aligned Semantic IDs Empowered Industrial Recommender System 作者单位：快手 论文链接：https://arxiv.org/pdf/2508.10584 来源：CIKM 2025 Motivation：论文要解决的问题是什么 Semantic id生产时，要么没有和协同信号对齐（fig2(1)），要么是两阶段对齐方式（fig2(2)）：
例如LETTER先生成协同emb，然后和semantic id对齐 或者例如QARM，先协同对齐emb，再生产semantic id 把协同对齐和生产semantic id分成两个阶段，天然有信息损失，不是最优的。本文的目的就是把生产协同emb，以及semantic id的协同对齐放到一个模型中联合训练完成，尽量减少信息损失（fig2(3)）。
主模型 主模型如上图所示，中间的ICDM是user和item的双塔模型，用于学习user和item的协同id-based emb；两边分别是生产user和item的semantic id的量化模型。
中间的ICDM就是经典的召回双塔模型，使用点击样本进行训练，唯一不同的是，在user和item塔都有流行度去偏模块，用于学习user和item的无偏emb，后续user和item的semantic id协同对齐用的也是无偏的emb。
两边分别是user和item的semantic id量化模型，两者比较类似，以item为例：
先把item的各种信息，如title、desc、ocr等信息用文本构造成prompt，输入到LLM，借助LLM的summary和reasoning能力，产出item的详细描述 然后把LLM产出的描述再输入到一个预训练的embedding模型PLM，文中用的是bge m3模型，得到item emb 后续就是标准的RQ-VAE过程了 需要注意的是，上述前两步，分别用到了LLM和PLM两个大模型，而且看图上这两个模型都是freeze的，也就是说并不微调这两个大模型。后续协同对齐用的emb是RQ-VAE重构emb的中间层结果，即图中的item quantized emb。
semantic id的协同对齐方面，有三大类对齐任务：
U2I对齐：量化user emb和协同item emb对齐、量化item emb和协同user emb对齐 U2U和I2I对齐：量化user emb和协同user emb对齐、量化item emb和协同item emb对齐 U2U和I2I的共现对齐：点击相同item的两个量化user emb对齐、同一个user点击的两个item的量化item emb对齐 由于fig3中的协同模型和semantic id模型是联合训练的，总共有3大类loss：
中间的ICDM的双塔召回模型的loss 两边的产semantic id的loss 三个模块的对齐loss 评论 可借鉴 把semantic id的生产和协同信号对齐统一成一阶段的模式，信息损失更少 中间的ICDM模型生产协同emb时进行了去偏，协同对齐的时候用的是去偏的emb，这是其他论文很少提到的 可改进 太复杂了！3个模块，3大类loss，每类loss又有很多个小loss，总loss数量加起来有十多个。。。 任务太多，各种去偏、对齐loss，真的不会互相影响吗？ 中间的ICDM模块有必要吗？我理解ICDM本质是为了训练产出协同emb，但是因为训练样本本身是点击样本，样本本身已经包含了搜推场景的协同信号，也就是ICDM本身没必要存在了，直接用相同的样本训练两边的semantic id量化模型就行了，也能实现在训练semantic id的过程中，完成协同信号的对齐 生产semantic id的emb来自LLM和PLM，但是这两个大模型都是freeze的，如果把这两个模型也sft，效果会不会更好？其实我原本以为的一阶段就是这样的，这也是我在【论文阅读：Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs】中提到的一阶段方法。 </p>
  </div>
  <footer class="entry-footer"><span title='2025-10-05 20:26:43 +0800 CST'>October 5, 2025</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to 论文阅读：DAS: Dual-Aligned Semantic IDs Empowered Industrial Recommender System" href="http://localhost:1313/posts/2025-10-05-das-paper-reading/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">论文阅读：QARM: Quantitative Alignment Multi-Modal Recommendation at Kuaishou
    </h2>
  </header>
  <div class="entry-content">
    <p>
基本信息 论文标题：QARM: Quantitative Alignment Multi-Modal Recommendation at Kuaishou 作者单位：快手 论文链接：https://arxiv.org/pdf/2411.11739 来源：CIKM 2025 Motivation：论文要解决的问题是什么 多模态emb在搜推场景应用时通常采用如下图的两阶段方式，先预训练多模态emb，然后作为一个冻结特征放到搜推模型中。这种方式存在2个问题：
表征不对齐：多模态emb预训练的任务通常是图片分类或者文本的MLM，和下游搜推任务不对齐 表征不更新：多模态emb在搜推任务中作为冻结特征，没有更新 本文的方法就是想要解决上述2个问题。 对齐搜推任务的多模态emb预训练 为了解决多模态emb表征不对齐的问题，本文提出的多模态emb预训练任务直接对齐搜推场景，使用U2I和I2I召回模型，挖掘出相似item pair，然后通过对比学习微调多模态大模型。
具体来说，通过U2I和I2I模型，能够拿到item emb；然后用每一个target item emb去行为流中检索出最相似的商品，作为trigger item emb。&lt;trigger, target&gt;构成一对正样本，然后进行对比学习训练。
通过召回模型构造的训练样本，和搜推场景的协同信号对齐了，解决了开头提到的第一个问题，即表征不对齐的问题。
Semantic id生产方法 Semantic id的生产方法如上图右半部分所示，有两种方式：
VQ：直接圈定一定数量（如N）的item emb作为底池，编号1~N，然后任意来一个item emb，通过对底池emb进行KNN搜索，找出top-k相似商品，假设是(a,b,…,k)，则VQ编码的semantic id就是(a,b,…,k)。文中取k=25，感觉挺大的。。。 RQ-Kmeans：对圈定的N个item emb不断进行Kmeans聚类、求残差、残差继续Kmeans聚类的过程。文中取迭代次数为L=6，但是没说每次聚到多少个类。 注意：文中的RQ-Kmeans方法和RQ-VAE还不一样，RQ-Kmeans没有训练过程，也没有重构loss，纯粹是每次进行聚类，然后选聚类中心作为码本的过程。文中也没有对比过为啥不用RQ-VAE。
产出两套semantic id之后，直接在下游排序任务中进行端到端更新，解决开头提到的表征不更新的问题。具体建模方法比较常规，不是本文的重点，略讲。
评论 可借鉴 多模态emb预训练任务是i2i的，直接和下游搜推任务对齐 semantic id有两种产出方式，VQ和RQ-Kmeans，尽可能多地保留原始多模态emb的信息 可改进 多模态emb预训练和下游任务对齐，在2025年不算新鲜事了，常规操作。而且文中i2i的构造过程依赖U2I和I2I召回模型，有外部依赖，不够漂亮 VQ的方法，k=25这也太长了吧，相当于一个小型行为流了，会导致下游任务的特征处理更复杂 为什么用RQ-Kmeans而不是RQ-VAE，没有任何说明与对比 从pretrain emb量化成semantic id的过程中，存在严重的信息丢失，这在Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs论文中有讨论 </p>
  </div>
  <footer class="entry-footer"><span title='2025-10-04 18:24:40 +0800 CST'>October 4, 2025</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to 论文阅读：QARM: Quantitative Alignment Multi-Modal Recommendation at Kuaishou" href="http://localhost:1313/posts/2025-10-04-qarm-paper-reading/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">论文阅读：Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs
    </h2>
  </header>
  <div class="entry-content">
    <p>
基本信息 论文标题：Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs 作者单位：香港城市大学&amp;腾讯 论文链接：https://arxiv.org/pdf/2509.02017 来源：CIKM 2025 Motivation：论文要解决的问题是什么 LLM4SR的基本范式如下，即用LLM直接来做搜推的范式（这种方式在学术界常见，但在工业界不常见）。由于LLM的输入词表范围是有限的（通常比较小），因此其token emb dim通常比较大，比如2048或者4096；而搜推场景的item量级很大，而且在不断更新，因此工业界经典的id-based的搜推模型的item emb dim通常比较小，比如64或128。经典的id-based的搜推模型能比较好地学习到搜推场景的协同信号，为了让LLM模型也能感知这种信息，LLM4SR范式通常会先预训练一个id-based的经典搜推模型，然后将其中的item id emb通过下图的Linear Projection的映射层，映射到LLM token emb的空间，让LLM也能感知搜推的协同信号。
上述LLM4SR范式存在两个问题：
维度坍缩：id-based训出来的id emb dim比较小（如64），LLM token emb dim比较大（如4096），在由id emb通过Linear Projection映射到toen emb的过程中，虽然64映射到4096空间了，但扩维后的矩阵存在低秩问题，即还是只利用了4096中的64维的空间。
论文中，作者分两种情况进行了分析，如果Linear Projection只是一个线性层的话，通过公式推导能得出上述结论；如果Linear Projection包含非线性变换，作者通过实验分析也发现了维度坍缩的现象。 灾难遗忘：除了使用id-based模型产出的id emb，LLM4SR也常用多模态模型产出item emb表征，然后转换成semantic id输入到LLM4SR中。在这种情况下，产出的semantic id通过会遗忘多模态item emb的信息，导致下游LLM4SR的效果不佳。
论文中，作者用公式9来衡量semantic id保留pretrain多模态emb的信息量。具体来说，如果行为流中的商品序列是{A,B,C,D}，target item是E。使用pretrain多模态emb能计算出E和A~D的相似度，例如相似度&lt;E,A&gt; &gt; &lt;E,B&gt;。如果将pretrain多模态emb转换成semantic id，然后由semantic id恢复出新的A~E的emb之后，再计算E和A~D的相似度，如果仍然有&lt;E,A&gt; &gt; &lt;E,B&gt;，则认为一致（concordant），否则不一致（disconcordant）。这个分析方法挺好的，通过这个指标能估算出转换成semantic id之后，仍然保留原有pretrain多模态emb对搜推场景的序关系的保留程度。 作者发现，转换成semantic id之后，信息只保留了37.14%；进一步，如果semantic id是在下游任务中端到端训练的，则信息只保留了5.5%，也就是说94.5%的pretrain emb的序的信息都丢掉了，也就是灾难遗忘。 Semantic id构建方法 3套emb来源，一套id-based经典搜推模型产出的包含协同信号的emb，另外两套是LLM2CLIP产出的多模态文本和图片emb。作者提到传统CLIP对长文本处理能力较弱，所以升级到LLM2CLIP，能更好地处理长文本。 Semantic id构建方法是经典的RQ-VAE的方法，但有如下两个改进点： 将emb的重构loss由MSE升级成MMD (maximum mean discrepancy)，MSE是计算原始emb和重构emb的欧式距离的误差，而MMD是计算两个分布的diff，实验表明能MMD比MSE能保留更多的pretrain多模态emb信息（即上述公式9），保留44.36% 对量化后的emb做了对齐，因为LLM2CLIP本身进行了图文模态的对齐，所以文中只新增了id emb分别和文本、图片模态的对齐 此外，还有一点论文没提但可能和常规RQ-VAE不同之处，就是原始emb在进行RQ-VAE之前，有一个Encoder升维的操作，在重构loss前对应有一个Decoder降维的操作，而semantic id量化恢复emb是Decoder之前的那个。这一升一降，估计也有助于缓解维度坍缩。 ...</p>
  </div>
  <footer class="entry-footer"><span title='2025-10-04 11:10:11 +0800 CST'>October 4, 2025</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to 论文阅读：Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs" href="http://localhost:1313/posts/2025-10-04-mme-sid-paper-reading/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">公告
    </h2>
  </header>
  <div class="entry-content">
    <p>博客数据恢复中，敬请期待！
测试图片： 测试代码：
1 2 3 4 5 6 7 8 9 10 11 12 13 // Necessary header files for input output functions #include &lt;iostream&gt; using namespace std; // main() function: where the execution of // C&#43;&#43; program begins int main() { // This statement prints &#34;Hello World&#34; cout &lt;&lt; &#34;Hello World&#34;; return 0; } 测试数学公式： This is an inline \(a^*=x-b^*\) equation.
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-08-15 22:03:06 +0800 CST'>August 15, 2025</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to 公告" href="http://localhost:1313/posts/2025-08-15-announcement/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">初探逻辑回归
    </h2>
  </header>
  <div class="entry-content">
    <p>最近实验室在组织学习NG的机器学习视频，我也跟进了一下。讲到逻辑回归那一课，一直想不明白，逻辑回归到底是怎样分类的？逻辑回归的分类面在哪里？逻辑回归有像SVM的max margin那样清晰的推导过程吗？为什么需要Sigmoid函数？今天就让我们来一窥逻辑回归的始末。
假设有一堆学生样本，为了简单起见，只有两个特征，分别是两门课的分数score1和score2，类标号y表示这个学生是否能被录取。可视化如下图，黑点表示y=1即被录取，红点表示y=0即未被录取，可以看到黑点处在score1和score2都比较高的区域。我们的任务就是给定这些训练样本，需要确定一个分类面来划分这两类数据。
分类面的实质就是$y=\mathbf{w^Tx}&#43;b$，其中$\mathbf{w}$和$\mathbf{x}$都是向量，对应到本例中，展开为$y=w_1x_1&#43;w_2x_2&#43;b$。所以，寻找分类面的过程就是寻找倾斜度$\mathbf{w}$和截距$b$。
因为分类的结果是离散的，只有0或者1，可以用感知机来分类。即
但是怎样找这里的$\mathbf{w}$和$b$使得分类结果最好呢，我们需要定义一个优化的目标函数或者说损失函数。这里只能定义为分类错误的个数，只能一点点挪动超平面来找分类错误最少的超平面了，即只能用暴力枚举的方法来找$\mathbf{w}$和$b$。
另一种方法是令我们的分类面算出来的值和真实标号越接近越好，即最小化误差$(\mathbf{w^Tx^{(i)}}&#43;b-y^{(i)})^2$，然后通过梯度下降求解$\mathbf{w}$和$b$。
但是这会有一个问题，对于上图数据，可以求到一个比较好的分类面，如下左图。但是如果数据中出现了如下右图右边的一个离群点或者噪声，为了最小化这个点的误差，即$(\mathbf{w^Tx^{(i)}}&#43;b-1)^2$，导致分类面往右偏了，这一偏直接导致很多y=1的样本分类错误。所以这种最小化误差的方法对离群点很敏感。
假设分类超平面还是$f(\mathbf{x})=\mathbf{w^Tx}&#43;b$，我们希望的分类效果是这样的：$f(\mathbf{x})=0$是分类面；$f(\mathbf{x})&gt;0$分类为1，且不管$f(\mathbf{x})$多大，都分为1；$f(\mathbf{x})&lt;0$分类为0，且不管$f(\mathbf{x})$多小，都分为0。
因为类标号是离散的{0,1}，所以想到把$f(\mathbf{x})$映射到[0,1]之间，即$g(f(\mathbf{x}))$。为了满足上述条件，$g(f(\mathbf{x}))$需要满足：
$g(0)=0.5$，即在分类面上无法判断类标号是0还是1 当$f(\mathbf{x})&gt;0$时，$g(f(\mathbf{x}))&gt;0.5$ 当$f(\mathbf{x})\rightarrow&#43;\infty$，$g(f(\mathbf{x}))\rightarrow 1$，且$g’(f(\mathbf{x}))\rightarrow 0$，即对于上右图右边的离群点，分类为1，且导数趋近于0，表示对其不敏感 当$f(\mathbf{x})&lt;0$时，$g(f(\mathbf{x}))&lt;0.5$ 当$f(\mathbf{x})\rightarrow-\infty$，$g(f(\mathbf{x}))\rightarrow 0$，且$g’(f(\mathbf{x}))\rightarrow 0$，和第3点类似 满足上述性质的函数之一就是Sigmoid函数，其定义域为$[-\infty,&#43;\infty]$，值域为[0,1]，正好把原始的函数结果$f(\mathbf{x})$映射到了[0,1]，而概率的取值范围正好是[0,1]，所以Sigmoid函数正好可以作为分类为1的概率。
所以逻辑回归最终的形式就是：
$$g(\mathbf{x})=\frac{1}{1&#43;e^{-(\mathbf{w^Tx}&#43;b)}}$$分类面依然还是$f(\mathbf{x})=\mathbf{w^Tx}&#43;b=0$，因为$f(\mathbf{x})=0$时，$g(\mathbf{x})=0.5$，正好满足上述条件1。
Sigmoid函数的另一个优点是，它把原始函数值映射到了概率空间，这样就可以用极大似然的方法求解参数$\mathbf{w}$和$b$。下面用参数$\mathbf{\theta}$代表参数$\mathbf{w}$和$b$，用$h_{\mathbf{\theta}}(\mathbf{x})$代表$g(f(\mathbf{x}))$。则有：
$$P(y=1|\mathbf{x};\mathbf{\theta})=h_{\mathbf{\theta}}(\mathbf{x})$$$$P(y=0|\mathbf{x};\mathbf{\theta})=1-h_{\mathbf{\theta}}(\mathbf{x})$$合并成一个式子就是：
$$P(y|\mathbf{x};\mathbf{\theta})=h_{\mathbf{\theta}}(\mathbf{x})^y(1-h_{\mathbf{\theta}}(\mathbf{x}))^{1-y}$$由于所有样本独立同分布（I.I.D.），似然函数就是
$$L(\mathbf{\theta})=P(\mathbf{y}|X;\mathbf{\theta})=\prod\limits_{i}P(y^{(i)}|\mathbf{x}^{(i)};\mathbf{\theta})=\prod\limits_{i}h_{\mathbf{\theta}}(\mathbf{x}^{(i)})^{y^{(i)}}(1-h_{\mathbf{\theta}}(\mathbf{x}^{(i)}))^{1-y^{(i)}}$$最大化似然的含义就是，在给定样本$X$的情况下，我们想找一个参数$\mathbf{\theta}$，使得观测到类标号$\mathbf{y}$的概率最大。
最大化似然等价于最大化log似然，log展开之后就是：
$$l(\mathbf{\theta})=logL(\mathbf{\theta})=\sum\limits_{i}y^{(i)}logh_{\mathbf{\theta}}(\mathbf{x}^{(i)})&#43;(1-y^{(i)})log(1-h_{\mathbf{\theta}}(\mathbf{x}^{(i)}))$$而很巧的是，最大化log似然，其实等效于最小化log对数损失。对于单个样本，损失为：
$$cost(h_{\theta}(\mathbf{x}),y) = \begin{cases}-log(h_{\theta}(\mathbf{x})) &amp; \text {if y=1} \\ -log(1-h_{\theta}(\mathbf{x})) &amp; \text{if y=0} \end{cases}$$即如果正确类标号是1，但算出来的$h_{\theta}(\mathbf{x})$很接近0的话，则损失$-log(h_{\theta}(\mathbf{x}))$就会很大。类标号为0的情况类似。把这两种情况合成一个式子就是：
$$cost(h_{\theta}(\mathbf{x}),y) = -ylog(h_{\theta}(\mathbf{x})) – (1-y)log(1-h_{\theta}(\mathbf{x}))$$所有样本的损失之和就是：
$$J(\mathbf{\theta})=cost(h_{\theta}(X),\mathbf{y}) = \sum\limits_{i}-y^{(i)}logh_{\mathbf{\theta}}(\mathbf{x}^{(i)})-(1-y^{(i)})log(1-h_{\mathbf{\theta}}(\mathbf{x}^{(i)}))$$所以最大化对数似然$\max l(\mathbf{\theta})$和最小化对数损失$\min J(\mathbf{\theta})$是等效的！最优化求解的方法用梯度下降和牛顿法都可以。
和Sigmoid很像的函数还有很多，比如y=arctan(x)也可以，不过Sigmoid有一个很好的特点，即它的导数可以由自身算出来，$f’(x)=f(x)(1-f(x))$。
传统的逻辑回归只能处理二分类问题，那么怎样将其扩展到解决多分类问题呢？有两种方法，一种方法是建立k个二元分类器，比如类标号有A,B,C，则建立3个二元分类器，分别是1）A和非A；2）B和非B；3）C和非C。训练每个2元分类器时，都对所有的数据重新标号为0或1，这样共需要训练k个二元分类器。
还有一种方法是直接将二元逻辑回归推广到多元回归，即Softmax回归，有关Softmax回归的内容，请参考此博客，非常详细。简单来说，二元逻辑回归的假设函数是：多元Softmax回归的假设函数在形式上有所不同：其中是模型的参数。请注意这一项对概率分布进行归一化，使得所有概率之和为1。
Softmax回归的损失函数如下，其实就是logistic回归损失函数的推广：
二元逻辑回归是多元Softmax回归在k=2时的特例，令k=2并利用Softmax回归参数冗余的特点，可以得到一般形式的二元逻辑回归假设函数，具体可以看原博客。
面对一个多元分类问题，是选择Softmax回归还是k个二元分类器呢，这取决于你的类别之间是否互斥，如果互斥，可以用Softmax回归，否则，请用k个二元分类器。
这就是逻辑回归的理论知识，下一篇博客将介绍逻辑回归在Python中的应用。
参考：
http://www.cnblogs.com/sparkwen/p/3441197.html https://tech.meituan.com/intro_to_logistic_regression.html http://blog.csdn.net/bitcarmanlee/article/details/51165444 http://ufldl.stanford.edu/wiki/index.php/Softmax%E5%9B%9E%E5%BD%92
</p>
  </div>
  <footer class="entry-footer"><span title='2017-11-26 18:54:44 +0800 CST'>November 26, 2017</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to 初探逻辑回归" href="http://localhost:1313/posts/2017-11-26-introduction-to-logistic-regression/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">2017年国庆旅行——郑州、杭州
    </h2>
  </header>
  <div class="entry-content">
    <p>今年国庆假期连着中秋，加起来有8天时间，考虑到上半年忙着找工作，太累了，打算利用这个假期好好放松一下。
一、行程规划 9月份的某个周末，规划好行程，制定了人生第一份独自出游的计划。整个过程只花了一天的时间，包括景点规划、住宿、车票购买。其实9月初就在脑海中规划这个事情，当时想的还是2个人同行，但是中间遇到了一些事情，最终只能一个人出游。一个人的话，不用考虑太多，为了节省路上的时间，全程购买高铁票，唯独从杭州回北京的高铁票没有了，幸运的是利用分流抢票软件抢到了一张硬座。住宿方面，一个人住青旅是再好不过了，既便宜、又可以遇到有意思的驴友。国内正规青旅可以在YHAChina上预定，我就是在这个网站上预定了杭州荷方青年旅社。没有在YHA上注册的青旅，可以通过booking.com预定，booking的优势是预定不收费，入住当天前取消也不收费，很不错，我就是在这个网站上预定了郑州的畅旅太空舱宾馆，不过到店之后老板建议我取消网站上的预定，进行线下支付，可以便宜几块钱。。。
二、郑州半日游 3号到达郑州之后开始下雨，booking上的青旅地址有误，浪费了不少时间才找到宾馆并办理了入住。这个太空舱宾馆是在某个高层小区的6层，由居住房改造而成的，开始我还担心是黑店，要求查证件，毕竟第一次住青旅，还是有点担心。后来陆续来了一些驴友，有俄罗斯帅哥、韩国萌妹，又考察了一下房间和网上的照片是一样的，也就不太担心了。太空舱宾馆在医学院地铁站旁边，楼下有一个永辉超市，地理位置还是很不错的。
办完入住之后已经4点多了，行程单上的郑州大学、河南博物馆肯定是没时间去了。于是去了农科路的一家巴奴火锅店吃火锅，一个人吃火锅心里真不是滋味。
回青旅的路上，需要经过二七广场站，虽然有点晚了，但想着别错过郑州为数不多的景点，就跑出来看了看。二七广场周边都是一些商场，没啥意思，二七纪念塔也已经闭馆了。看着联体双塔造型的二七纪念塔，觉得好奇怪，为什么要建成联体的呢，网上查阅资料才得知，此塔为纪念二七大罢工（也称为京汉铁路工人大罢工）中牺牲的汪胜友、司文德两位烈士，我猜大多数郑州人也不知道吧。
三、少林寺一日游 4号早上6:30起床，7点出门去郑州长途汽车中心站，准备坐大巴前往登封市。无奈天公不作美，还在下雨，汽车中心站在郑州火车站旁边，地铁只能到郑州火车站，前前后后还要步行。所以虽然青旅离中心站不远，但到中心站的时候已经8:15了。
中心站大厅有很多自动售票机，而且可以在线支付，所以快速购买了8:40前往登封的汽车票，票价28元。进站的时候，安检居然不让带水进去，太可恶了，只能把水扔掉。上车之后，磨蹭到9点才发车，到达登封汽车站的时间已经是中午11点了。这个时候，有很多黑车拉客去少林寺景区，需要四五十块钱，在我犹豫的时候，直达少林寺景区的8路公交来了，只要5块钱，所以这里提醒大家，从登封汽车站去少林寺景区，等8路公交是最实惠的。
前往少林寺景区的路上拥堵不堪。将近12点才到达景区门口。买了少林寺景区通票100元（学生票半价，后悔本科的时候没多出去玩玩）。
进入景区之后，跟着人群，先后经过了演武厅、少林寺常住院、塔林。演武厅要2点才上演武术表演，所以略过。少林寺常住院里面就是各种殿，比如大雄宝殿、藏经阁。基本上每个殿里面都会有一个佛像，供游客参拜。说实话，这些殿堂，没有解说，看完也就看完了，并没有留下深刻的印象。
3点钟的时候，做了个明智的选择，乘少林索道去看自然风光了（注意嵩杨索道是去看二祖庵的，还是人文景观）。下了索道，瞬间被眼前的景色惊艳住，由于下雨，山上烟雾缭绕，如临仙境；山涧瀑布飞流直下，哗哗作响；三皇栈道奇峰怪石，好不惊险。本来还想去感受下垂悬雾中的吊桥，由于时间关系只得作罢。
回来的路上，雨过天晴，一扫连日来的阴霾，真是豁然开朗，心情极其舒畅！
返程时没必要先坐8路公交到登封汽车站了，在景区出口右侧有从少林寺直达郑州火车站的大巴，票价30，很方便。
四、杭州半日游 5号早上6点起床，赶8点去杭州的高铁。下午1点多到达杭州，根据导航前往荷方青年旅社。走出定安路地铁口，扑鼻而来的桂花香，甜到心里了，看着周围的白墙黛瓦、花格窗棂，我知道我来到江南了！
入住的杭州荷方青年旅社在清河坊步行街的尽头，所以导航的时候，顺带逛了逛清河坊小吃街。沿街的酒幡和各种幌子瞬间有种回到南宋的感觉。旅舍由二十世纪五六十年代的传统江南风格的四合院民居改建而成，傍山而居。白墙黛瓦，花格窗棂，青石板，柚子树，清爽舒适。
办理好入住之后，根据计划前往浙大紫金港校区。浙大今年120周年校庆，校门口站了两个志愿者，看起来一脸青涩，我问他们浙大的外语学院和计算机学院在哪里，他们说他们是大一新生，不知道这两个学院在哪…真不知道志愿者是干啥的。
浙大紫金港校区里面有个人工湖，叫启真湖，还挺大的，有点类似于北大未名湖，湖里还养殖了黑天鹅，比武大的鉴湖有意思。除此之外，其他的建筑并没有太多的特点，也就是一个正常的学校了。走在校园里，也是满园的桂花飘香，此时好想回到武大。
吃过晚饭之后，听说南山路的夜景不错，于是在南山路上溜达了一圈，权当饭后消食。
五、西湖一日游 西湖很大，为了不错过每一个景点，我在网上查了很多攻略，其中知乎上一个用户的骑行线路深得我心，我是完完全全的根据他给的线路图一个景点一个景点遍历的。虽然清河坊离柳浪闻莺最近，但我还是硬生生先骑车到断桥残雪作为起点，固执可见一斑:-)
另外，吸取了游少林寺看不懂人文景观的教训，这次我提前下载了一个口袋导游APP，该APP可以根据定位自动播放所在景点的介绍，很不错。
漫步在西湖边，给我最大的感受就是舒适、悠闲。依然是熟悉的桂花香，随处可见的荷叶，清风徐来，杨柳依依。若是走累了，坐在湖边的石头上，观鱼逗鱼也别有一番乐趣。
这次环游西湖很有意思的一件事是自己和自己玩定向越野。当我来到第一个景点断桥残雪时，我发现有一个御碑亭和对应的标志碑，上面都写着“断桥残雪”，只不过御碑亭上是康熙、乾隆等皇帝题写的，标志碑是中华人民共和国国务院立的。所以西湖十景的每个景点肯定都有对应的御碑亭和标志碑，我当时就决定，每到一个景点，请路人帮我拍一张和标志碑的合影，一来观景有了目标，二来强迫自己开口说话，和路人搭讪。
由于我是严格按照上面的路线图游完的，没有经过双峰插云和三潭印月，所以只有8张合影。
看着这些照片，我只想说路人和路人的拍照水平差别好大:-) 其实重点不是照片，而是寻找标志碑和找路人拍照的过程。比如雷锋夕照的标志碑并不在雷峰塔脚下，而是要走出雷峰塔，去到旁边的小山丘上才能找到。而柳浪闻莺的标志碑就更难找了，这个公园很大，标志碑的位置很隐蔽，我用百度地图导航来回走了3遍都没找到，最后问了景点的一个售货员才知道，这个标志碑在钱王祠前面，路的内测，需要绕一个很长的弯才能找到。最后当我找到柳浪闻莺的标志碑的时候，天已经黑了，由于位置比较偏僻，几乎没有游客，我等了十分钟，终于等来一个游客，帮我拍了一张合影，我猜80%的游客都未曾找到过这个标志碑。
关于拍照。以前自己不敢也不想麻烦路人帮忙拍照，现在算是勇敢的做出尝试，其实路人是很愿意帮助别人的，当然我找的都是年轻人。有意思的是，在雷峰塔脚下，我看到一个和我一样独自游览雷峰塔的年轻人，想自拍又苦于无人帮助，于是我主动提出帮忙，正好也借机让他帮我拍照。互拍完之后我们就散了，没想到登上雷峰塔塔顶之后，我们又相遇了，一阵欣喜之后，又决定互拍。真是猿粪呀。
环游西湖结束之后，准备找一个特色餐厅吃饭。阿溜说她之前在西湖边的外婆家吃过，挺不错的。外婆家的slogan是“我家就在西湖边”，那就去尝尝地道的外婆菜咯。取完号之后发现前面还有40&#43;桌在等，火爆程度可见一斑。幸好带了kindle，就坐在湖边的长凳上看起了《月亮与六便士》。等到大概8点的时候，终于叫上号了。点了西湖有名的西湖醋鱼和东坡肉，还点了一杯稻花米乳。这大概是我点菜最失败的一次了，西湖醋鱼是草鱼，刺太多，而且有点腥；东坡肉一整块也没完全切开，拿下去重新切了之后，一块块七零八落，观感极差。至于稻花米乳，就是真真正正的稻米磨成的汁，无味。虽然菜不好吃，但没尝试过怎么知道呢，所以秉承“勇于尝试”的精神，我并没有感到太沮丧。
回到清河坊特色街已经晚上10点了，为了挑选纪念品，挨个店进去考察。到最后发现能体现杭州西湖特色的也就是印有西湖十景的冰箱贴了，以后决定每去一个地方都买当地的冰箱贴，争取博士毕业前把工位上的墙贴满。
六、西溪一日游 制定计划的时候，考虑到6号骑行环游西湖肯定会很累，所以决定7号去西溪，乘坐游船转一圈，正好歇歇脚。
西溪湿地很大，分为东、中、西三个部分，中部是生活街区，免费开放的，东西部要收费。门票全价80，船票全价60，电瓶车5元。
我在西溪天堂买好所有的票之后，乘坐电瓶车到天目山路周家村出入口，沿着游船线路，先后游玩了周家村→渔村烟雨→深潭口。
周家村在办火柿节，没什么好玩的。渔村烟雨的花样比较多，主要有三个展厅，第一个展厅演示了西溪当地人养蚕织布的情景；第二个展厅西溪人家展示了西溪当地人家的家具、饮食等风格，诸如灶台、风车、打谷机等都和我老家的很像；第三个展厅表演西溪当地人婚嫁的情景，因为此处陆路不通，迎娶新娘只能乘船，挺有意思的。深潭口有一片养殖珍珠的水域，电影《非诚勿扰》曾在这里取景，除此之外，好像没有什么特别的地方。
西溪游船如下左图所示，十几分钟就能从一个景点到达下一个景点，每经过一个景点，就会在船票上戳一个孔表示你不能再在这个点上船了。下次有机会要试一下右图的摇橹船，哈哈。
西溪湿地公园给我的感觉和西湖是完全不一样的，西湖是美景&#43;人文情怀，是阳春白雪似的美，声名远扬，游人如织；而西溪湿地更多的是江南水乡的体现，是下里巴人的美，更加贴近普通老百姓的生活，游人可能只有西湖的20%？
...</p>
  </div>
  <footer class="entry-footer"><span title='2017-10-08 10:56:16 +0800 CST'>October 8, 2017</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to 2017年国庆旅行——郑州、杭州" href="http://localhost:1313/posts/2017-10-08-2017-solo-travel-in-zhengzhou-and-hangzhou/"></a>
</article>
<footer class="page-footer">
  <nav class="pagination">
    <a class="next" href="http://localhost:1313/posts/page/2/">Next&nbsp;2/6&nbsp;»
    </a>
  </nav>
</footer>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">bitJoy</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
