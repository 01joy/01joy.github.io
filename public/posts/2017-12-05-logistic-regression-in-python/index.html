<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>逻辑回归之Python应用实例 | bitJoy</title>
<meta name="keywords" content="逻辑回归, python, 机器学习">
<meta name="description" content="上一篇博客主要介绍了逻辑回归的理论知识，这篇博客咱们用Python机器学习包sklearn中的LogisticRegression做一个分类的实例。
数据还是学生样本，只有两个特征，分别是两门课的分数score1和score2，类标号y表示这个学生是否能被录取。先上分类效果图：

完整的Python代码如下：


  1
  2
  3
  4
  5
  6
  7
  8
  9
 10
 11
 12
 13
 14
 15
 16
 17
 18
 19
 20
 21
 22
 23
 24
 25
 26
 27
 28
 29
 30
 31
 32
 33
 34
 35
 36
 37
 38
 39
 40
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145


# -*- coding: utf-8 -*-
&#34;&#34;&#34;
Created on Wed Nov 08 17:49:41 2017
 
@author: zhenlin
&#34;&#34;&#34;
 
import numpy as np  
import pandas as pd
from sklearn.cross_validation import train_test_split
from sklearn.linear_model import LogisticRegression
import matplotlib.pyplot as plt
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import classification_report
 
# 1. 构造数据
 
sample_number = 200
 
# 第一个高斯分布参数
mean1 = [0, 4] # 两个维度上的均值
cov1 = [[5, 3], [3, 10]] # 两个维度的协方差矩阵，必须满足对称半正定
 
# 第二个高斯分布参数
mean2 = [7, 5]
cov2 = [[7, 2], [2, 15]]
 
# 从两个二元高斯分布中随机采样数据点
class1_x1, class1_x2 = np.random.multivariate_normal(mean1, cov1, sample_number).T # .T表示转置
class2_x1, class2_x2 = np.random.multivariate_normal(mean2, cov2, sample_number).T
 
# 两个高斯分布对应两个类标号
data = [[class1_x1[i],class1_x2[i],0] for i in range(sample_number)]&#43;[[class2_x1[i],class2_x2[i],1] for i in range(sample_number)]
 
# 填充到pandas中
data = pd.DataFrame(data,columns=[&#39;score1&#39;,&#39;score2&#39;,&#39;result&#39;])
 
score_data = data[[&#39;score1&#39;,&#39;score2&#39;]]
result_data = data[&#39;result&#39;]
 
# 2. 训练模型
 
average_precision = 0 # 平均准确度
iters = 10 # 交叉验证次数
 
for i in xrange(iters):
    # 数据划分，80%用于训练，20%用于预测
    x_train, x_test, y_train, y_test = train_test_split(score_data, result_data, test_size = 0.2)
    # 构造默认逻辑回归模型
    model = LogisticRegression()
    # 训练
    model.fit(x_train, y_train)
    # 预测
    predict_y = model.predict(x_test)
    # 计算测试集上的准确度
    average_precision &#43;= np.mean(predict_y == y_test)
 
average_precision /= iters
  
# 3. 绘制分类面 - 法1
 
x1_min, x1_max = score_data[&#39;score1&#39;].min() - .5, score_data[&#39;score1&#39;].max() &#43; .5
 
def generate_face(prob):
    y = -np.log(1.0 / prob - 1.0)
    n = 500
    x1 = np.linspace(x1_min, x1_max, n)
    # w1x1&#43;w2x2&#43;b=y
    x2 = (-model.coef_[0][0] / float(model.coef_[0][1])) * x1 &#43; (y - model.intercept_) / float(model.coef_[0][1])
    return x1, x2
 
pos_data = data[data[&#39;result&#39;] == 1]
neg_data = data[data[&#39;result&#39;] == 0]
plt.scatter(x = pos_data[&#39;score1&#39;], y = pos_data[&#39;score2&#39;], color = &#39;black&#39;, marker = &#39;o&#39;)
plt.scatter(x = neg_data[&#39;score1&#39;], y = neg_data[&#39;score2&#39;], color = &#39;red&#39;, marker = &#39;*&#39;)
 
face_04_x1, face_04_x2 = generate_face(0.4)
face_05_x1, face_05_x2 = generate_face(0.5)
face_06_x1, face_06_x2 = generate_face(0.6)
 
plt.plot(face_04_x1, face_04_x2)
plt.plot(face_05_x1, face_05_x2)
plt.plot(face_06_x1, face_06_x2)
plt.xlim(score_data[&#39;score1&#39;].min(), score_data[&#39;score1&#39;].max())
plt.ylim(score_data[&#39;score2&#39;].min(), score_data[&#39;score2&#39;].max())
plt.xlabel(&#39;score1&#39;)
plt.ylabel(&#39;score2&#39;)
plt.legend([&#39;prob_threshold = 0.4&#39;, &#39;prob_threshold = 0.5&#39;, &#39;prob_threshold = 0.6&#39;], loc=&#39;center left&#39;, bbox_to_anchor=(1, 0.865))
plt.show()
 
 
# 4. 绘制分类面 - 法2
 
pos_data = data[data[&#39;result&#39;] == 1]
neg_data = data[data[&#39;result&#39;] == 0]
 
h = 0.02
s1_min, s1_max = score_data[&#39;score1&#39;].min() - .5, score_data[&#39;score1&#39;].max() &#43; .5
s2_min, s2_max = score_data[&#39;score2&#39;].min() - .5, score_data[&#39;score2&#39;].max() &#43; .5
 
# 生成s1在[s1_min, s1_max]，且s2在[s2_min, s2_max]的网格数据点
# meshgrid含义参见：http://blog.sciencenet.cn/blog-791749-675394.html
s1, s2 = np.meshgrid(np.arange(s1_min, s1_max, h), np.arange(s2_min, s2_max, h))
# 把两个坐标的值按列拼在一起构成二维数据点
Z = model.predict(np.c_[s1.ravel(), s2.ravel()])
 
# 绘制边界和散点
Z = Z.reshape(s1.shape)
# 坐标点是(s1[i], s2[i])，对应颜色是Z[i]，颜色主题使用plt.cm.Paired
plt.pcolormesh(s1, s2, Z, cmap = plt.cm.Paired)
plt.scatter(x = pos_data[&#39;score1&#39;], y = pos_data[&#39;score2&#39;], color = &#39;black&#39;, marker = &#39;o&#39;)
plt.scatter(x = neg_data[&#39;score1&#39;], y = neg_data[&#39;score2&#39;], color = &#39;red&#39;, marker = &#39;*&#39;)
plt.xlim(s1.min(), s1.max())
plt.ylim(s2.min(), s2.max())
plt.xlabel(&#39;score1&#39;)
plt.ylabel(&#39;score2&#39;)
plt.show()
 
# 5. 评估模型
 
# 对于测试数据，模型输出1的概率
answer = model.predict_proba(x_test)[:,1]
 
# 计算不同概率阈值下的P和R
precision, recall, thresholds = precision_recall_curve(y_test, answer)
 
# prob &gt; 0.5的报告为1
report = answer &gt; 0.5
 
print(classification_report(y_test, report, target_names = [&#39;neg&#39;, &#39;pos&#39;]))
print(&#39;average precision: %f&#39;%average_precision)
 
# 6. 绘制PRC曲线
 
# step阶跃图，在点(recall[i],precision[i])进行跳变
plt.step(recall, precision, color=&#39;b&#39;, alpha=0.2, where=&#39;post&#39;)
# 对PRC下方填充颜色
plt.fill_between(recall, precision, step=&#39;post&#39;, alpha=0.2, color=&#39;b&#39;)
 
plt.xlabel(&#39;Recall&#39;)
plt.ylabel(&#39;Precision&#39;)
plt.ylim([0.0, 1.05])
plt.xlim([0.0, 1.0])
plt.title(&#39;2-class Precision-Recall curve&#39;)
plt.show()


下面将逐模块介绍代码细节，大神可以略过。">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:1313/posts/2017-12-05-logistic-regression-in-python/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.36819bea596090d8b48cf10d9831382996197aa7e4fc86f792f7c08c9ca4d23b.css" integrity="sha256-NoGb6llgkNi0jPENmDE4KZYZeqfk/Ib3kvfAjJyk0js=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/2017-12-05-logistic-regression-in-python/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
    
    
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>
  MathJax = {
    tex: {
      displayMath: [['\\[', '\\]'], ['$$', '$$']],  
      inlineMath: [['\\(', '\\)']]                  
    },
    loader:{
      load: ['ui/safe']
    },
  };
</script>
    
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="bitJoy (Alt + H)">bitJoy</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/categories" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/archives" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/about" title="About">
                    <span>About</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      逻辑回归之Python应用实例
    </h1>
    <div class="post-meta"><span title='2017-12-05 21:20:01 +0800 CST'>December 5, 2017</span>&nbsp;·&nbsp;4 min

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#%e4%b8%80%e6%9e%84%e9%80%a0%e6%95%b0%e6%8d%ae" aria-label="一、构造数据">一、构造数据</a></li>
                <li>
                    <a href="#%e4%ba%8c%e8%ae%ad%e7%bb%83%e6%a8%a1%e5%9e%8b" aria-label="二、训练模型">二、训练模型</a></li>
                <li>
                    <a href="#%e4%b8%89%e7%bb%98%e5%88%b6%e5%88%86%e7%b1%bb%e9%9d%a2%e6%b3%951" aria-label="三、绘制分类面（法1）">三、绘制分类面（法1）</a></li>
                <li>
                    <a href="#%e5%9b%9b%e7%bb%98%e5%88%b6%e5%88%86%e7%b1%bb%e9%9d%a2%e6%b3%952" aria-label="四、绘制分类面（法2）">四、绘制分类面（法2）</a></li>
                <li>
                    <a href="#%e4%ba%94%e8%af%84%e4%bc%b0%e6%a8%a1%e5%9e%8b" aria-label="五、评估模型">五、评估模型</a></li>
                <li>
                    <a href="#%e5%85%ad%e7%bb%98%e5%88%b6prc%e6%9b%b2%e7%ba%bf" aria-label="六、绘制PRC曲线">六、绘制PRC曲线</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>上一篇博客主要介绍了逻辑回归的理论知识，这篇博客咱们用Python机器学习包sklearn中的LogisticRegression做一个分类的实例。</p>
<p>数据还是学生样本，只有两个特征，分别是两门课的分数score1和score2，类标号y表示这个学生是否能被录取。先上分类效果图：</p>
<p><img loading="lazy" src="/posts/2017-12-05-logistic-regression-in-python/lr_face_3.png"></p>
<p>完整的Python代码如下：</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 43
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 44
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 45
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 46
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 47
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 48
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 49
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 50
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 51
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 52
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 53
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 54
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 55
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 56
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 57
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 58
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 59
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 60
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 61
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 62
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 63
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 64
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 65
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 66
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 67
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 68
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 69
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 70
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 71
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 72
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 73
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 74
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 75
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 76
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 77
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 78
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 79
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 80
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 81
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 82
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 83
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 84
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 85
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 86
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 87
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 88
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 89
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 90
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 91
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 92
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 93
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 94
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 95
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 96
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 97
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 98
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 99
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">100
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">101
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">102
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">103
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">104
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">105
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">106
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">107
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">108
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">109
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">110
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">111
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">112
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">113
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">114
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">115
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">116
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">117
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">118
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">119
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">120
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">121
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">122
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">123
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">124
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">125
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">126
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">127
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">128
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">129
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">130
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">131
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">132
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">133
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">134
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">135
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">136
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">137
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">138
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">139
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">140
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">141
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">142
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">143
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">144
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">145
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># -*- coding: utf-8 -*-</span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">Created on Wed Nov 08 17:49:41 2017
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74"> 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">@author: zhenlin
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np  
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.cross_validation <span style="color:#f92672">import</span> train_test_split
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.linear_model <span style="color:#f92672">import</span> LogisticRegression
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> precision_recall_curve
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> classification_report
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 1. 构造数据</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>sample_number <span style="color:#f92672">=</span> <span style="color:#ae81ff">200</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 第一个高斯分布参数</span>
</span></span><span style="display:flex;"><span>mean1 <span style="color:#f92672">=</span> [<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">4</span>] <span style="color:#75715e"># 两个维度上的均值</span>
</span></span><span style="display:flex;"><span>cov1 <span style="color:#f92672">=</span> [[<span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">3</span>], [<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">10</span>]] <span style="color:#75715e"># 两个维度的协方差矩阵，必须满足对称半正定</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 第二个高斯分布参数</span>
</span></span><span style="display:flex;"><span>mean2 <span style="color:#f92672">=</span> [<span style="color:#ae81ff">7</span>, <span style="color:#ae81ff">5</span>]
</span></span><span style="display:flex;"><span>cov2 <span style="color:#f92672">=</span> [[<span style="color:#ae81ff">7</span>, <span style="color:#ae81ff">2</span>], [<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">15</span>]]
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 从两个二元高斯分布中随机采样数据点</span>
</span></span><span style="display:flex;"><span>class1_x1, class1_x2 <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>multivariate_normal(mean1, cov1, sample_number)<span style="color:#f92672">.</span>T <span style="color:#75715e"># .T表示转置</span>
</span></span><span style="display:flex;"><span>class2_x1, class2_x2 <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>multivariate_normal(mean2, cov2, sample_number)<span style="color:#f92672">.</span>T
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 两个高斯分布对应两个类标号</span>
</span></span><span style="display:flex;"><span>data <span style="color:#f92672">=</span> [[class1_x1[i],class1_x2[i],<span style="color:#ae81ff">0</span>] <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(sample_number)]<span style="color:#f92672">+</span>[[class2_x1[i],class2_x2[i],<span style="color:#ae81ff">1</span>] <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(sample_number)]
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 填充到pandas中</span>
</span></span><span style="display:flex;"><span>data <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(data,columns<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;score1&#39;</span>,<span style="color:#e6db74">&#39;score2&#39;</span>,<span style="color:#e6db74">&#39;result&#39;</span>])
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>score_data <span style="color:#f92672">=</span> data[[<span style="color:#e6db74">&#39;score1&#39;</span>,<span style="color:#e6db74">&#39;score2&#39;</span>]]
</span></span><span style="display:flex;"><span>result_data <span style="color:#f92672">=</span> data[<span style="color:#e6db74">&#39;result&#39;</span>]
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 2. 训练模型</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>average_precision <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span> <span style="color:#75715e"># 平均准确度</span>
</span></span><span style="display:flex;"><span>iters <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span> <span style="color:#75715e"># 交叉验证次数</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> xrange(iters):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 数据划分，80%用于训练，20%用于预测</span>
</span></span><span style="display:flex;"><span>    x_train, x_test, y_train, y_test <span style="color:#f92672">=</span> train_test_split(score_data, result_data, test_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.2</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 构造默认逻辑回归模型</span>
</span></span><span style="display:flex;"><span>    model <span style="color:#f92672">=</span> LogisticRegression()
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 训练</span>
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>fit(x_train, y_train)
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 预测</span>
</span></span><span style="display:flex;"><span>    predict_y <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>predict(x_test)
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 计算测试集上的准确度</span>
</span></span><span style="display:flex;"><span>    average_precision <span style="color:#f92672">+=</span> np<span style="color:#f92672">.</span>mean(predict_y <span style="color:#f92672">==</span> y_test)
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>average_precision <span style="color:#f92672">/=</span> iters
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 3. 绘制分类面 - 法1</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>x1_min, x1_max <span style="color:#f92672">=</span> score_data[<span style="color:#e6db74">&#39;score1&#39;</span>]<span style="color:#f92672">.</span>min() <span style="color:#f92672">-</span> <span style="color:#ae81ff">.5</span>, score_data[<span style="color:#e6db74">&#39;score1&#39;</span>]<span style="color:#f92672">.</span>max() <span style="color:#f92672">+</span> <span style="color:#ae81ff">.5</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">generate_face</span>(prob):
</span></span><span style="display:flex;"><span>    y <span style="color:#f92672">=</span> <span style="color:#f92672">-</span>np<span style="color:#f92672">.</span>log(<span style="color:#ae81ff">1.0</span> <span style="color:#f92672">/</span> prob <span style="color:#f92672">-</span> <span style="color:#ae81ff">1.0</span>)
</span></span><span style="display:flex;"><span>    n <span style="color:#f92672">=</span> <span style="color:#ae81ff">500</span>
</span></span><span style="display:flex;"><span>    x1 <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>linspace(x1_min, x1_max, n)
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># w1x1+w2x2+b=y</span>
</span></span><span style="display:flex;"><span>    x2 <span style="color:#f92672">=</span> (<span style="color:#f92672">-</span>model<span style="color:#f92672">.</span>coef_[<span style="color:#ae81ff">0</span>][<span style="color:#ae81ff">0</span>] <span style="color:#f92672">/</span> float(model<span style="color:#f92672">.</span>coef_[<span style="color:#ae81ff">0</span>][<span style="color:#ae81ff">1</span>])) <span style="color:#f92672">*</span> x1 <span style="color:#f92672">+</span> (y <span style="color:#f92672">-</span> model<span style="color:#f92672">.</span>intercept_) <span style="color:#f92672">/</span> float(model<span style="color:#f92672">.</span>coef_[<span style="color:#ae81ff">0</span>][<span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> x1, x2
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>pos_data <span style="color:#f92672">=</span> data[data[<span style="color:#e6db74">&#39;result&#39;</span>] <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>neg_data <span style="color:#f92672">=</span> data[data[<span style="color:#e6db74">&#39;result&#39;</span>] <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>scatter(x <span style="color:#f92672">=</span> pos_data[<span style="color:#e6db74">&#39;score1&#39;</span>], y <span style="color:#f92672">=</span> pos_data[<span style="color:#e6db74">&#39;score2&#39;</span>], color <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;black&#39;</span>, marker <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;o&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>scatter(x <span style="color:#f92672">=</span> neg_data[<span style="color:#e6db74">&#39;score1&#39;</span>], y <span style="color:#f92672">=</span> neg_data[<span style="color:#e6db74">&#39;score2&#39;</span>], color <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;red&#39;</span>, marker <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;*&#39;</span>)
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>face_04_x1, face_04_x2 <span style="color:#f92672">=</span> generate_face(<span style="color:#ae81ff">0.4</span>)
</span></span><span style="display:flex;"><span>face_05_x1, face_05_x2 <span style="color:#f92672">=</span> generate_face(<span style="color:#ae81ff">0.5</span>)
</span></span><span style="display:flex;"><span>face_06_x1, face_06_x2 <span style="color:#f92672">=</span> generate_face(<span style="color:#ae81ff">0.6</span>)
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(face_04_x1, face_04_x2)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(face_05_x1, face_05_x2)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(face_06_x1, face_06_x2)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlim(score_data[<span style="color:#e6db74">&#39;score1&#39;</span>]<span style="color:#f92672">.</span>min(), score_data[<span style="color:#e6db74">&#39;score1&#39;</span>]<span style="color:#f92672">.</span>max())
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylim(score_data[<span style="color:#e6db74">&#39;score2&#39;</span>]<span style="color:#f92672">.</span>min(), score_data[<span style="color:#e6db74">&#39;score2&#39;</span>]<span style="color:#f92672">.</span>max())
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;score1&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;score2&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>legend([<span style="color:#e6db74">&#39;prob_threshold = 0.4&#39;</span>, <span style="color:#e6db74">&#39;prob_threshold = 0.5&#39;</span>, <span style="color:#e6db74">&#39;prob_threshold = 0.6&#39;</span>], loc<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;center left&#39;</span>, bbox_to_anchor<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0.865</span>))
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 4. 绘制分类面 - 法2</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>pos_data <span style="color:#f92672">=</span> data[data[<span style="color:#e6db74">&#39;result&#39;</span>] <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>neg_data <span style="color:#f92672">=</span> data[data[<span style="color:#e6db74">&#39;result&#39;</span>] <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>h <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.02</span>
</span></span><span style="display:flex;"><span>s1_min, s1_max <span style="color:#f92672">=</span> score_data[<span style="color:#e6db74">&#39;score1&#39;</span>]<span style="color:#f92672">.</span>min() <span style="color:#f92672">-</span> <span style="color:#ae81ff">.5</span>, score_data[<span style="color:#e6db74">&#39;score1&#39;</span>]<span style="color:#f92672">.</span>max() <span style="color:#f92672">+</span> <span style="color:#ae81ff">.5</span>
</span></span><span style="display:flex;"><span>s2_min, s2_max <span style="color:#f92672">=</span> score_data[<span style="color:#e6db74">&#39;score2&#39;</span>]<span style="color:#f92672">.</span>min() <span style="color:#f92672">-</span> <span style="color:#ae81ff">.5</span>, score_data[<span style="color:#e6db74">&#39;score2&#39;</span>]<span style="color:#f92672">.</span>max() <span style="color:#f92672">+</span> <span style="color:#ae81ff">.5</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 生成s1在[s1_min, s1_max]，且s2在[s2_min, s2_max]的网格数据点</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># meshgrid含义参见：http://blog.sciencenet.cn/blog-791749-675394.html</span>
</span></span><span style="display:flex;"><span>s1, s2 <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>meshgrid(np<span style="color:#f92672">.</span>arange(s1_min, s1_max, h), np<span style="color:#f92672">.</span>arange(s2_min, s2_max, h))
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 把两个坐标的值按列拼在一起构成二维数据点</span>
</span></span><span style="display:flex;"><span>Z <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>predict(np<span style="color:#f92672">.</span>c_[s1<span style="color:#f92672">.</span>ravel(), s2<span style="color:#f92672">.</span>ravel()])
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 绘制边界和散点</span>
</span></span><span style="display:flex;"><span>Z <span style="color:#f92672">=</span> Z<span style="color:#f92672">.</span>reshape(s1<span style="color:#f92672">.</span>shape)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 坐标点是(s1[i], s2[i])，对应颜色是Z[i]，颜色主题使用plt.cm.Paired</span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>pcolormesh(s1, s2, Z, cmap <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>cm<span style="color:#f92672">.</span>Paired)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>scatter(x <span style="color:#f92672">=</span> pos_data[<span style="color:#e6db74">&#39;score1&#39;</span>], y <span style="color:#f92672">=</span> pos_data[<span style="color:#e6db74">&#39;score2&#39;</span>], color <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;black&#39;</span>, marker <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;o&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>scatter(x <span style="color:#f92672">=</span> neg_data[<span style="color:#e6db74">&#39;score1&#39;</span>], y <span style="color:#f92672">=</span> neg_data[<span style="color:#e6db74">&#39;score2&#39;</span>], color <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;red&#39;</span>, marker <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;*&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlim(s1<span style="color:#f92672">.</span>min(), s1<span style="color:#f92672">.</span>max())
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylim(s2<span style="color:#f92672">.</span>min(), s2<span style="color:#f92672">.</span>max())
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;score1&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;score2&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 5. 评估模型</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 对于测试数据，模型输出1的概率</span>
</span></span><span style="display:flex;"><span>answer <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>predict_proba(x_test)[:,<span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 计算不同概率阈值下的P和R</span>
</span></span><span style="display:flex;"><span>precision, recall, thresholds <span style="color:#f92672">=</span> precision_recall_curve(y_test, answer)
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#75715e"># prob &gt; 0.5的报告为1</span>
</span></span><span style="display:flex;"><span>report <span style="color:#f92672">=</span> answer <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0.5</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>print(classification_report(y_test, report, target_names <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;neg&#39;</span>, <span style="color:#e6db74">&#39;pos&#39;</span>]))
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;average precision: </span><span style="color:#e6db74">%f</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">%</span>average_precision)
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 6. 绘制PRC曲线</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#75715e"># step阶跃图，在点(recall[i],precision[i])进行跳变</span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>step(recall, precision, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;b&#39;</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>, where<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;post&#39;</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 对PRC下方填充颜色</span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>fill_between(recall, precision, step<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;post&#39;</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;b&#39;</span>)
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;Recall&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;Precision&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylim([<span style="color:#ae81ff">0.0</span>, <span style="color:#ae81ff">1.05</span>])
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlim([<span style="color:#ae81ff">0.0</span>, <span style="color:#ae81ff">1.0</span>])
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;2-class Precision-Recall curve&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></td></tr></table>
</div>
</div><p>下面将逐模块介绍代码细节，大神可以略过。</p>
<h1 id="一构造数据">一、构造数据<a hidden class="anchor" aria-hidden="true" href="#一构造数据">#</a></h1>
<p>数据的来源可以有很多种方式，sklearn包中自带7个<a href="http://scikit-learn.org/stable/datasets/index.html#toy-datasets">Toy datasets</a>，比如我们耳熟能详的鸢尾花卉数据集iris和手写数字数据集digits。为了学一学numpy，我们尝试自行构造数据集，这样也方便读者重复。我们可以从两个不同参数的高斯分布中采样相同数量的数据点，由于数据包含两个维度(score1, score2)，所以必须是二维高斯分布。二维高斯分布概率密度函数为：</p>
<p>参数包括：</p>
<p><img loading="lazy" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1d6238c86bf561c952e0560e6f6ad3591278fb82"></p>
<p>\(\mu\)中的\(\mu_X\)和\(\mu_Y\)分别表示两个维度上的均值，\(\Sigma\)是这两个维度上的协方差矩阵，需要满足对称半正定。</p>
<p>numpy中的<a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.random.multivariate_normal.html">random.multivariate_normal</a>可以从多元正态分布中进行采样，传入的参数包括均值mean, 协方差矩阵cov和采样数据点个数。比如本文中第二类数据点的均值为[7,5]，表示在score1维上的均值为7，在score2维上的均值为5，从图上黑点的横纵坐标分布也可以看出来；协方差矩阵为\(\begin{bmatrix}7 & 2\\2 & 15\end{bmatrix}\)，表示score1和score2上的方差分别为7和15，然后标准差的积再乘以相关系数等于2。用这些参数调用multivariate_normal就能得到对应二维平面\(x_1Ox_2\)上的数据点了。</p>
<p>最后，给两类数据点贴上不同的类标号，填充到Pandas中就大功告成了。Pandas中每一行表示一个样本，共有三列，分别表示score1、score2和result，其中result就是类标号。</p>
<h1 id="二训练模型">二、训练模型<a hidden class="anchor" aria-hidden="true" href="#二训练模型">#</a></h1>
<p>由于是直接调用sklearn中的逻辑回归函数，所以这一步非常简单。为了评估模型的准确度，我们做了一个交叉验证，即随机把数据分成80%用于训练，20%用于预测，重复10次，求预测准确度的平均值。这可以用模型选择中的<a href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html">train_test_split</a>快速完成。</p>
<p>调用sklearn.linear_model.LogisticRegression()就能得到一个逻辑回归模型，该函数有很多参数，但是作为入门，所有参数都使用默认值。训练直接调用model.fit(x,y)，预测直接调用model.predict(x)。需要注意的是，model中带了很多成员变量，比如训练得到的分类面参数coef_和intercept_等，后面会用到。</p>
<h1 id="三绘制分类面法1">三、绘制分类面（法1）<a hidden class="anchor" aria-hidden="true" href="#三绘制分类面法1">#</a></h1>
<p>上一篇博客提到，虽然\(f(\mathbf{x})\)被Sigmoid函数映射到了概率空间，但逻辑回归的分类面还是\(f(\mathbf{x})=\mathbf{w^T x}+b=0\)。model通过fit函数训练之后，就能得到分类面的法向量\(\mathbf{w}\)（coef_）和截距\(b\)（intercept_），也就是说对于分类面\(w_1x_1+w_2x_2+b=0\)，我们已经知道了\(w_1\)、\(w_2\)和\(b\)，所以就可以在平面\(x_1Ox_2\)上画出这条直线了。具体的方法就是使用np.linspace先在\(x_1\)上选取足够多的点，代入\(w_1x_1+w_2x_2+b=0\)得到对应的\(x_2\)。该分类面如下图的prob_threshold=0.5。</p>
<p><img loading="lazy" src="/posts/2017-12-05-logistic-regression-in-python/lr_face_4.png"></p>
<p>事实上，逻辑回归的分类面可以不止一个，我们上面得到的分类面是\(f(\mathbf{x})=0\)，代入到\(g(\mathbf{x})\)就是\(g(\mathbf{x})=0.5\)，也就是说当逻辑回归计算到的概率&gt;=0.5分类为1，&lt;0.5分类为0。但是我们也可以提高这个阈值，比如要求概率&gt;=0.6分类为1，&lt;0.6分类为0，这时，相当于我们对于分类为1的阈值提高了，要求更严格了，所以分类面应该向右边黑点方向移动。</p>
<p>求解prob_threshold=0.6的分类面也不难，令\(g(\mathbf{x})=0.6\)，得到\(f(\mathbf{x})=-lg(\frac{1}{0.6}-1)\)，剩下的过程和\(f(\mathbf{x})=0\)是一样的。由此得到的分类面如上图的prob_threshold=0.6那条线，确实在prob_threshold=0.5的右边。类似的，可以画出prob_threshold=0.4的分类面。</p>
<h1 id="四绘制分类面法2">四、绘制分类面（法2）<a hidden class="anchor" aria-hidden="true" href="#四绘制分类面法2">#</a></h1>
<p>还有一种简单粗暴的方法可以快速绘制出分类面。分类面的本质是在该分类面左右两侧的类标签不一样，如果我们把平面上所有点都预测一遍，对预测值为1的标上一种颜色，对预测值为0的标上另一种颜色，那么这两种颜色的交界处自然就是分类面了。</p>
<p>首先，我们使用np.meshgrid生成网格数据点，关于np.meshgrid的用法，<a href="http://blog.sciencenet.cn/blog-791749-675394.html">这篇博客</a>的介绍很好理解。然后对所有网格数据点调用model.predict进行预测。最后使用plt.pcolormesh的<a href="https://matplotlib.org/examples/color/colormaps_reference.html">plt.cm.Paired</a>颜色主题进行着色，即类标签为1的一种颜色，类标签为0的另一种颜色。最后把原始训练数据点画上去，就得到博客开篇的那张分类面图：</p>
<p><img loading="lazy" src="/posts/2017-12-05-logistic-regression-in-python/lr_face_3.png"></p>
<h1 id="五评估模型">五、评估模型<a hidden class="anchor" aria-hidden="true" href="#五评估模型">#</a></h1>
<p>model.predict是直接预测出类标号1或者0，而model.predict_proba是给出类标号分别为1和0的概率，用户可以自行根据prob_threshold进行分类。</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>precision, recall, thresholds <span style="color:#f92672">=</span> precision_recall_curve(y_test, answer)
</span></span></code></pre></td></tr></table>
</div>
</div><p><a href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html">precision_recall_curve</a>的参数是正确答案y_test和model.predict_proba预测出来的概率，返回值分别表示不同threshold阈值下的precision和recall。sklearn官方的例子如下：</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>y_true <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span>y_scores <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([<span style="color:#ae81ff">0.1</span>, <span style="color:#ae81ff">0.4</span>, <span style="color:#ae81ff">0.35</span>, <span style="color:#ae81ff">0.8</span>])
</span></span><span style="display:flex;"><span>precision, recall, thresholds <span style="color:#f92672">=</span> precision_recall_curve(y_true, y_scores)
</span></span></code></pre></td></tr></table>
</div>
</div><p>得到的结果如下：</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>precision
</span></span><span style="display:flex;"><span>array([ <span style="color:#ae81ff">0.66</span><span style="color:#f92672">...</span>, <span style="color:#ae81ff">0.5</span> , <span style="color:#ae81ff">1.</span> , <span style="color:#ae81ff">1.</span> ])
</span></span><span style="display:flex;"><span>recall
</span></span><span style="display:flex;"><span>array([ <span style="color:#ae81ff">1.</span> , <span style="color:#ae81ff">0.5</span>, <span style="color:#ae81ff">0.5</span>, <span style="color:#ae81ff">0.</span> ])
</span></span><span style="display:flex;"><span>thresholds
</span></span><span style="display:flex;"><span>array([ <span style="color:#ae81ff">0.35</span>, <span style="color:#ae81ff">0.4</span> , <span style="color:#ae81ff">0.8</span> ])
</span></span></code></pre></td></tr></table>
</div>
</div><p>比如当threshold=0.4时，表示&gt;=0.4分类为1，&lt;0.4分类为0，则预测结果为[0,1,0,1]。正确率为预测为1的结果中对了几个1/2=0.5，召回率为召回了多少个正确答案为1的结果1/2=0.5。其他阈值的计算类似。</p>
<p>最后调用classification_report会算出不同类别的precision、recall和F1，以及对应的支持数据个数。</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">8
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>             precision    recall  f1<span style="color:#f92672">-</span>score   support
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>        neg       <span style="color:#ae81ff">0.89</span>      <span style="color:#ae81ff">1.00</span>      <span style="color:#ae81ff">0.94</span>        <span style="color:#ae81ff">42</span>
</span></span><span style="display:flex;"><span>        pos       <span style="color:#ae81ff">1.00</span>      <span style="color:#ae81ff">0.87</span>      <span style="color:#ae81ff">0.93</span>        <span style="color:#ae81ff">38</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>avg <span style="color:#f92672">/</span> total       <span style="color:#ae81ff">0.94</span>      <span style="color:#ae81ff">0.94</span>      <span style="color:#ae81ff">0.94</span>        <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>average precision: <span style="color:#ae81ff">0.925000</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="六绘制prc曲线">六、绘制PRC曲线<a hidden class="anchor" aria-hidden="true" href="#六绘制prc曲线">#</a></h1>
<p>PRC曲线就是precision recall curve，由于上一步已经调用precision_recall_curve得到了不同阈值下的precision和recall，这一步直接拿来用就好了。为了防止画出来的曲线抖动形成毛刺，我们使用plt.step阶跃函数来绘制，起到平滑的作用。最后使用plt.fill_between填充曲线下方的面积。得到下图：</p>
<p><img loading="lazy" src="/posts/2017-12-05-logistic-regression-in-python/lr_prc.png"></p>
<p>至此，整个示例讲解完毕。</p>
<p>如果要使用逻辑回归处理多分类问题，只需要构造好多标签的训练数据就好了，剩下的就交给模型自己处理。LogisticRegression的multi_class参数可以设置使用何种策略求解多分类问题，one-vs-rest (OvR)即构建k个二元分类器，multinomial即使用Softmax回归，默认使用OvR。</p>
<p><img loading="lazy" src="/posts/2017-12-05-logistic-regression-in-python/lr_face_5.png"></p>
<p>参考：</p>
<ul>
<li><a href="http://blog.csdn.net/u011721501/article/details/49661585">http://blog.csdn.net/u011721501/article/details/49661585</a></li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/">逻辑回归</a></li>
      <li><a href="http://localhost:1313/tags/python/">Python</a></li>
      <li><a href="http://localhost:1313/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="http://localhost:1313/posts/2017-12-16-a-trip-to-xiamen/">
    <span class="title">« Prev</span>
    <br>
    <span>厦门之行</span>
  </a>
  <a class="next" href="http://localhost:1313/posts/2017-11-26-introduction-to-logistic-regression/">
    <span class="title">Next »</span>
    <br>
    <span>初探逻辑回归</span>
  </a>
</nav>

  </footer><script src="https://giscus.app/client.js"
        data-repo="01joy/01joy.github.io"
        data-repo-id="R_kgDOPefF-w"
        data-category="Announcements"
        data-category-id="DIC_kwDOPefF-84CuPVG"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="top"
        data-theme="preferred_color_scheme"
        data-lang="zh-CN"
        data-loading="lazy"
        crossorigin="anonymous"
        async>
</script>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">bitJoy</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
