<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>论文阅读：Large Reasoning Embedding Models: Towards Next-Generation Dense Retrieval Paradigm | bitJoy</title>
<meta name="keywords" content="多模态, 大模型, Embedding, 强化学习, GRPO">
<meta name="description" content="
基本信息

论文标题：Large Reasoning Embedding Models: Towards Next-Generation Dense Retrieval Paradigm
作者单位：阿里巴巴
论文链接：https://arxiv.org/abs/2510.14321
来源：arxiv

一、问题
电商emb召回场景，目前的方法都是直接字面语义上的对比学习训练（direct-embedding methods），即q2i的对比学习训练。对于复杂、困难的query，语义理解能力不足，比如下图Fig1中的query=&ldquo;比茶更提神的饮料&rdquo;，仍然会召回很多茶，因为字面理解没有理解query背后的深层含义。

二、方法
使用LLM强大的推理能力（reasoning），先推理出CoT，然后基于CoT再产emb。比如上面的例子中，经过LLM推理之后，推理出咖啡、红牛等关键词，通过这些关键词再去产emb然后召回，效果就好很多。
2.1 训练样本构造方法
如下图Fig2中的Data Construction部分：

收集线上query，尤其是那种困难query，就是在现有direct-embedding表现不好的query
把这些query喂给现有召回模型，得到召回商品集合①
然后使用强大的Qwen3-30B-A3B-Instruct生产CoT扩展信息

Unconstrained Reasoning：首先不加任何限制地生产CoT，尽可能利用大模型的世界知识和推理能力，生产充分完全的CoT信息
Information Extraction：由于上一步产出的CoT信息太长了，不利于线上推理，因此把上一步产出的CoT和原始query再次输入给大模型，让大模型抽取其中的关键信息，以keyword list形式输出
Post Processing：最后对上一步抽取的关键词进行后处理，去除重复词，去除query中已有的词等，得到精简、干净的关键词列表，列表最大长度是16


接着把query和CoT喂给已有的向量召回模型，得到扩展的召回商品集合②

由于要训练模型的Reasoning能力，所以只取出集合②-①的差集部分，这部分是CoT带来的增益商品集合


最后使用相关性模型对商品集合②-①进行过滤，过滤出相关的商品
通过上述步骤，产出约7.5kw的&lt;query, CoT, item&gt;三元组
把上述样本划分成两部分，7.1kw的&lt;query, CoT, item&gt;三元组用于Cold start预训练；剩余400w的&lt;query, item&gt;用于RL微调


2.2 Cold Start预训练
对应图Fig2左下角部分，该模块通过大规模的&lt;query, CoT,item&gt;三元组数据预训练，想要达到两个目的：一是让基础模型具备think能力；二是让基础模型产出的emb和下游q2i任务对齐。
这里使用的基础模型是Qwen2.5-3B-Instruct，比生产CoT的模型（Qwen3-30B-A3B-Instruct）小，其实也有点蒸馏的感觉，把大模型的CoT能力蒸馏到小模型中。
训练任务包括两个，一个是CoT的NTP loss（对应图中的SFT loss），另一个是q2i的对比学习InfoNCE loss。query塔和item塔共享参数，他们的emb都是最后一个特殊token &lt;emb&gt; 的emb。


Loss组合：

2.3 RL微调
上一步的SFT主要进行模仿学习，模仿更大的大模型的think能力，小模型本身的reasoning能力受限，接下来需要用GRPO对小模型进行RL微调。RL微调同时对生产CoT和生产emb两个任务都有作用，具体看下面的reward：
RL微调设计了3个reward：

Format Reward：产出的CoT格式符合“&lt;think&gt; Specific CoT &lt;/think&gt;&lt;emb&gt;”就得1分，否则得0分
Length Reward：产出的CoT格式符合长度限制（&lt;=16）就得1分，否则得0分
Retrieval Accuracy Reward：联合原始query和产出的CoT产出的增强query emb，与batch内所有的item emb求相似度，正确item所在的排名为\(rank(d_i)\)，再根据公式12计算一个排名的reward。核心思想是：正确的item与query的相似度排名越高则reward越大（即rank值越小则reward越大）。


最后，上述3个reward通过三个β系数组合起来：
">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:1313/posts/2025-12-13-alibaba-large-reasoning-embedding-model-lrem-paper-reading/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.36819bea596090d8b48cf10d9831382996197aa7e4fc86f792f7c08c9ca4d23b.css" integrity="sha256-NoGb6llgkNi0jPENmDE4KZYZeqfk/Ib3kvfAjJyk0js=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/2025-12-13-alibaba-large-reasoning-embedding-model-lrem-paper-reading/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
    
    
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>
  MathJax = {
    tex: {
      displayMath: [['\\[', '\\]'], ['$$', '$$']],  
      inlineMath: [['\\(', '\\)']]                  
    },
    loader:{
      load: ['ui/safe']
    },
  };
</script>
    
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="bitJoy (Alt + H)">bitJoy</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/categories" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/archives" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/about" title="About">
                    <span>About</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      论文阅读：Large Reasoning Embedding Models: Towards Next-Generation Dense Retrieval Paradigm
    </h1>
    <div class="post-meta"><span title='2025-12-13 18:25:12 +0800 CST'>December 13, 2025</span>&nbsp;·&nbsp;1 min

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#%e5%9f%ba%e6%9c%ac%e4%bf%a1%e6%81%af" aria-label="基本信息">基本信息</a></li>
                <li>
                    <a href="#%e4%b8%80%e9%97%ae%e9%a2%98" aria-label="一、问题">一、问题</a></li>
                <li>
                    <a href="#%e4%ba%8c%e6%96%b9%e6%b3%95" aria-label="二、方法">二、方法</a><ul>
                        
                <li>
                    <a href="#21-%e8%ae%ad%e7%bb%83%e6%a0%b7%e6%9c%ac%e6%9e%84%e9%80%a0%e6%96%b9%e6%b3%95" aria-label="2.1 训练样本构造方法">2.1 训练样本构造方法</a></li>
                <li>
                    <a href="#22-cold-start%e9%a2%84%e8%ae%ad%e7%bb%83" aria-label="2.2 Cold Start预训练">2.2 Cold Start预训练</a></li>
                <li>
                    <a href="#23-rl%e5%be%ae%e8%b0%83" aria-label="2.3 RL微调">2.3 RL微调</a></li>
                <li>
                    <a href="#24-%e8%ae%ad%e7%bb%83%e7%bb%86%e8%8a%82" aria-label="2.4 训练细节">2.4 训练细节</a></li></ul>
                </li>
                <li>
                    <a href="#%e4%b8%89%e7%bb%93%e6%9e%9c" aria-label="三、结果">三、结果</a></li>
                <li>
                    <a href="#%e5%9b%9b%e8%af%84%e4%bb%b7" aria-label="四、评价">四、评价</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p><img loading="lazy" src="/posts/2025-12-13-alibaba-large-reasoning-embedding-model-lrem-paper-reading/LREM-paper-cover.png"></p>
<h1 id="基本信息">基本信息<a hidden class="anchor" aria-hidden="true" href="#基本信息">#</a></h1>
<ul>
<li>论文标题：Large Reasoning Embedding Models: Towards Next-Generation Dense Retrieval Paradigm</li>
<li>作者单位：阿里巴巴</li>
<li>论文链接：<a href="https://arxiv.org/abs/2510.14321">https://arxiv.org/abs/2510.14321</a></li>
<li>来源：arxiv</li>
</ul>
<h1 id="一问题">一、问题<a hidden class="anchor" aria-hidden="true" href="#一问题">#</a></h1>
<p>电商emb召回场景，目前的方法都是直接字面语义上的对比学习训练（direct-embedding methods），即q2i的对比学习训练。对于复杂、困难的query，语义理解能力不足，比如下图Fig1中的query=&ldquo;比茶更提神的饮料&rdquo;，仍然会召回很多茶，因为字面理解没有理解query背后的深层含义。</p>
<p><img loading="lazy" src="/posts/2025-12-13-alibaba-large-reasoning-embedding-model-lrem-paper-reading/LREM-Fig1.png"></p>
<h1 id="二方法">二、方法<a hidden class="anchor" aria-hidden="true" href="#二方法">#</a></h1>
<p>使用LLM强大的推理能力（reasoning），先推理出CoT，然后基于CoT再产emb。比如上面的例子中，经过LLM推理之后，推理出咖啡、红牛等关键词，通过这些关键词再去产emb然后召回，效果就好很多。</p>
<h2 id="21-训练样本构造方法">2.1 训练样本构造方法<a hidden class="anchor" aria-hidden="true" href="#21-训练样本构造方法">#</a></h2>
<p>如下图Fig2中的Data Construction部分：</p>
<ul>
<li>收集线上query，尤其是那种困难query，就是在现有direct-embedding表现不好的query</li>
<li>把这些query喂给现有召回模型，得到召回商品集合①</li>
<li>然后使用强大的Qwen3-30B-A3B-Instruct生产CoT扩展信息
<ul>
<li>Unconstrained Reasoning：首先不加任何限制地生产CoT，尽可能利用大模型的世界知识和推理能力，生产充分完全的CoT信息</li>
<li>Information Extraction：由于上一步产出的CoT信息太长了，不利于线上推理，因此把上一步产出的CoT和原始query再次输入给大模型，让大模型抽取其中的关键信息，以keyword list形式输出</li>
<li>Post Processing：最后对上一步抽取的关键词进行后处理，去除重复词，去除query中已有的词等，得到精简、干净的关键词列表，列表最大长度是16</li>
</ul>
</li>
<li>接着把query和CoT喂给已有的向量召回模型，得到扩展的召回商品集合②
<ul>
<li>由于要训练模型的Reasoning能力，所以只取出集合②-①的差集部分，这部分是CoT带来的增益商品集合</li>
</ul>
</li>
<li>最后使用相关性模型对商品集合②-①进行过滤，过滤出相关的商品</li>
<li>通过上述步骤，产出约7.5kw的&lt;query, CoT, item&gt;三元组</li>
<li>把上述样本划分成两部分，7.1kw的&lt;query, CoT, item&gt;三元组用于Cold start预训练；剩余400w的&lt;query, item&gt;用于RL微调</li>
</ul>
<p><img loading="lazy" src="/posts/2025-12-13-alibaba-large-reasoning-embedding-model-lrem-paper-reading/LREM-Fig2.png"></p>
<h2 id="22-cold-start预训练">2.2 Cold Start预训练<a hidden class="anchor" aria-hidden="true" href="#22-cold-start预训练">#</a></h2>
<p>对应图Fig2左下角部分，该模块通过大规模的&lt;query, CoT,item&gt;三元组数据预训练，想要达到两个目的：一是让基础模型具备think能力；二是让基础模型产出的emb和下游q2i任务对齐。</p>
<p>这里使用的基础模型是Qwen2.5-3B-Instruct，比生产CoT的模型（Qwen3-30B-A3B-Instruct）小，其实也有点蒸馏的感觉，把大模型的CoT能力蒸馏到小模型中。</p>
<p>训练任务包括两个，一个是CoT的NTP loss（对应图中的SFT loss），另一个是q2i的对比学习InfoNCE loss。query塔和item塔共享参数，他们的emb都是最后一个特殊token &lt;emb&gt; 的emb。</p>
<p><img loading="lazy" src="/posts/2025-12-13-alibaba-large-reasoning-embedding-model-lrem-paper-reading/LREM-formula4.png">
<img loading="lazy" src="/posts/2025-12-13-alibaba-large-reasoning-embedding-model-lrem-paper-reading/LREM-formula5-7.png"></p>
<p>Loss组合：
<img loading="lazy" src="/posts/2025-12-13-alibaba-large-reasoning-embedding-model-lrem-paper-reading/LREM-formula8.png"></p>
<h2 id="23-rl微调">2.3 RL微调<a hidden class="anchor" aria-hidden="true" href="#23-rl微调">#</a></h2>
<p>上一步的SFT主要进行模仿学习，模仿更大的大模型的think能力，小模型本身的reasoning能力受限，接下来需要用GRPO对小模型进行RL微调。RL微调同时对生产CoT和生产emb两个任务都有作用，具体看下面的reward：</p>
<p>RL微调设计了3个reward：</p>
<ul>
<li>Format Reward：产出的CoT格式符合“&lt;think&gt; Specific CoT &lt;/think&gt;&lt;emb&gt;”就得1分，否则得0分</li>
<li>Length Reward：产出的CoT格式符合长度限制（&lt;=16）就得1分，否则得0分</li>
<li>Retrieval Accuracy Reward：联合原始query和产出的CoT产出的增强query emb，与batch内所有的item emb求相似度，正确item所在的排名为\(rank(d_i)\)，再根据公式12计算一个排名的reward。核心思想是：正确的item与query的相似度排名越高则reward越大（即rank值越小则reward越大）。
<img loading="lazy" src="/posts/2025-12-13-alibaba-large-reasoning-embedding-model-lrem-paper-reading/LREM-formula11-12.png"></li>
</ul>
<p>最后，上述3个reward通过三个β系数组合起来：
<img loading="lazy" src="/posts/2025-12-13-alibaba-large-reasoning-embedding-model-lrem-paper-reading/LREM-formula13.png"></p>
<p>RL的训练目标，GRPO loss如下：
<img loading="lazy" src="/posts/2025-12-13-alibaba-large-reasoning-embedding-model-lrem-paper-reading/LREM-formula14-16.png"></p>
<p>在RL阶段，除了有GRPO loss，原有的InfoNCE对比学习loss也还在，两个loss通过系数γ组合起来，如公式16所示。</p>
<h2 id="24-训练细节">2.4 训练细节<a hidden class="anchor" aria-hidden="true" href="#24-训练细节">#</a></h2>
<ul>
<li>产CoT的推理模型：Qwen3-30B-A3B-Instruct</li>
<li>emb基座模型：Qwen2.5-3B-Instruct</li>
<li>训练资源：128 GPUs</li>
<li>预训练阶段：
<ul>
<li>CoT最大长度：16</li>
<li>loss系数：\(\lambda_1=0.1, \lambda_2=1\)，也就是InfoNCE loss是主导的，NTP的loss权重很小</li>
<li>batchsize=128</li>
<li>lr=1e-5，cosine scheduler with a warmup ratio of 0.03</li>
<li>训练1个epoch</li>
</ul>
</li>
<li>RL阶段：
<ul>
<li>GRPO每次采样8个CoT</li>
<li>length reward长度阈值16</li>
<li>三个reward系数：\(\beta_1=0.5, \beta_2=0.2, \beta_3=1\)，\(\beta_3\)最大，即准度的reward最重要</li>
<li>loss系数\(\gamma_1=1,\gamma_2=0.1\)，即GRPO的loss权重最大</li>
<li>batchsize=256，RL阶段的batchsize是预训练阶段的2倍</li>
<li>lr=1e-6，cosine scheduler with a warmup ratio of 0.03，RL阶段的lr比预训练小</li>
<li>训练1个epoch</li>
</ul>
</li>
</ul>
<h1 id="三结果">三、结果<a hidden class="anchor" aria-hidden="true" href="#三结果">#</a></h1>
<ul>
<li>如下图所示，最后一行LREM(Cold Start+RL)效果最好，但是LREM(Cold Start)效果很差啊，比Qwen2.5的好几个base都差。。。这就很奇怪了，理论上LREM(Cold Start)去掉CoT和SFT loss的结构和Qwen2.5 (Uni-Attn. Last)的结构是完全一样的，但是前者的指标比后者差很多，难道是加了CoT和SFT loss有负向影响？</li>
<li>LREM(Cold Start+RL)比LREM(Cold Start)提升非常大，也能说明LREM(Cold Start)效果很差。但是不应该呀，RL的几个reward，理论上在预训练阶段都有训练到，即使对于准度的reward3，其实也相当于positive在in-batch内的相似度要大于其他negative，本质上和InfoNCE loss的目的是一致的，为啥换成RL的形式后提升这么大？
<img loading="lazy" src="/posts/2025-12-13-alibaba-large-reasoning-embedding-model-lrem-paper-reading/LREM-Tab1.png"></li>
<li>作者还分析了CoT的作用，把CoT换成空的、随机字符串、或者单纯重复query，效果都下降很多，说明CoT很重要。
<img loading="lazy" src="/posts/2025-12-13-alibaba-large-reasoning-embedding-model-lrem-paper-reading/LREM-Tab2.png"></li>
</ul>
<h1 id="四评价">四、评价<a hidden class="anchor" aria-hidden="true" href="#四评价">#</a></h1>
<ul>
<li>问题切入点很好，特别是在相关性、召回场景，query更加多样，困难的query也更多，而且本文主要就是解决困难query的场景，但是这种情况在线上的占比应该很小？作者没讲</li>
<li>CoT数据的生产经过了很多步骤，看得出来经过了多轮迭代优化，也说明这个环节有很多坑，直接用更大模型产出的无约束的CoT可能效果不行。。。</li>
<li>本文只针对query进行了CoT扩张，能不能对item也扩展一下呢？</li>
<li>本文最终效果提升很大，但是这个提升真的来自RL吗，感觉有点怀疑呀。个人感觉CoT的信息可能更重要一点，需要补充一个对比实验，即用emb基座模型直接加入本文产出的CoT进行对比学习预训练，不加后面的RL，看看效果怎么样。就是CoT只作为附加特征，相当于LREM(Cold Start)基础上去掉SFT loss，感觉这样就能取得不错的效果吧。</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/%E5%A4%9A%E6%A8%A1%E6%80%81/">多模态</a></li>
      <li><a href="http://localhost:1313/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/">大模型</a></li>
      <li><a href="http://localhost:1313/tags/embedding/">Embedding</a></li>
      <li><a href="http://localhost:1313/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/">强化学习</a></li>
      <li><a href="http://localhost:1313/tags/grpo/">GRPO</a></li>
    </ul>
<nav class="paginav">
  <a class="next" href="http://localhost:1313/posts/2025-11-09-resolve-the-uri-too-long-error-of-giscus-in-hugo/">
    <span class="title">Next »</span>
    <br>
    <span>解决Hugo的Giscus评论系统出现URI_TOO_LONG的问题</span>
  </a>
</nav>

  </footer><script src="https://giscus.app/client.js"
        data-repo="01joy/01joy.github.io"
        data-repo-id="R_kgDOPefF-w"
        data-category="Announcements"
        data-category-id="DIC_kwDOPefF-84CuPVG"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="top"
        data-theme="preferred_color_scheme"
        data-lang="zh-CN"
        data-loading="lazy"
        crossorigin="anonymous"
        async>
</script>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">bitJoy</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
