<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>Posts | bitJoy</title>
<meta name="keywords" content="">
<meta name="description" content="Posts - bitJoy">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:1313/posts/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.36819bea596090d8b48cf10d9831382996197aa7e4fc86f792f7c08c9ca4d23b.css" integrity="sha256-NoGb6llgkNi0jPENmDE4KZYZeqfk/Ib3kvfAjJyk0js=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="http://localhost:1313/posts/index.xml">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
    
    
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>
  MathJax = {
    tex: {
      displayMath: [['\\[', '\\]'], ['$$', '$$']],  
      inlineMath: [['\\(', '\\)']]                  
    },
    loader:{
      load: ['ui/safe']
    },
  };
</script>
    
</head>

<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="bitJoy (Alt + H)">bitJoy</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/categories" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/archives" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/about" title="About">
                    <span>About</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main"> 
<header class="page-header">
  <h1>
    Posts
  </h1>
</header>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Neural Networks and Deep Learning（三·一）梯度消失
    </h2>
  </header>
  <div class="entry-content">
    <p>原文的第三章内容较多，本博客将分三个部分进行介绍：梯度消失、过拟合与正则化、权重初始化及其他，首先介绍梯度消失问题。
为简单起见，假设网络只包含一个输入和一个神经元，网络的损失是均方误差损失MSE，激活函数是Sigmoid函数。则该网络的参数只包含权重\(w\)和偏移量\(b\)。我们想训练这个网络，使得当输入为1时，输出0。
假设我们随机初始化\(w_0=0.6\)，\(b_0=0.9\)，则网络的损失随着训练的epoch变化曲线如下，看起来挺好的，一开始损失下降很快，随着epoch增加，损失下降逐渐平缓，直至收敛。
但是，如果随机初始化\(w_0=2.0\)，\(b_0=2.0\)，则网络的损失一开始下降得很缓慢，要训练到快200个epoch时，损失才快速下降。可以看到同样是300个epoch，由于初始化权重的差别，损失下降的趋势完全不一样，而且对于下面这种情况，到300个epoch时，损失还有下降的空间，所以期望的output不如上面的接近目标值0。
为什么同样的网络，只是因为初始化权重的差异，损失的变化曲线却相差这么多呢，这和我们选择的损失函数与激活函数有关。
回顾一下，我们在上一讲的末尾介绍到如果损失函数是MSE且激活函数是Sigmoid时，有\(\delta^L = (a^L-y) \odot \{\sigma(z^L)(1-\sigma(z^L))\}\)，又因为网络只有一个神经元，所以梯度如下：
$$\begin{eqnarray}\frac{\partial C}{\partial w} &amp; = &amp; (a-y)\sigma&#39;(z) x = a \sigma&#39;(z),\tag{1}\\\frac{\partial C}{\partial b} &amp; = &amp; (a-y)\sigma&#39;(z) = a \sigma&#39;(z)\tag{2}\end{eqnarray}$$其中第二个等号是把\(x=1\)和\(y=0\)带入得到的。由此可见，误差对两个参数\(w\)和\(b\)的梯度都和激活函数的导数有关，因为激活函数是Sigmoid，当神经元的输出接近0或1时，梯度几乎为0，误差反向传播就会非常慢，导致上图出现损失下降非常慢的现象。这就是梯度消失的原因。
为了解决这个问题，我们可以采取两种策略，一是替换损失函数，一是替换激活函数。
第一种方法是将MSE的损失函数替换为交叉熵损失函数，激活函数依然是Sigmoid。我们考虑一个比本文开头更复杂的网络，仍然是一个输出神经元，但包含多个输入神经元。
此时，交叉熵损失函数定义如下，其中的\(n\)表示训练样本数，\(\frac{1}{n}\sum_x\)表示对所有输入样本\(x\)的交叉熵损失求均值。
$$\begin{eqnarray}C = -\frac{1}{n} \sum_x \left[y \ln a &#43; (1-y ) \ln (1-a) \right]\tag{3}\end{eqnarray}$$我们首先考察为什么(3)可以是一个损失函数，损失函数需要满足如下两个条件：
非负； 当网络输出和目标答案越接近，损失越小；反之损失越大。 简单代入几组不同的样本很容易验证交叉熵满足上述两个条件 ，所以交叉熵可以作为一个损失函数。
下面我们再考察一下为什么交叉熵损失函数&#43;Sigmoid激活函数可以解决梯度消失的问题。首先推导交叉熵损失\(C\)对权重\(w_j\)和\(b\)的梯度：
$$\begin{eqnarray}\frac{\partial C}{\partial w_j} &amp; = &amp; -\frac{1}{n} \sum_x \left(\frac{y }{\sigma(z)} -\frac{(1-y)}{1-\sigma(z)} \right)\frac{\partial \sigma}{\partial w_j} \tag{4}\\&amp; = &amp; -\frac{1}{n} \sum_x \left(\frac{y}{\sigma(z)}-\frac{(1-y)}{1-\sigma(z)} \right)\sigma&#39;(z) x_j\tag{5}\\&amp; = &amp; \frac{1}{n}\sum_x \frac{\sigma&#39;(z) x_j}{\sigma(z) (1-\sigma(z))}(\sigma(z)-y).\tag{6}\end{eqnarray}$$上式分子Sigmoid的导数正好可以和分母抵消，得到：
...</p>
  </div>
  <footer class="entry-footer"><span title='2019-03-18 10:33:32 +0800 CST'>March 18, 2019</span>&nbsp;·&nbsp;2 min</footer>
  <a class="entry-link" aria-label="post link to Neural Networks and Deep Learning（三·一）梯度消失" href="http://localhost:1313/posts/2019-03-18-neural-networks-and-deep-learning-3-1-gradient-vanishing/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Neural Networks and Deep Learning（二）BP网络
    </h2>
  </header>
  <div class="entry-content">
    <p>这一讲介绍误差反向传播（backpropagation）网络，简称BP网络。
以上一讲介绍的MNIST手写数字图片分类问题为研究对象，首先明确输入输出：输入就是一张28×28的手写数字图片，展开后可以表示成一个长度为784的向量；输出可以表示为一个长度为10的one-hot向量，比如输入是一张“3”的图片，则输出向量为(0,0,0,1,0,0,0,0,0,0,0)。
然后构造一个如下的三层全连接网络。第一层为输入层，包含784个神经元，正好对应输入的一张28×28的图片。第二层为隐藏层，假设隐藏层有15个神经元。第三层为输出层，正好10个神经元，对应该图片的one-hot结果。
全连接网络表示上一层的每个神经元都和下一层的每个神经元有连接，即每个神经元的输入来自上一层所有神经元的输出，每个神经元的输出连接到下一层的所有神经元。每条连边上都有一个权重w。
每个神经元执行的操作非常简单，就是把跟它连接的每个输入乘以边上的权重，然后累加起来。
比如上面的一个神经元，它的输出就是：
$$\begin{eqnarray}\mbox{output} = \left\{ \begin{array}{ll}0 &amp; \mbox{if} \sum_j w_j x_j \leq \mbox{ threshold} \\1 &amp; \mbox{if} \sum_j w_j x_j &gt; \mbox{threshold}\end{array}\right.\tag{1}\end{eqnarray}$$其中的threshold就是该神经元激活的阈值，如果累加值超过threshold，则该神经元被激活，输出为1，否则为0。这就是最原始的感知机网络。感知机网络也可以写成如下的向量形式，用激活阈值b代替threshold，然后移到左边。神经网络中，每条边具有权重w，每个神经元具有激活阈值b。
$$\begin{eqnarray}\mbox{output} = \left\{ \begin{array}{ll} 0 &amp; \mbox{if } w\cdot x &#43; b \leq 0 \\1 &amp; \mbox{if } w\cdot x &#43; b &gt; 0\end{array}\right.\tag{2}\end{eqnarray}$$ 但是感知机网络的这种激活方式不够灵活，它在threshold左右有一个突变，如果输入或者某个边上的权重稍微有一点变化，输出结果可能就千差万别了。于是后来人们提出了用sigmoid函数来当激活函数，它在0附近的斜率较大，在两边的斜率较小，能达到和阶梯函数类似的效果，而且函数光滑可导。sigmoid的函数形式如下，其中\(z\equiv w \cdot x &#43; b\)为神经元激活之前的值。
$$\begin{eqnarray} \sigma(z) \equiv \frac{1}{1&#43;e^{-z}}\tag{3}\end{eqnarray}$$sigmmoid函数还有一个优点就是它的导数很好计算，可以用它本身来表示：
$$\begin{eqnarray}\sigma&#39;(z)=\sigma(z)(1-\sigma(z))\tag{4}\end{eqnarray}$$BP网络的参数就是所有连线上的权重w和所有神经元中的激活阈值b，如果知道这些参数，给定一个输入x，则可以很容易的通过正向传播（feedforward）的方法计算到输出，即不断的执行\(w \cdot x &#43; b\)操作，然后用sigmoid激活，再把上一层的输出传递给下一层作为输入，直到最后一层。
1 2 3 4 5 def feedforward(self, a): &#34;&#34;&#34;Return the output of the network if ``a`` is input.&#34;&#34;&#34; for b, w in zip(self.biases, self.weights): a = sigmoid(np.dot(w, a)&#43;b) return a 同时，网络的误差可以用均方误差（mean squared error, MSE）表示，即网络在最后一层的激活值（即网络的输出值）\(a\)和对应训练集输入\(x\)的正确答案\(y(x)\)的差的平方。有\(n\)个输入则误差取平均，\(\dfrac{1}{2}\)是为了后续求导方便。
...</p>
  </div>
  <footer class="entry-footer"><span title='2018-12-14 12:18:07 +0800 CST'>December 14, 2018</span>&nbsp;·&nbsp;2 min</footer>
  <a class="entry-link" aria-label="post link to Neural Networks and Deep Learning（二）BP网络" href="http://localhost:1313/posts/2018-12-14-neutral-networks-and-deep-learning-2-bp/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Neural Networks and Deep Learning（一）MNIST数据集介绍
    </h2>
  </header>
  <div class="entry-content">
    <p>最近开始学习神经网络和深度学习，使用的是网上教程：http://neuralnetworksanddeeplearning.com/，这是学习心得第一讲，介绍经典的MNIST手写数字图片数据集。
MNIST（Modified National Institute of Standards and Technology database）数据集改编自美国国家标准与技术研究所收集的更大的NIST数据集，该数据集来自250个不同人手写的数字图片，一半是人口普查局的工作人员，一半是高中生。该数据集包括60000张训练集图片和10000张测试集图片，训练集和测试集都提供了正确答案。每张图片都是28×28=784大小的灰度图片，也就是一个28×28的矩阵，里面每个值是一个像素点，值在[0,1]之间，0表示白色，1表示黑色，(0,1)之间表示不同的灰度。下面是该数据集中的一些手写数字图片，可以有一个感性的认识。
MNIST数据集可以在Yann LeCun的网站上下载到：http://yann.lecun.com/exdb/mnist/，但是他提供的MNIST数据集格式比较复杂，需要自己写代码进行解析。目前很多深度学习框架都自带了MNIST数据集，比较流行的是转换为pkl格式的版本：http://deeplearning.net/data/mnist/mnist.pkl.gz，该版本把原始的60000张训练集进一步划分成了50000张小训练集和10000张验证集，下面以这个版本为例进行介绍。
pkl是python内置的一种格式，可以将python的各种数据结构序列化存储到磁盘中，需要时又可以读取并反序列化到内存中。mnist.pkl.gz做了两次操作，先pkl序列化，再gz压缩存储，所以要读取该文件，需要先解压再反序列化，在python3中，读取mnist.pkl.gz的方式如下：
1 2 3 4 5 import pickle import gzip f = gzip.open(‘../data/mnist.pkl.gz’, ‘rb’) training_data, validation_data, test_data = pickle.load(f, encoding=’bytes’) f.close() 这样就得到了训练集、验证集和测试集。将数据集序列化到文件中的方法也很简单，需要注意的是pickle在序列化和反序列化时有不同的协议，可以用protocol参数进行设置。
1 2 3 4 dataset=[training_data, validation_data, test_data] f=gzip.open(‘../data/mnist3.pkl.gz’,’wb’) pickle.dump(dataset,f,protocol=3) f.close() 我们从mnist.pkl.gz读取到的training_data, validation_data, test_data这三个数据的结构是一样的，每个都是一个二维的tuple。以training_data为例，training_data[0]是训练样本，是一个50000×784的矩阵，表示有50000个训练样本，每个训练样本是一个784的一维数组，784就是把一张28×28的图片展开reshape成的一维数组；training_data[1]是训练样本对应的类标号，大小为50000的一维数组，每个值为0~9中的某个数，表示对应样本的数字标号。
...</p>
  </div>
  <footer class="entry-footer"><span title='2018-11-25 11:33:45 +0800 CST'>November 25, 2018</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to Neural Networks and Deep Learning（一）MNIST数据集介绍" href="http://localhost:1313/posts/2018-11-25-neutral-networks-and-deep-learning-1-mnist-dataset/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Ubuntu下使用VSCode连接Github
    </h2>
  </header>
  <div class="entry-content">
    <p>VSCode是微软开源的一个很强大的IDE，可以支持几乎所有编程语言，而且是跨平台的，Linux用户终于可以用上宇宙最强IDE了。我最近在使用VSCode编写调试Python项目，其调试功能很强大，和VS上调试C&#43;&#43;的感觉是一样的，强烈推荐。
VSCode还可以连接Github，进行版本控制。下面以我最近学习的深度学习项目为例，介绍下怎样在Ubuntu下使用VSCode连接Github。以我fork的repo为例：https://github.com/01joy/neural-networks-and-deep-learning。
连接Github有两种方式，一种是HTTPS，另一种是SSH，在每个repo页面的右边，有一个Clone or download按钮，可以获取到这两种连接方式的地址。HTTPS方式和网址类似，以HTTPS开头；SSH方式以git@githu.com开头。使用HTTPS连接比较简单，但是每次push的时候需要输入用户名和密码，比较麻烦，如果想记住密码，需要把用户名和密码以明文的形式保存到一个文件中，个人感觉不方便且不安全。下面以SSH连接为例进行介绍。
首先设置Github提交时的用户名和密码，一般设置成全局的：https://help.github.com/articles/setting-your-username-in-git/、https://help.github.com/articles/setting-your-commit-email-address-in-git/ 生成一对新的SSH公钥和私钥，并添加到ssh-agent中。注意生成的时候需要输入passphrase，这个passphrase不是Github的密码，自己随便取一个记住就好。https://help.github.com/articles/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent/ 把SSH的公钥添加到Github账号中：https://help.github.com/articles/adding-a-new-ssh-key-to-your-github-account/ 测试SSH连接是否成功：https://help.github.com/articles/testing-your-ssh-connection/ （可选）修改SSH密码，即第1步设置的passphrase：https://help.github.com/articles/working-with-ssh-key-passphrases/ 到这里，本级就能通过SSH连接Github了。 如果没有安装VSCode，可以直接通过Ubuntu的终端连接Github，步骤如下：
在本地创建一个和远程repo名称一样的空文件夹 终端cd到该文件夹内 git init # 在该文件夹内初始化 git remote add origin git@github.com:01joy/notes-on-writing.git # 使用repo的SSH地址 git pull origin master # 把远程代码拉到本地 修改代码 git add . # 在根目录执行，添加所有修改 git commit -m ‘comments’ # commit第7步添加的修改 git push origin master # 把第8步发布到远程 如果安装了VSCode，其实和直接用终端是一样的，在菜单栏的Terminal下新建一个终端，在这个终端内执行上述代码，如果在第4步出现”Enter password to unlock the private key”时，输入创建SSH时第2步的密码即可，只需一次，下次就不用再输入密码了。点击File的Open Folder打开本地repo文件夹。点击VSCode左边栏的Explorer可以在编辑器下修改代码。切换到左边栏的Source Control可以进行Git相关操作，修改的文件右边会出现一个M，点击这个M会出现diff视图；Source Control左边的右上角有三个点，点击这个按钮会出现很多Git操作，包括commit、push等，其实相当于调用上述代码，效果是一样的。
VSCode快捷键Ctrl&#43;Shift&#43;P会出现命令窗口，在里面输入commit、push等会出现相关操作的，能起到一定的加速效果，当然也可以自定义快捷键。
Have Fun!
</p>
  </div>
  <footer class="entry-footer"><span title='2018-11-13 11:09:48 +0800 CST'>November 13, 2018</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to Ubuntu下使用VSCode连接Github" href="http://localhost:1313/posts/2018-11-13-access-github-from-vscode-in-ubuntu/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Word2016批注行距太大的问题
    </h2>
  </header>
  <div class="entry-content">
    <p>最近导师给我批注文章，说我的Word文档的批注行距极大，从入学到现在一直都是如此，对他造成了极大的困扰，希望我能解决这个问题。
但是我自己用Word2016查看导师的批注，看不出行距极大的问题，显示完全是正常的。后来猜测导师用的是旧版的Word2010，于是在虚拟机中安装了Word2010，进行测试。
经过长时间的Debug，终于发现问题所在。Word针对批注有一个默认的样式，为“批注文字（使用前隐藏）”，可以点击样式右下角的箭头，或者直接按快捷键Ctrl&#43;Shift&#43;Alt&#43;S调出样式窗口。然后点击底部的管理样式就可以看到所有的样式了。有意思的是，批注文字样式默认是隐藏的，所以在下图的样式列表中是找不到这个样式的。
找到批注文字样式，点击修改，在弹出的窗口中点击左下角的格式，选择段落，就可以看到批注的默认格式了。段落格式看不出什么异常，Word2016和Word2010的批注段落格式都是一样的，其中“如果定义了文档网格，则对齐到网格”都是默认选中的。
有意思的是，Word2016和Word2010对网格的默认设置却不一样。在布局、页面设置中点击右下角的箭头，打开页面设置对话框。切换到文档网格选项卡。
Word2016默认指定了行网格，而Word2010默认却是无网格。因为批注文字样式中选中了“如果定义了文档网格，则对齐到网格”这个选项，Word2016默认指定了行网格，所以批注文字会对齐到行网格，导致行间距太大，Word2010默认没有指定任何网格，所以其批注文字的行间距是正常。
Word2016文档网格，默认指定了行网格
Word2010文档网格，默认无网格
解决办法就是，修改Word2016的设置，选中“无网格”，并设置为默认值，这样以后新建的Word文档默认都是无网格，批注的行间距也就正常了。
</p>
  </div>
  <footer class="entry-footer"><span title='2018-09-01 10:53:25 +0800 CST'>September 1, 2018</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to Word2016批注行距太大的问题" href="http://localhost:1313/posts/2018-09-01-the-line-space-problem-of-annotation-in-word-2016/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">2017年终总结
    </h2>
  </header>
  <div class="entry-content">
    <p>2017年是目前为止最折腾的一年。
科研工作 今年的科研任务包括两个方面，一方面是pLink2软件的完善和发布，另一方面是完成pLink2文章初稿。软件方面，上半年忙着修改完善算法，下半年重写界面代码，修改各种bug并反复测试。最终在12月31日晚通过邮件正式发布。文章方面，元旦软件发布之后，一月份抽两周时间完成了初稿，算是自己的第一篇全英文初稿，正文加附录接近一万词。不过因为有一个实验结果不太好，还需要接着完善算法，文字也很稚嫩，需要反复修改。希望能在2018年上半年投出去。
个人提高 上半年忙着找工作，一直在刷题看书攒面经，经过自己的不懈努力，收获了微软、百度、头条、Face&#43;&#43;等心仪的Offer。在确定自己找工作没问题之后，被李沐的博客“忽悠”，下半年华丽丽的转博了，赶在了2015级最后一次转博前夕。
因为找工作，看了7本专业书；因为有Kindle，以及忙里偷闲，竟也看了9本非专业书。元旦完成软件发布任务之后，奖励自己去电影院连看了一整天的电影，这种休假方式也是蛮奇葩的，今年累计去电影院看的电影数已经达到16了。上半年和欣欣看了一场“OFO轻睐演唱会”，第一次参加演唱会，现场的感觉和看视频不一样，气氛很热烈，大家都很兴奋，会情不自禁跟着一起唱。国庆第一次一个人远行，去了郑州、登封和杭州，加上12月份参加厦门质谱会议，今年去的第三个城市已经达到了4个。
运动方面。在两个师兄的帮助以及室友的陪练下，真的学会了蛙泳，今年8月份还拿到了深水证，为此贺老师每个月奖励我100块钱，简单粗暴又有效的奖励机制:-)。临近年底的时候，心血来潮，准备提高乒乓球技术，混入了所里的乒乓球圈子，拜师王老师门下，经过训练以及看视频学习，竟偶尔能赢浩哥了，今年再接再厉。
今年约好了和哥一起回家过年，给家里买了一台55寸的乐视超级电视，给父母的红包也涨了不少。总体来说，家里在一年一年变好。
对照年初定的目标，
发表pLink 2文章。只完成了初稿。 至少完成毕业工作的80%。转博了。 刷完LeetCode所有简单题和中等题，找工作之前最好刷完两遍。完成。 找到一个满意的工作。完成，具体请看https://bitjoy.net/posts/2018-02-04-2018-campus-recruiting/。 读10本书。完成16：《编程珠玑》、《C&#43;&#43; Primer》、《程序员面试笔试宝典》、《STL源码剖析》、《剑指Offer》、《深度探索C&#43;&#43;对象模型》、《编程之美》、《人间失格》、《枪炮、病菌与钢铁》、《杀死一只知更鸟》、《别闹了，费曼先生》、《月亮与六便士》、《突破极限》、《解忧杂货店》、《北京折叠》、《以色列，一个国家的诞生123》。 去电影院看10场电影。完成16：《爱乐之城》、《摔跤吧！爸爸》、《银河护卫队2》、《战狼2》、《敦刻尔克》、《羞羞的铁拳》、《看不见的客人》、《东方快车谋杀案》、《寻梦环游记》、《帕丁顿熊2》、《芳华》、《解忧杂货店》、《前任3：再见前任》、《无问西东》、《南极之恋》、《太空救援》。 看一场话剧（音乐会、歌剧等都可以）。完成。2017年7月2日，北京工人体育场，OFO轻睐演唱会。 学会游泳。完成，学会蛙泳和踩水，年中拿到深水证。 去第三个城市。完成，国庆去了郑州、登封、杭州，12月份第一次坐飞机去了厦门。 总体来说，2017年的目标都完成了，而且好几项是超额完成。2018年目标如下：
发表pLink2文章，科研的重中之重。 开展新课题，或SUMO或深度学习。 完成博士课程的学习。 读10本书。 去电影院看10场电影。 去北京公园年票范围中的19家公园。 看一场话剧（音乐会、歌剧等都可以）。 学会自由泳。 乒乓球稳赢。 去第三个城市。 机动目标，高温假带父母来北京玩。 突然发现每年的目标都差不多，读万卷书和行万里路是每年都有的保留项目。
找工作，分手，转博，软件发布，文章写作构成了我2017年的365天，喜忧参半，在跌跌撞撞中前行。2018年要保持一如既往的冲劲，打赢转博之后的第一仗！
</p>
  </div>
  <footer class="entry-footer"><span title='2018-02-18 21:00:20 +0800 CST'>February 18, 2018</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to 2017年终总结" href="http://localhost:1313/posts/2018-02-18-summary-of-2017/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">一念成博
    </h2>
  </header>
  <div class="entry-content">
    <p>证明你能做一件事的最好方法就是做成这件事！
从保研开始，我根本就没打算读博士，心里想的是，好好学习，认真刷题，顺利毕业，高薪就业。
2016年底，也就是进实验室半年之后，贺老师开始“怂恿”我读博：“贫寒人家子弟，有个高学历，在这个拼爹的时代，更容易出人头地。年轻时多读点儿难读的书，也会更好地在未来人工智能时代生存。”我不为所动。
2017年春节在家，疯狂刷题看书，为开学后的实习面试以及半年之后的校招面试准备着。
2017年2月份，开年工作计划会，老师说只要我愿意读博，博士的三个课题都帮我规划好了，要知道我们实验室没有哪个博士生是在三年级之前就确定方向的，大家都是摸着石头过河。
我还是不为所动，疯狂刷题看书，攒实习面经。
到了8月，老师最后来信希望我能认真考虑一下读博的事情：“pFind&#43;NIBS是难得的良性成长环境，换一个新环境未见得能成长像现在这么快”。甚至把我的博士女朋友都搬出来了。我跟欣欣聊了聊，思想开始有点动摇了。但是那段时间忙于找工作，没空想太多。
9月10日教师节，我和欣欣分手，与工作无关，与硕士博士无关。
后来有一天，当我在对比百度凤巢和微软的Offer时，偶然看到凤巢前辈李沐博士写的一篇博客：《博士这五年》。李沐是上海交大ACM班的，毕业之后去了百度凤巢，但是后来毅然辞职去CMU攻读博士学位。博士五年期间，他不但发表了多篇很牛的paper，而且亲手写了一个类似TensorFlow的深度学习平台MXNet，MXNet现已加入Apache家族，并被Amazon选为官方深度学习框架。他博士答辩的评委有来自Google, Amazon, Apple的AI负责人，阵容非常强大。最后，李沐光荣毕业，加入Amazon。
这篇博客的结尾在谈到如何选择工作和读博时有一段话，令我印象深刻：“不过我觉得还是会选择读博。赚钱以后还有大把时间可以，但是能花几年时间在某个领域从入门到精通甚至到推动这个领域发展的机会就一次……更重要的是理想和情怀。人一生要工作五十年，为什么不花五年来追求下理想和情怀呢？”。
看完这篇博客之后，那一整天，我都没心思上班。校招至今，拿了一堆Offer，不能说轻而易举，但是我现在知道拿Offer就跟考试一样，只要准备好，不会差到哪里去。甚至可以说，校招面试比回答贺老师的问题要简单多了。未来可以工作的时间还很长，何不花几年时间来挑战自己呢。当你在面对两难选择时，选择更难的那个，日后你会感谢当初自己的选择。
人拼了命的工作，到底是为了什么，除了更早的成为工厂里的螺丝钉，成为房奴、孩奴，你还能得到什么。是的，提前三年工作，你也许能赚到100万，能积累更丰富的工作经验和更广阔的人脉。但是，这又怎样，这些东西该来的肯定会来，博士毕业之后，我同样能得到，只是比大多数人晚了一点。
与其早早毕业，成为一个nobody，还不如再潜心修炼几年，成为somebody。博士这几年，我能得到更加系统全面的训练，pFind&#43;NIBS的良性科研环境，也不可多得。曾经在知乎上看到有个人回答为什么选择读博：“在一个很安全的环境里，父母健在，自己不用操心赚钱养家；有老板给你提供指导、资金；你可以安心研究自己感兴趣的问题；发表的文章也将署上自己的名字，流传后世；习得的技能也将转化为自己的能力；获得的博士学位也将是自己的荣誉…”，这么好的事情，为什么不去做呢？
那一天之后，我内心几乎就决定要转博了。
然而，话虽如此，想到要放弃到手的大Offer，继续在实验室里待至少三年；想到免不了要经历大多数博士师兄师姐们经历过的痛苦日子；想到彼时同学们都已经年入x万，有房有车，说不定我日后的面试官就是现在的同学；想到我最亲密的女朋友对我的不信任；想到自己的苦衷无处倾诉…
那段日子过得很艰难，也许是我到目前为止最低谷的时期。左手是各大互联网公司的Offer，立即可以实现我很多的愿望；右手是若干年未知的博士磨砺。虽然内心知道往右走是正确的，但还是下不了这个狠心。脑海中的两个小人，吵个不停。
期间和很多在读的、已毕业的博士师兄师姐们聊过，也和很多公司的面试官聊过，当然也和老师父母聊过。得到的回答无外乎三种：读、不读，根据自己的情况决定。这些谈话更像是换了种方式的倾述，我已经记不清具体的内容了，只知道，我做选择的决心越来越坚定了。
之后恰逢十一长假，给自己放了一个长长的假。规划去了郑州、登封、杭州。了却夙愿，重新开始。
10月9日，长假结束。我给老师发了一封邮件：“贺老师，您好。非常感谢您的信任和等待，我决定读博了！这将是我人生二十多年来所作的第一个重大决定，我接受挑战！”
人这一生，说长也长，说短也短，去做你认为对的事情吧，去追求你想要的生活。愿我们都能绽放美丽，不负芳华！
</p>
  </div>
  <footer class="entry-footer"><span title='2018-02-14 20:28:36 +0800 CST'>February 14, 2018</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to 一念成博" href="http://localhost:1313/posts/2018-02-14-why-phd/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">伪·2018届校招面经
    </h2>
  </header>
  <div class="entry-content">
    <p>作为一名曾经的2018届硕士毕业生，为找工作忙活了大半年，最终收获了微软、百度、头条、Face&#43;&#43;等十多个Offer。校招季对我来说，在9月份就差不多结束了。本来很早就酝酿了这篇博客，但是由于之后一系列事情，耽搁至今，趁着提交完年终技术报告，回家之前，把这段经历记录一下。
首先介绍一些计算机专业校招的基本情况。由于移动互联网、人工智能等浪潮的兴起，计算机专业的毕业生就业前景可谓一片大好，尤其是对于名校毕业基础扎实的同学，应届生薪资倒挂老员工的事情几乎每年都在上演。所以首先祝贺所有CSer，这是属于你们的时代，各行各业都有属于你的舞台，尽情去施展才华吧。
本专业的毕业生就业去向主要有这么几类：国内互联网公司、国外互联网公司（外企）、国企。其中国内互联网公司又分大厂和新兴创业公司，大厂如BAT、网易、360、京东、华为等，创业公司主要集中在人工智能这块，如商汤科技、Face&#43;&#43;、头条、滴滴等。外企大概也分为两类，一类是来自日本的企业，比如Indeed、WAP；另一类是来自美国的企业，比如Microsoft、Google、Hulu、FreeWheel、Amazon等。国企是指传统的国有企业里面的IT部门，比如各大银行、证监会等。这几类公司的校招时间刚好都错开了，一般来说，日企来华校招是最早的，大概每年5月份就来了；接着是国内互联网公司的内推季，大概在7~8月份；进入9月份之后，就是国内互联网公司的正式校招了；美国的企业大概会在9~10月份启动校招，有可能一直持续到11月份；国企就比较晚了，听说最晚能持续到第二年3、4月份的。这种安排，对我们来说，既是好事，也是坏事，好处就是对于纠结的同学，可以每种类型的公司都试一试，多拿几个offer，最后根据自己的情况决定去哪里；坏处就是持续时间真的很长，面到最后，身心俱疲，需要做好心理准备。
我经历过的面试主要是国内互联网和部分外企的研发岗，下面也将主要介绍这两类企业，按时间先后顺序。
Indeed（FAILED） Indeed是全球最大的招聘信息搜索引擎公司，总部位于美国德州的首府奥斯汀，2012年被日本的Recruit收购，然后成立了Indeed Tokyo办公室。本文提到的Indeed都是指Indeed Tokyo，即拿到offer的话，要求去东京工作，不过可以轮转去奥斯汀总部。
Indeed是最早开始校招的，当国内公司还在实习招聘的时候，它就跑来进行校招了。我参加了2017年4月17日在北大举办的校园宣讲会，介绍了Indeed的基本情况和招聘流程，以及抽奖机械硬盘等。Indeed的办公室很有科技范，其工位设置尤为吸引人，是六边形的环形设计，每个人既可以专注于自己的工作，又便于和组内同事讨论。宣讲的人包括HR和从该校毕业的学长，这个HR是中国人，后面有一轮HR面也是他，大家可以多多留意。
Indeed最大的吸引力是，700万~800万日元的年薪，折合人民币大概四五十万吧，这样诱人的薪资，让每个路过其宣传海报的同学都驻足观看。当然其面试难度也不小，首先有一轮在线笔试，这个在线笔试有三次机会，只要有一次全部AC，就算通过。在线笔试题一共4道，难度比LeetCode稍大，但是一定提醒大家，他们家的题都有数据范围，而且范围很小，前3题用暴力解法几乎都可以过，所以一定要先试试暴力求解，不行再想DP。
通过在线笔试之后，会有一个大约30分钟的HR面，就是上面提到的来华宣讲的中国人。这个面试严格来说是Case interview，通过Skype进行，主要考察逻辑逻辑思维能力和英文口语能力。由于是中国人，所以刚开始会用中文介绍下题意，然后让你思考一下，最后用英文给出解答。我当时的题目是，如何把微信支付的流水从xxx提高到yyy。由于提前非常认真的看了http://www.caseinterview.com/的视频教学，学到很多，这次HR面顺利通过。
通过HR面之后，还有一轮Skype技术面，是从Indeed Tokyo那边打过来的，需要解算法题，通常是一题&#43;好几个follow up。不过很多是往年的原题，在一亩三分地上都有，大家可以仔细在上面看看。我当时被问到的题是之前准备过的，但是没答好，比较突兀的给出了最优解，面试官可能觉得我是背答案了吧。。。
如果这轮Skype技术面也通过的话，就可以免费飞到东京参加on-site面了，听说on-site面是3轮面试，一整个上午或一整个下午，几乎也是原题，可以在一亩三分地上找到。
说来也奇怪，Indeed每年的面试题都差不多，但通过面试的人总是寥寥无几，这才是高级的面试官，考察的是应聘者的解题思路，而不是答案。
Indeed Tokyo很不错，如果能拿到Offer，说明你很优秀，离人生巅峰也不远了。
Works Applications（FAILED） Works Applications简称WAP，是一家日本的ERP软件开发公司，ERP全称是Enterprise Resource Planning，简单理解就是面向企业用户的各种管理系统。WAP是正宗的日本企业，其风格和Indeed Tokyo截然不同，上班要求穿正装，估计各种行为规范也不少，但是钱也不少，折合人民币估计也有四十多万吧。WAP虽然总部在东京，但它在上海有办公室，国内校招生基本上都在上海办公。
WAP的招聘流程和Indeed很像，首先会有一个宣讲会，建议大家都参加，类似于报名考试。宣讲会之后会收到一个在线笔试的链接，要求3天之内做完2道编程题，题目比较简单。在线笔试通过之后，有一轮在线技术面试，使用的是牛客网平台，要求视频面时不能离开面试页面查资料。视频面也比较简单，大概Leetcode的easy~medium题。
对于WAP，前期的在线面试只是开胃小菜，好戏还在后头。通过两轮在线面试之后，会邀请去某个酒店现场面试。现场面试有三轮，全程英文，一般是先来段英文自我介绍，然后开始做题。比较搞笑的是，见到一面面试官时，被问到感觉如何，我说good，然后面试官说别人都是很nervous，我居然说good，感觉要被自己坑了，还好出的题都会做。前两面都不难，大概LeetCode中等题，第三面感觉是一个boss，已经不考LeetCode算法题了，考类似智力题的东西，比如有人被考到囚犯和帽子颜色的问题，我被问到的是怎样实现求两数的平均值，常规的(a&#43;b)/2有可能导致a&#43;b溢出，我想了很多方法，面试官都不满意，后来发现《程序员面试笔试宝典》上有。求平均值的问题可以先转换为求和，用位运算是a&#43;b=((a&amp;b)«1)&#43;(a^b)，a&#43;b就是按位加，对应二进制也是按位加，要进位的情况就是对应位都为1，所以先用a&amp;b找出需要进位的位，然后左移1位表示进位；还有些位可能只有一个1或者没有1，这部分加和的结果可以用异或表示，即a^b，所以a&#43;b=((a&amp;b)«1)&#43;(a^b)。那么，求平均值就是(a&#43;b)/2=(a&amp;b)&#43;((a^b)»1)。要是早点看了《程序员面试笔试宝典》，我估计也能拿到WAP的Offer了。
三轮技术面之后，会有一个HR面，听说如果前面的技术面过关的话，HR面会遇到日本boss，直接发放Offer；否则是一个中国人，寒暄几句之后，被告知技术面没有通过，但是可以参加暑期为期一周的实习活动，实习通过的话，也可以获得Offer。每年的实习主题都差不多，比如做一个酒店管理系统、电影院管理系统之类的，由于我觉得时间代价太高了，没有参加暑期实习。
虽然WAP的工资很好，但是要想拿Offer，比Indeed简单，LeetCode中等题足够，好好准备一下现场第三面。另外，即使拿到Offer，也要考虑一下工作内容是否符合自己的兴趣，毕竟ERP和当前火热的AI相比还是太古老了，而且穿正装上班估计也只此一家了。
深信服（OFFER） 深信服公司是面向企业的安全与云计算解决方案供应商，可以理解为企业版360。听说创始人是从华为跳出来的，公司整体风格和华为很像，从宣讲会上还听说这家薪资不错，尤其是博士，宣称比BAT华为都高。
深信服的提前批招聘也很早，7月初就来所里宣讲了。首先有两轮电话技术面试，面试官都会提前短信约时间，给人感觉不错。电话面试的内容比较广，网络、操作系统、C&#43;&#43;、算法等都会问到。面试官手里应该有一个问题清单，挨个问下去，不会的跳过，节奏比较快。所以面试深信服之前，要好好复习计算机基础，尤其是网络相关的，因为其主营业务和网络密切相关。
能通过前两轮电话面试的，基础都很扎实，接下来会邀请去参加他们的星云计划暑期夏令营。原本夏令营是要去深圳总部的，但是北京的很多同学都没时间，于是临时把夏令营分成了南北两波，北京的同学被安排在九华山庄度假村。在这里会听好多深信服的介绍和讲座，其中有一个清华的博士，在校期间发过很牛的Paper，自称是那一届的全国博士Top5，谈了很多选择去深信服的理由，核心思想是博士在深信服有很大的自主权，可以试错，主导一些项目，而且薪资估计真的很高。最后会有一个Boss面，主要是问项目经历，Boss是连夜赶来北京的，面试的时候哈欠连天，也没问什么实质性的问题。去的人应该都过了。其实这个夏令营主要是去体验生活的:)
最后的Offer，中规中矩，薪资并没有想象的高，也不是自己喜欢做的事情，拒。
华为（OFFER） 华为就不用介绍了，早年凭借电信网络产品赚得盆满钵满，近几年的智能手机业务更是冲出国门走向世界，真的是我国民族企业的榜样。华为严格来说是一个制造商企业，不算互联网企业，而且其招聘比较看重学历，给人感觉有点像国企。但是毕竟其产品都是计算机相关设备，对计算机专业人才的需求还是很旺盛的。华为的另一大特点是有钱，并且舍得给员工砸钱，我上一届的硕士师兄去了华为，工资碾压BAT，成功倒挂一大批老员工。仔细看看近几年各大重点高校的毕业生去向，去华为的占了很大比例，如果你想快速积累财富，又能吃苦，去华为能很好的满足你的要求。
因为师兄去了华为，3月份收到内部通知说可以提前批内推了，于是把简历给了师兄进行内推。7月初的时候要求做一个性格测试，华为特色，其他公司都没有这一环节，据说是在筛选符合华为价值观的同学。7月22日参加华为提前批优招，真的是优招，去的大部分是清北中科院的，猜测还要求本科是985高校。 优招面试很简单，因为是业务面试，主要问问项目，面试官是那种成功人士风格的Boss。二面就不问技术了，会问周围同学老师是怎样评价自己的，科研压力大吗，想去哪工作之类的，类似的问题也是在衡量应聘者和华为公司的match程度。我应该是非常match的，面试结束的时候，Boss还跟我握手了！
优招面试结束后没几天，会有一个在线笔试，编程题，三道题，最好全AC，我是前两题AC，第三题过了80%。至此，华为所有的笔试面试都结束了。但是直到9月初，才被再次邀请去华为北研参加Offer沟通会，这个会和大一刚入学参加各大社团的招新差不多，华为的各大部门开始抢人，我去了2012实验室中央软件院。
四维图新（OFFER） 华为虽然是最早面完的，但是Offer迟迟没有下来，国内其他互联网公司又还没开始面试，心急之下，看到四维图新在招聘C&#43;&#43;研发工程师，做地图搜索的，和自己有点关系。网上查了一下，发现还是腾讯地图的数据供应商，而且还是母校武大测绘学院有很紧密的合作，应该是个靠谱的公司。
跑去面试，可能是公司比较小，面试流程还很原始，直接在接待室问了我几个问题，有些题目有一定难度，连红黑树都被问到了。然后被直接拉去工位，打开VS，开始编程，所幸全部AC。等了一会，直接HR面，拿到普通OFFER。我说想申请SP，HR说下周再来一轮Boss面吧。于是下周又跑去Boss面，Boss果然是Boss，气场就不一样，问题也很灵活，都是他们地图搜索开发过程中的实际问题，比如给定中国地图和一个GPS坐标，怎样快速定位这个坐标。类似的题目很有意思，虽然有一个题目回答得不是很好，但总体上聊得还比较开心。Boss面完之后，又一轮HR面，被告知拿到SP，而且如果能来实习，实习表现好，且能申请到户口指标，则有可能有户口。
这个Offer是我校招季拿到的最早的Offer，薪资还不错，也算是稳住了阵脚。但是公司规模和名气都不算大，暂时拿来保底吧。
百度（OFFER） 百度公司和我的专业是最匹配的了，国内做搜索技术最强的，非百度莫属。百度很人性化的一点是，公司不同部门的招聘分开进行，互不冲突，所以可以同时向不同部门投递简历。我就一口气投递了网页搜索部、商务搜索部和基础架构部。很幸运，同时拿到了这三个部门的提前批Offer。
百度各部门的面试流程都很像，前两轮技术面，第三轮是Boss面或者HR面，越往后面试官的级别越高，第三面的面试官很可能就是你未来的Leader。第一轮面试比较基础，问一些网络、操作系统、C&#43;&#43;的基础知识，然后写两道算法题。第二面先写两道算法题，然后问项目，项目问得很细，我的几个搜索引擎的项目，不但问了项目的实现细节，还问了很多follow up，比如，在实战场景中，千亿级别的数据量，怎样建索引使得查询更高效，如何实现怎个搜索过程等。因为面的是搜索部门，他们对相关的技术非常了解，不要抱任何侥幸心理，不会就说不会，切莫班门弄虎。第三面Boss面比较宏观，问问职业规划，如果面试官对你比较感兴趣，会主动介绍本部门的工作，凤巢的三面面试官甚至直接加了我的微信，受宠若惊啊。
提前批面试完毕之后，9月初会有一个在线笔试，这个笔试也会刷人，所以不要掉以轻心，一定要认真准备。我当时是因为宿舍网络问题，被坑死了，那个在线笔试的系统也很变态，是个国外的系统，动不动就掉线，还只能登陆3次，超过自动退出。于是，很悲剧的3题只AC了2题。之后的几天，一直寝食难安，担心会栽在最后的笔试上。
所幸，没过多久，收到了电话通知，笔试通过，需要确定部门，让我从三个部门中选一个。我当时那个纠结啊，网页搜索部、商务搜索部和基础架构部都是百度非常核心的部门，基架的低层技术很强，网搜是典型的文本检索，商搜是广告检索，网搜的三面面试官对我很好，时不时在微信上联系我；我和商搜的三面面试官也聊得很开心，商搜是百度最赚钱的部门，各种大牛非常之多。几番权衡之后，选择了商搜（凤巢），同时也拿到了SP。
Microsoft（OFFER） 微软是我面的唯一一个美国外企，面试流程数它最多了，前后经历了：1轮在线笔试&#43;2轮skype面试&#43;3轮on-site面试。
首先，要拿到微软的skype面试机会就很难，需要通过Hihocoder的在线笔试。Hihocoder的题型和难度都相比于LeetCode复杂得多，我有一次很幸运的做到了前100名好像，拿到了skype面试机会。两轮skype面试难度也不小，比如search range，不但要求bug free，还要求你写测试用例；还比如对快排进行优化；手写堆排序；概率题等。微软的在线编程和skype面试和国内互联网不太一样，建议大家看看一亩三分地上的面经。
过了两轮skype面之后，会被邀请去参加他们的探星夏令营，大概是在8月中旬，地点就在丹棱街的微软大厦。探星夏令营第一天是参观，我因为实验室忙就没去，第二天是三轮面试。我因为研究的方向是搜索引擎，所以被安排到bing组面试了。微软的现场面试难度也不小，不是像LeetCode那样直接叫你写个DP、排序什么的，而是给出一个实际问题，需要将其抽象成一个计算机问题，然后才是代码实现。前两面顺利通过。此时已经是下午4点多了，HR说三面安排不过来，让回去等。这一等直接从8月中旬等到9月初，期间还以为是二面挂了，“让回去等”是委婉的拒绝 ，看来微软还是说话算话的。三面是Boss面，和国内互联网比较像，面项目，问了很多细节，然后根据项目衍生出一个字符串压缩的题目，让写压缩和解压缩的代码。虽然写完了，但是没保证bug free，和面试官聊了聊可能的bug以及解决方案。
过了大概一周，面试结果出来了，没有直接说给Offer，但是说面试反馈非常Positive，让加一个微信群。国庆节之前，收到微软HR电话，让我们稍安勿躁，国庆后会给正式Offer。后来直到10月31日，才收到HR的电话，正式通知Offer详情。接起电话，HR就说准备好纸笔，因为Offer内容比较多，然后就说了Package里面的各种福利，各种美金。总的来说，Package加起来在硕士里面应该是Top级别的，外企各种Balance，不加班，做的是自己喜欢的方向，而且还有可能拿户口，甚至人肉翻墙，可以说这个Offer是非常诱人的。
京东（OFFER） 京东和百度类似，也是部门自己招聘，所以可以面多个部门。我面了AI和大数据部门以及商业推荐部门。印象比较深的是，原本面了一个做分布式的组，一面发现我更适合做搜索和架构，然后就被推荐到一个做京东智能音箱的组，这个组的三面面试官是从雅虎北研过来的，听口音感觉是广东人。因为我是做搜索，智能音箱里面也需要搜索，两个人聊得很不错，面试官当场就说帮我争取SP。
面完技术面之后，过了大概一周，还要进行HR面。面试通知邮件也没说是哪个部门的。其中有个部门的HR面居然是群面，太奇葩了，也是我经历过的唯一一个群面。一屋子3个面试官，6个学生，就菜鸟网络和京东物流的对比展开讨论。首先自我介绍，有清华北大的，也有中科院各所的，还有北邮的。每次讨论我都是倒数几个发言的，对于这种压力测试，真是不适用。不过还好，HR后来跟我说我的表现不错。
HR跟我谈薪资的时候，我客套说差不多就行，后来这两个部门都拿到了Offer，薪资还真的就是差不多，白菜价。因为已经有其他选择，也没有再争取SP。听别人说争取一下能有28左右？感觉京东的定价真是因人而异啊。后来有一天还收到三面面试官的电话，问我去向定哪了，真觉得有点愧对他。
360（OFFER） 本来不打算面360，但是该公司在8月8号组织了一场中科院专场招聘会，在所有OFFER都还没有最终确定的情况下，去360逛一逛也没坏处。360的办公楼在酒仙桥，和MTK在一起，周围在施工，几乎没有吃饭的地方，给人的第一印象不是很好。10点钟到现场之后，已经人山人海了，和菜市场没什么区别，中间等待的时间都超过了面试时间。
面试分为三轮，前两轮是技术面，第三轮是HR面。一面问了一些基础知识，写了一两个算法题。二面遇到了负责360地图开发的程序员，因为地图中也涉及POI搜索，聊得很欢。HR面被问到知道360的哪些产品，虽然我现在一个360的产品都不用了，但是知道的还是不少。
面完之后，觉得Offer稳了，然后开心的回所里。第二天收到邮件通知，面试通过，还需参加一个在线笔试，类似于行测。做完之后，查看状态，被告知所有面试笔试都通过了，个人信息已经在Offer池中，但是没有正式Offer。Offer池是什么鬼，也就是没人要被扔到池子里等人捞呗。问了下其他人，大部分也是被扔到池子里了，只听说有一个人收到书面Offer。从此对360无感，无论是你们组织面试，还是我们参加面试，费了一天劲，硬是不发OFFER，坑爹。后来在10月16日，收到一封360的邮件，正式书面Offer，难道是被人相中捞起来了，真是无语。拒。
阿里巴巴（FAILED） 阿里内推只能选一个部门，内推失败之后也只有一次校招机会，所以大家选部门一定要慎重，根据自己的实力和兴趣进行选择。当时群里给出了蚂蚁金服的内推消息之后，我第一时间就选择内推蚂蚁金服了。结果面了两轮之后查状态已经挂了，也没感觉面得差。可能是因为内推蚂蚁金服的人太多了，实力要求也很高，而且自己做搜索引擎的，和蚂蚁金服不太match。
因为内推挂了之后，无法再面其他部门了。只能参加校招流程，校招在线笔试之后一直就没消息，状态也没更新，难度笔试挂了？
...</p>
  </div>
  <footer class="entry-footer"><span title='2018-02-04 19:03:36 +0800 CST'>February 4, 2018</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to 伪·2018届校招面经" href="http://localhost:1313/posts/2018-02-04-2018-campus-recruiting/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">厦门之行
    </h2>
  </header>
  <div class="entry-content">
    <p>2017年12月7日~13日，打着参加“第三届全国质谱分析学术报告会”的旗号，实验室一行11人开启了为期一周的厦门之旅。有关学术交流的总结报告，已经在实验室内部分享了，这篇博客还是来聊聊吃喝玩乐的事吧:)
第一次乘坐飞机 本次出行分为飞机组和火车组，大部队说飞机不安全要坐火车，我因为想体验一下乘坐飞机的感受，于是选择了飞机组。第一次坐飞机，体验有三点：1）快。从北京到厦门，横跨整个中国，只花了3个小时，真的好快，除去吃午餐等时间，连一部电影都没看完！2）噪。起飞和降落的时候噪声特别大，平飞的时候噪声也不小，而且快要到目的地时，会有短暂的耳胀，孙老师说第一次坐飞机的人好像都会出现耳胀的情况。还有就是有时候飞机比较颠簸，放在桌子上的水都快晃出来了。3）美。我因为第一次坐飞机，特地选了一个靠窗的位置，想体验一把俯瞰神州大地的感觉。从窗户往下看时，地形地貌和谷歌卫星地图一摸一样，窗外的云就像一朵朵棉花糖，很漂亮，很像各种神话剧中的天庭。
飞机上不让开手机，这是在北京首都国际机场起飞前抓拍的照片，以后坐飞机记得带相机
南国风光 下飞机之后，立即体验到了厦门这座城市的“热情”，20℃左右的温度，卸下厚重的羽绒服，看着路边的红花绿叶正艳，来到沙滩上，吹吹海风，一身清爽。南方的城市由于经常下雨，街道看起来很干净，柏油马路显露着其原本的黝黑色，路边的叶子绿的发亮，不像在北京被蒙上厚厚的一层灰。路上车辆和红绿灯不多，也很少听到鸣笛，听说厦门全岛禁止鸣笛，斑马线处虽然没有红绿灯，但是有摄像头，强制车辆遇到行人时必须礼让。这种规定在北京是不可能实行的吧。总体而言，厦门彰显了南方城市应有的魅力，和杭州类似，但又更加清新靓丽，是一个休闲生活的好地方。
厦门大学——也许是中国最美丽的大学 本次参会，我们特地提前一天到达，留出时间来参观游览，地点之一就是厦门大学。厦大很美，这是来自一个在武大待了4年的人的由衷赞美。得益于其依山傍水的地理位置，校园内有锦绣的芙蓉湖、美丽的情人谷水库等景点，气氛十分静谧，这点相比于武大小小的鉴湖就好很多。由于地处热带，校园内随处可见高大挺拔的棕榈树，配上古朴的清水墙、多彩的琉璃顶，给人一种别样的美感。如果你要问厦大和武大哪个更美，我只能说她们都美！武大是幽静娴雅的大家闺秀，厦大则像开放热情的新时代女子。武大更加符合中国传统的园林审美，厦大更具风情和现代气息。两校都有山有水，都无愧于中国最美丽的大学的称号！
看见有人在厦大的情人谷水库泛舟，真是“亦可赛艇”呀:)
厦大还有一个特别的地方——芙蓉隧道，长达一公里，隧道内壁两侧，画满了风格各异，色彩缤纷的涂鸦，号称是中国最文艺的隧道，中国最长的涂鸦隧道。致青春，怀念那种开放、包容的大学氛围。
环游鼓浪屿 会议结束的那天下午，我们前往国家5A级旅游景区鼓浪屿风景名胜区游玩。鼓浪屿，面积不到2平方千米，人口约2万，有“海上花园”、“万国建筑博览会”、“钢琴之岛”之美称。除环岛电动车外不允许机动车辆上岛，因此气氛幽静。2005年《中国国家地理》杂志将鼓浪屿评为“中国最美的城区”第一名。2017年7月在波兰克拉科夫举行的第41届世界遗产大会上被正式列入《世界遗产名录》。鼓浪屿、厦门岛和大陆的关系，就像月球、地球和太阳的关系。
我们首先从厦门国际邮轮中心乘坐邮轮前往鼓浪屿的三丘田码头，邮轮北边能看到远处横跨鹭江海沧大桥，非常的简洁漂亮，据说是亚洲第一、世界第二（仅次于丹麦）的三跨连续全漂浮钢箱梁悬索桥，代表着20世纪中国建桥水平最高成就。由于是国际邮轮中心，所以也能看到不少外国邮轮，我当时就看到了欧洲和韩国的邮轮经过。
20分钟之后，就到达了鼓浪屿的三丘田码头。我们沿着鼓浪屿的海岸线，优哉游哉的走着，嬉笑打闹，听着浪涛声，赏着落日余晖，好不惬意。
我们原本是打算步行环岛游览一周的，但是走到卢戆章雕塑的地方，好多人都走不动了，打算穿过岛屿，提前返回。我个人其实挺想继续前进到鼓声洞的，鼓浪屿名称的由来就是因为在鼓声洞能听到阵阵浪涛拍击岩洞而发出轰隆巨响。
横穿鼓浪屿的路不是很好走，蜿蜒曲折、上下颠簸，走到龙头路小吃街的时候，大家都饿得不行。小吃街排队的食客特别多，为了早点吃饱，大家分头行动，每两三个人排一家店，所以最终还吃了不少美食，比如沈家闽南肠粉、小马哥起司马铃薯、汤满贯等。有意思的是，在沈家闽南肠粉和小马哥起司马铃薯的中间，有一家土耳其冰淇淋店，两边的食客都排起了长龙，唯独这家店门前冷落鞍马稀。大家吃着美食就开始聊起来了，虽说厦门冬天不冷，但也没有热到对冰淇淋有那么大的渴望。更重要的是，走到此处的游客肯定饿了，首先想到的是填饱肚子，冰淇淋属于饭后甜点，应该算“奢侈品”了，如果这个店换成“土耳其烤肉”，估计能火，哈哈。
岛上其实还有很多景点，比如风琴博物馆、菽庄花园、日光岩、海底世界等，但是我们都没进去，可能是因为沿途的风景太美了，这些收费的室内景点还不足以吸引我们吧。鼓浪屿的风景太美，可玩、可看的景点太多，半天的时间绝对不够用。下次再去，一定要细细品味。
http://j.map.baidu.com/M2cPN
厦门植物园 回北京之前，我们去了火车站附近的厦门植物园游玩。厦门植物园也称为万石植物园，背靠五老峰南普陀，集植物景观、自然景观、人文景观于一体，景色相当不错。我们沿路经过了百花厅、奇趣植物区、新碑林、摩崖石刻、长寿峡、半山观景台、多肉植物区、雨林世界、药用植物区，看到了很多奇花异草，整个行程在多肉植物区看到高大的仙人掌时达到高潮，非常值得游览的一个景点。
厦门植物园石碑 类似食人花的猪笼草，开启之后像一个笼子 奇丑无比的白花异木棉 万石丛中 半山观景台，背景是厦门世茂双子塔 疯狂生长的仙人掌和仙人球 类似毛毛虫的仙人掌。。。 放了一个大招，生出许多仙人掌:) 胡吃海喝 在厦门的这一周，大家都说不是在吃就是在吃的路上，不论是酒店的自助餐还是在外面吃饭，都吃得很不错，我基本上每餐都是十分饱。在酒店的伙食，相对来说，早餐是最好的，午餐和晚餐比较一般，可能是因为早餐酒店提供，午餐和晚餐是会议主办方提供吧，毕竟会议注册费很便宜，伙食也不会太好。不过每餐都有海鲜、厦门特色沙茶面、各种肉、水果、甜点、饮料，相比于北京的食堂是好太多了。
丰盛的早餐
到厦门的第一天晚上，我和师弟去中山路小吃街逛了逛，结果并没有任何惊喜，感觉全国的小吃街都差不多：烧烤、臭豆腐、各种煎饼包子、粥、饼。中山路的新华书店倒是值得一逛，他们家第三层的书不少，国内外文学、小说、工具书一应俱全，一改我对新华书店只有教科书的旧思想。
在外面吃的话，每餐必点被称为花蛤的“虫子”，还有另一种称为蛏（cheng）子的“虫子”，和花蛤很像，但是是长方形，且有两条美腿。知乎上有一个回答仔细的辨析了花蛤、蛏子、蚬子、蚶子、蛤蜊、海瓜子、贝壳的区别，很有意思。不过话说这些海底动物长得都很奇怪，有些还有很多软体触角，看着让人恶心。席间，有个师兄讲了个笑话，问为啥海底动物长得都这么丑，答案是因为海底没光，反正都看不见，大家就随便长长了:)。
说到海产品，必不可少的是鱼了，厦门的清蒸金昌鱼非常好吃，味道鲜美，没有小刺，和上次在杭州吃到的西湖醋鱼简直是一个天上，一个地下，强烈推荐。
...</p>
  </div>
  <footer class="entry-footer"><span title='2017-12-16 10:29:58 +0800 CST'>December 16, 2017</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to 厦门之行" href="http://localhost:1313/posts/2017-12-16-a-trip-to-xiamen/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">逻辑回归之Python应用实例
    </h2>
  </header>
  <div class="entry-content">
    <p>上一篇博客主要介绍了逻辑回归的理论知识，这篇博客咱们用Python机器学习包sklearn中的LogisticRegression做一个分类的实例。
数据还是学生样本，只有两个特征，分别是两门课的分数score1和score2，类标号y表示这个学生是否能被录取。先上分类效果图：
完整的Python代码如下：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 # -*- coding: utf-8 -*- &#34;&#34;&#34; Created on Wed Nov 08 17:49:41 2017 @author: zhenlin &#34;&#34;&#34; import numpy as np import pandas as pd from sklearn.cross_validation import train_test_split from sklearn.linear_model import LogisticRegression import matplotlib.pyplot as plt from sklearn.metrics import precision_recall_curve from sklearn.metrics import classification_report # 1. 构造数据 sample_number = 200 # 第一个高斯分布参数 mean1 = [0, 4] # 两个维度上的均值 cov1 = [[5, 3], [3, 10]] # 两个维度的协方差矩阵，必须满足对称半正定 # 第二个高斯分布参数 mean2 = [7, 5] cov2 = [[7, 2], [2, 15]] # 从两个二元高斯分布中随机采样数据点 class1_x1, class1_x2 = np.random.multivariate_normal(mean1, cov1, sample_number).T # .T表示转置 class2_x1, class2_x2 = np.random.multivariate_normal(mean2, cov2, sample_number).T # 两个高斯分布对应两个类标号 data = [[class1_x1[i],class1_x2[i],0] for i in range(sample_number)]&#43;[[class2_x1[i],class2_x2[i],1] for i in range(sample_number)] # 填充到pandas中 data = pd.DataFrame(data,columns=[&#39;score1&#39;,&#39;score2&#39;,&#39;result&#39;]) score_data = data[[&#39;score1&#39;,&#39;score2&#39;]] result_data = data[&#39;result&#39;] # 2. 训练模型 average_precision = 0 # 平均准确度 iters = 10 # 交叉验证次数 for i in xrange(iters): # 数据划分，80%用于训练，20%用于预测 x_train, x_test, y_train, y_test = train_test_split(score_data, result_data, test_size = 0.2) # 构造默认逻辑回归模型 model = LogisticRegression() # 训练 model.fit(x_train, y_train) # 预测 predict_y = model.predict(x_test) # 计算测试集上的准确度 average_precision &#43;= np.mean(predict_y == y_test) average_precision /= iters # 3. 绘制分类面 - 法1 x1_min, x1_max = score_data[&#39;score1&#39;].min() - .5, score_data[&#39;score1&#39;].max() &#43; .5 def generate_face(prob): y = -np.log(1.0 / prob - 1.0) n = 500 x1 = np.linspace(x1_min, x1_max, n) # w1x1&#43;w2x2&#43;b=y x2 = (-model.coef_[0][0] / float(model.coef_[0][1])) * x1 &#43; (y - model.intercept_) / float(model.coef_[0][1]) return x1, x2 pos_data = data[data[&#39;result&#39;] == 1] neg_data = data[data[&#39;result&#39;] == 0] plt.scatter(x = pos_data[&#39;score1&#39;], y = pos_data[&#39;score2&#39;], color = &#39;black&#39;, marker = &#39;o&#39;) plt.scatter(x = neg_data[&#39;score1&#39;], y = neg_data[&#39;score2&#39;], color = &#39;red&#39;, marker = &#39;*&#39;) face_04_x1, face_04_x2 = generate_face(0.4) face_05_x1, face_05_x2 = generate_face(0.5) face_06_x1, face_06_x2 = generate_face(0.6) plt.plot(face_04_x1, face_04_x2) plt.plot(face_05_x1, face_05_x2) plt.plot(face_06_x1, face_06_x2) plt.xlim(score_data[&#39;score1&#39;].min(), score_data[&#39;score1&#39;].max()) plt.ylim(score_data[&#39;score2&#39;].min(), score_data[&#39;score2&#39;].max()) plt.xlabel(&#39;score1&#39;) plt.ylabel(&#39;score2&#39;) plt.legend([&#39;prob_threshold = 0.4&#39;, &#39;prob_threshold = 0.5&#39;, &#39;prob_threshold = 0.6&#39;], loc=&#39;center left&#39;, bbox_to_anchor=(1, 0.865)) plt.show() # 4. 绘制分类面 - 法2 pos_data = data[data[&#39;result&#39;] == 1] neg_data = data[data[&#39;result&#39;] == 0] h = 0.02 s1_min, s1_max = score_data[&#39;score1&#39;].min() - .5, score_data[&#39;score1&#39;].max() &#43; .5 s2_min, s2_max = score_data[&#39;score2&#39;].min() - .5, score_data[&#39;score2&#39;].max() &#43; .5 # 生成s1在[s1_min, s1_max]，且s2在[s2_min, s2_max]的网格数据点 # meshgrid含义参见：http://blog.sciencenet.cn/blog-791749-675394.html s1, s2 = np.meshgrid(np.arange(s1_min, s1_max, h), np.arange(s2_min, s2_max, h)) # 把两个坐标的值按列拼在一起构成二维数据点 Z = model.predict(np.c_[s1.ravel(), s2.ravel()]) # 绘制边界和散点 Z = Z.reshape(s1.shape) # 坐标点是(s1[i], s2[i])，对应颜色是Z[i]，颜色主题使用plt.cm.Paired plt.pcolormesh(s1, s2, Z, cmap = plt.cm.Paired) plt.scatter(x = pos_data[&#39;score1&#39;], y = pos_data[&#39;score2&#39;], color = &#39;black&#39;, marker = &#39;o&#39;) plt.scatter(x = neg_data[&#39;score1&#39;], y = neg_data[&#39;score2&#39;], color = &#39;red&#39;, marker = &#39;*&#39;) plt.xlim(s1.min(), s1.max()) plt.ylim(s2.min(), s2.max()) plt.xlabel(&#39;score1&#39;) plt.ylabel(&#39;score2&#39;) plt.show() # 5. 评估模型 # 对于测试数据，模型输出1的概率 answer = model.predict_proba(x_test)[:,1] # 计算不同概率阈值下的P和R precision, recall, thresholds = precision_recall_curve(y_test, answer) # prob &gt; 0.5的报告为1 report = answer &gt; 0.5 print(classification_report(y_test, report, target_names = [&#39;neg&#39;, &#39;pos&#39;])) print(&#39;average precision: %f&#39;%average_precision) # 6. 绘制PRC曲线 # step阶跃图，在点(recall[i],precision[i])进行跳变 plt.step(recall, precision, color=&#39;b&#39;, alpha=0.2, where=&#39;post&#39;) # 对PRC下方填充颜色 plt.fill_between(recall, precision, step=&#39;post&#39;, alpha=0.2, color=&#39;b&#39;) plt.xlabel(&#39;Recall&#39;) plt.ylabel(&#39;Precision&#39;) plt.ylim([0.0, 1.05]) plt.xlim([0.0, 1.0]) plt.title(&#39;2-class Precision-Recall curve&#39;) plt.show() 下面将逐模块介绍代码细节，大神可以略过。
...</p>
  </div>
  <footer class="entry-footer"><span title='2017-12-05 21:20:01 +0800 CST'>December 5, 2017</span>&nbsp;·&nbsp;4 min</footer>
  <a class="entry-link" aria-label="post link to 逻辑回归之Python应用实例" href="http://localhost:1313/posts/2017-12-05-logistic-regression-in-python/"></a>
</article>
<footer class="page-footer">
  <nav class="pagination">
    <a class="prev" href="http://localhost:1313/posts/page/2/">
      «&nbsp;Prev&nbsp;2/8
    </a>
    <a class="next" href="http://localhost:1313/posts/page/4/">Next&nbsp;4/8&nbsp;»
    </a>
  </nav>
</footer>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">bitJoy</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
