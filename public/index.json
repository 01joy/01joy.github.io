[{"content":"\n基本信息 论文标题：Enhancing Embedding Representation Stability in Recommendation Systems with Semantic ID 作者单位：Meta 论文链接：https://arxiv.org/pdf/2504.02137 来源：RecSys 2025 Motivation：论文要解决的问题是什么 搜推广的模型严重依赖于item id embedding的表征质量，但在工业场景下，搜推广的id表征存在如下挑战：\nid量级非常大，常常是数十亿甚至是百亿的规模。因此，通常不可能给每个id一个单独的embedding（即文中的individual embedding, IE），IE的成本太高 id分布非常不均匀，马太效应严重。文中统计：0.1%的头部item占据了25%的曝光量；5.5%的腰部item占据了50%的曝光量；94.4%的尾部item只占据了25%的曝光量 id分布漂移严重：搜推广场景中item的变化非常频繁，无时无刻不在发生着新id的产生和旧id的退出，而且不同id存活的时间周期也不尽相同，所以id的准入准出策略很难完美适配所有item 针对上述问题，常见的做法是对item id采用hash然后查emb的方式（即文中的random hash，RH），将所有id hash到一个固定大小的空间，然后查emb。但是RH方式有如下缺点：\n存在hash冲突，把不相关的id hash到一个桶里，导致语义混乱，学习效果不佳 无法解决id分布漂移的问题，比如hash到同一个桶的A、B两个id，如果B出现频率变高，则会带偏A的分布，影响了A的效果 无法进行知识共享，例如新出了商品iphone15，iphone15无法共享到老的iphone14的emb知识，iphone15的id emb必须完全重新学习。针对这种情况，作者做了一个更加极端的AA实验，就是copy一个完全相同的商品，只换item id，如果是IE或者RH策略，则新商品由于id emb是随机初始化的，效果不佳，这是id-based的通病 基于前缀n-gram的semantic id表征方法 针对上述问题，作者沿用了semantic id的思路，首先使用内容理解团队产出的文本、图片等多模态emb，然后基于过去3个月的item多模态emb，训练RQ-VAE模型，并产出所有item的semantic id。\n上述过程都是常规操作，重点在于如何基于semantic id得到item emb表征。假设semantic id是L层，每层的codebook size是K：\n最常规的做法：每层都初始化一个K*d的emb table，每层sid查各自的emb table，然后把L层的sid emb加起来。但是本文完全没有提这种方法，也没有和这种方法比较，非常奇怪。 为了比较，我个人再详细描述下这种常规做法。比如老item A的sid是(c1,c2,c3)；新来一个item B，它的sid是(c1,c2,c4)。用常规方法，A的emb是c1+c2+c3，B的emb是c1+c2+c4。两者c1、c2是可以共享的，所以常规方法也能起到一定的知识共享的效果，共享项有2项：c1、c2。但是因为RQ-VAE的沙漏问题，c2很有可能是沙漏瓶颈，信息量不足。 作者对比了Table 1中的几种方法： Trigram和Fourgram差不多，如果L=3用Trigram、L=4用Fourgram的话，本质上是把L个sid映射成了一个无冲突的int。但是这种方法映射出来的int数量太多了，是\\(K^L\\)。如果K=1024、L=3，则\\(K^L\\)就已经超过10亿了，这和直接无冲突的IE方法一样了，而且存在新id无法共享老id学到的知识的问题 All bigrams，就是所有的sid的2-gram。还是上面的例子，A的emb相当于\\(c_1c_2+c_2c_3\\)，B的emb相当于\\(c_1c_2+c_2c_4\\)，两者可共享\\(c_1c_2\\)项，相比于常规方法，虽然共享项数变少了，但粒度更精细了，孰好孰坏未可知。由Table 2可知，All bigrams的效果至少比Trigram和Fourgram好很多了，而且如果层数L越大，可共享项越多 Prefix-ngram（简称Prefix-SID方法），本文提出的新方法，把所有前缀组合成新id查emb，然后所有emb再求和。还是上面的例子，A的emb相当于\\(c_1+c_1c_2+c_1c_2c_3+c_2+c_2c_3+c_3\\)，B的emb相当于\\(c_1+c_1c_2+c_1c_2c_4+c_2+c_2c_4+c_4\\)，两者可共享\\(c_1, c_1c_2, c_2\\)三项，比之前的所有方法可共享的信息都多，而且如果层数L越大，可共享项越多，因此这种方法的效果最好，训练也最稳定 实验结果很丰富，做了很多分析，Prefix-SID方法有如下优势：\n相比于IE和RH方法，Prefix-SID方法对中长尾item的提升尤其显著，因为新id和老id的表征有了知识共享 对id分布漂移问题更不敏感：由于电商模型训练时消费数据的顺序是和数据的时间一致的，比如一个月的数据，按照1号、2号、\u0026hellip;31号这样的时间先后顺序依次训练，理论上4号的模型在4号的测试集上的效果是最好的。作者做了一个实验，分别用20号和4号的模型都在4号的测试集上进行评测，看看20号的模型指标相比4号降低了多少。作者发现，使用Prefix-SID方法和IE方法，两者的指标降低幅度都差不多，都比较小。首先IE方法由于不存在hash冲突，所以20号的模型仍然能比较好地预测4号的数据；其次，Prefix-SID方法虽然有hash冲突，但是因为冲突的item都是语义相似的，可以进行新老item的知识共享，所以这个冲突反而是好事，对模型效果无影响。但是作者发现RH方法的20号的模型在4号数据上评测指标下降比较多，因为有hash冲突，而且冲突是随机的，20号的分布已经变化很大了，导致在4号数据上效果不佳。Table 4的指标越小越好。 基于Prefix-SID方法虽然也有hash冲突，但是冲突到同一个semantic id的item表征更相似，而RH冲突到同一个桶里的item是完全随机的，相似度差。作者以IE为base，把Prefix-SID和RH都各自都冲突到同一个桶的IE emb提取出来，计算类内相似度和类间相似度，发现基于Prefix-SID的类内相似度方差小，类间距离大，说明Prefix-SID确实能把相似item聚到一起。 评论 可借鉴 基于Prefix-SID方法确实能提高新item和老item的信息共享数量，方法值得借鉴 论文实验分析很丰富 可改进 基于Prefix-SID方法居然没有和最常规的加和方法比较，是本文最大的不足 ","permalink":"http://localhost:1313/posts/2025-10-09-meta-prefix-ngram-sid-paper-reading/","summary":"\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/2025-10-09-meta-prefix-ngram-sid-paper-reading/meta-ngram-sid-paper-cover.png\"\u003e\u003c/p\u003e\n\u003ch1 id=\"基本信息\"\u003e基本信息\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e论文标题：Enhancing Embedding Representation Stability in Recommendation Systems with Semantic ID\u003c/li\u003e\n\u003cli\u003e作者单位：Meta\u003c/li\u003e\n\u003cli\u003e论文链接：\u003ca href=\"https://arxiv.org/pdf/2504.02137\"\u003ehttps://arxiv.org/pdf/2504.02137\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e来源：RecSys 2025\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"motivation论文要解决的问题是什么\"\u003eMotivation：论文要解决的问题是什么\u003c/h1\u003e\n\u003cp\u003e搜推广的模型严重依赖于item id embedding的表征质量，但在工业场景下，搜推广的id表征存在如下挑战：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eid量级非常大，常常是数十亿甚至是百亿的规模。因此，通常不可能给每个id一个单独的embedding（即文中的individual embedding, IE），IE的成本太高\u003c/li\u003e\n\u003cli\u003eid分布非常不均匀，马太效应严重。文中统计：0.1%的头部item占据了25%的曝光量；5.5%的腰部item占据了50%的曝光量；94.4%的尾部item只占据了25%的曝光量\u003c/li\u003e\n\u003cli\u003eid分布漂移严重：搜推广场景中item的变化非常频繁，无时无刻不在发生着新id的产生和旧id的退出，而且不同id存活的时间周期也不尽相同，所以id的准入准出策略很难完美适配所有item\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: center\"\u003e\u003cimg loading=\"lazy\" src=\"/posts/2025-10-09-meta-prefix-ngram-sid-paper-reading/meta-ngram-sid-fig2.png\"\u003e\u003c/th\u003e\n          \u003cth style=\"text-align: center\"\u003e\u003cimg loading=\"lazy\" src=\"/posts/2025-10-09-meta-prefix-ngram-sid-paper-reading/meta-ngram-sid-fig3.png\"\u003e\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e针对上述问题，常见的做法是对item id采用hash然后查emb的方式（即文中的random hash，RH），将所有id hash到一个固定大小的空间，然后查emb。但是RH方式有如下缺点：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e存在hash冲突，把不相关的id hash到一个桶里，导致语义混乱，学习效果不佳\u003c/li\u003e\n\u003cli\u003e无法解决id分布漂移的问题，比如hash到同一个桶的A、B两个id，如果B出现频率变高，则会带偏A的分布，影响了A的效果\u003c/li\u003e\n\u003cli\u003e无法进行知识共享，例如新出了商品iphone15，iphone15无法共享到老的iphone14的emb知识，iphone15的id emb必须完全重新学习。针对这种情况，作者做了一个更加极端的AA实验，就是copy一个完全相同的商品，只换item id，如果是IE或者RH策略，则新商品由于id emb是随机初始化的，效果不佳，这是id-based的通病\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"基于前缀n-gram的semantic-id表征方法\"\u003e基于前缀n-gram的semantic id表征方法\u003c/h1\u003e\n\u003cp\u003e针对上述问题，作者沿用了semantic id的思路，首先使用内容理解团队产出的文本、图片等多模态emb，然后基于过去3个月的item多模态emb，训练RQ-VAE模型，并产出所有item的semantic id。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/2025-10-09-meta-prefix-ngram-sid-paper-reading/meta-ngram-sid-fig1.png\"\u003e\u003c/p\u003e\n\u003cp\u003e上述过程都是常规操作，重点在于如何基于semantic id得到item emb表征。假设semantic id是L层，每层的codebook size是K：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e最常规的做法：每层都初始化一个K*d的emb table，每层sid查各自的emb table，然后把L层的sid emb加起来。但是本文完全没有提这种方法，也没有和这种方法比较，非常奇怪。\n\u003cul\u003e\n\u003cli\u003e为了比较，我个人再详细描述下这种常规做法。比如老item A的sid是(c1,c2,c3)；新来一个item B，它的sid是(c1,c2,c4)。用常规方法，A的emb是c1+c2+c3，B的emb是c1+c2+c4。两者c1、c2是可以共享的，所以常规方法也能起到一定的知识共享的效果，共享项有2项：c1、c2。但是因为\u003ca href=\"https://arxiv.org/abs/2407.21488\"\u003eRQ-VAE的沙漏问题\u003c/a\u003e，c2很有可能是沙漏瓶颈，信息量不足。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e作者对比了Table 1中的几种方法：\u003c/li\u003e\n\u003cli\u003eTrigram和Fourgram差不多，如果L=3用Trigram、L=4用Fourgram的话，本质上是把L个sid映射成了一个无冲突的int。但是这种方法映射出来的int数量太多了，是\\(K^L\\)。如果K=1024、L=3，则\\(K^L\\)就已经超过10亿了，这和直接无冲突的IE方法一样了，而且存在新id无法共享老id学到的知识的问题\u003c/li\u003e\n\u003cli\u003eAll bigrams，就是所有的sid的2-gram。还是上面的例子，A的emb相当于\\(c_1c_2+c_2c_3\\)，B的emb相当于\\(c_1c_2+c_2c_4\\)，两者可共享\\(c_1c_2\\)项，相比于常规方法，虽然共享项数变少了，但粒度更精细了，孰好孰坏未可知。由Table 2可知，All bigrams的效果至少比Trigram和Fourgram好很多了，而且如果层数L越大，可共享项越多\u003c/li\u003e\n\u003cli\u003ePrefix-ngram（简称Prefix-SID方法），本文提出的新方法，把所有前缀组合成新id查emb，然后所有emb再求和。还是上面的例子，A的emb相当于\\(c_1+c_1c_2+c_1c_2c_3+c_2+c_2c_3+c_3\\)，B的emb相当于\\(c_1+c_1c_2+c_1c_2c_4+c_2+c_2c_4+c_4\\)，两者可共享\\(c_1, c_1c_2, c_2\\)三项，比之前的所有方法可共享的信息都多，而且如果层数L越大，可共享项越多，因此这种方法的效果最好，训练也最稳定\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: center\"\u003e\u003cimg loading=\"lazy\" src=\"/posts/2025-10-09-meta-prefix-ngram-sid-paper-reading/meta-ngram-sid-tab1.png\"\u003e\u003c/th\u003e\n          \u003cth style=\"text-align: center\"\u003e\u003cimg loading=\"lazy\" src=\"/posts/2025-10-09-meta-prefix-ngram-sid-paper-reading/meta-ngram-sid-tab2.png\"\u003e\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e实验结果很丰富，做了很多分析，Prefix-SID方法有如下优势：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e相比于IE和RH方法，Prefix-SID方法对中长尾item的提升尤其显著，因为新id和老id的表征有了知识共享\u003c/li\u003e\n\u003cli\u003e对id分布漂移问题更不敏感：由于电商模型训练时消费数据的顺序是和数据的时间一致的，比如一个月的数据，按照1号、2号、\u0026hellip;31号这样的时间先后顺序依次训练，理论上4号的模型在4号的测试集上的效果是最好的。作者做了一个实验，分别用20号和4号的模型都在4号的测试集上进行评测，看看20号的模型指标相比4号降低了多少。作者发现，使用Prefix-SID方法和IE方法，两者的指标降低幅度都差不多，都比较小。首先IE方法由于不存在hash冲突，所以20号的模型仍然能比较好地预测4号的数据；其次，Prefix-SID方法虽然有hash冲突，但是因为冲突的item都是语义相似的，可以进行新老item的知识共享，所以这个冲突反而是好事，对模型效果无影响。但是作者发现RH方法的20号的模型在4号数据上评测指标下降比较多，因为有hash冲突，而且冲突是随机的，20号的分布已经变化很大了，导致在4号数据上效果不佳。Table 4的指标越小越好。\n\u003cimg loading=\"lazy\" src=\"/posts/2025-10-09-meta-prefix-ngram-sid-paper-reading/meta-ngram-sid-tab4.png\"\u003e\u003c/li\u003e\n\u003cli\u003e基于Prefix-SID方法虽然也有hash冲突，但是冲突到同一个semantic id的item表征更相似，而RH冲突到同一个桶里的item是完全随机的，相似度差。作者以IE为base，把Prefix-SID和RH都各自都冲突到同一个桶的IE emb提取出来，计算类内相似度和类间相似度，发现基于Prefix-SID的类内相似度方差小，类间距离大，说明Prefix-SID确实能把相似item聚到一起。\n\u003cimg loading=\"lazy\" src=\"/posts/2025-10-09-meta-prefix-ngram-sid-paper-reading/meta-ngram-sid-tab5.png\"\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"评论\"\u003e评论\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e可借鉴\n\u003cul\u003e\n\u003cli\u003e基于Prefix-SID方法确实能提高新item和老item的信息共享数量，方法值得借鉴\u003c/li\u003e\n\u003cli\u003e论文实验分析很丰富\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e可改进\n\u003cul\u003e\n\u003cli\u003e基于Prefix-SID方法居然没有和最常规的加和方法比较，是本文最大的不足\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e","title":"论文阅读：Enhancing Embedding Representation Stability in Recommendation Systems with Semantic ID"},{"content":"\n基本信息 论文标题：VL-CLIP: Enhancing Multimodal Recommendations via Visual Grounding and LLM-Augmented CLIP Embeddings 作者单位：沃尔玛 论文链接：https://arxiv.org/pdf/2507.17080 来源：RecSys 2025 Motivation：论文要解决的问题是什么 多模态q2i召回通常使用CLIP的对比学习方式进行训练，在电商场景下存在2个问题：\nCLIP这种方式通常是对图片整体的表征，缺乏细粒度的目标检测能力，尤其在电商场景，比如fig1，卖衣服场景，传统CLIP只能识别整张图片是一件T恤，难以关注T恤上的图案等细节特征；另外，电商图片往往存在很多附加背景、道具、模特等元素，会影响主体物体的表征 电商标题、属性等文本描述通常参差不齐，存在错误、堆砌、图文不符等问题，导致CLIP训练时图文对齐效果不佳 VL-CLIP解决方案 针对图片的处理：\n将图片和商品类型（product type）输入到开源模型Grounding DINO中，让模型进行目标检测，将可信度超过某个阈值且可信度最高的区域抠出来，输入到CLIP的图像encoder中。通过这步预处理，相当于对电商图片进行了关键主体识别和提取，只提取和商品最相关的主体进行图像表征。文中使用的图像编码器是ViT-B/32。 针对文本的处理：\n将商品的类型、标题、描述、性别、年龄等文本描述以及图片本身输入到Summarizer多模态大模型，让大模型产出精简、准确的文本描述\\(q_0\\) 将\\(q_0\\)和商品图文信息输入到Evaluator多模态大模型，让大模型对\\(q_0\\)的质量进行评判，如果\\(q_0\\)质量很好，则直接输出\u0026lt;STOP\u0026gt;；否则指出\\(q_0\\)的问题所在，并说明改进方法 如果第2步输出不是\u0026lt;STOP\u0026gt;，则将第2步的输出再输入到Refiner大模型，让大模型根据第2步的结果继续调整并输出更优的文本描述\\(q_i\\) 不断重复第2、3步，直到输出\u0026lt;STOP\u0026gt;，或者最多重复5遍 将产出的精准的文本描述q输入到CLIP的文本encoder中，文中使用的是BERT系列。产出的emb维度是512 上述Summarizer、Evaluator、Refiner都是VLM，文中使用的是GPT-4o，三个任务的prompt设计参考论文附录Table 9 上述对图片和文本的处理本质上是去噪，提取图片的主体物品、让文本描述更加精准。\n产出多模态emb之后，后续的操作就是常规的召回流程了，使用HNSW进行ANN召回。\n评论 可借鉴 使用Grounding DINO对图片进行主体识别，值得借鉴 使用VLM对商品标题、描述等文本信息进行去噪，值得借鉴 但如果商品量级很大的话，这两个步骤估计会很耗时 可改进 如果是q2i场景，直接用query文本是不是更真实，更接近搜索日子的真实数据分布？ ","permalink":"http://localhost:1313/posts/2025-10-08-vl-clip-paper-reading/","summary":"\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/2025-10-08-vl-clip-paper-reading/VL-CLIP-paper-cover.png\"\u003e\u003c/p\u003e\n\u003ch1 id=\"基本信息\"\u003e基本信息\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e论文标题：VL-CLIP: Enhancing Multimodal Recommendations via Visual Grounding and LLM-Augmented CLIP Embeddings\u003c/li\u003e\n\u003cli\u003e作者单位：沃尔玛\u003c/li\u003e\n\u003cli\u003e论文链接：\u003ca href=\"https://arxiv.org/pdf/2507.17080\"\u003ehttps://arxiv.org/pdf/2507.17080\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e来源：RecSys 2025\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"motivation论文要解决的问题是什么\"\u003eMotivation：论文要解决的问题是什么\u003c/h1\u003e\n\u003cp\u003e多模态q2i召回通常使用CLIP的对比学习方式进行训练，在电商场景下存在2个问题：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCLIP这种方式通常是对图片整体的表征，缺乏细粒度的目标检测能力，尤其在电商场景，比如fig1，卖衣服场景，传统CLIP只能识别整张图片是一件T恤，难以关注T恤上的图案等细节特征；另外，电商图片往往存在很多附加背景、道具、模特等元素，会影响主体物体的表征\u003c/li\u003e\n\u003cli\u003e电商标题、属性等文本描述通常参差不齐，存在错误、堆砌、图文不符等问题，导致CLIP训练时图文对齐效果不佳\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/2025-10-08-vl-clip-paper-reading/VL-CLIP-fig1.png\"\u003e\u003c/p\u003e\n\u003ch1 id=\"vl-clip解决方案\"\u003eVL-CLIP解决方案\u003c/h1\u003e\n\u003cp\u003e针对图片的处理：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e将图片和商品类型（product type）输入到开源模型\u003ca href=\"https://github.com/IDEA-Research/GroundingDINO\"\u003eGrounding DINO\u003c/a\u003e中，让模型进行目标检测，将可信度超过某个阈值且可信度最高的区域抠出来，输入到CLIP的图像encoder中。通过这步预处理，相当于对电商图片进行了关键主体识别和提取，只提取和商品最相关的主体进行图像表征。文中使用的图像编码器是ViT-B/32。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/2025-10-08-vl-clip-paper-reading/VL-CLIP-fig2.png\"\u003e\u003c/p\u003e\n\u003cp\u003e针对文本的处理：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e将商品的类型、标题、描述、性别、年龄等文本描述以及图片本身输入到Summarizer多模态大模型，让大模型产出精简、准确的文本描述\\(q_0\\)\u003c/li\u003e\n\u003cli\u003e将\\(q_0\\)和商品图文信息输入到Evaluator多模态大模型，让大模型对\\(q_0\\)的质量进行评判，如果\\(q_0\\)质量很好，则直接输出\u0026lt;STOP\u0026gt;；否则指出\\(q_0\\)的问题所在，并说明改进方法\u003c/li\u003e\n\u003cli\u003e如果第2步输出不是\u0026lt;STOP\u0026gt;，则将第2步的输出再输入到Refiner大模型，让大模型根据第2步的结果继续调整并输出更优的文本描述\\(q_i\\)\u003c/li\u003e\n\u003cli\u003e不断重复第2、3步，直到输出\u0026lt;STOP\u0026gt;，或者最多重复5遍\u003c/li\u003e\n\u003cli\u003e将产出的精准的文本描述q输入到CLIP的文本encoder中，文中使用的是BERT系列。产出的emb维度是512\u003c/li\u003e\n\u003cli\u003e上述Summarizer、Evaluator、Refiner都是VLM，文中使用的是GPT-4o，三个任务的prompt设计参考论文附录Table 9\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/2025-10-08-vl-clip-paper-reading/VL-CLIP-fig3.png\"\u003e\u003c/p\u003e\n\u003cp\u003e上述对图片和文本的处理本质上是去噪，提取图片的主体物品、让文本描述更加精准。\u003c/p\u003e\n\u003cp\u003e产出多模态emb之后，后续的操作就是常规的召回流程了，使用HNSW进行ANN召回。\u003c/p\u003e\n\u003ch1 id=\"评论\"\u003e评论\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e可借鉴\n\u003cul\u003e\n\u003cli\u003e使用Grounding DINO对图片进行主体识别，值得借鉴\u003c/li\u003e\n\u003cli\u003e使用VLM对商品标题、描述等文本信息进行去噪，值得借鉴\u003c/li\u003e\n\u003cli\u003e但如果商品量级很大的话，这两个步骤估计会很耗时\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e可改进\n\u003cul\u003e\n\u003cli\u003e如果是q2i场景，直接用query文本是不是更真实，更接近搜索日子的真实数据分布？\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e","title":"论文阅读：VL-CLIP: Enhancing Multimodal Recommendations via Visual Grounding and LLM-Augmented CLIP Embeddings"},{"content":"\n基本信息 论文标题：Generative Recommendation with Semantic IDs: A Practitioner’s Handbook 作者单位：Snap 论文链接：https://arxiv.org/pdf/2507.22224 来源：CIKM 2025 这是CIKM 2025的一篇resource文章，比较简单。核心内容是开源了一个基于semantic id的生成式推荐框架GRID，可以很方便地做各种消融对比实验。\n主要内容 主要结论如下：\n对于semantic id生成算法，简单的RQ-KMeans效果反而是最好的，好于R-VQ和RQ-VAE 生产pretrain emb的LLM模型参数量越大，效果越好，但是提升幅度有限 生产semantic id的codebook size和网络层数并不是越大越好，常规的3层，每层256个id效果反而最好 生成式推荐时，是否需要在用户行为序列基础上增加一个user id，实验发现增加user id效果反而变差，不增加user id效果最好 生成式网络结构encoder-decoder对比decoder-only，发现前者效果更好，因为前者能充分学习到行为序列完整的信息 对行为流进行滑动窗口数据增强能提升模型的泛化能力 当semantic id到item存在映射冲突时，随机选一个item的效果和对冲突item追加一个区分标识（digit），两者效果差不多 在生成式beam search的时候，限制只输出合法semantic id和不增加限制，两者效果差不多 评论 看这篇文章主要是想看看不同semantic id生产方法的对比，发现RQ-KMeans居然比RQ-VAE更好。个人感觉这两个方法效果应该差不多，后者应该更好点才对。首先，RQ-VAE的量化loss本质上和KMeans聚类是一个意思；其次，RQ-VAE还增加了一个重构loss，感觉产出来的semantic id和原始emb的信息损失应该更少。\n此外，本文的所有实验都是基于亚马逊的公开数据集，数据量肯定不能和真正的工业数据集相提并论，所以文中很多结论有可能只适用于本文的设定，换一个场景估计结论就变了，所以看看就好。\n最后，文中很多结论只写了现象，要是能增加原因分析就好了。\n","permalink":"http://localhost:1313/posts/2025-10-07-grid-paper-reading/","summary":"\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/2025-10-07-grid-paper-reading/GRID-paper-cover.png\"\u003e\u003c/p\u003e\n\u003ch1 id=\"基本信息\"\u003e基本信息\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e论文标题：Generative Recommendation with Semantic IDs: A Practitioner’s Handbook\u003c/li\u003e\n\u003cli\u003e作者单位：Snap\u003c/li\u003e\n\u003cli\u003e论文链接：\u003ca href=\"https://arxiv.org/pdf/2507.22224\"\u003ehttps://arxiv.org/pdf/2507.22224\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e来源：CIKM 2025\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e这是CIKM 2025的一篇resource文章，比较简单。核心内容是开源了一个基于semantic id的生成式推荐框架GRID，可以很方便地做各种消融对比实验。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/2025-10-07-grid-paper-reading/GRID-fig1.png\"\u003e\u003c/p\u003e\n\u003ch1 id=\"主要内容\"\u003e主要内容\u003c/h1\u003e\n\u003cp\u003e主要结论如下：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e对于semantic id生成算法，简单的RQ-KMeans效果反而是最好的，好于R-VQ和RQ-VAE\u003c/li\u003e\n\u003cli\u003e生产pretrain emb的LLM模型参数量越大，效果越好，但是提升幅度有限\u003c/li\u003e\n\u003cli\u003e生产semantic id的codebook size和网络层数并不是越大越好，常规的3层，每层256个id效果反而最好\u003c/li\u003e\n\u003cli\u003e生成式推荐时，是否需要在用户行为序列基础上增加一个user id，实验发现增加user id效果反而变差，不增加user id效果最好\u003c/li\u003e\n\u003cli\u003e生成式网络结构encoder-decoder对比decoder-only，发现前者效果更好，因为前者能充分学习到行为序列完整的信息\u003c/li\u003e\n\u003cli\u003e对行为流进行滑动窗口数据增强能提升模型的泛化能力\u003c/li\u003e\n\u003cli\u003e当semantic id到item存在映射冲突时，随机选一个item的效果和对冲突item追加一个区分标识（digit），两者效果差不多\u003c/li\u003e\n\u003cli\u003e在生成式beam search的时候，限制只输出合法semantic id和不增加限制，两者效果差不多\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"评论\"\u003e评论\u003c/h1\u003e\n\u003cp\u003e看这篇文章主要是想看看不同semantic id生产方法的对比，发现RQ-KMeans居然比RQ-VAE更好。个人感觉这两个方法效果应该差不多，后者应该更好点才对。首先，RQ-VAE的量化loss本质上和KMeans聚类是一个意思；其次，RQ-VAE还增加了一个重构loss，感觉产出来的semantic id和原始emb的信息损失应该更少。\u003c/p\u003e\n\u003cp\u003e此外，本文的所有实验都是基于亚马逊的公开数据集，数据量肯定不能和真正的工业数据集相提并论，所以文中很多结论有可能只适用于本文的设定，换一个场景估计结论就变了，所以看看就好。\u003c/p\u003e\n\u003cp\u003e最后，文中很多结论只写了现象，要是能增加原因分析就好了。\u003c/p\u003e","title":"论文阅读：Generative Recommendation with Semantic IDs: A Practitioner’s Handbook"},{"content":"\n基本信息 论文标题：Progressive Semantic Residual Quantization for Multimodal-Joint Interest Modeling in Music Recommendation 作者单位：网易云音乐 论文链接：https://arxiv.org/pdf/2508.20359 来源：CIKM 2025 Motivation：论文要解决的问题是什么 多模态emb在搜推的应用方式，通常是先将多模态emb转换成semantic id，然后把semantic id用到搜推模型中，这种方式有如下两个问题：\n模态内语义退化：多模态emb转换成semantic id通常使用RQ-VAE或者RQ-KMeans的方法，这种方法在不断残差的过程中，后续残差聚类结果已经不能反映初始emb的聚类效果了。其实就是semantic id的沙漏问题，具体可以看这篇文章，后续有空再分享这个问题。 简单来说，如下图所示，初始有DJ、Rock、Lullaby、Choir四个类，但是对残差emb（即RQ-VAE的第二层）聚类的话，初始的四个类的item就打散了，会聚到不同的簇中，也就是RQ-VAE的后续层的聚类效果已经和初始emb的聚类效果很不一样了，这就是文中说的语义退化问题 模态间建模差异：搜推场景的item通常有多种模态特征，比如文本、图像、音频等，传统方法在多模态融合方面比较简单，不能很好地捕捉多模态之间的关系。 PSRQ生产semantic id 本文是音乐推荐场景，主要用到两种模态：text和audio，分别用百川和MERT提取text和audio的模态emb。\n生产semantic id的方法如下图所示：\nfig2a是传统的RQ-KMeans的方法，每一层都用上一层的残差进行聚类。如上文所述，由于沙漏问题，会导致后续层次的semantic id存在语义退化问题 fig2b是本文新提出的PSRQ量化方法，在RQ-KMeans基础上，每一层除了有上一层的残差向量，还会concat上初始emb减去残差emb后的向量。这样就能区分出残差相似，但初始emb不同的item了，也就避免了RQ方法的沙漏问题，后续semantic id也能保留初始emb的语义信息。fig1d能看出来第二层semantic id仍然能够反映初始emb的分类效果。 Semantic id在下游的应用方法 如下图所示：\n每个item有两套多模态emb：text和audio，但是有三套semantic id，除了text和audio各自产一套semantic id之外，还会把text和audio的emb concat起来，再产一套semantic id，相当于多模态融合的semantic id semantic id的emb在排序模型中随机初始化，然后端到端训练 semantic id在用户建模时，使用DIN模型，query用的是多模态融合的semantic id emb，行为流分别用text和audio的semantic id emb。作者说这种方法既能捕捉到单模态细粒度的信息，又能建模跨模态的交互信息 评论 可借鉴 PSRQ的semantic id生产方法确实很有意思，在每一层都用上原始emb，这样不同簇的item在每一层都能分开，不会出现沙漏问题，使得每一层的semantic id都能保留原始emb的语义聚类信息 产了多套semantic id，单模态semantic id是常规操作；多模态emb concat后也产一套semantic id，是个创新点 用户建模时query用多模态semantic id，行为流用单模态semantic id，也是个创新点，虽然论文说这种方法效果最好，但是有点存疑 论文有个实验结果对比了不同semantic id量化方法的效果，结论是：PSRQ \u0026gt; RQ-KMeans = RQ-VAE \u0026gt; VQ \u0026gt; PQ 可改进 pretrain emb和semantic id的生产都没有对齐协同信号 semantic id在下游应用时直接端到端训练，而没有使用codebook初始化，会不会丢失信息比较多？ 产semantic id的过程中，模态内语义退化的问题，描述了现象，但是没有用定量的指标来说明问题，感觉可以借鉴【论文阅读：Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs】的方法，定量说明后续层的semantic id的聚类效果或者说区分能力相比初始emb已经相差甚远了 fig2b中，第一层的codebook的dim=d，后续层的codebook的dim=2d，那么后续层的残差dim也是2d，那么初始emb怎么和后续的残差emb相减呢，维度对不上啊？我理解可能是这样的，后续层聚类的时候用的是concat的dim=2d的emb，但是算聚类中心的时候只用了残差本身的emb，这样就能解释得通了，但是文中对这部分的细节没有解释。 ","permalink":"http://localhost:1313/posts/2025-10-06-psrq-paper-reading/","summary":"\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/2025-10-06-psrq-paper-reading/PSRQ-paper-cover.png\"\u003e\u003c/p\u003e\n\u003ch1 id=\"基本信息\"\u003e基本信息\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e论文标题：Progressive Semantic Residual Quantization for Multimodal-Joint Interest Modeling in Music Recommendation\u003c/li\u003e\n\u003cli\u003e作者单位：网易云音乐\u003c/li\u003e\n\u003cli\u003e论文链接：\u003ca href=\"https://arxiv.org/pdf/2508.20359\"\u003ehttps://arxiv.org/pdf/2508.20359\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e来源：CIKM 2025\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"motivation论文要解决的问题是什么\"\u003eMotivation：论文要解决的问题是什么\u003c/h1\u003e\n\u003cp\u003e多模态emb在搜推的应用方式，通常是先将多模态emb转换成semantic id，然后把semantic id用到搜推模型中，这种方式有如下两个问题：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e模态内语义退化\u003c/strong\u003e：多模态emb转换成semantic id通常使用RQ-VAE或者RQ-KMeans的方法，这种方法在不断残差的过程中，后续残差聚类结果已经不能反映初始emb的聚类效果了。其实就是semantic id的沙漏问题，具体可以看\u003ca href=\"https://arxiv.org/abs/2407.21488\"\u003e这篇文章\u003c/a\u003e，后续有空再分享这个问题。\n\u003cul\u003e\n\u003cli\u003e简单来说，如下图所示，初始有DJ、Rock、Lullaby、Choir四个类，但是对残差emb（即RQ-VAE的第二层）聚类的话，初始的四个类的item就打散了，会聚到不同的簇中，也就是RQ-VAE的后续层的聚类效果已经和初始emb的聚类效果很不一样了，这就是文中说的语义退化问题\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e模态间建模差异\u003c/strong\u003e：搜推场景的item通常有多种模态特征，比如文本、图像、音频等，传统方法在多模态融合方面比较简单，不能很好地捕捉多模态之间的关系。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/2025-10-06-psrq-paper-reading/PSRQ-fig1.png\"\u003e\u003c/p\u003e\n\u003ch1 id=\"psrq生产semantic-id\"\u003ePSRQ生产semantic id\u003c/h1\u003e\n\u003cp\u003e本文是音乐推荐场景，主要用到两种模态：text和audio，分别用百川和MERT提取text和audio的模态emb。\u003c/p\u003e\n\u003cp\u003e生产semantic id的方法如下图所示：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003efig2a是传统的RQ-KMeans的方法，每一层都用上一层的残差进行聚类。如上文所述，由于沙漏问题，会导致后续层次的semantic id存在语义退化问题\u003c/li\u003e\n\u003cli\u003efig2b是本文新提出的PSRQ量化方法，在RQ-KMeans基础上，每一层除了有上一层的残差向量，还会concat上初始emb减去残差emb后的向量。\u003cstrong\u003e这样就能区分出残差相似，但初始emb不同的item了\u003c/strong\u003e，也就避免了RQ方法的沙漏问题，后续semantic id也能保留初始emb的语义信息。fig1d能看出来第二层semantic id仍然能够反映初始emb的分类效果。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/2025-10-06-psrq-paper-reading/PSRQ-fig2.png\"\u003e\u003c/p\u003e\n\u003ch1 id=\"semantic-id在下游的应用方法\"\u003eSemantic id在下游的应用方法\u003c/h1\u003e\n\u003cp\u003e如下图所示：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e每个item有两套多模态emb：text和audio，但是有三套semantic id，除了text和audio各自产一套semantic id之外，还会把text和audio的emb concat起来，再产一套semantic id，相当于多模态融合的semantic id\u003c/li\u003e\n\u003cli\u003esemantic id的emb在排序模型中随机初始化，然后端到端训练\u003c/li\u003e\n\u003cli\u003esemantic id在用户建模时，使用DIN模型，query用的是多模态融合的semantic id emb，行为流分别用text和audio的semantic id emb。作者说这种方法既能捕捉到单模态细粒度的信息，又能建模跨模态的交互信息\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/2025-10-06-psrq-paper-reading/PSRQ-fig3.png\"\u003e\u003c/p\u003e\n\u003ch1 id=\"评论\"\u003e评论\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e可借鉴\n\u003cul\u003e\n\u003cli\u003ePSRQ的semantic id生产方法确实很有意思，在每一层都用上原始emb，这样不同簇的item在每一层都能分开，不会出现沙漏问题，使得每一层的semantic id都能保留原始emb的语义聚类信息\u003c/li\u003e\n\u003cli\u003e产了多套semantic id，单模态semantic id是常规操作；多模态emb concat后也产一套semantic id，是个创新点\u003c/li\u003e\n\u003cli\u003e用户建模时query用多模态semantic id，行为流用单模态semantic id，也是个创新点，虽然论文说这种方法效果最好，但是有点存疑\u003c/li\u003e\n\u003cli\u003e论文有个实验结果对比了不同semantic id量化方法的效果，结论是：PSRQ \u0026gt; RQ-KMeans = RQ-VAE \u0026gt; VQ \u0026gt; PQ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e可改进\n\u003cul\u003e\n\u003cli\u003epretrain emb和semantic id的生产都没有对齐协同信号\u003c/li\u003e\n\u003cli\u003esemantic id在下游应用时直接端到端训练，而没有使用codebook初始化，会不会丢失信息比较多？\u003c/li\u003e\n\u003cli\u003e产semantic id的过程中，模态内语义退化的问题，描述了现象，但是没有用定量的指标来说明问题，感觉可以借鉴\u003ca href=\"https://bitjoy.net/posts/2025-10-04-mme-sid-paper-reading/\"\u003e【论文阅读：Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs】\u003c/a\u003e的方法，定量说明后续层的semantic id的聚类效果或者说区分能力相比初始emb已经相差甚远了\u003c/li\u003e\n\u003cli\u003efig2b中，第一层的codebook的dim=d，后续层的codebook的dim=2d，那么后续层的残差dim也是2d，那么初始emb怎么和后续的残差emb相减呢，维度对不上啊？我理解可能是这样的，后续层聚类的时候用的是concat的dim=2d的emb，但是算聚类中心的时候只用了残差本身的emb，这样就能解释得通了，但是文中对这部分的细节没有解释。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e","title":"论文阅读：Progressive Semantic Residual Quantization for Multimodal-Joint Interest Modeling in Music Recommendation"},{"content":"\n基本信息 论文标题：DAS: Dual-Aligned Semantic IDs Empowered Industrial Recommender System 作者单位：快手 论文链接：https://arxiv.org/pdf/2508.10584 来源：CIKM 2025 Motivation：论文要解决的问题是什么 Semantic id生产时，要么没有和协同信号对齐（fig2(1)），要么是两阶段对齐方式（fig2(2)）：\n例如LETTER先生成协同emb，然后和semantic id对齐 或者例如QARM，先协同对齐emb，再生产semantic id 把协同对齐和生产semantic id分成两个阶段，天然有信息损失，不是最优的。本文的目的就是把生产协同emb，以及semantic id的协同对齐放到一个模型中联合训练完成，尽量减少信息损失（fig2(3)）。\n主模型 主模型如上图所示，中间的ICDM是user和item的双塔模型，用于学习user和item的协同id-based emb；两边分别是生产user和item的semantic id的量化模型。\n中间的ICDM就是经典的召回双塔模型，使用点击样本进行训练，唯一不同的是，在user和item塔都有流行度去偏模块，用于学习user和item的无偏emb，后续user和item的semantic id协同对齐用的也是无偏的emb。\n两边分别是user和item的semantic id量化模型，两者比较类似，以item为例：\n先把item的各种信息，如title、desc、ocr等信息用文本构造成prompt，输入到LLM，借助LLM的summary和reasoning能力，产出item的详细描述 然后把LLM产出的描述再输入到一个预训练的embedding模型PLM，文中用的是bge m3模型，得到item emb 后续就是标准的RQ-VAE过程了 需要注意的是，上述前两步，分别用到了LLM和PLM两个大模型，而且看图上这两个模型都是freeze的，也就是说并不微调这两个大模型。后续协同对齐用的emb是RQ-VAE重构emb的中间层结果，即图中的item quantized emb。\nsemantic id的协同对齐方面，有三大类对齐任务：\nU2I对齐：量化user emb和协同item emb对齐、量化item emb和协同user emb对齐 U2U和I2I对齐：量化user emb和协同user emb对齐、量化item emb和协同item emb对齐 U2U和I2I的共现对齐：点击相同item的两个量化user emb对齐、同一个user点击的两个item的量化item emb对齐 由于fig3中的协同模型和semantic id模型是联合训练的，总共有3大类loss：\n中间的ICDM的双塔召回模型的loss 两边的产semantic id的loss 三个模块的对齐loss 评论 可借鉴 把semantic id的生产和协同信号对齐统一成一阶段的模式，信息损失更少 中间的ICDM模型生产协同emb时进行了去偏，协同对齐的时候用的是去偏的emb，这是其他论文很少提到的 可改进 太复杂了！3个模块，3大类loss，每类loss又有很多个小loss，总loss数量加起来有十多个。。。 任务太多，各种去偏、对齐loss，真的不会互相影响吗？ 中间的ICDM模块有必要吗？我理解ICDM本质是为了训练产出协同emb，但是因为训练样本本身是点击样本，样本本身已经包含了搜推场景的协同信号，也就是ICDM本身没必要存在了，直接用相同的样本训练两边的semantic id量化模型就行了，也能实现在训练semantic id的过程中，完成协同信号的对齐 生产semantic id的emb来自LLM和PLM，但是这两个大模型都是freeze的，如果把这两个模型也sft，效果会不会更好？其实我原本以为的一阶段就是这样的，这也是我在【论文阅读：Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs】中提到的一阶段方法。 ","permalink":"http://localhost:1313/posts/2025-10-05-das-paper-reading/","summary":"\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/2025-10-05-das-paper-reading/das-paper-cover.png\"\u003e\u003c/p\u003e\n\u003ch1 id=\"基本信息\"\u003e基本信息\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e论文标题：DAS: Dual-Aligned Semantic IDs Empowered Industrial Recommender System\u003c/li\u003e\n\u003cli\u003e作者单位：快手\u003c/li\u003e\n\u003cli\u003e论文链接：\u003ca href=\"https://arxiv.org/pdf/2508.10584\"\u003ehttps://arxiv.org/pdf/2508.10584\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e来源：CIKM 2025\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"motivation论文要解决的问题是什么\"\u003eMotivation：论文要解决的问题是什么\u003c/h1\u003e\n\u003cp\u003eSemantic id生产时，要么没有和协同信号对齐（fig2(1)），要么是两阶段对齐方式（fig2(2)）：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e例如\u003ca href=\"https://arxiv.org/abs/2405.07314\"\u003eLETTER\u003c/a\u003e先生成协同emb，然后和semantic id对齐\u003c/li\u003e\n\u003cli\u003e或者例如\u003ca href=\"https://arxiv.org/pdf/2411.11739\"\u003eQARM\u003c/a\u003e，先协同对齐emb，再生产semantic id\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e把协同对齐和生产semantic id分成两个阶段，天然有信息损失，不是最优的。本文的目的就是把生产协同emb，以及semantic id的协同对齐放到一个模型中联合训练完成，尽量减少信息损失（fig2(3)）。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/2025-10-05-das-paper-reading/das-fig2.png\"\u003e\u003c/p\u003e\n\u003ch1 id=\"主模型\"\u003e主模型\u003c/h1\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/2025-10-05-das-paper-reading/das-fig3.png\"\u003e\u003c/p\u003e\n\u003cp\u003e主模型如上图所示，中间的ICDM是user和item的双塔模型，用于学习user和item的协同id-based emb；两边分别是生产user和item的semantic id的量化模型。\u003c/p\u003e\n\u003cp\u003e中间的ICDM就是经典的召回双塔模型，使用点击样本进行训练，唯一不同的是，在user和item塔都有流行度去偏模块，用于学习user和item的无偏emb，后续user和item的semantic id协同对齐用的也是无偏的emb。\u003c/p\u003e\n\u003cp\u003e两边分别是user和item的semantic id量化模型，两者比较类似，以item为例：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e先把item的各种信息，如title、desc、ocr等信息用文本构造成prompt，输入到LLM，借助LLM的summary和reasoning能力，产出item的详细描述\u003c/li\u003e\n\u003cli\u003e然后把LLM产出的描述再输入到一个预训练的embedding模型PLM，文中用的是bge m3模型，得到item emb\u003c/li\u003e\n\u003cli\u003e后续就是标准的RQ-VAE过程了\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e需要注意的是，上述前两步，分别用到了LLM和PLM两个大模型，而且看图上这两个模型都是freeze的，也就是说并不微调这两个大模型。后续协同对齐用的emb是RQ-VAE重构emb的中间层结果，即图中的item quantized emb。\u003c/p\u003e\n\u003cp\u003esemantic id的协同对齐方面，有三大类对齐任务：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eU2I对齐：量化user emb和协同item emb对齐、量化item emb和协同user emb对齐\u003c/li\u003e\n\u003cli\u003eU2U和I2I对齐：量化user emb和协同user emb对齐、量化item emb和协同item emb对齐\u003c/li\u003e\n\u003cli\u003eU2U和I2I的共现对齐：点击相同item的两个量化user emb对齐、同一个user点击的两个item的量化item emb对齐\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e由于fig3中的协同模型和semantic id模型是联合训练的，总共有3大类loss：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e中间的ICDM的双塔召回模型的loss\u003c/li\u003e\n\u003cli\u003e两边的产semantic id的loss\u003c/li\u003e\n\u003cli\u003e三个模块的对齐loss\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"评论\"\u003e评论\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e可借鉴\n\u003cul\u003e\n\u003cli\u003e把semantic id的生产和协同信号对齐统一成一阶段的模式，信息损失更少\u003c/li\u003e\n\u003cli\u003e中间的ICDM模型生产协同emb时进行了去偏，协同对齐的时候用的是去偏的emb，这是其他论文很少提到的\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e可改进\n\u003cul\u003e\n\u003cli\u003e太复杂了！3个模块，3大类loss，每类loss又有很多个小loss，总loss数量加起来有十多个。。。\u003c/li\u003e\n\u003cli\u003e任务太多，各种去偏、对齐loss，真的不会互相影响吗？\u003c/li\u003e\n\u003cli\u003e中间的ICDM模块有必要吗？我理解ICDM本质是为了训练产出协同emb，但是因为训练样本本身是点击样本，样本本身已经包含了搜推场景的协同信号，也就是ICDM本身没必要存在了，直接用相同的样本训练两边的semantic id量化模型就行了，也能实现在训练semantic id的过程中，完成协同信号的对齐\u003c/li\u003e\n\u003cli\u003e生产semantic id的emb来自LLM和PLM，但是这两个大模型都是freeze的，如果把这两个模型也sft，效果会不会更好？其实我原本以为的一阶段就是这样的，这也是我在\u003ca href=\"https://bitjoy.net/posts/2025-10-04-mme-sid-paper-reading/\"\u003e【论文阅读：Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs】\u003c/a\u003e中提到的一阶段方法。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e","title":"论文阅读：DAS: Dual-Aligned Semantic IDs Empowered Industrial Recommender System"},{"content":"\n基本信息 论文标题：QARM: Quantitative Alignment Multi-Modal Recommendation at Kuaishou 作者单位：快手 论文链接：https://arxiv.org/pdf/2411.11739 来源：CIKM 2025 Motivation：论文要解决的问题是什么 多模态emb在搜推场景应用时通常采用如下图的两阶段方式，先预训练多模态emb，然后作为一个冻结特征放到搜推模型中。这种方式存在2个问题：\n表征不对齐：多模态emb预训练的任务通常是图片分类或者文本的MLM，和下游搜推任务不对齐 表征不更新：多模态emb在搜推任务中作为冻结特征，没有更新 本文的方法就是想要解决上述2个问题。 对齐搜推任务的多模态emb预训练 为了解决多模态emb表征不对齐的问题，本文提出的多模态emb预训练任务直接对齐搜推场景，使用U2I和I2I召回模型，挖掘出相似item pair，然后通过对比学习微调多模态大模型。\n具体来说，通过U2I和I2I模型，能够拿到item emb；然后用每一个target item emb去行为流中检索出最相似的商品，作为trigger item emb。\u0026lt;trigger, target\u0026gt;构成一对正样本，然后进行对比学习训练。\n通过召回模型构造的训练样本，和搜推场景的协同信号对齐了，解决了开头提到的第一个问题，即表征不对齐的问题。\nSemantic id生产方法 Semantic id的生产方法如上图右半部分所示，有两种方式：\nVQ：直接圈定一定数量（如N）的item emb作为底池，编号1~N，然后任意来一个item emb，通过对底池emb进行KNN搜索，找出top-k相似商品，假设是(a,b,\u0026hellip;,k)，则VQ编码的semantic id就是(a,b,\u0026hellip;,k)。文中取k=25，感觉挺大的。。。 RQ-Kmeans：对圈定的N个item emb不断进行Kmeans聚类、求残差、残差继续Kmeans聚类的过程。文中取迭代次数为L=6，但是没说每次聚到多少个类。 注意：文中的RQ-Kmeans方法和RQ-VAE还不一样，RQ-Kmeans没有训练过程，也没有重构loss，纯粹是每次进行聚类，然后选聚类中心作为码本的过程。文中也没有对比过为啥不用RQ-VAE。\n产出两套semantic id之后，直接在下游排序任务中进行端到端更新，解决开头提到的表征不更新的问题。具体建模方法比较常规，不是本文的重点，略讲。\n评论 可借鉴 多模态emb预训练任务是i2i的，直接和下游搜推任务对齐 semantic id有两种产出方式，VQ和RQ-Kmeans，尽可能多地保留原始多模态emb的信息 可改进 多模态emb预训练和下游任务对齐，在2025年不算新鲜事了，常规操作。而且文中i2i的构造过程依赖U2I和I2I召回模型，有外部依赖，不够漂亮 VQ的方法，k=25这也太长了吧，相当于一个小型行为流了，会导致下游任务的特征处理更复杂 为什么用RQ-Kmeans而不是RQ-VAE，没有任何说明与对比 从pretrain emb量化成semantic id的过程中，存在严重的信息丢失，这在Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs论文中有讨论 ","permalink":"http://localhost:1313/posts/2025-10-04-qarm-paper-reading/","summary":"\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/2025-10-04-qarm-paper-reading/QARM-paper-cover.png\"\u003e\u003c/p\u003e\n\u003ch1 id=\"基本信息\"\u003e基本信息\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e论文标题：QARM: Quantitative Alignment Multi-Modal Recommendation at Kuaishou\u003c/li\u003e\n\u003cli\u003e作者单位：快手\u003c/li\u003e\n\u003cli\u003e论文链接：\u003ca href=\"https://arxiv.org/pdf/2411.11739\"\u003ehttps://arxiv.org/pdf/2411.11739\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e来源：CIKM 2025\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"motivation论文要解决的问题是什么\"\u003eMotivation：论文要解决的问题是什么\u003c/h1\u003e\n\u003cp\u003e多模态emb在搜推场景应用时通常采用如下图的两阶段方式，先预训练多模态emb，然后作为一个冻结特征放到搜推模型中。这种方式存在2个问题：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e表征不对齐\u003c/strong\u003e：多模态emb预训练的任务通常是图片分类或者文本的MLM，和下游搜推任务不对齐\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e表征不更新\u003c/strong\u003e：多模态emb在搜推任务中作为冻结特征，没有更新\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e本文的方法就是想要解决上述2个问题。\n\u003cimg loading=\"lazy\" src=\"/posts/2025-10-04-qarm-paper-reading/QARM-fig1.png\"\u003e\u003c/p\u003e\n\u003ch1 id=\"对齐搜推任务的多模态emb预训练\"\u003e对齐搜推任务的多模态emb预训练\u003c/h1\u003e\n\u003cp\u003e为了解决多模态emb表征不对齐的问题，本文提出的多模态emb预训练任务直接对齐搜推场景，使用U2I和I2I召回模型，挖掘出相似item pair，然后通过对比学习微调多模态大模型。\u003c/p\u003e\n\u003cp\u003e具体来说，通过U2I和I2I模型，能够拿到item emb；然后用每一个target item emb去行为流中检索出最相似的商品，作为trigger item emb。\u0026lt;trigger, target\u0026gt;构成一对正样本，然后进行对比学习训练。\u003c/p\u003e\n\u003cp\u003e通过召回模型构造的训练样本，和搜推场景的协同信号对齐了，解决了开头提到的第一个问题，即表征不对齐的问题。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/2025-10-04-qarm-paper-reading/QARM-fig3.png\"\u003e\u003c/p\u003e\n\u003ch1 id=\"semantic-id生产方法\"\u003eSemantic id生产方法\u003c/h1\u003e\n\u003cp\u003eSemantic id的生产方法如上图右半部分所示，有两种方式：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eVQ\u003c/strong\u003e：直接圈定一定数量（如N）的item emb作为底池，编号1~N，然后任意来一个item emb，通过对底池emb进行KNN搜索，找出top-k相似商品，假设是(a,b,\u0026hellip;,k)，则VQ编码的semantic id就是(a,b,\u0026hellip;,k)。文中取k=25，感觉挺大的。。。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRQ-Kmeans\u003c/strong\u003e：对圈定的N个item emb不断进行Kmeans聚类、求残差、残差继续Kmeans聚类的过程。文中取迭代次数为L=6，但是没说每次聚到多少个类。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e注意：文中的RQ-Kmeans方法和RQ-VAE还不一样，RQ-Kmeans没有训练过程，也没有重构loss，纯粹是每次进行聚类，然后选聚类中心作为码本的过程。文中也没有对比过为啥不用RQ-VAE。\u003c/p\u003e\n\u003cp\u003e产出两套semantic id之后，直接在下游排序任务中进行端到端更新，解决开头提到的表征不更新的问题。具体建模方法比较常规，不是本文的重点，略讲。\u003c/p\u003e\n\u003ch1 id=\"评论\"\u003e评论\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e可借鉴\n\u003cul\u003e\n\u003cli\u003e多模态emb预训练任务是i2i的，直接和下游搜推任务对齐\u003c/li\u003e\n\u003cli\u003esemantic id有两种产出方式，VQ和RQ-Kmeans，尽可能多地保留原始多模态emb的信息\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e可改进\n\u003cul\u003e\n\u003cli\u003e多模态emb预训练和下游任务对齐，在2025年不算新鲜事了，常规操作。而且文中i2i的构造过程依赖U2I和I2I召回模型，有外部依赖，不够漂亮\u003c/li\u003e\n\u003cli\u003eVQ的方法，k=25这也太长了吧，相当于一个小型行为流了，会导致下游任务的特征处理更复杂\u003c/li\u003e\n\u003cli\u003e为什么用RQ-Kmeans而不是RQ-VAE，没有任何说明与对比\u003c/li\u003e\n\u003cli\u003e从pretrain emb量化成semantic id的过程中，存在严重的信息丢失，这在\u003ca href=\"https://bitjoy.net/posts/2025-10-04-mme-sid-paper-reading/\"\u003eEmpowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs\u003c/a\u003e论文中有讨论\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e","title":"论文阅读：QARM: Quantitative Alignment Multi-Modal Recommendation at Kuaishou"},{"content":"\n基本信息 论文标题：Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs 作者单位：香港城市大学\u0026amp;腾讯 论文链接：https://arxiv.org/pdf/2509.02017 来源：CIKM 2025 Motivation：论文要解决的问题是什么 LLM4SR的基本范式如下，即用LLM直接来做搜推的范式（这种方式在学术界常见，但在工业界不常见）。由于LLM的输入词表范围是有限的（通常比较小），因此其token emb dim通常比较大，比如2048或者4096；而搜推场景的item量级很大，而且在不断更新，因此工业界经典的id-based的搜推模型的item emb dim通常比较小，比如64或128。经典的id-based的搜推模型能比较好地学习到搜推场景的协同信号，为了让LLM模型也能感知这种信息，LLM4SR范式通常会先预训练一个id-based的经典搜推模型，然后将其中的item id emb通过下图的Linear Projection的映射层，映射到LLM token emb的空间，让LLM也能感知搜推的协同信号。\n上述LLM4SR范式存在两个问题：\n维度坍缩：id-based训出来的id emb dim比较小（如64），LLM token emb dim比较大（如4096），在由id emb通过Linear Projection映射到toen emb的过程中，虽然64映射到4096空间了，但扩维后的矩阵存在低秩问题，即还是只利用了4096中的64维的空间。\n论文中，作者分两种情况进行了分析，如果Linear Projection只是一个线性层的话，通过公式推导能得出上述结论；如果Linear Projection包含非线性变换，作者通过实验分析也发现了维度坍缩的现象。 灾难遗忘：除了使用id-based模型产出的id emb，LLM4SR也常用多模态模型产出item emb表征，然后转换成semantic id输入到LLM4SR中。在这种情况下，产出的semantic id通过会遗忘多模态item emb的信息，导致下游LLM4SR的效果不佳。\n论文中，作者用公式9来衡量semantic id保留pretrain多模态emb的信息量。具体来说，如果行为流中的商品序列是{A,B,C,D}，target item是E。使用pretrain多模态emb能计算出E和A~D的相似度，例如相似度\u0026lt;E,A\u0026gt; \u0026gt; \u0026lt;E,B\u0026gt;。如果将pretrain多模态emb转换成semantic id，然后由semantic id恢复出新的A~E的emb之后，再计算E和A~D的相似度，如果仍然有\u0026lt;E,A\u0026gt; \u0026gt; \u0026lt;E,B\u0026gt;，则认为一致（concordant），否则不一致（disconcordant）。这个分析方法挺好的，通过这个指标能估算出转换成semantic id之后，仍然保留原有pretrain多模态emb对搜推场景的序关系的保留程度。 作者发现，转换成semantic id之后，信息只保留了37.14%；进一步，如果semantic id是在下游任务中端到端训练的，则信息只保留了5.5%，也就是说94.5%的pretrain emb的序的信息都丢掉了，也就是灾难遗忘。 Semantic id构建方法 3套emb来源，一套id-based经典搜推模型产出的包含协同信号的emb，另外两套是LLM2CLIP产出的多模态文本和图片emb。作者提到传统CLIP对长文本处理能力较弱，所以升级到LLM2CLIP，能更好地处理长文本。 Semantic id构建方法是经典的RQ-VAE的方法，但有如下两个改进点： 将emb的重构loss由MSE升级成MMD (maximum mean discrepancy)，MSE是计算原始emb和重构emb的欧式距离的误差，而MMD是计算两个分布的diff，实验表明能MMD比MSE能保留更多的pretrain多模态emb信息（即上述公式9），保留44.36% 对量化后的emb做了对齐，因为LLM2CLIP本身进行了图文模态的对齐，所以文中只新增了id emb分别和文本、图片模态的对齐 此外，还有一点论文没提但可能和常规RQ-VAE不同之处，就是原始emb在进行RQ-VAE之前，有一个Encoder升维的操作，在重构loss前对应有一个Decoder降维的操作，而semantic id量化恢复emb是Decoder之前的那个。这一升一降，估计也有助于缓解维度坍缩。 主模型 为了缓解维度坍缩，使用3套emb，一套id-based协同信号emb，另外两套是文本和图片的多模态emb 每套emb既包含原始emb过Linear Projection投影之后的表征（低维投影到高维，存在维度坍缩问题）；也包含由原始emb训练产出的semantic id重构回来的emb（天然高维emb） 为了避免灾难遗忘，semantic id使用上述优化的MMD loss训练产出，并且semantic id emb使用在训练semantic id emb产出的codebook emb进行初始化，然后随着LLM4SR finetuning，而不是完全随机初始化然后端到端训练 最后在LLM4SR输出层，有一个Multimodal Frequency-aware Fusion模块，next token prediction任务相当于一个n分类任务。在这个模块中，对target item也会新增一套emb talbe，这样总共就有4套emb table了。然后词表中每个item会根据热度过一个函数得到四种模态的emb的权重，然后4个emb进行融合。通过这种方式也能一定程度上缓解维度坍缩。 评论 可借鉴 论文的分析方法值得借鉴，例如对维度坍缩的推理分析、灾难遗忘的定量分析等 semantic id训练时的MMD loss缓解灾难遗忘 semantic id emb在下游应用时，使用训练的codebook emb进行初始化，而不是随机初始化，能缓解灾难遗忘 使用多套emb及semantic id，缓解维度坍缩 融合多套emb时，考虑item热度信息，动态调整融合权重 可改进 LLM4SR主要用于学术场景，没有考虑工业场景item id数据量巨大，而且不断更新的情况，因此在工业场景不常见 即使用上MMD loss，pretrain emb信息页只保留了44.36%，如果目标是100%的话，这个绝对差距还很大 没有论证semantic id emb遗忘pretrain emb信息对下游任务的影响，虽然遗忘信息了，但端到端训练也学到新知识了，功过相抵，也许效果不一定差？ semantic id通常通过两阶段训练得到，先预训练emb，然后训练semantic id，两阶段过程天然容易使semantic id遗忘预训练emb的信息，如果将两者合并成一阶段的，即把训练semantic id的网络模块加入到预训练emb的网络中，在预训练emb的过程中，就完成semantic id的训练，那么semantic id遗忘的信息会不会更少？类似的思想在召回双塔模型Poeem（https://arxiv.org/abs/2105.03933）中就有过。 ","permalink":"http://localhost:1313/posts/2025-10-04-mme-sid-paper-reading/","summary":"\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/2025-10-04-mme-sid-paper-reading/mme-sid-paper-cover.png\"\u003e\u003c/p\u003e\n\u003ch1 id=\"基本信息\"\u003e基本信息\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e论文标题：Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs\u003c/li\u003e\n\u003cli\u003e作者单位：香港城市大学\u0026amp;腾讯\u003c/li\u003e\n\u003cli\u003e论文链接：\u003ca href=\"https://arxiv.org/pdf/2509.02017\"\u003ehttps://arxiv.org/pdf/2509.02017\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e来源：CIKM 2025\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"motivation论文要解决的问题是什么\"\u003eMotivation：论文要解决的问题是什么\u003c/h1\u003e\n\u003cp\u003eLLM4SR的基本范式如下，即用LLM直接来做搜推的范式（这种方式在学术界常见，但在工业界不常见）。由于LLM的输入词表范围是有限的（通常比较小），因此其token emb dim通常比较大，比如2048或者4096；而搜推场景的item量级很大，而且在不断更新，因此工业界经典的id-based的搜推模型的item emb dim通常比较小，比如64或128。经典的id-based的搜推模型能比较好地学习到搜推场景的协同信号，为了让LLM模型也能感知这种信息，LLM4SR范式通常会先预训练一个id-based的经典搜推模型，然后将其中的item id emb通过下图的Linear Projection的映射层，映射到LLM token emb的空间，让LLM也能感知搜推的协同信号。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/2025-10-04-mme-sid-paper-reading/E4SRec.png\"\u003e\u003c/p\u003e\n\u003cp\u003e上述LLM4SR范式存在两个问题：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e维度坍缩\u003c/strong\u003e：id-based训出来的id emb dim比较小（如64），LLM token emb dim比较大（如4096），在由id emb通过Linear Projection映射到toen emb的过程中，虽然64映射到4096空间了，但扩维后的矩阵存在低秩问题，即还是只利用了4096中的64维的空间。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e论文中，作者分两种情况进行了分析，如果Linear Projection只是一个线性层的话，通过公式推导能得出上述结论；如果Linear Projection包含非线性变换，作者通过实验分析也发现了维度坍缩的现象。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e灾难遗忘\u003c/strong\u003e：除了使用id-based模型产出的id emb，LLM4SR也常用多模态模型产出item emb表征，然后转换成semantic id输入到LLM4SR中。在这种情况下，产出的semantic id通过会遗忘多模态item emb的信息，导致下游LLM4SR的效果不佳。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e论文中，作者用公式9来衡量semantic id保留pretrain多模态emb的信息量。具体来说，如果行为流中的商品序列是{A,B,C,D}，target item是E。使用pretrain多模态emb能计算出E和A~D的相似度，例如相似度\u0026lt;E,A\u0026gt; \u0026gt; \u0026lt;E,B\u0026gt;。如果将pretrain多模态emb转换成semantic id，然后由semantic id恢复出新的A~E的emb之后，再计算E和A~D的相似度，如果仍然有\u0026lt;E,A\u0026gt; \u0026gt; \u0026lt;E,B\u0026gt;，则认为一致（concordant），否则不一致（disconcordant）。这个分析方法挺好的，通过这个指标能估算出转换成semantic id之后，仍然保留原有pretrain多模态emb对搜推场景的\u003cstrong\u003e序\u003c/strong\u003e关系的保留程度。\u003c/li\u003e\n\u003cli\u003e作者发现，转换成semantic id之后，信息只保留了37.14%；进一步，如果semantic id是在下游任务中端到端训练的，则信息只保留了5.5%，也就是说94.5%的pretrain emb的序的信息都丢掉了，也就是灾难遗忘。\n\u003cimg loading=\"lazy\" src=\"/posts/2025-10-04-mme-sid-paper-reading/mme-sid-formula9.png\"\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"semantic-id构建方法\"\u003eSemantic id构建方法\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e3套emb来源，一套id-based经典搜推模型产出的包含协同信号的emb，另外两套是LLM2CLIP产出的多模态文本和图片emb。作者提到传统CLIP对长文本处理能力较弱，所以升级到LLM2CLIP，能更好地处理长文本。\u003c/li\u003e\n\u003cli\u003eSemantic id构建方法是经典的RQ-VAE的方法，但有如下两个改进点：\u003c/li\u003e\n\u003cli\u003e将emb的重构loss由MSE升级成MMD (maximum mean discrepancy)，MSE是计算原始emb和重构emb的欧式距离的误差，而MMD是计算两个分布的diff，实验表明能MMD比MSE能保留更多的pretrain多模态emb信息（即上述公式9），保留44.36%\u003c/li\u003e\n\u003cli\u003e对量化后的emb做了对齐，因为LLM2CLIP本身进行了图文模态的对齐，所以文中只新增了id emb分别和文本、图片模态的对齐\u003c/li\u003e\n\u003cli\u003e此外，还有一点论文没提但可能和常规RQ-VAE不同之处，就是原始emb在进行RQ-VAE之前，有一个Encoder升维的操作，在重构loss前对应有一个Decoder降维的操作，而semantic id量化恢复emb是Decoder之前的那个。这一升一降，估计也有助于缓解维度坍缩。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/2025-10-04-mme-sid-paper-reading/mme-sid-fig2.png\"\u003e\u003c/p\u003e","title":"论文阅读：Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs"},{"content":"博客数据恢复中，敬请期待！\n测试图片： 测试代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 // Necessary header files for input output functions #include \u0026lt;iostream\u0026gt; using namespace std; // main() function: where the execution of // C++ program begins int main() { // This statement prints \u0026#34;Hello World\u0026#34; cout \u0026lt;\u0026lt; \u0026#34;Hello World\u0026#34;; return 0; } 测试数学公式： This is an inline \\(a^*=x-b^*\\) equation.\nThese are block equations:\n\\[a^*=x-b^*\\]\\[ a^*=x-b^* \\]\\[ a^*=x-b^* \\]These are also block equations:\n$$a^*=x-b^*$$$$ a^*=x-b^* $$$$ a^*=x-b^* $$","permalink":"http://localhost:1313/posts/2025-08-15-announcement/","summary":"\u003cp\u003e博客数据恢复中，敬请期待！\u003c/p\u003e\n\u003cp\u003e测试图片：\n\u003cimg alt=\"这是图片\" loading=\"lazy\" src=\"/posts/2025-08-15-announcement/myimg.png\"\u003e\u003c/p\u003e\n\u003cp\u003e测试代码：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\n\u003ctable style=\"border-spacing:0;padding:0;margin:0;border:0;\"\u003e\u003ctr\u003e\u003ctd style=\"vertical-align:top;padding:0;margin:0;border:0;\"\u003e\n\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 1\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 2\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 3\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 4\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 5\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 6\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 7\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 8\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 9\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e10\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e11\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e12\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e13\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd style=\"vertical-align:top;padding:0;margin:0;border:0;;width:100%\"\u003e\n\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-cpp\" data-lang=\"cpp\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e// Necessary header files for input output functions\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e\u003cspan style=\"color:#75715e\"\u003e#include\u003c/span\u003e \u003cspan style=\"color:#75715e\"\u003e\u0026lt;iostream\u0026gt;\u003c/span\u003e\u003cspan style=\"color:#75715e\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eusing\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003enamespace\u003c/span\u003e std;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e// main() function: where the execution of\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e// C++ program begins\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003emain\u003c/span\u003e() {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#75715e\"\u003e// This statement prints \u0026#34;Hello World\u0026#34;\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e    cout \u003cspan style=\"color:#f92672\"\u003e\u0026lt;\u0026lt;\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;Hello World\u0026#34;\u003c/span\u003e;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e测试数学公式：\nThis is an inline \\(a^*=x-b^*\\) equation.\u003c/p\u003e","title":"公告"},{"content":"这是我的个人博客，数据恢复中\u0026hellip;\n欢迎评论，如需私信请联系: bitjoy@163.com\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e这是我的个人博客，数据恢复中\u0026hellip;\u003c/p\u003e\n\u003cp\u003e欢迎评论，如需私信请联系: \u003ca href=\"mailto:bitjoy@163.com\"\u003ebitjoy@163.com\u003c/a\u003e\u003c/p\u003e","title":"关于"},{"content":"今天中午和超哥在食堂吃饭的时候聊起了电动汽车加电站的问题，很有意思。\n超哥现在开的是一辆电动汽车，他说目前也挺满意的，只要在北京市内开，几乎没问题，充电桩到处都有，马力也足，开起来没有任何噪声。唯一的问题是需要每天充电，去到稍微远一点的京郊可能会电量不足。\n然后就讨论到目前电动汽车的瓶颈，主要还是在电池上，一个是续航时间短，另一个是充电时间慢。\n然后我就想现在的加油车为什么没有上面的两个问题呢，第一个问题，如果加的油少的话，是不是也会出现续航时间短的问题呢，所以把电动汽车的电池做大一点，密度高一点是不是就可以了呢，虽然技术上可能会有难度，但是我觉得并没有第二个问题严重，所以我觉得电池续航短不是太大的问题。。。\n对于第二个问题，在加油站给汽车加油只需要几分钟的时间，但是电动车在充电桩充电可能需要几十分钟甚至一个多小时，所以充电时间慢确实是一个很严重的问题。我当时就说一辆越野车如果要跑沙漠的话，会在车上预存好几桶油备用，类似的，电动车能不能在车上备上几个电池，没电了就换呢，就像手机备用电池一样。然后超哥进一步说不如干脆在现有加油站的基础上，建一个加电站，每辆电动车进站之后，卸下车上的电池，换上提前充满电的电池，整个过程和加油完全一样，还比加油干净。\n我突然觉得，哇塞，这个idea不错呀，统一所有电动车的电池，电池没电之后，到站换电池，一个电池就像一个小型的集装箱（或者docker）一样，被卸下来，然后插上满电电池，so easy~但是为啥没公司这么做呢。此时旁边坐着的一位老师也加入了对话，他说电池寿命有长有短，如果自己刚买的新车，没电了拿去换了一个旧电池，肯定不爽；再说了，要统一全国的电池标准，几乎是不可能的，在全国建这样的加电站，没有哪个公司能承担得起这样的成本，最终羊毛出在羊身上，电动车的价格肯定会上涨的….\n这位老师说的都对，但是我依然觉得这个idea是可行的，关键是要看有关部门有没有这个魄力来做这件事。比如国家或行业层面可以强制统一电池的标准，XX汽车协会规定今后的汽车电池必须做成0.5m0.5m0,5m的方块，正负极距离5cm，便于拆卸等；同时要求电动汽车的电池安放位置必须在汽车的后右侧等一些列规定。即使国家层面没人愿意做这件事，哪家有魄力的电动汽车公司，是不是可以尝试一下呢，比如特斯拉，统一旗下所有电车的电池规格，并在全球建造加电站，统一更换特斯拉的电池。如果特斯拉这样做了，我相信买特斯拉的车主是愿意承担一部分费用的，毕竟这样的加电站最终还是方便了自己。至于说新车换到旧电池，其实大可不必担心，说不定你的旧车会换到别人的新电池呢，而且特斯拉可以建立一个标准，只有电池能量转换效率大于80%的电池才能进入加电站循环，这样保证了每个人换到的电池续航有保障，至于新旧，我才不管呢，反正下一次加电又要换了。\n我个人还是挺喜欢电动汽车的，节能、环保、静音，还看起来酷酷的:-)好希望这个idea能在未来实现呀~\n知乎：电动汽车为什么不统一电池，充电站更换相同档次满电电池？\n","permalink":"http://localhost:1313/posts/2017-01-03-electric-vehicle-charging-station/","summary":"\u003cp\u003e今天中午和超哥在食堂吃饭的时候聊起了电动汽车加电站的问题，很有意思。\u003c/p\u003e\n\u003cp\u003e超哥现在开的是一辆电动汽车，他说目前也挺满意的，只要在北京市内开，几乎没问题，充电桩到处都有，马力也足，开起来没有任何噪声。唯一的问题是需要每天充电，去到稍微远一点的京郊可能会电量不足。\u003c/p\u003e\n\u003cp\u003e然后就讨论到目前电动汽车的瓶颈，主要还是在电池上，一个是续航时间短，另一个是充电时间慢。\u003c/p\u003e\n\u003cp\u003e然后我就想现在的加油车为什么没有上面的两个问题呢，第一个问题，如果加的油少的话，是不是也会出现续航时间短的问题呢，所以把电动汽车的电池做大一点，密度高一点是不是就可以了呢，虽然技术上可能会有难度，但是我觉得并没有第二个问题严重，所以我觉得电池续航短不是太大的问题。。。\u003c/p\u003e\n\u003cp\u003e对于第二个问题，在加油站给汽车加油只需要几分钟的时间，但是电动车在充电桩充电可能需要几十分钟甚至一个多小时，所以充电时间慢确实是一个很严重的问题。我当时就说一辆越野车如果要跑沙漠的话，会在车上预存好几桶油备用，类似的，电动车能不能在车上备上几个电池，没电了就换呢，就像手机备用电池一样。然后超哥进一步说不如干脆在现有加油站的基础上，建一个加电站，每辆电动车进站之后，卸下车上的电池，换上提前充满电的电池，整个过程和加油完全一样，还比加油干净。\u003c/p\u003e\n\u003cp\u003e我突然觉得，哇塞，这个idea不错呀，统一所有电动车的电池，电池没电之后，到站换电池，一个电池就像一个小型的集装箱（或者docker）一样，被卸下来，然后插上满电电池，so easy~但是为啥没公司这么做呢。此时旁边坐着的一位老师也加入了对话，他说电池寿命有长有短，如果自己刚买的新车，没电了拿去换了一个旧电池，肯定不爽；再说了，要统一全国的电池标准，几乎是不可能的，在全国建这样的加电站，没有哪个公司能承担得起这样的成本，最终羊毛出在羊身上，电动车的价格肯定会上涨的….\u003c/p\u003e\n\u003cp\u003e这位老师说的都对，但是我依然觉得这个idea是可行的，关键是要看有关部门有没有这个魄力来做这件事。比如国家或行业层面可以强制统一电池的标准，XX汽车协会规定今后的汽车电池必须做成0.5m\u003cem\u003e0.5m\u003c/em\u003e0,5m的方块，正负极距离5cm，便于拆卸等；同时要求电动汽车的电池安放位置必须在汽车的后右侧等一些列规定。即使国家层面没人愿意做这件事，哪家有魄力的电动汽车公司，是不是可以尝试一下呢，比如特斯拉，统一旗下所有电车的电池规格，并在全球建造加电站，统一更换特斯拉的电池。如果特斯拉这样做了，我相信买特斯拉的车主是愿意承担一部分费用的，毕竟这样的加电站最终还是方便了自己。至于说新车换到旧电池，其实大可不必担心，说不定你的旧车会换到别人的新电池呢，而且特斯拉可以建立一个标准，只有电池能量转换效率大于80%的电池才能进入加电站循环，这样保证了每个人换到的电池续航有保障，至于新旧，我才不管呢，反正下一次加电又要换了。\u003c/p\u003e\n\u003cp\u003e我个人还是挺喜欢电动汽车的，节能、环保、静音，还看起来酷酷的:-)好希望这个idea能在未来实现呀~\u003c/p\u003e\n\u003cp\u003e知乎：电动汽车为什么不统一电池，充电站更换相同档次满电电池？\u003c/p\u003e","title":"电动汽车加电站"},{"content":"最怕空气突然安静 最怕朋友突然的关心 最怕回忆突然翻滚绞痛着不平息 最怕突然听到你的消息 想念如果会有声音 不愿那是悲伤的哭泣 事到如今终於让自已属於我自已 只剩眼泪还骗不过自己 突然好想你你会在哪里 过的快乐或委屈 突然好想你突然锋利的回忆 突然模糊的眼睛 我们像一首最美丽的歌曲 变成两部悲伤的电影 为什麽你带我走过最难忘的旅行 然後留下最痛的纪念品 我们那麽甜那麽美那麽相信 那麽疯那麽热烈的曾经 为何我们还是要奔向 各自的幸福和遗憾中老去 突然好想你你会在哪里 过的快乐或委屈 突然好想你突然锋利的回忆 突然模糊的眼睛 最怕空气突然安静 最怕朋友突然的关心 最怕回忆突然翻滚绞痛着不平息 最怕突然听到你的消息 最怕此生已经决定自己过 没有你却又突然听到你的消息 就好像是突然之间，整个世界都失去了你的声音，以前每天都会收到你的喜怒哀乐、衣食住行、午安晚安，突然之间，空气都安静了，没有了你的消息。翻遍你的空间、朋友圈、微博、博客，都没有消息，不知道你在干什么，好伤心。\n想你，想知道你在哪里，想知道你在干什么，想要发消息给你，又害怕不能收到你的回信，然后郁闷一整天。想要引起你的注意，绞尽脑汁故意发一些不着边际的微博，等了一整天，没有收到你的点赞或评论。\n约你出来吃饭，你一句简单得不能再简单的“可以”，冷冰冰。见到你，裹着厚厚的棉衣，戴着帽子和手套，没有一丝的眼神交流，两个人就这样默默的吃着不知道什么味道的饭菜。\n想要打破这宁静的空气，之前想到无数要和你说的人和事，现在却一句话也说不出。两个最熟悉的人，突然之间，像多年未见的朋友，因完全不同的人生轨迹而没有任何共同语言，成了最熟悉的陌生人。\n你说最近科研压力很大，周围的同学又是发论文，又是发专利，你却一无所有。挑战赛答辩和开题答辩在即，手足无措。\n你说未来太渺茫，没钱买房买车，就算月入两万，要在北京买房也得攒20年。即使买了房，在北京还要买车还要摇号，看病也很贵，还要担心孩子上学各种问题。\n我向来是个不会安慰别人的人，但是我尽力想要告诉你，你已经很优秀了，从小到大的尖子生，多才多艺，研一在雁栖湖那么多高手，你照样轻松拿下第一。你的编程能力也远超你们实验室的人，只不过你目前处于一种有力没处使的状态，你的导师让你干一些杂活，如果你的导师也让专心指导你的挑战赛，你现在肯定也写论文了。\n我尽力安慰你，希望你对对未来乐观一点。面包会有的，不要太在意这些东西，生活快乐最重要，不要太在意别人的看法，自己纵向比较有进步就行了。突然觉得自己词穷，完全不会安慰一个人。\n世界上比你悲惨的人多得太多了，为什么不想想自己有的，至少你有一个健康的身体。\n是的，我猜到了，你不理我和我们上周的体检结果有关。我有病，是的，我有病，而且是不可能治好的病，是随时都可能发病的病。我知道这对于你来说很为难，你有矛盾，我理解，只是我希望你能把你的所有顾虑都告诉我，至少让我和你一起分担，如果你说因为我的病，因为我那卑微的背景，想要离开我，我无话可说，这也无可厚非，我接受。\n刚开始交往时，我没有告诉你，是我的错。上周的检查结果至少说明你是健康的，我很庆幸，没有伤害到你。如果因为我而让你不开心，让你纠结，请一定让我知道，我会默默走开，我是一个讲理的人。希望你永远健康快乐。\n你说这东西还有窗口期，我认，再过几个月，我们再去检查一次，我默默祈祷你是健康的。我知道你和我一样，对一件微小的事也要纠结半天，我不想让你那样难过。\n我原本以为我是一个耐得住安静和寂寞的人，我一度还觉得你像一个叽叽喳喳的小鸟不停的在我耳边发出噪声。直到有一天，我发现你的声音不见了，我开始慌了，不安、烦躁、忧郁充斥我的大脑，想要马上见到你问个一清二楚。也许这就是日久生情，这就是感情吧。\n熟悉了你随性而又纠结的脾气；习惯了每次和你一起吃饭时纠结菜里到底有没有混猪肉；习惯了每次吃饭时要双份碗筷和三份汤的感觉；渐渐喜欢上了和你一起漫无目的的逛街试衣服的感觉；习惯了买两本一样的书，然后每次你看得都比我快，逼迫我不得不也快快的看；喜欢和你一起看电影出去玩的感觉。\n也不知从什么时候开始，微信里的情侣表情都积了厚厚的一层灰；好久好久都没有掰你了，你的手指应该纤细如初了吧。带上耳机，听了一整晚的音乐，已经很久很久没有听歌了。\n以前常常对电视剧里的爱情嗤之以鼻，完全不能理解他们为什么要为爱情哭得死去活来，现在，我大概理解了。\n你说每个正常人遇到我这种情况，都会矛盾，会需要思考、抉择和权衡，是的，爱情完全不是小说里的义无反顾，说到底是各种利益的权衡。\n10月真是一个让人忧伤的月份，亲人的离世，自己也前前后后进了三次医院，揭开了深藏心底N年的伤疤，曾经一直陪伴在身边的人也想要离开。科研上的压力就更不说了，老板一直不停的催促，每天活得像个陀螺，没有方向的转，没有一丝的停顿。\n这病态的社会。\n亲爱的，我愿意等你，我尊重你的决定，如果你离开，我会祝福你，如果你留下，我希望你不是在怜悯我。\n","permalink":"http://localhost:1313/posts/2016-10-28-waiting-for-you/","summary":"\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e最怕空气突然安静\n最怕朋友突然的关心\n最怕回忆突然翻滚绞痛着不平息\n最怕突然听到你的消息\n\n想念如果会有声音\n不愿那是悲伤的哭泣\n事到如今终於让自已属於我自已\n只剩眼泪还骗不过自己\n\n突然好想你你会在哪里\n过的快乐或委屈\n突然好想你突然锋利的回忆\n突然模糊的眼睛\n\n我们像一首最美丽的歌曲\n变成两部悲伤的电影\n为什麽你带我走过最难忘的旅行\n然後留下最痛的纪念品\n\n我们那麽甜那麽美那麽相信\n那麽疯那麽热烈的曾经\n为何我们还是要奔向\n各自的幸福和遗憾中老去\n\n突然好想你你会在哪里\n过的快乐或委屈\n突然好想你突然锋利的回忆\n突然模糊的眼睛\n\n最怕空气突然安静\n最怕朋友突然的关心\n最怕回忆突然翻滚绞痛着不平息\n最怕突然听到你的消息\n最怕此生已经决定自己过\n没有你却又突然听到你的消息\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e就好像是突然之间，整个世界都失去了你的声音，以前每天都会收到你的喜怒哀乐、衣食住行、午安晚安，突然之间，空气都安静了，没有了你的消息。翻遍你的空间、朋友圈、微博、博客，都没有消息，不知道你在干什么，好伤心。\u003c/p\u003e\n\u003cp\u003e想你，想知道你在哪里，想知道你在干什么，想要发消息给你，又害怕不能收到你的回信，然后郁闷一整天。想要引起你的注意，绞尽脑汁故意发一些不着边际的微博，等了一整天，没有收到你的点赞或评论。\u003c/p\u003e\n\u003cp\u003e约你出来吃饭，你一句简单得不能再简单的“可以”，冷冰冰。见到你，裹着厚厚的棉衣，戴着帽子和手套，没有一丝的眼神交流，两个人就这样默默的吃着不知道什么味道的饭菜。\u003c/p\u003e\n\u003cp\u003e想要打破这宁静的空气，之前想到无数要和你说的人和事，现在却一句话也说不出。两个最熟悉的人，突然之间，像多年未见的朋友，因完全不同的人生轨迹而没有任何共同语言，成了最熟悉的陌生人。\u003c/p\u003e\n\u003cp\u003e你说最近科研压力很大，周围的同学又是发论文，又是发专利，你却一无所有。挑战赛答辩和开题答辩在即，手足无措。\u003c/p\u003e\n\u003cp\u003e你说未来太渺茫，没钱买房买车，就算月入两万，要在北京买房也得攒20年。即使买了房，在北京还要买车还要摇号，看病也很贵，还要担心孩子上学各种问题。\u003c/p\u003e\n\u003cp\u003e我向来是个不会安慰别人的人，但是我尽力想要告诉你，你已经很优秀了，从小到大的尖子生，多才多艺，研一在雁栖湖那么多高手，你照样轻松拿下第一。你的编程能力也远超你们实验室的人，只不过你目前处于一种有力没处使的状态，你的导师让你干一些杂活，如果你的导师也让专心指导你的挑战赛，你现在肯定也写论文了。\u003c/p\u003e\n\u003cp\u003e我尽力安慰你，希望你对对未来乐观一点。面包会有的，不要太在意这些东西，生活快乐最重要，不要太在意别人的看法，自己纵向比较有进步就行了。突然觉得自己词穷，完全不会安慰一个人。\u003c/p\u003e\n\u003cp\u003e世界上比你悲惨的人多得太多了，为什么不想想自己有的，至少你有一个健康的身体。\u003c/p\u003e\n\u003cp\u003e是的，我猜到了，你不理我和我们上周的体检结果有关。我有病，是的，我有病，而且是不可能治好的病，是随时都可能发病的病。我知道这对于你来说很为难，你有矛盾，我理解，只是我希望你能把你的所有顾虑都告诉我，至少让我和你一起分担，如果你说因为我的病，因为我那卑微的背景，想要离开我，我无话可说，这也无可厚非，我接受。\u003c/p\u003e\n\u003cp\u003e刚开始交往时，我没有告诉你，是我的错。上周的检查结果至少说明你是健康的，我很庆幸，没有伤害到你。如果因为我而让你不开心，让你纠结，请一定让我知道，我会默默走开，我是一个讲理的人。希望你永远健康快乐。\u003c/p\u003e\n\u003cp\u003e你说这东西还有窗口期，我认，再过几个月，我们再去检查一次，我默默祈祷你是健康的。我知道你和我一样，对一件微小的事也要纠结半天，我不想让你那样难过。\u003c/p\u003e\n\u003cp\u003e我原本以为我是一个耐得住安静和寂寞的人，我一度还觉得你像一个叽叽喳喳的小鸟不停的在我耳边发出噪声。直到有一天，我发现你的声音不见了，我开始慌了，不安、烦躁、忧郁充斥我的大脑，想要马上见到你问个一清二楚。也许这就是\u003ca href=\"http://zhihu.com/question/26049681/answer/32014770\"\u003e日久生情\u003c/a\u003e，这就是感情吧。\u003c/p\u003e\n\u003cp\u003e熟悉了你随性而又纠结的脾气；习惯了每次和你一起吃饭时纠结菜里到底有没有混猪肉；习惯了每次吃饭时要双份碗筷和三份汤的感觉；渐渐喜欢上了和你一起漫无目的的逛街试衣服的感觉；习惯了买两本一样的书，然后每次你看得都比我快，逼迫我不得不也快快的看；喜欢和你一起看电影出去玩的感觉。\u003c/p\u003e\n\u003cp\u003e也不知从什么时候开始，微信里的情侣表情都积了厚厚的一层灰；好久好久都没有掰你了，你的手指应该纤细如初了吧。带上耳机，听了一整晚的音乐，已经很久很久没有听歌了。\u003c/p\u003e\n\u003cp\u003e以前常常对电视剧里的爱情嗤之以鼻，完全不能理解他们为什么要为爱情哭得死去活来，现在，我大概理解了。\u003c/p\u003e\n\u003cp\u003e你说每个正常人遇到我这种情况，都会矛盾，会需要思考、抉择和权衡，是的，爱情完全不是小说里的义无反顾，说到底是各种利益的权衡。\u003c/p\u003e\n\u003cp\u003e10月真是一个让人忧伤的月份，亲人的离世，自己也前前后后进了三次医院，揭开了深藏心底N年的伤疤，曾经一直陪伴在身边的人也想要离开。科研上的压力就更不说了，老板一直不停的催促，每天活得像个陀螺，没有方向的转，没有一丝的停顿。\u003c/p\u003e\n\u003cp\u003e这病态的社会。\u003c/p\u003e\n\u003cp\u003e亲爱的，我愿意等你，我尊重你的决定，如果你离开，我会祝福你，如果你留下，我希望你不是在怜悯我。\u003c/p\u003e","title":"最怕空气突然安静"},{"content":"今天阅读《C++ Primer, 5e》的第二章，介绍C++的基本内置类型，觉得有一些平时工作容易出错的知识点，现摘录如下：\n1 unsigned char c = -1; // 假设char占8比特，c的值为255 当我们赋给无符号类型一个超出它表示范围的值时，结果是初始值对无符号类型表示数值总数取模后的余数。例如，8比特大小的unsigned char可以表示0至255区间内的值，如果我们赋了一个区间以外的值，则实际的结果是该值对256取模后所得的余数。因此，把-1赋给8比特大小的unsigned char所得的结果是255。\n1 signed char c2 = 256; // 假设char占8比特，c2的值是未定义的 当我们赋给带符号类型一个超出它表示范围的值时，结果是未定义的（undefined）。此时，程序可能继续工作、可能崩溃，也可能生成垃圾数据。\n1 2 3 4 unsigned u = 10; int i = -42; std::cout \u0026lt;\u0026lt; i + i \u0026lt;\u0026lt; std::endl; // 输出-84 std::cout \u0026lt;\u0026lt; u + i \u0026lt;\u0026lt; std::endl; // 如果int占32位，输出4294967264 在第一个输出表达式里，两个（负）整数相加并得到了期望的结果。在第二个输出表达式里，相加前首先把整数-42转换成无符号数。把负数转换成无符号数类似于直接给无符号数赋一个负数，结果等于这个负数加上无符号数的模。unsigned (int)的取值范围是0~\\(2^{32}-1\\)，所以总数有\\(2^{32}\\)个数，-42%\\(2^{32}\\)=-42+\\(2^{32}\\)，u+i=10+(-42+\\(2^{32}\\))=4294967264。\n1 2 3 unsigned u1 = 42, u2 = 10; std::cout \u0026lt;\u0026lt; u1 – u2 \u0026lt;\u0026lt; std::endl; // 正确：输出32 std::cout \u0026lt;\u0026lt; u2 – u1 \u0026lt;\u0026lt; std::endl; // 正确：不过，结果是取模后的值 当从无符号数中减去一个值时，不管这个值是不是无符号数，我们都必须确保结果不能是一个负值。\n无符号数不会小于0这一事实同样关系到循环的写法。例如我们常用的循环如下：\n1 2 for (int i = 10; i \u0026gt;= 0; --i) std::cout \u0026lt;\u0026lt; i \u0026lt;\u0026lt; std::endl; 可能你会觉得反正也不打算输出负数，可以用无符号数来重写这个循环。然而，这个不经意的改变却意味着死循环；\n1 2 3 // 错误：变量u永远也不会小于0，循环条件一直成立 for (unsigned u = 10; u \u0026gt;= 0; --u) std::cout \u0026lt;\u0026lt; u \u0026lt;\u0026lt; std::endl; 来看看当u等于0时发生了什么，这次迭代输出0，然后继续执行for语句里的表达式。表达式\u0026ndash;u从u当中减去1，得到的结果-1并不满足无符号数的要求，此时像所有表示范围之外的其他数字一样，-1被自动地转换成一个合法的无符号数。假设int类型占32位，则当u等于0时，–u的结果将会是-1%\\(2^{32}\\)=4294967295。\n一种解决的办法是，用while语句来代替for语句，因为前者让我们能够在输出变量之前（而非之后）先减1：\n1 2 3 4 5 unsigned u = 11; // 确定要输出的最大数，从比它大1的数开始 while (u \u0026gt; 0){ --u; std::cout \u0026lt;\u0026lt; u \u0026lt;\u0026lt; std::endl; } ","permalink":"http://localhost:1313/posts/2016-09-24-memo-about-cpp-built-in-types/","summary":"\u003cp\u003e今天阅读《C++ Primer, 5e》的第二章，介绍C++的基本内置类型，觉得有一些平时工作容易出错的知识点，现摘录如下：\u003c/p\u003e\n\u003chr\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\n\u003ctable style=\"border-spacing:0;padding:0;margin:0;border:0;\"\u003e\u003ctr\u003e\u003ctd style=\"vertical-align:top;padding:0;margin:0;border:0;\"\u003e\n\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e1\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd style=\"vertical-align:top;padding:0;margin:0;border:0;;width:100%\"\u003e\n\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-cpp\" data-lang=\"cpp\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eunsigned\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003echar\u003c/span\u003e c \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e-\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e; \u003cspan style=\"color:#75715e\"\u003e// 假设char占8比特，c的值为255\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e当我们赋给无符号类型一个超出它表示范围的值时，结果是初始值对无符号类型表示数值总数取模后的余数。例如，8比特大小的unsigned char可以表示0至255区间内的值，如果我们赋了一个区间以外的值，则实际的结果是该值对256取模后所得的余数。因此，把-1赋给8比特大小的unsigned char所得的结果是255。\u003c/p\u003e\n\u003chr\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\n\u003ctable style=\"border-spacing:0;padding:0;margin:0;border:0;\"\u003e\u003ctr\u003e\u003ctd style=\"vertical-align:top;padding:0;margin:0;border:0;\"\u003e\n\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e1\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd style=\"vertical-align:top;padding:0;margin:0;border:0;;width:100%\"\u003e\n\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-cpp\" data-lang=\"cpp\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003esigned\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003echar\u003c/span\u003e c2 \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e256\u003c/span\u003e; \u003cspan style=\"color:#75715e\"\u003e// 假设char占8比特，c2的值是未定义的\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e当我们赋给带符号类型一个超出它表示范围的值时，结果是未定义的（undefined）。此时，程序可能继续工作、可能崩溃，也可能生成垃圾数据。\u003c/p\u003e\n\u003chr\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\n\u003ctable style=\"border-spacing:0;padding:0;margin:0;border:0;\"\u003e\u003ctr\u003e\u003ctd style=\"vertical-align:top;padding:0;margin:0;border:0;\"\u003e\n\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e1\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e2\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e3\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e4\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd style=\"vertical-align:top;padding:0;margin:0;border:0;;width:100%\"\u003e\n\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-cpp\" data-lang=\"cpp\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eunsigned\u003c/span\u003e u \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e10\u003c/span\u003e;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e i \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e-\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e42\u003c/span\u003e;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003estd\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003ecout \u003cspan style=\"color:#f92672\"\u003e\u0026lt;\u0026lt;\u003c/span\u003e i \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e i \u003cspan style=\"color:#f92672\"\u003e\u0026lt;\u0026lt;\u003c/span\u003e std\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003eendl; \u003cspan style=\"color:#75715e\"\u003e// 输出-84\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003estd\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003ecout \u003cspan style=\"color:#f92672\"\u003e\u0026lt;\u0026lt;\u003c/span\u003e u \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e i \u003cspan style=\"color:#f92672\"\u003e\u0026lt;\u0026lt;\u003c/span\u003e std\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003eendl; \u003cspan style=\"color:#75715e\"\u003e// 如果int占32位，输出4294967264\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e在第一个输出表达式里，两个（负）整数相加并得到了期望的结果。在第二个输出表达式里，相加前首先把整数-42转换成无符号数。把负数转换成无符号数类似于直接给无符号数赋一个负数，结果等于这个负数加上无符号数的模。unsigned (int)的取值范围是0~\\(2^{32}-1\\)，所以总数有\\(2^{32}\\)个数，-42%\\(2^{32}\\)=-42+\\(2^{32}\\)，u+i=10+(-42+\\(2^{32}\\))=4294967264。\u003c/p\u003e\n\u003chr\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\n\u003ctable style=\"border-spacing:0;padding:0;margin:0;border:0;\"\u003e\u003ctr\u003e\u003ctd style=\"vertical-align:top;padding:0;margin:0;border:0;\"\u003e\n\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e1\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e2\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e3\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd style=\"vertical-align:top;padding:0;margin:0;border:0;;width:100%\"\u003e\n\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-cpp\" data-lang=\"cpp\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eunsigned\u003c/span\u003e u1 \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e42\u003c/span\u003e, u2 \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e10\u003c/span\u003e;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003estd\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003ecout \u003cspan style=\"color:#f92672\"\u003e\u0026lt;\u0026lt;\u003c/span\u003e u1 \u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e–\u003c/span\u003e u2 \u003cspan style=\"color:#f92672\"\u003e\u0026lt;\u0026lt;\u003c/span\u003e std\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003eendl; \u003cspan style=\"color:#75715e\"\u003e// 正确：输出32\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003estd\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003ecout \u003cspan style=\"color:#f92672\"\u003e\u0026lt;\u0026lt;\u003c/span\u003e u2 \u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e–\u003c/span\u003e u1 \u003cspan style=\"color:#f92672\"\u003e\u0026lt;\u0026lt;\u003c/span\u003e std\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003eendl; \u003cspan style=\"color:#75715e\"\u003e// 正确：不过，结果是取模后的值\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e当从无符号数中减去一个值时，不管这个值是不是无符号数，我们都必须确保结果不能是一个负值。\u003c/p\u003e","title":"C++基本数据类型备忘"},{"content":"随机矩阵是这样一类方阵，其元素为非负实数，且行和或列和为1。如果行和为1，则称为行随机矩阵；如果列和为1，则称为列随机矩阵；如果行和和列和都为1，则称为双随机矩阵。\n前面我们介绍的谷歌矩阵和HMM中的转移矩阵都属于随机矩阵，所以随机矩阵也称为概率矩阵、转移矩阵、或马尔可夫矩阵。\n随机矩阵有一个性质，就是其所有特征值的绝对值小于等于1，且其最大特征值为1。下面通过两种方法证明这个结论。\n首先，随机矩阵A肯定有特征值1，即\n$$\\begin{equation}A\\vec 1=1\\times\\vec 1\\end{equation}$$其中的单位向量\\(\\vec 1=(\\frac{1}{n},…,\\frac{1}{n})^T\\)，因为A的行和为1，所以上述等式成立。即1是A的特征值。\n反证法 假设存在大于1的特征值\\(\\lambda\\)，则有\\(A\\vec x=\\lambda\\vec x\\)。令\\(x_k\\)是\\(\\vec x\\)中最大的元素。又因为A的元素非负，且行和为1，所以\\(\\lambda\\vec x\\)中的每个元素都是\\(\\vec x\\)中元素的凸组合，所以\\(\\lambda\\vec x\\)中的每个元素都小于等于\\(x_k\\)。\n$$\\begin{equation}a_{i1}x_1+a_{i2}x_2+…+a_{in}x_n=\\lambda x_i\\leq x_k\\end{equation}$$但是如果\\(\\lambda\u003e1\\)，则\\(\\lambda x_k\u003ex_k\\)，和(2)式矛盾，所以\\(\\lambda\\leq 1\\)。又因为(1)式，所以A的最大特征值为1。\n常规证法 设对称随机矩阵A的特征值\\(\\lambda\\)对应的特征向量为\\(x\\)（为了简便，以下省略向量符号），则有\\(Ax=\\lambda x\\)，即\\(x^TAx=\\lambda x^Tx\\)，欲证明\\(|\\lambda|\\leq 1\\)，只需证明\n$$\\begin{equation}\\lambda=\\frac{\u003c x, Ax \u003e}{\u003c x, x \u003e}\\leq 1\\end{equation}$$根据定义有：\n$$\\begin{equation}\u003c x, Ax \u003e=\\sum_{i=1}^na_{ii}x_i^2+2\\sum_{i \u003c j, i\\sim j}a_{ij}x_ix_j\\end{equation}$$对于\\(i \u003c j, i\\sim j\\)，有：\n$$\\begin{equation}a_{ij}(x_i-x_j)^2=a_{ij}x_i^2-2a_{ij}x_ix_j+a_{ij}x_j^2\\end{equation}$$两边求和并移项得到：\n$$ \\begin{equation} \\begin{array} \\displaystyle{2\\sum_{i \u003c j}}a_{ij}x_ix_j \u0026 = \u0026 \\displaystyle{\\sum_{i \u003c j}a_{ij}x_i^2+\\sum_{i \u003c j}a_{ij}x_j^2-\\sum_{i \u003c j}a_{ij}(x_i-x_j)^2}\\\\ \u0026 = \u0026 \\displaystyle{\\sum_{i \u003c j}a_{ij}x_i^2+\\sum_{i \u003c j}a_{ji}x_j^2-\\sum_{i \u003c j}a_{ij}(x_i-x_j)^2}\\\\ \u0026 = \u0026 \\displaystyle{\\sum_{i \u003c j}a_{ij}x_i^2+\\sum_{i \u003e j}a_{ij}x_i^2-\\sum_{i \u003c j}a_{ij}(x_i-x_j)^2}\\\\ \u0026 = \u0026 \\displaystyle{\\sum_i(\\sum_{j\\neq i}a_{ij}x_i^2)-\\sum_{i \u003c j}a_{ij}(x_i-x_j)^2}\\\\ \u0026 = \u0026 \\displaystyle{\\sum_i(x_i^2(1-a_{ii}))-\\sum_{i \u003c j}a_{ij}(x_i-x_j)^2} \\end{array} \\end{equation} $$第2、3个等号都是因为A是对称矩阵，所以可以把\\(a_{ij}\\)替换为\\(a_{ji}\\)，然后互换\\(i,j\\)下标。最后一个等号是因为A的行和为1。\n将(6)代入(4)式得到：\n$$ \\begin{equation} \\begin{array} \\displaystyle{\u003c x, Ax \u003e} \u0026 = \u0026 \\displaystyle{\\sum_ia_{ii}x_i^2+\\sum_i(x_i^2(1-a_{ii}))-\\sum_{i \u003c j}a_{ij}(x_i-x_j)^2}\\\\ \u0026 = \u0026 \\displaystyle{\\sum_ix_i^2-\\sum_{i \u003c j}a_{ij}(x_i-x_j)^2} \\end{array} \\end{equation} $$所以：\n$$ \\begin{equation} \\lambda=\\frac{\u003c x, Ax \u003e}{\u003c x, x\u003e} = \\frac{\\sum_ix_i^2-\\sum_{i \u003c j}a_{ij}(x_i-x_j)^2}{\\sum_ix_i^2} \\leq 1 \\end{equation} $$又因为(1)式，所以A的最大特征值为1。\n随机矩阵的第二大特征值\\(\\lambda(A)\\)也很有用，\\(1-\\lambda(A)\\)被称为矩阵A的谱间隔（spectral gap），它衡量的是最大特征值和第二大特征值之间的差值。\\(\\lambda(A)\\)在马尔可夫随机游走领域有重要作用。\n$$\\begin{equation}||A^lp-1||_2\\leq \\lambda^l(A)\\end{equation}$$上式是扩张图（Expander）领域很重要的一个引理，A为扩张图的邻接矩阵，\\(p\\)为在所有节点上的初始概率分布，\\(\\lambda(A)\\)为矩阵A的第二大的特征值。因为\\(\\lambda(A)\u003c1\\)，所以\\(\\lambda^l(A)\\)会快速的降到0。也就是说，在初始概率\\(p\\)上，随机游走\\(l\\)步，很快就能达到均匀分布\\(1\\)。\n参考：《Computational Complexity: A Modern Approach》书上7.A.RANDOM WALKS AND EIGENVALUES介绍了这个引理，该书地址：http://theory.cs.princeton.edu/complexity/，相关内容在第153页。\n","permalink":"http://localhost:1313/posts/2016-08-23-the-eigenvalue-of-stochastic-matrix/","summary":"\u003cp\u003e\u003ca href=\"https://en.wikipedia.org/wiki/Stochastic_matrix\"\u003e随机矩阵\u003c/a\u003e是这样一类方阵，其元素为非负实数，且行和或列和为1。如果行和为1，则称为行随机矩阵；如果列和为1，则称为列随机矩阵；如果行和和列和都为1，则称为双随机矩阵。\u003c/p\u003e\n\u003cp\u003e前面我们介绍的\u003ca href=\"https://bitjoy.net/posts/2016-08-04-googles-pagerank-and-beyond/\"\u003e谷歌矩阵\u003c/a\u003e和\u003ca href=\"https://bitjoy.net/posts/2016-08-20-introduction-to-hmm-1/\"\u003eHMM中的转移矩阵\u003c/a\u003e都属于随机矩阵，所以随机矩阵也称为概率矩阵、转移矩阵、或马尔可夫矩阵。\u003c/p\u003e\n\u003cp\u003e随机矩阵有一个性质，就是其所有特征值的绝对值小于等于1，且其最大特征值为1。下面通过两种方法证明这个结论。\u003c/p\u003e\n\u003cp\u003e首先，随机矩阵A肯定有特征值1，即\u003c/p\u003e\n$$\\begin{equation}A\\vec 1=1\\times\\vec 1\\end{equation}$$\u003cp\u003e其中的单位向量\\(\\vec 1=(\\frac{1}{n},…,\\frac{1}{n})^T\\)，因为A的行和为1，所以上述等式成立。即1是A的特征值。\u003c/p\u003e\n\u003ch1 id=\"反证法\"\u003e\u003ca href=\"https://mikespivey.wordpress.com/2013/01/17/eigenvalue-stochasti/\"\u003e反证法\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003e假设存在大于1的特征值\\(\\lambda\\)，则有\\(A\\vec x=\\lambda\\vec x\\)。令\\(x_k\\)是\\(\\vec x\\)中最大的元素。又因为A的元素非负，且行和为1，所以\\(\\lambda\\vec x\\)中的每个元素都是\\(\\vec x\\)中元素的凸组合，所以\\(\\lambda\\vec x\\)中的每个元素都小于等于\\(x_k\\)。\u003c/p\u003e\n$$\\begin{equation}a_{i1}x_1+a_{i2}x_2+…+a_{in}x_n=\\lambda x_i\\leq x_k\\end{equation}$$\u003cp\u003e但是如果\\(\\lambda\u003e1\\)，则\\(\\lambda x_k\u003ex_k\\)，和(2)式矛盾，所以\\(\\lambda\\leq 1\\)。又因为(1)式，所以A的最大特征值为1。\u003c/p\u003e\n\u003ch1 id=\"常规证法\"\u003e常规证法\u003c/h1\u003e\n\u003cp\u003e设\u003cstrong\u003e对称随机矩阵A\u003c/strong\u003e的特征值\\(\\lambda\\)对应的特征向量为\\(x\\)（为了简便，以下省略向量符号），则有\\(Ax=\\lambda x\\)，即\\(x^TAx=\\lambda x^Tx\\)，欲证明\\(|\\lambda|\\leq 1\\)，只需证明\u003c/p\u003e\n$$\\begin{equation}\\lambda=\\frac{\u003c x, Ax \u003e}{\u003c x, x \u003e}\\leq 1\\end{equation}$$\u003cp\u003e根据定义有：\u003c/p\u003e\n$$\\begin{equation}\u003c x, Ax \u003e=\\sum_{i=1}^na_{ii}x_i^2+2\\sum_{i \u003c j, i\\sim j}a_{ij}x_ix_j\\end{equation}$$\u003cp\u003e对于\\(i \u003c j, i\\sim j\\)，有：\u003c/p\u003e\n$$\\begin{equation}a_{ij}(x_i-x_j)^2=a_{ij}x_i^2-2a_{ij}x_ix_j+a_{ij}x_j^2\\end{equation}$$\u003cp\u003e两边求和并移项得到：\u003c/p\u003e\n$$\n\\begin{equation}\n\\begin{array}\n\\displaystyle{2\\sum_{i \u003c j}}a_{ij}x_ix_j \u0026 = \u0026 \\displaystyle{\\sum_{i \u003c j}a_{ij}x_i^2+\\sum_{i \u003c j}a_{ij}x_j^2-\\sum_{i \u003c j}a_{ij}(x_i-x_j)^2}\\\\\n\u0026 = \u0026 \\displaystyle{\\sum_{i \u003c j}a_{ij}x_i^2+\\sum_{i \u003c j}a_{ji}x_j^2-\\sum_{i \u003c j}a_{ij}(x_i-x_j)^2}\\\\ \u0026 = \u0026 \\displaystyle{\\sum_{i \u003c j}a_{ij}x_i^2+\\sum_{i \u003e j}a_{ij}x_i^2-\\sum_{i \u003c j}a_{ij}(x_i-x_j)^2}\\\\\n\u0026 = \u0026 \\displaystyle{\\sum_i(\\sum_{j\\neq i}a_{ij}x_i^2)-\\sum_{i \u003c j}a_{ij}(x_i-x_j)^2}\\\\\n\u0026 = \u0026 \\displaystyle{\\sum_i(x_i^2(1-a_{ii}))-\\sum_{i \u003c j}a_{ij}(x_i-x_j)^2}\n\\end{array}\n\\end{equation}\n$$\u003cp\u003e第2、3个等号都是因为A是对称矩阵，所以可以把\\(a_{ij}\\)替换为\\(a_{ji}\\)，然后互换\\(i,j\\)下标。最后一个等号是因为A的行和为1。\u003c/p\u003e","title":"随机矩阵及其特征值"},{"content":"马尔可夫聚类算法（The Markov Cluster Algorithm, MCL）是一种快速可扩展的基于图的聚类算法。它的基本思想为：在一个稀疏图G中，如果某个区域A是稠密的（是一个聚类），则在A中随机游走k步，还在A内的概率很大，也就是说，A内的k步路径（k-length path）很多。所以我们可以在图中随机游走k步，如果某个区域连通的概率很大，则该区域是一个聚类。随机游走的下一步只和当前所处节点有关，也就是说这是一个马尔可夫的随机游走过程。\n我们用一个例子来演示马尔可夫聚类算法的过程。\n上图是一个很小的网络，我们用肉眼大概能看出有三个聚类，分别是左边的{1,6,7,10}，中间的{2,3,5}和右边的{4,8,9,11,12}。我们用MCL看看结果如何。\n为了随机游走，我们常用邻接矩阵来表示图，如果i,j有边，则N[i][j]=1，否则N[i][j]=0。又随机游走可能有自回路，所以加上单位矩阵I，得到矩阵N+I。\nMCL有两个关键的步骤，分别是Expansion和Inflation。\nExpansion就是不断对矩阵进行幂次运算，相当于随机游走。假设随机游走了2步，则得到如下图的关联矩阵\\((N+I)^2\\)，第1行第10列为4，说明1到10的2-length path有4条：1→6→10，1→7→10，1→1→10，1→10→10。随机游走k步之后，\\((N+I)^k[i][j]\\)越大，说明\\(i\\)和\\(j\\)之间的连通性越强。\n$$\\begin{equation}Expand(M)=M^k\\end{equation}$$\nInflation是为了增强更强的连接，减弱更弱的连接，只有这样才能得到边界比较明确的聚类。MCL的做法是对元素做幂次运算，然后按列归一化，公式为：\n$$\\begin{equation}(\\Gamma_rM)_{pq}=\\frac{(M_{pq})^r}{\\sum_{i=1}^k(M_{iq})^r}\\end{equation}$$参数经验值是\\(k=r=2\\)。不断做Expansion和Inflation操作，直到算法收敛，得到若干个聚类。中间过程请点此查看，下图为最终结果。\n从图中可以看出，和1有边的只剩下6,7,10了，所以得到聚类{1,6,7,10}，同理能得到聚类{2,3,5}和{4,8,9,11,12} ，和我们肉眼得到的结果是一致的。\nMCL算法的原理很简单，得到的聚类效果也不错。下面总结一下MCL的算法过程：\n给定无向图G，Expansion和Inflation的参数\\(k\\)和\\(r\\) 生成G的邻接矩阵\\(N\\) 添加自回路，得到矩阵\\(N+I\\) 循环对\\(N+I\\)做Expansion和Inflation操作，即计算公式(1)和(2)，直到收敛 根据最终得到的矩阵，进行划分聚类 此算法是我在上《生物信息学中的算法设计》课上是学到的，当时觉得这个算法真是神奇，如此简单，但又如此有效，实在高明。查阅文献得知，此为Stijn van Dongen的博士论文，本博客的图片均来自其博士论文，想深入了解图聚类算法，请下载他的论文。\n","permalink":"http://localhost:1313/posts/2016-08-22-the-markov-cluster-algorithm/","summary":"\u003cp\u003e马尔可夫聚类算法（The Markov Cluster Algorithm, MCL）是一种快速可扩展的基于图的聚类算法。它的基本思想为：在一个稀疏图G中，如果某个区域A是稠密的（是一个聚类），则在A中随机游走k步，还在A内的概率很大，也就是说，A内的k步路径（k-length path）很多。所以我们可以在图中随机游走k步，如果某个区域连通的概率很大，则该区域是一个聚类。随机游走的下一步只和当前所处节点有关，也就是说这是一个马尔可夫的随机游走过程。\u003c/p\u003e\n\u003cp\u003e我们用一个例子来演示马尔可夫聚类算法的过程。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"mcl-1\" loading=\"lazy\" src=\"/posts/2016-08-22-the-markov-cluster-algorithm/mcl-1.png\"\u003e\u003c/p\u003e\n\u003cp\u003e上图是一个很小的网络，我们用肉眼大概能看出有三个聚类，分别是左边的{1,6,7,10}，中间的{2,3,5}和右边的{4,8,9,11,12}。我们用MCL看看结果如何。\u003c/p\u003e\n\u003cp\u003e为了随机游走，我们常用邻接矩阵来表示图，如果i,j有边，则N[i][j]=1，否则N[i][j]=0。又随机游走可能有自回路，所以加上单位矩阵I，得到矩阵N+I。\u003c/p\u003e\n\u003cp\u003eMCL有两个关键的步骤，分别是Expansion和Inflation。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eExpansion\u003c/strong\u003e就是不断对矩阵进行幂次运算，相当于随机游走。假设随机游走了2步，则得到如下图的关联矩阵\\((N+I)^2\\)，第1行第10列为4，说明1到10的2-length path有4条：1→6→10，1→7→10，1→1→10，1→10→10。随机游走k步之后，\\((N+I)^k[i][j]\\)越大，说明\\(i\\)和\\(j\\)之间的连通性越强。\u003c/p\u003e\n$$\\begin{equation}Expand(M)=M^k\\end{equation}$$\u003cp\u003e\u003cimg alt=\"mcl-2\" loading=\"lazy\" src=\"/posts/2016-08-22-the-markov-cluster-algorithm/mcl-2.png\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eInflation\u003c/strong\u003e是为了增强更强的连接，减弱更弱的连接，只有这样才能得到边界比较明确的聚类。MCL的做法是对元素做幂次运算，然后按列归一化，公式为：\u003c/p\u003e\n$$\\begin{equation}(\\Gamma_rM)_{pq}=\\frac{(M_{pq})^r}{\\sum_{i=1}^k(M_{iq})^r}\\end{equation}$$\u003cp\u003e参数经验值是\\(k=r=2\\)。不断做Expansion和Inflation操作，直到算法收敛，得到若干个聚类。\u003ca href=\"/posts/2016-08-22-the-markov-cluster-algorithm/mcl-3.pdf\"\u003e中间过程请点此查看\u003c/a\u003e，下图为最终结果。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"mcl-4\" loading=\"lazy\" src=\"/posts/2016-08-22-the-markov-cluster-algorithm/mcl-4.png\"\u003e\u003c/p\u003e\n\u003cp\u003e从图中可以看出，和1有边的只剩下6,7,10了，所以得到聚类{1,6,7,10}，同理能得到聚类{2,3,5}和{4,8,9,11,12} ，和我们肉眼得到的结果是一致的。\u003c/p\u003e\n\u003cp\u003eMCL算法的原理很简单，得到的聚类效果也不错。下面总结一下MCL的算法过程：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e给定无向图G，Expansion和Inflation的参数\\(k\\)和\\(r\\)\u003c/li\u003e\n\u003cli\u003e生成G的邻接矩阵\\(N\\)\u003c/li\u003e\n\u003cli\u003e添加自回路，得到矩阵\\(N+I\\)\u003c/li\u003e\n\u003cli\u003e循环对\\(N+I\\)做Expansion和Inflation操作，即计算公式(1)和(2)，直到收敛\u003c/li\u003e\n\u003cli\u003e根据最终得到的矩阵，进行划分聚类\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e此算法是我在上《生物信息学中的算法设计》课上是学到的，当时觉得这个算法真是神奇，如此简单，但又如此有效，实在高明。查阅文献得知，此为\u003ca href=\"http://www.micans.org/mcl/\"\u003eStijn van Dongen的博士论文\u003c/a\u003e，本博客的图片均来自其博士论文，想深入了解图聚类算法，请\u003ca href=\"http://micans.org/mcl/lit/svdthesis.pdf.gz\"\u003e下载他的论文\u003c/a\u003e。\u003c/p\u003e","title":"马尔可夫聚类算法"},{"content":"上一回介绍了HMM的解码问题，今天我们介绍HMM的学习问题和识别问题，先来看学习问题。\n正如上一回结束时所说，HMM的学习问题是：仅已知观测序列\\(\\vec y\\)，要估计出模型参数组\\(\\vec\\lambda=(\\mu,A,B)\\)，其中\\(\\mu\\)为初始概率分布向量，\\(A\\)为转移概率矩阵，\\(B\\)为发射概率矩阵。\n算法设计 求解HMM的参数学习问题，就是求解如下的最优化问题：\n$$\\begin{equation} P(\\vec Y = \\vec y|\\hat \\lambda)=\\max\\limits_{\\vec \\lambda} P(\\vec Y = \\vec y|\\vec \\lambda)\\end{equation}$$也就是找一个参数\\(\\vec \\lambda\\)，使得模型在该参数下最有可能产生当前的观测\\(\\vec y\\)。如果使用极大似然法求解，对于似然函数\\(P(\\vec Y=\\vec y|\\vec \\lambda)=\\sum\\limits_{i_1,…,i_T}\\mu_{i_1}b_{i_1y_1}a_{i_1i_2}…a_{i_{T-1}i_T}b_{i_Ty_T}\\)而言，这个最大值问题的计算量过大，在实际中是不可能被采用的。为此，人们构造了一个递推算法，使其能相当合理地给出模型参数\\(\\vec \\lambda\\)的粗略估计。其核心思想是：并不要求备选\\(\\vec\\lambda\\)使得\\(P(\\vec Y=\\vec y|\\vec \\lambda)\\)达到最大或局部极大，而只要求使\\(P(\\vec Y=\\vec y|\\vec \\lambda)\\)相当大，从而使计算变为实际可能。\nEM算法 为此，我们定义一个描述模型“趋势”的量\\(Q(\\vec\\lambda^*|\\vec\\lambda)\\)代替似然函数\\(P(\\vec Y=\\vec y|\\vec\\lambda)\\)，其定义为：\n$$\\begin{equation} Q(\\vec\\lambda^*|\\vec\\lambda)=\\sum\\limits_{\\vec x}P(\\vec x,\\vec y|\\vec\\lambda)\\ln P(\\vec x,\\vec y|\\vec\\lambda^*)\\end{equation}$$利用在\\(0 \u003c x \u003c 1\\)时，不等式\\(\\ln x\\leq x-1\\)成立，可以证明：\n$$\\begin{equation} Q(\\vec\\lambda^*|\\vec\\lambda)-Q(\\vec\\lambda|\\vec\\lambda)\\leq P(\\vec Y=\\vec y|\\vec\\lambda^*)-P(\\vec Y=\\vec y|\\vec\\lambda)\\end{equation}$$由此可见，对于固定的\\(\\vec\\lambda\\)，只要\\(Q(\\vec\\lambda^*|\\vec\\lambda)\u003eQ(\\vec\\lambda|\\vec\\lambda)\\)，就有\\(P(\\vec Y=\\vec y|\\vec\\lambda^*)\u003eP(\\vec Y=\\vec y|\\vec\\lambda)\\)。于是想把模型\\(\\vec\\lambda_m\\)修改为更好的模型\\(\\vec\\lambda_{m+1}\\)，只需找\\(\\vec\\lambda_{m+1}\\)使得：\n$$\\begin{equation}Q(\\vec\\lambda_{m+1}|\\vec\\lambda_m)=\\sup_{\\vec\\lambda}Q(\\vec\\lambda|\\vec\\lambda_m)\\end{equation}$$即只要把\\(Q(\\vec\\lambda|\\vec\\lambda_m)\\)关于\\(\\vec\\lambda\\)的最大值处取成\\(\\vec\\lambda_{m+1}\\)，就有\\(P(\\vec Y=\\vec y|\\vec\\lambda_{m+1})\u003eP(\\vec Y=\\vec y|\\vec\\lambda_m)\\)。\n这样得到的模型序列\\(\\{\\vec\\lambda_m\\}\\)能保证\\(P(\\vec Y=\\vec y|\\vec\\lambda_m)\\)关于\\(m\\)是严格递增的，虽然在这里还不能在理论上证明\\(P(\\vec Y=\\vec y|\\vec\\lambda_m)\\)收敛到\\(\\max_{\\vec\\lambda}P(\\vec Y=\\vec y|\\vec\\lambda)\\)，但是当\\(m\\)充分大时，\\(\\vec\\lambda_m\\)也还能提供在实际中较为满意的粗略近似。\n综上论述，我们把如上得到的近似模型列\\(\\vec\\lambda_m\\)的方法归结为两个步骤：\nE步骤（求期望）：计算$$\\begin{equation}Q(\\vec\\lambda^*|\\vec\\lambda)=\\sum\\limits_{\\vec x}P(\\vec x,\\vec y|\\vec\\lambda)\\ln P(\\vec x,\\vec y|\\vec\\lambda^*)\\end{equation}$$ M步骤（求最大）：求\\(\\vec\\lambda_{m+1}\\)使$$\\begin{equation}Q(\\vec\\lambda_{m+1}|\\vec\\lambda_m)=\\sup_{\\vec\\lambda}Q(\\vec\\lambda|\\vec\\lambda_m)\\end{equation}$$ 这两个步骤合起来构成的算法，称为期望最大化（Expectation-maximization, EM）算法。EM算法是针对在测量数据不完全时，求参数的一种近似于最大似然估计的统计方法。\nBaum-Welch算法 隐Markov模型中的M-步骤的解可以有显式表示，这就是一组把模型参数修改为新的模型参数的递推公式，这组公式正好是在隐Markov模型中普遍应用的著名的Baum-Welch公式。\n$$\\begin{equation}\\hat\\mu_i^{m+1}=\\frac{P(\\vec Y=\\vec y,X_1=i|\\vec\\lambda_m)}{P(\\vec Y=\\vec y|\\vec\\lambda_m)}=\\gamma_1(i)\\end{equation}$$$$\\begin{equation}\\hat a_{ij}^{m+1}=\\frac{\\sum\\limits_{t=1}^{T-1}P(X_t=i,X_{t+1}=j|\\vec Y=\\vec y,\\vec\\lambda_m)}{\\sum\\limits_{t=1}^{T-1}P(X_t=i|\\vec Y=\\vec y,\\vec\\lambda_m)}\\triangleq\\frac{\\sum\\limits_{t=1}^{T-1}\\xi_t(i,j)}{\\sum\\limits_{t=1}^{T-1}\\gamma_t(i)}\\end{equation}$$$$\\begin{equation}\\hat b_{il}^{m+1}=\\frac{\\sum\\limits_{t=1}^TP(\\vec Y=\\vec y,X_t=i|\\vec\\lambda_m)I_{\\{l\\}}(y_t)}{\\sum\\limits_{t=1}^TP(\\vec Y=\\vec y,X_t=i|\\vec\\lambda_m)}\\triangleq\\frac{\\sum\\limits_{t=1,y_t=l}^T\\gamma_t(i)}{\\sum\\limits_{t=1}^T\\gamma_t(i)}\\end{equation}$$Baum-Welch算法用到了如下几个公式：\n向前算法，\\(\\alpha_t(i)=P(Y_1=y_1,…,Y_t=y_t,X_t=i|\\lambda)\\)，满足前\\(t\\)个状态，推进到满足前\\(t+1\\)个状态（\\(t\\rightarrow t+1\\)）：\\(\\begin{equation}\\alpha_1(i)=\\mu_ib_{iy_1}\\quad \\alpha_{t+1}(i)=\\sum\\limits_j\\alpha_t(j)a_{ji}b_{iy_{t+1}}\\end{equation}\\) 向后算法，\\(\\beta_t(i)=P(Y_{t+1}=y_{t+1},…,Y_T=y_T|X_t=i,\\lambda)\\)，满足后\\(t-1\\)个状态，推进到满足后\\(t\\)个状态（\\(t+1\\rightarrow t\\)）：\\(\\begin{equation}\\beta_T(i)=1\\quad \\beta_t(i)=\\sum\\limits_j\\beta_{t+1}(j)a_{ij}b_{jy_{t+1}}\\end{equation}\\) 向前向后算法，满足所有观测状态，且\\(t\\)时刻的隐状态为\\(i\\)：\\(\\begin{equation}\\gamma_t(i)=P(X_t=i|\\vec Y=\\vec y,\\vec\\lambda)=\\frac{P(\\vec Y=\\vec y,X_t=i|\\vec\\lambda)}{\\sum\\limits_iP(\\vec Y=\\vec y,X_t=i|\\vec\\lambda)}=\\frac{\\alpha_t(i)\\beta_t(i)}{\\sum\\limits_i\\alpha_t(i)\\beta_t(i)}\\end{equation}\\) 以及记号\\(\\begin{equation}\\xi_t(i,j)\\triangleq P(X_t=i,X_{t+1}=j|\\vec Y=\\vec y,\\vec\\lambda)=\\frac{\\alpha_t(i)a_{ij}b_{jy_{t+1}}\\beta_{t+1}(j)}{\\sum\\limits_i\\alpha_t(i)\\beta_t(i)}\\end{equation}\\) 算法流程 最后，我们可以将Baum-Welch公式应用于EM算法中的M步骤，来逐步改进模型参数\\(\\vec\\lambda\\)。为了使训练结果更加可信，通常应该有多条观测序列。假设输入为所有\\(k\\)次观测序列集合\\(S\\)和收敛阈值\\(\\epsilon\\)，输出为训练得到的模型参数\\(\\hat{\\vec\\lambda}\\)，则基于Baum-Welch公式的EM算法求解HMM学习问题的伪代码如下：\n现在要求解另一个韦小宝的骰子的问题：韦小宝有两个有偏的骰子A,B，A,B掷出相同点数的概率不同，每次韦小宝随机拿一个骰子并投掷，记录下正面朝上的点数，重复100次，得到一条长度为100的点数序列，如此重复100次，得到100条类似的序列。现只给定这100条点数序列，要求解出韦小宝每次投掷的是哪个骰子，并分析这两个骰子有什么区别。\n这就是一个典型的HMM的参数学习问题，利用上述伪代码可以很快的求解出模型参数\\(\\vec\\lambda\\)，A,B的发射概率就是它们的不同点。\nHMM的识别问题是：对于一个特定的观测链\\(\\vec y\\)，已知它可能是由已经学习好的若干模型之一所得的观测，要决定此观测究竟是得自其中哪一个模型，这称为识别问题。\n判决步骤：\n根据参数求出在每一个模型中，出现给定样本的概率\\(P(\\vec Y=\\vec y|\\lambda_k)\\)，归一化就得到给定样本来自每个模型的概率\\(P(\\lambda_k|\\vec Y=\\vec y)\\)。 利用贝叶斯原理，就可以得到最好模型的猜测。 本博客开头提到，要求解\\(P(\\vec Y=\\vec y|\\lambda)\\)需要指数时间（\\(O(N^T)\\)）：\n$$\\begin{equation}P(\\vec Y=\\vec y|\\vec \\lambda)=\\sum\\limits_{i_1,…,i_T}\\mu_{i_1}b_{i_1y_1}a_{i_1i_2}…a_{i_{T-1}i_T}b_{i_Ty_T}\\end{equation}$$所以可以利用向前算法（式(10)）或者向后算法（式(11)），对应的结果分别为：\n$$\\begin{equation}P(\\vec Y=\\vec y|\\lambda)=\\sum_{i=1}^N\\alpha_T(i)\\end{equation}$$$$\\begin{equation}P(\\vec Y=\\vec y|\\lambda)=\\sum_{i=1}^N\\beta_1(i)\\mu_ib_{iy_1}\\end{equation}$$然后利用贝叶斯公式得到\\(P(\\lambda_k|\\vec Y=\\vec y)\\)，使结果最大的\\(k\\)即为所求模型。\n","permalink":"http://localhost:1313/posts/2016-08-21-introduction-to-hmm-2/","summary":"\u003cp\u003e上一回介绍了HMM的解码问题，今天我们介绍HMM的学习问题和识别问题，先来看学习问题。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e正如上一回结束时所说，\u003cstrong\u003eHMM的学习问题\u003c/strong\u003e是：仅已知观测序列\\(\\vec y\\)，要估计出模型参数组\\(\\vec\\lambda=(\\mu,A,B)\\)，其中\\(\\mu\\)为初始概率分布向量，\\(A\\)为转移概率矩阵，\\(B\\)为发射概率矩阵。\u003c/p\u003e\n\u003ch1 id=\"算法设计\"\u003e算法设计\u003c/h1\u003e\n\u003cp\u003e求解HMM的参数学习问题，就是求解如下的最优化问题：\u003c/p\u003e\n$$\\begin{equation} P(\\vec Y = \\vec y|\\hat \\lambda)=\\max\\limits_{\\vec \\lambda} P(\\vec Y = \\vec y|\\vec \\lambda)\\end{equation}$$\u003cp\u003e也就是找一个参数\\(\\vec \\lambda\\)，使得模型在该参数下最有可能产生当前的观测\\(\\vec y\\)。如果使用极大似然法求解，对于似然函数\\(P(\\vec Y=\\vec y|\\vec \\lambda)=\\sum\\limits_{i_1,…,i_T}\\mu_{i_1}b_{i_1y_1}a_{i_1i_2}…a_{i_{T-1}i_T}b_{i_Ty_T}\\)而言，这个最大值问题的计算量过大，在实际中是不可能被采用的。为此，人们构造了一个递推算法，使其能相当合理地给出模型参数\\(\\vec \\lambda\\)的粗略估计。其核心思想是：并不要求备选\\(\\vec\\lambda\\)使得\\(P(\\vec Y=\\vec y|\\vec \\lambda)\\)达到最大或局部极大，而只要求使\\(P(\\vec Y=\\vec y|\\vec \\lambda)\\)相当大，从而使计算变为实际可能。\u003c/p\u003e\n\u003ch1 id=\"em算法\"\u003eEM算法\u003c/h1\u003e\n\u003cp\u003e为此，我们定义一个描述模型“趋势”的量\\(Q(\\vec\\lambda^*|\\vec\\lambda)\\)代替似然函数\\(P(\\vec Y=\\vec y|\\vec\\lambda)\\)，其定义为：\u003c/p\u003e\n$$\\begin{equation} Q(\\vec\\lambda^*|\\vec\\lambda)=\\sum\\limits_{\\vec x}P(\\vec x,\\vec y|\\vec\\lambda)\\ln P(\\vec x,\\vec y|\\vec\\lambda^*)\\end{equation}$$\u003cp\u003e利用在\\(0 \u003c x \u003c 1\\)时，不等式\\(\\ln x\\leq x-1\\)成立，可以证明：\u003c/p\u003e\n$$\\begin{equation} Q(\\vec\\lambda^*|\\vec\\lambda)-Q(\\vec\\lambda|\\vec\\lambda)\\leq P(\\vec Y=\\vec y|\\vec\\lambda^*)-P(\\vec Y=\\vec y|\\vec\\lambda)\\end{equation}$$\u003cp\u003e由此可见，对于固定的\\(\\vec\\lambda\\)，只要\\(Q(\\vec\\lambda^*|\\vec\\lambda)\u003eQ(\\vec\\lambda|\\vec\\lambda)\\)，就有\\(P(\\vec Y=\\vec y|\\vec\\lambda^*)\u003eP(\\vec Y=\\vec y|\\vec\\lambda)\\)。于是想把模型\\(\\vec\\lambda_m\\)修改为更好的模型\\(\\vec\\lambda_{m+1}\\)，只需找\\(\\vec\\lambda_{m+1}\\)使得：\u003c/p\u003e\n$$\\begin{equation}Q(\\vec\\lambda_{m+1}|\\vec\\lambda_m)=\\sup_{\\vec\\lambda}Q(\\vec\\lambda|\\vec\\lambda_m)\\end{equation}$$\u003cp\u003e即只要把\\(Q(\\vec\\lambda|\\vec\\lambda_m)\\)关于\\(\\vec\\lambda\\)的最大值处取成\\(\\vec\\lambda_{m+1}\\)，就有\\(P(\\vec Y=\\vec y|\\vec\\lambda_{m+1})\u003eP(\\vec Y=\\vec y|\\vec\\lambda_m)\\)。\u003c/p\u003e\n\u003cp\u003e这样得到的模型序列\\(\\{\\vec\\lambda_m\\}\\)能保证\\(P(\\vec Y=\\vec y|\\vec\\lambda_m)\\)关于\\(m\\)是严格递增的，虽然在这里还不能在理论上证明\\(P(\\vec Y=\\vec y|\\vec\\lambda_m)\\)收敛到\\(\\max_{\\vec\\lambda}P(\\vec Y=\\vec y|\\vec\\lambda)\\)，但是当\\(m\\)充分大时，\\(\\vec\\lambda_m\\)也还能提供在实际中较为满意的粗略近似。\u003c/p\u003e","title":"隐马尔可夫模型及其应用（2）学习问题\u0026识别问题"},{"content":"隐马尔可夫模型（Hidden Markov Model, HMM）是统计模型，它用来描述一个含有隐含未知参数的马尔可夫过程。其难点是从可观察的参数中确定该过程的隐含参数。然后利用这些参数来作进一步的分析，例如模式识别。\n先举一个简单的例子以直观地理解HMM的实质——韦小宝的骰子。\n假设韦小宝有两个骰子，一个正常的骰子A，A以1/6的概率均等的出现每个点；一个不正常的骰子B，B出现5,6点数的概率为0.3，出现其他点数的概率为0.1。显然投掷B更容易出现大的点数。每次试验第一次投掷时，韦小宝会以0.4的概率出千（即投掷B）。但是在一次试验中，韦小宝不太可能一直出千，所以骰子会在A、B之间转换，比如这次投了B，下次可能会以0.1的概率投A。A、B之间的转移概率如下图。\n某一次试验，我们观察到韦小宝掷出的骰子序列为\\(O=(1,3,4,5,5,6,6,3,2,6)\\)，请问韦小宝什么时候出千了。这个问题就可以通过HMM求解。\nHMM有2个状态：\n观测状态。我们观察到的骰子序列称为观测状态\\(\\mathbf{Y}=\\{y_1,y_2,…,y_T\\}\\) 隐状态。隐含在每个观测状态里面的是隐状态\\(\\mathbf{X}=\\{x_1,x_2,…,x_T\\}\\) T是时间，也可以认为是观测的次数。HMM有3个参数：\n初始分布\\(\\mathbf{\\mu}=(\\mu_i)\\)，\\(\\mu_i=Pr(x_1=i)\\)，即第一次观测时，每个隐状态出现的概率 转移概率矩阵\\(A=(a_{ij})\\)，\\(a_{ij}=Pr(x_{t+1}=j|x_t=i)\\)，即t时刻的隐状态为i，t+1时刻转移到隐状态j的概率 发射概率矩阵\\(B=(b_{il})\\)，\\(b_{il}=Pr(y_t=l|x_t=i)\\)，即t时候隐状态为i的情况下，观测到状态为l的概率 参数\\(\\mathbf{\\lambda=\\{\\mu,A,B\\}}\\)称为HMM的模型参数。具体到上面的例子，我们有初始分布和转移概率为：\n发射概率为：\n观测状态为\\(\\mathbf{Y}=(1,3,4,5,5,6,6,3,2,6)\\)，问题就是求解出隐状态\\(\\mathbf{X}\\)，此问题被称为HMM的解码问题，可以由著名的维特比算法（Viterbi algorithm）解决。\n解码问题是要求出使得观测状态\\(Y\\)出现概率最大的隐状态\\(X\\)，假设有N个隐状态（本例为2），共有T个时刻（本例为10），则每个时刻有N个取值可能，则共有\\(N^T\\)条可能的隐状态链（本例为\\(2^{10}\\)）。我们需要求出每一条隐状态链下T个发射概率的乘积，然后取最大值，这是指数时间复杂度的（\\(O(N^T)\\)）。\n但是Viterbi算法是一个动态规划算法，只需多项式时间即可解决该问题。该算法的原理很好理解，假设我们求得到\\(s_{i2}\\)的最大概率路径为下图中的红线\\(s_{11}\\rightarrow s_{22}\\rightarrow … s_{i2}\\)，则在求经过\\(s_{i2}\\)到\\(s_{(i+1)1}\\)的最大概率路径时，不需要再测试\\(s_{13}\\rightarrow s_{21}\\rightarrow s_{i2}\\rightarrow s_{(i+1)1}\\)这条路径（下图蓝线），因为显然已经知道红线概率大于蓝线概率了。图中还有很多类似蓝线的路径都可以不用计算了，大大提高了求解速度。\n因为计算第\\(i+1\\)时刻的累积概率只和第\\(i\\)时刻的概率有关，每次至多计算\\(N*N\\)个概率乘积（可以从\\(i\\)时刻的\\(N\\)个状态到达\\(i+1\\)时刻的某个状态，\\(i+1\\)时刻共有\\(N\\)个状态），最多计算T次（共T个时刻），所以时间复杂度降到了\\(O(N^2T)\\)。\n下面我们形式化的描述Viterbi算法。\n假设\\(\\delta_t(i)\\)为\\(t\\)时刻取到隐状态\\(i\\)，且1~t的观测状态都符合观测值\\(Y\\)的各个路径的最大概率，即\n$$ \\begin{equation}\\delta_t(i)=\\underset{i_1,…,i_{t-1}}{\\max}Pr(X_t=i,X_{t-1}=i_{t-1},…,X_1=i_1,Y_t=y_t,…,Y_1=y_1|\\mathbf{\\lambda})\\end{equation} $$联系上图，可认为\\(\\delta_t(i)\\)为红线。则递推公式为：\n$$ \\begin{equation}\\delta_{t+1}(i)=b_{iy_{t+1}}\\underset{j}{\\max}(\\delta_t(j)a_{ji})\\end{equation} $$由\\(j\\)到\\(i\\)的转移概率，再乘上\\(i\\)发射\\(y_{t+1}\\)的概率。\n在初始时刻\\(t=1\\)，有：\n$$ \\begin{equation}\\delta_1(i)=\\mu_ib_{iy_1}\\end{equation} $$最后的全局最大概率为\\(\\underset{j}{\\max}\\delta_T(j)\\)。为了得到完整路径，我们保留每一隐状态取得最大概率时的上一隐状态，即：\n$$ \\begin{equation}\\psi_{t+1}(i)=j^*\\end{equation} $$其中\\(j^*\\)要满足\n$$ \\begin{equation}\\delta_{t+1}(i)=b_{iy_{t+1}}\\delta_t(j^*)a_{j^*i}\\end{equation} $$最后使用如下回溯法得到所有最佳隐状态：\n$$\\begin{equation}X_T=i^*\\in\\{i:\\delta_T(i)=\\underset{j}{\\max}\\delta_T(j)\\}\\end{equation}$$$$\\begin{equation}X_t=\\psi_{t+1}(X_{t+1})\\end{equation}$$下面我们利用Viterbi算法来求解韦小宝的骰子这个例子。\n\\(t=1\\)时，\\(y_1=1\\)，有\\(\\delta_1(A)=0.6*1/6=0.1\\)，\\(\\delta_1(B)=0.4*0.1=0.04\\)。\n\\(t=2\\)时，\\(y_2=3\\)，有：\n隐状态为A：a）A-\u0026gt;A有\\(\\delta_2(A)=(1/6)*0.1*0.8=1.33*10^{-2}\\)；b）B-\u0026gt;A有\\(\\delta_2(A)=(1/6)*0.04*0.1=6.6*10^{-4}\\)。所以A-\u0026gt;A，\\(\\psi_2(A)=A\\)。 隐状态为B：a）A-\u0026gt;B有\\(\\delta_2(B)=0.1*0.1*0.2=2*10^{-3}\\)；b）B-\u0026gt;B有\\(\\delta_2(B)=0.1*0.04*0.9=3.6*10^{-3}\\)。所以B-\u0026gt;B，\\(\\psi_2(B)=B\\)。 如此计算下去，可以得到如下表： \\(t=10\\)时最大概率为\\(\\delta_{10}(B)\\)，经过回溯得到最佳隐状态为：\n所以HMM很神奇吧，可以抓住韦小宝从第5次开始就一直在出千，而且出千之后，掷出的点数大部分为5和6。\nViterbi算法还可用于解决语音识别或者拼音输入法。我们知道中文的一个拼音可以对应多个汉字，连续的一段拼音就能组成成千上万种可能的句子，哪一个句子才是最佳候选呢？我们可以把每个拼音当成观测状态，同音的汉字当成可能的隐状态。通过背景语料库统计得到每个汉字出现在词首的概率、汉字之间的转移概率和汉字与拼音之间的发射概率，这样我们就能得到模型参数，然后利用Viterbi算法求解出一个最佳的隐状态序列，这样就能完成一个简易的拼音输入法。\nHMM在实际中主要有3个方面的应用，分别是：\n从一段观测序列\\(\\mathbf{Y}\\)及已知模型\\(\\mathbf{\\lambda=(\\mu,A,B)}\\)出发，估计出隐状态\\(\\mathbf{X}\\)的最佳值，称为解码问题，这是状态估计问题。这篇博客讨论的就是这个问题。 从一段观测序列\\(\\mathbf{Y}\\)出发，估计模型参数组\\(\\mathbf{\\lambda=(\\mu,A,B)}\\)，称为学习问题，就是参数估计问题。 对于一个特定的观测链\\(\\mathbf{Y}\\)，已知它可能是由已经学习好的若干模型之一所得的观测，要决定此观测究竟是得自其中哪一个模型，这称为识别问题，就是分类问题。 关于HMM的学习问题和识别问题，请听下回分解。\n","permalink":"http://localhost:1313/posts/2016-08-20-introduction-to-hmm-1/","summary":"\u003cp\u003e\u003ca href=\"https://zh.wikipedia.org/wiki/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B\"\u003e隐马尔可夫模型\u003c/a\u003e（Hidden Markov Model, HMM）是统计模型，它用来描述一个含有隐含未知参数的马尔可夫过程。其难点是从可观察的参数中确定该过程的隐含参数。然后利用这些参数来作进一步的分析，例如模式识别。\u003c/p\u003e\n\u003cp\u003e先举一个简单的例子以直观地理解HMM的实质——韦小宝的骰子。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"hmm-2\" loading=\"lazy\" src=\"/posts/2016-08-20-introduction-to-hmm-1/hmm-2.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e假设韦小宝有两个骰子，一个正常的骰子A，A以1/6的概率均等的出现每个点；一个不正常的骰子B，B出现5,6点数的概率为0.3，出现其他点数的概率为0.1。显然投掷B更容易出现大的点数。每次试验\u003cstrong\u003e第一次投掷时\u003c/strong\u003e，韦小宝会以0.4的概率出千（即投掷B）。但是在一次试验中，韦小宝不太可能一直出千，所以骰子会在A、B之间转换，比如这次投了B，下次可能会以0.1的概率投A。A、B之间的转移概率如下图。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"hmm-1\" loading=\"lazy\" src=\"/posts/2016-08-20-introduction-to-hmm-1/hmm-1.png\"\u003e\u003c/p\u003e\n\u003cp\u003e某一次试验，我们观察到韦小宝掷出的骰子序列为\\(O=(1,3,4,5,5,6,6,3,2,6)\\)，请问韦小宝什么时候出千了。这个问题就可以通过HMM求解。\u003c/p\u003e\n\u003cp\u003eHMM有2个状态：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e观测状态。我们观察到的骰子序列称为观测状态\\(\\mathbf{Y}=\\{y_1,y_2,…,y_T\\}\\)\u003c/li\u003e\n\u003cli\u003e隐状态。隐含在每个观测状态里面的是隐状态\\(\\mathbf{X}=\\{x_1,x_2,…,x_T\\}\\)\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eT是时间，也可以认为是观测的次数。HMM有3个参数：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e初始分布\\(\\mathbf{\\mu}=(\\mu_i)\\)，\\(\\mu_i=Pr(x_1=i)\\)，即第一次观测时，每个隐状态出现的概率\u003c/li\u003e\n\u003cli\u003e转移概率矩阵\\(A=(a_{ij})\\)，\\(a_{ij}=Pr(x_{t+1}=j|x_t=i)\\)，即t时刻的隐状态为i，t+1时刻转移到隐状态j的概率\u003c/li\u003e\n\u003cli\u003e发射概率矩阵\\(B=(b_{il})\\)，\\(b_{il}=Pr(y_t=l|x_t=i)\\)，即t时候隐状态为i的情况下，观测到状态为l的概率\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e参数\\(\\mathbf{\\lambda=\\{\\mu,A,B\\}}\\)称为HMM的模型参数。具体到上面的例子，我们有初始分布和转移概率为：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"hmm-3\" loading=\"lazy\" src=\"/posts/2016-08-20-introduction-to-hmm-1/hmm-3.png\"\u003e\u003c/p\u003e\n\u003cp\u003e发射概率为：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"hmm-4\" loading=\"lazy\" src=\"/posts/2016-08-20-introduction-to-hmm-1/hmm-4.png\"\u003e\u003c/p\u003e\n\u003cp\u003e观测状态为\\(\\mathbf{Y}=(1,3,4,5,5,6,6,3,2,6)\\)，问题就是求解出隐状态\\(\\mathbf{X}\\)，此问题被称为HMM的解码问题，可以由著名的\u003ca href=\"https://zh.wikipedia.org/wiki/%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95\"\u003e维特比算法（Viterbi algorithm）\u003c/a\u003e解决。\u003c/p\u003e\n\u003cp\u003e解码问题是要求出使得观测状态\\(Y\\)出现概率最大的隐状态\\(X\\)，假设有N个隐状态（本例为2），共有T个时刻（本例为10），则每个时刻有N个取值可能，则共有\\(N^T\\)条可能的隐状态链（本例为\\(2^{10}\\)）。我们需要求出每一条隐状态链下T个发射概率的乘积，然后取最大值，这是指数时间复杂度的（\\(O(N^T)\\)）。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"hmm-5\" loading=\"lazy\" src=\"/posts/2016-08-20-introduction-to-hmm-1/hmm-5.png\"\u003e\u003c/p\u003e\n\u003cp\u003e但是Viterbi算法是一个动态规划算法，只需多项式时间即可解决该问题。该算法的原理很好理解，假设我们求得到\\(s_{i2}\\)的最大概率路径为下图中的红线\\(s_{11}\\rightarrow s_{22}\\rightarrow … s_{i2}\\)，则在求经过\\(s_{i2}\\)到\\(s_{(i+1)1}\\)的最大概率路径时，不需要再测试\\(s_{13}\\rightarrow s_{21}\\rightarrow s_{i2}\\rightarrow s_{(i+1)1}\\)这条路径（下图蓝线），因为显然已经知道红线概率大于蓝线概率了。图中还有很多类似蓝线的路径都可以不用计算了，大大提高了求解速度。\u003c/p\u003e\n\u003cp\u003e因为计算第\\(i+1\\)时刻的累积概率只和第\\(i\\)时刻的概率有关，每次至多计算\\(N*N\\)个概率乘积（可以从\\(i\\)时刻的\\(N\\)个状态到达\\(i+1\\)时刻的某个状态，\\(i+1\\)时刻共有\\(N\\)个状态），最多计算T次（共T个时刻），所以时间复杂度降到了\\(O(N^2T)\\)。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"hmm-6\" loading=\"lazy\" src=\"/posts/2016-08-20-introduction-to-hmm-1/hmm-6.png\"\u003e\u003c/p\u003e\n\u003cp\u003e下面我们形式化的描述Viterbi算法。\u003c/p\u003e\n\u003cp\u003e假设\\(\\delta_t(i)\\)为\\(t\\)时刻取到隐状态\\(i\\)，且1~t的观测状态都符合观测值\\(Y\\)的各个路径的最大概率，即\u003c/p\u003e\n$$\n\\begin{equation}\\delta_t(i)=\\underset{i_1,…,i_{t-1}}{\\max}Pr(X_t=i,X_{t-1}=i_{t-1},…,X_1=i_1,Y_t=y_t,…,Y_1=y_1|\\mathbf{\\lambda})\\end{equation}\n$$\u003cp\u003e联系上图，可认为\\(\\delta_t(i)\\)为红线。则递推公式为：\u003c/p\u003e\n$$\n\\begin{equation}\\delta_{t+1}(i)=b_{iy_{t+1}}\\underset{j}{\\max}(\\delta_t(j)a_{ji})\\end{equation}\n$$\u003cp\u003e由\\(j\\)到\\(i\\)的转移概率，再乘上\\(i\\)发射\\(y_{t+1}\\)的概率。\u003c/p\u003e\n\u003cp\u003e在初始时刻\\(t=1\\)，有：\u003c/p\u003e\n$$\n\\begin{equation}\\delta_1(i)=\\mu_ib_{iy_1}\\end{equation}\n$$\u003cp\u003e最后的全局最大概率为\\(\\underset{j}{\\max}\\delta_T(j)\\)。为了得到完整路径，我们保留每一隐状态取得最大概率时的上一隐状态，即：\u003c/p\u003e\n$$\n\\begin{equation}\\psi_{t+1}(i)=j^*\\end{equation}\n$$\u003cp\u003e其中\\(j^*\\)要满足\u003c/p\u003e\n$$\n\\begin{equation}\\delta_{t+1}(i)=b_{iy_{t+1}}\\delta_t(j^*)a_{j^*i}\\end{equation}\n$$\u003cp\u003e最后使用如下回溯法得到所有最佳隐状态：\u003c/p\u003e\n$$\\begin{equation}X_T=i^*\\in\\{i:\\delta_T(i)=\\underset{j}{\\max}\\delta_T(j)\\}\\end{equation}$$$$\\begin{equation}X_t=\\psi_{t+1}(X_{t+1})\\end{equation}$$\u003cp\u003e下面我们利用Viterbi算法来求解韦小宝的骰子这个例子。\u003c/p\u003e\n\u003cp\u003e\\(t=1\\)时，\\(y_1=1\\)，有\\(\\delta_1(A)=0.6*1/6=0.1\\)，\\(\\delta_1(B)=0.4*0.1=0.04\\)。\u003c/p\u003e\n\u003cp\u003e\\(t=2\\)时，\\(y_2=3\\)，有：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e隐状态为A：a）A-\u0026gt;A有\\(\\delta_2(A)=(1/6)*0.1*0.8=1.33*10^{-2}\\)；b）B-\u0026gt;A有\\(\\delta_2(A)=(1/6)*0.04*0.1=6.6*10^{-4}\\)。所以A-\u0026gt;A，\\(\\psi_2(A)=A\\)。\u003c/li\u003e\n\u003cli\u003e隐状态为B：a）A-\u0026gt;B有\\(\\delta_2(B)=0.1*0.1*0.2=2*10^{-3}\\)；b）B-\u0026gt;B有\\(\\delta_2(B)=0.1*0.04*0.9=3.6*10^{-3}\\)。所以B-\u0026gt;B，\\(\\psi_2(B)=B\\)。\n如此计算下去，可以得到如下表：\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg alt=\"hmm-7\" loading=\"lazy\" src=\"/posts/2016-08-20-introduction-to-hmm-1/hmm-7.png\"\u003e\u003c/p\u003e\n\u003cp\u003e\\(t=10\\)时最大概率为\\(\\delta_{10}(B)\\)，经过回溯得到最佳隐状态为：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"hmm-8\" loading=\"lazy\" src=\"/posts/2016-08-20-introduction-to-hmm-1/hmm-8.png\"\u003e\u003c/p\u003e\n\u003cp\u003e所以HMM很神奇吧，可以抓住韦小宝从第5次开始就一直在出千，而且出千之后，掷出的点数大部分为5和6。\u003c/p\u003e\n\u003cp\u003eViterbi算法还可用于解决语音识别或者拼音输入法。我们知道中文的一个拼音可以对应多个汉字，连续的一段拼音就能组成成千上万种可能的句子，哪一个句子才是最佳候选呢？我们可以把每个拼音当成观测状态，同音的汉字当成可能的隐状态。通过背景语料库统计得到每个汉字出现在词首的概率、汉字之间的转移概率和汉字与拼音之间的发射概率，这样我们就能得到模型参数，然后利用Viterbi算法求解出一个最佳的隐状态序列，这样就能完成一个简易的拼音输入法。\u003c/p\u003e\n\u003cp\u003eHMM在实际中主要有3个方面的应用，分别是：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e从一段观测序列\\(\\mathbf{Y}\\)及已知模型\\(\\mathbf{\\lambda=(\\mu,A,B)}\\)出发，估计出隐状态\\(\\mathbf{X}\\)的最佳值，称为解码问题，这是状态估计问题。这篇博客讨论的就是这个问题。\u003c/li\u003e\n\u003cli\u003e从一段观测序列\\(\\mathbf{Y}\\)出发，估计模型参数组\\(\\mathbf{\\lambda=(\\mu,A,B)}\\)，称为学习问题，就是参数估计问题。\u003c/li\u003e\n\u003cli\u003e对于一个特定的观测链\\(\\mathbf{Y}\\)，已知它可能是由已经学习好的若干模型之一所得的观测，要决定此观测究竟是得自其中哪一个模型，这称为识别问题，就是分类问题。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e关于HMM的学习问题和识别问题，请听下回分解。\u003c/p\u003e","title":"隐马尔可夫模型及其应用（1）简介\u0026解码问题"},{"content":"半年的时光又过去了，圆满结束了一年的集中教学任务，离开了美丽的雁栖湖，回到闹市中关村。\n这半年基本上延续了研一上学期的高强度学习，四门硬课。《高级算法》这门课由四位大师级的老师授课，内容囊括了近似算法、计算复杂性、随机算法、局部搜索、全息规约等，完全是神一样的课。最后复习的时候，大家都生不如死啊，不过经过一个月的挑灯夜战，我还是取得了97分的好成绩，值了。\n《大数据系统与大规模数据分析》这门课的老师是一个年轻的海归，要求很严格，有专门的算法检查平时作业是否抄袭，真的有好几个同学因为抄袭而得0分。这门课的大作业是在GraphLite上实现SVD，我带领队员经过一个月的努力比较圆满的完成了大作业，感谢组里的编程大神。\n《机器学习方法与应用》是面向电子学院的课程，讲得太简单，考试基本是概念题，不建议选修。\n《生物信息学中的算法设计》这门课其实应该叫统计机器学习在生物信息领域的应用，讲的内容比《机器学习方法与应用》的内容更深更广。不过内容太多也难以消化，好好做大作业应该会有不少收获。\n集中教学一年，研一上的GPA是87分，研一下的GPA是89.3分，平均是88.1分。\n除了完成若干个课程大作业，这学期还完成了两个组内大作业，分别是倒排索引和蛋白质搜索引擎，也多谢XN和我一起查Bug、对答案。（天啊，我半年是做了多少个大作业啊…）\n这半年每周二回所和师姐交接任务，真是要感谢天真呆萌的JL师姐，当初保研的时候就被师姐的热情所感染，现在又有幸接替师姐的接力棒，好幸运。\n要说上半年最大的收获，应该是收获了一枚女朋友吧~没错，就是我这篇博客里提到的欣欣~真的没想到这么聊得来，一起吃饭、看电影、聊代码、骑行、游山玩水。这半年拍的照片，比我前22年拍的照片还多。和她在一起很开心，不过有时候也会很累，身体累（羸弱），有时候也心累，毕竟课程压力和组内压力摆在那里，白天去玩了，晚上还是要加班补回来的。有时候冷落了她，也会感到愧疚不安，特别是我在复习《高级算法》期间，两人都很少见面，那一次是真的惹欣欣生气了:-(\n总结一下在雁栖湖一年的收获，大致有如下图的四个方面：\n看看年初计划的完成情况：\n完成国科大下学期的课程任务：完成 接手pLink软件：完成 刷完LeetCode所有题目：上半年基本没刷题，下半年一定完成 读10本书：目前读了《数学之美》、《大话设计模式》、《我不知道该说什么，关于死亡还是爱情》、《男人来自火星、女人来自金星，卷I》，还差6本，下半年加油！ 去电影院看10场电影：目前看了《美人鱼》、《北京遇上西雅图之不二情书》、《忍者神龟2：破影而出》，还差好多… 改正坐姿：有一段时间刻意改正了，但是这东西貌似改不过来？ 下半年就进入实验室，开始科研实战了，做交联的师兄师姐都毕业了，留下我一个人，感觉好艰难，希望我能顺利进入角色，协助师兄把文章发了，维护好pLink2的软件，并且开发集群版。\n","permalink":"http://localhost:1313/posts/2016-08-20-2016-mid-year-summary/","summary":"\u003cp\u003e半年的时光又过去了，圆满结束了一年的集中教学任务，离开了美丽的雁栖湖，回到闹市中关村。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"ucas-schedule-2016-spring\" loading=\"lazy\" src=\"/posts/2016-08-20-2016-mid-year-summary/ucas-schedule-2016-spring.png\"\u003e\u003c/p\u003e\n\u003cp\u003e这半年基本上延续了研一上学期的高强度学习，四门硬课。《高级算法》这门课由四位大师级的老师授课，内容囊括了近似算法、计算复杂性、随机算法、局部搜索、全息规约等，完全是神一样的课。最后复习的时候，大家都生不如死啊，不过经过一个月的挑灯夜战，我还是取得了97分的好成绩，值了。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"advanced-algorithm\" loading=\"lazy\" src=\"/posts/2016-08-20-2016-mid-year-summary/advanced-algorithm.png\"\u003e\u003c/p\u003e\n\u003cp\u003e《大数据系统与大规模数据分析》这门课的老师是一个年轻的海归，要求很严格，有专门的算法检查平时作业是否抄袭，真的有好几个同学因为抄袭而得0分。这门课的大作业是在GraphLite上实现SVD，我带领队员经过一个月的努力比较圆满的完成了大作业，感谢组里的编程大神。\u003c/p\u003e\n\u003cp\u003e《机器学习方法与应用》是面向电子学院的课程，讲得太简单，考试基本是概念题，不建议选修。\u003c/p\u003e\n\u003cp\u003e《生物信息学中的算法设计》这门课其实应该叫统计机器学习在生物信息领域的应用，讲的内容比《机器学习方法与应用》的内容更深更广。不过内容太多也难以消化，好好做大作业应该会有不少收获。\u003c/p\u003e\n\u003cp\u003e集中教学一年，研一上的GPA是87分，研一下的GPA是89.3分，平均是88.1分。\u003c/p\u003e\n\u003cp\u003e除了完成若干个课程大作业，这学期还完成了两个组内大作业，分别是倒排索引和蛋白质搜索引擎，也多谢XN和我一起查Bug、对答案。（天啊，我半年是做了多少个大作业啊…）\u003c/p\u003e\n\u003cp\u003e这半年每周二回所和师姐交接任务，真是要感谢天真呆萌的JL师姐，当初保研的时候就被师姐的热情所感染，现在又有幸接替师姐的接力棒，好幸运。\u003c/p\u003e\n\u003cp\u003e要说上半年最大的收获，应该是收获了一枚女朋友吧~没错，就是我\u003cdel\u003e这篇博客\u003c/del\u003e里提到的欣欣~真的没想到这么聊得来，一起吃饭、看电影、聊代码、骑行、游山玩水。这半年拍的照片，比我前22年拍的照片还多。和她在一起很开心，不过有时候也会很累，身体累（羸弱），有时候也心累，毕竟课程压力和组内压力摆在那里，白天去玩了，晚上还是要加班补回来的。有时候冷落了她，也会感到愧疚不安，特别是我在复习《高级算法》期间，两人都很少见面，那一次是真的惹欣欣生气了:-(\u003c/p\u003e\n\u003cp\u003e总结一下在雁栖湖一年的收获，大致有如下图的四个方面：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"mid-year 2016 summary\" loading=\"lazy\" src=\"/posts/2016-08-20-2016-mid-year-summary/mid-year-2016-summary.png\"\u003e\u003c/p\u003e\n\u003cp\u003e看看\u003ca href=\"https://bitjoy.net/posts/2016-01-03-2016-happy-new-year/\"\u003e年初计划\u003c/a\u003e的完成情况：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cdel\u003e完成国科大下学期的课程任务：完成\u003c/del\u003e\u003c/li\u003e\n\u003cli\u003e\u003cdel\u003e接手pLink软件：完成\u003c/del\u003e\u003c/li\u003e\n\u003cli\u003e刷完LeetCode所有题目：上半年基本没刷题，下半年一定完成\u003c/li\u003e\n\u003cli\u003e读10本书：目前读了《数学之美》、《大话设计模式》、《我不知道该说什么，关于死亡还是爱情》、《男人来自火星、女人来自金星，卷I》，还差6本，下半年加油！\u003c/li\u003e\n\u003cli\u003e去电影院看10场电影：目前看了《美人鱼》、《北京遇上西雅图之不二情书》、《忍者神龟2：破影而出》，还差好多…\u003c/li\u003e\n\u003cli\u003e改正坐姿：有一段时间刻意改正了，但是这东西貌似改不过来？\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e下半年就进入实验室，开始科研实战了，做交联的师兄师姐都毕业了，留下我一个人，感觉好艰难，希望我能顺利进入角色，协助师兄把文章发了，维护好pLink2的软件，并且开发集群版。\u003c/p\u003e","title":"2016年中总结"},{"content":"我们知道常规的快速排序算法是一个不稳定的算法，也就是两个相等的数排序之后的顺序可能和在原序列中的顺序不同。这是因为当选定一个枢轴（pivot），要把其他数分到小于pivot和大于pivot的两边的时候，不同实现的分法不一样。\n下面我实现了一种稳定版快速排序算法，在Partition函数中保持了原序列中所有元素的相对顺序，只把pivot放到了它的正确位置。具体方法是三遍扫描原序列：1）第一遍先把小于pivot的元素按先后顺序放到tmp里，然后把pivot放到它的正确位置tmp[k]；2）第二遍把大于pivot的元素按先后顺序追加在tmp里，这样除了pivot以前的其他元素，都保持了和原序列中一样的顺序；3）第三遍把tmp赋值回原数组A。\n当排序算法稳定之后，就可以借此统计逆序数了，文件Q5.txt中共包含100000个不同的整数，每行一个数。我们可以使用稳定版快速排序算法对其排序，并统计出其中的逆序数个数。\n具体的Python 3实现如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 # -*- coding: utf-8 -*- \u0026#34;\u0026#34;\u0026#34; Created on Tue Oct 6 00:21:37 2015 @author: bitjoy \u0026#34;\u0026#34;\u0026#34; import time inversions = 0 def Partition(A, p, r): global inversions tmp = [0] * (r-p+1) pivot = A[p] k = 0 for i in range(p+1, r+1): # first if A[i] \u0026lt; pivot: tmp[k] = A[i] inversions = inversions + i – k – p k = k + 1 tmp[k] = pivot ans = k + p k = k + 1 for i in range(p+1, r+1): # second if A[i] \u0026gt; pivot: tmp[k] = A[i] k = k + 1 k = 0 for i in range(p, r+1): # third A[i] = tmp[k] k = k + 1 return ans def QuickSortAndCount(A, p, r): if p \u0026lt; r: q = Partition(A, p, r) QuickSortAndCount(A, p, q-1) QuickSortAndCount(A, q + 1, r) if __name__ == \u0026#34;__main__\u0026#34;: Q5 = open(\u0026#39;Q5.txt\u0026#39;, encoding = \u0026#39;utf-8\u0026#39;) data = [ int(x) for x in Q5 ] Q5.close() start = time.clock() QuickSortAndCount(data, 0, len(data) -1 ) end = time.clock() print(\u0026#34;number of inversions:%d\\ntime:%f s\u0026#34;%(inversions,end-start)) 虽然这种快排的时间复杂度还是O(nlgn)，但是在Partition函数中扫描了3次数组，并且借用了辅助数组tmp，不再是in-place排序算法，所以排序用时会比常规快排或者归并排序要慢。\n","permalink":"http://localhost:1313/posts/2016-08-18-the-stable-quick-sort/","summary":"\u003cp\u003e我们知道常规的快速排序算法是一个不稳定的算法，也就是两个相等的数排序之后的顺序可能和在原序列中的顺序不同。这是因为当选定一个枢轴（pivot），要把其他数分到小于pivot和大于pivot的两边的时候，不同实现的分法不一样。\u003c/p\u003e\n\u003cp\u003e下面我实现了一种稳定版快速排序算法，在Partition函数中保持了原序列中所有元素的相对顺序，只把pivot放到了它的正确位置。具体方法是三遍扫描原序列：1）第一遍先把小于pivot的元素按先后顺序放到tmp里，然后把pivot放到它的正确位置tmp[k]；2）第二遍把大于pivot的元素按先后顺序追加在tmp里，这样除了pivot以前的其他元素，都保持了和原序列中一样的顺序；3）第三遍把tmp赋值回原数组A。\u003c/p\u003e\n\u003cp\u003e当排序算法稳定之后，就可以借此统计逆序数了，文件\u003ca href=\"/posts/2016-08-18-the-stable-quick-sort/Q5.zip\"\u003eQ5.txt\u003c/a\u003e中共包含100000个\u003cstrong\u003e不同\u003c/strong\u003e的整数，每行一个数。我们可以使用稳定版快速排序算法对其排序，并统计出其中的逆序数个数。\u003c/p\u003e\n\u003cp\u003e具体的Python 3实现如下：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\n\u003ctable style=\"border-spacing:0;padding:0;margin:0;border:0;\"\u003e\u003ctr\u003e\u003ctd style=\"vertical-align:top;padding:0;margin:0;border:0;\"\u003e\n\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 1\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 2\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 3\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 4\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 5\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 6\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 7\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 8\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 9\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e10\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e11\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e12\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e13\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e14\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e15\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e16\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e17\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e18\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e19\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e20\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e21\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e22\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e23\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e24\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e25\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e26\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e27\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e28\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e29\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e30\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e31\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e32\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e33\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e34\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e35\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e36\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e37\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e38\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e39\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e40\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e41\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e42\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e43\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e44\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e45\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e46\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd style=\"vertical-align:top;padding:0;margin:0;border:0;;width:100%\"\u003e\n\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# -*- coding: utf-8 -*-\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u0026#34;\u0026#34;\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003eCreated on Tue Oct 6 00:21:37 2015\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e@author: bitjoy\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u0026#34;\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e time\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einversions \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ePartition\u003c/span\u003e(A, p, r):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eglobal\u003c/span\u003e inversions\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    tmp \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [\u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e] \u003cspan style=\"color:#f92672\"\u003e*\u003c/span\u003e (r\u003cspan style=\"color:#f92672\"\u003e-\u003c/span\u003ep\u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    pivot \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e A[p]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    k \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e i \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e range(p\u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e, r\u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e): \u003cspan style=\"color:#75715e\"\u003e# first\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e A[i] \u003cspan style=\"color:#f92672\"\u003e\u0026lt;\u003c/span\u003e pivot:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            tmp[k] \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e A[i]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            inversions \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e inversions \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e i \u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e–\u003c/span\u003e k \u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e–\u003c/span\u003e p\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            k \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e k \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        tmp[k] \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e pivot\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        ans \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e k \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e p\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        k \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e k \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e i \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e range(p\u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e, r\u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e): \u003cspan style=\"color:#75715e\"\u003e# second\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e A[i] \u003cspan style=\"color:#f92672\"\u003e\u0026gt;\u003c/span\u003e pivot:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            tmp[k] \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e A[i]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            k \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e k \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            k \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e i \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e range(p, r\u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e): \u003cspan style=\"color:#75715e\"\u003e# third\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        A[i] \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e tmp[k]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        k \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e k \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e ans\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eQuickSortAndCount\u003c/span\u003e(A, p, r):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e p \u003cspan style=\"color:#f92672\"\u003e\u0026lt;\u003c/span\u003e r:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    q \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e Partition(A, p, r)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    QuickSortAndCount(A, p, q\u003cspan style=\"color:#f92672\"\u003e-\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    QuickSortAndCount(A, q \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e, r)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e __name__ \u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;__main__\u0026#34;\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    Q5 \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e open(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;Q5.txt\u0026#39;\u003c/span\u003e, encoding \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;utf-8\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    data \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [ int(x) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e x \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e Q5 ]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    Q5\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eclose()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    start \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e time\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eclock()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    QuickSortAndCount(data, \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e, len(data) \u003cspan style=\"color:#f92672\"\u003e-\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e )\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    end \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e time\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eclock()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    print(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;number of inversions:\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e%d\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e\\n\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003etime:\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e%f\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e s\u0026#34;\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e%\u003c/span\u003e(inversions,end\u003cspan style=\"color:#f92672\"\u003e-\u003c/span\u003estart))\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e虽然这种快排的时间复杂度还是O(nlgn)，但是在Partition函数中扫描了3次数组，并且借用了辅助数组tmp，不再是in-place排序算法，所以排序用时会比常规快排或者归并排序要慢。\u003c/p\u003e","title":"稳定版快速排序算法"},{"content":"哈弗曼编码是一个很经典的压缩算法，压缩率能达到50%，甚至更低。它的基本原理包括四个步骤：\n统计文件中每个字符出现的频率。 构建一个哈弗曼树。建树的过程是不断的合并频率最小的两个节点，父亲节点的频率为两个孩子节点的频率之和。如此循环直到合并成一个根节点。叶子节点为不同的字符及其频率。 生成哈弗曼编码。从树根开始对树进行编码，比如进入左孩子的边标记为0，进入右孩子的边标记为1，这里的0和1都是二进制位。这样之后，每个叶子节点都有一个唯一的二进制编码，这就是哈弗曼编码。频率越低的字符哈弗曼编码越长，频率越高的字符哈弗曼编码越短，这样就能起到压缩的效果。 第二遍扫描文件，把字符转换为对应的哈弗曼编码，保存成压缩文件。 解压缩的过程就是解析二进制位，然后查找哈弗曼树，每找到一个叶子节点，就解析出一个字符，直到解析完所有二进制位。下面详细解释我的C++实现。\n首先定义一个哈弗曼编码类，对外只提供压缩Compress和解压缩Decompress两个接口。值得注意的是有一个Node结构体，用于构成哈弗曼树的节点。此外count_node的key是字符频率，value是所在节点，且是multimap类型的，所以count_node会自动按字符频率有小到大排序，在构建哈弗曼树时，每次只需要取count_node的前两个节点进行合并即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 class HuffmanCode { public: HuffmanCode(); void Compress(string src, string dest); void Decompress(string src, string dest); virtual ~HuffmanCode(); private: void CountLetter(string src); void ConstructHuffmanTree(); void GenerateHuffmanCode(); void WriteHuffmanCode(ofstream \u0026amp;os); void Compressing(string src, string dest); void InsertIntoHuffmanTree(char letter, string \u0026amp;code, int \u0026amp;k); void ConstructHuffmanTreeFromFile(ifstream \u0026amp;is); void Decompressing(ifstream \u0026amp;is, ofstream \u0026amp;os); map\u0026lt;char, int\u0026gt; letter_count; typedef struct Node { int id; bool is_leaf; char letter; int parent, lchild, rchild; Node() { } Node(int i, bool il, char lt, int p, int lc, int rc) : id(i), is_leaf(il), letter(lt), parent(p), lchild(lc), rchild(rc) { } }; multimap\u0026lt;int, Node\u0026gt; count_node; vector\u0026lt;Node\u0026gt; huffman_tree; map\u0026lt;char, vector\u0026lt;char\u0026gt;\u0026gt; letter_hcode; // hufman code for each letter }; 压缩函数Compress串起压缩的整个流程，包括统计字符频率、构建哈弗曼树、生成哈弗曼编码以及最后将原始文件转换成哈弗曼编码的二进制文件。\n1 2 3 4 5 6 void HuffmanCode::Compress(string src, string dest) { CountLetter(src); ConstructHuffmanTree(); GenerateHuffmanCode(); Compressing(src, dest); } Compress中的前三个函数不难，值得注意的是Compressing函数，它是真正进行压缩的函数。函数首先调用WriteHuffmanCode把每个字符的哈弗曼编码写入文件，作为文件头信息，以备后续解压使用。然后循环读取文件，把字符转换为哈弗曼二进制编码。每8 bit哈弗曼二进制位构成一个char byte，多个byte构成os_buf，当os_buf满时写入文件。\n在最后边界位置，需要小心处理。因为可能所有二进制位并不刚好是8的整数倍，所以在压缩文件的末尾用 1 byte作为标记。如果flag为0x0，则所有二进制位刚好是8的整数倍，无需特别处理。如果flag为0x01，则还剩小于8个二进制位需要单独放在一个byte里面，所以还需要一个byte存储剩余多少个二进制位。假设最后3个bytes分别为x,y,z，则如果z==0x0，则x,y常规解析；如果z==0x01，则只解析x中的前y个bits。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 void HuffmanCode::Compressing(string src, string dest) { ifstream is(src, ios::binary); ofstream os(dest, ios::binary); WriteHuffmanCode(os); char *is_buf = new char[MAX_LEN], *os_buf = new char[MAX_LEN]; list\u0026lt;char\u0026gt; tmp_hcode; int start_pos = 0, i, j, k, len, t; char c, flag = 0x0; // flag for the last byte list\u0026lt;char\u0026gt;::iterator it; while (is.peek() != EOF) { is.read(is_buf, MAX_LEN); len = is.gcount(); for (i = 0; i \u0026lt; len; i++) tmp_hcode.insert(tmp_hcode.end(), letter_hcode[is_buf[i]].begin(), letter_hcode[is_buf[i]].end()); k = tmp_hcode.size() / 8; t = 0; i = 0; it = tmp_hcode.begin(); while (i \u0026lt; 8 * k) { c = 0x0; for (j = i; j \u0026lt;= i + 7; j++) { c = (*it == \u0026#39;1\u0026#39;) ? (c | (1 \u0026lt;\u0026lt; (i + 7 – j))) : c; // char -\u0026gt; bit it++; } os_buf[t++] = c; i += 8; } os.write(os_buf, t * sizeof(char)); tmp_hcode.erase(tmp_hcode.begin(), it); } c = 0x0; i = 7; bool done = true; while (it != tmp_hcode.end()) { done = false; c = (*it == \u0026#39;1\u0026#39;) ? (c | (1 \u0026lt;\u0026lt; i)) : c; // left bits i–; it++; } if (!done) { os.write(\u0026amp;c, sizeof(char)); c = 7 – i; // only c bits used in the last byte os.write(\u0026amp;c, sizeof(char)); flag = 0x1; // the last byte is incomplete } os.write(\u0026amp;flag, sizeof(char)); is.close(); os.close(); delete[] is_buf; delete[] os_buf; } 函数Decompress串起解压缩的整个流程。首先调用ConstructHuffmanTreeFromFile读取压缩文件的头信息，也就是字符和哈弗曼编码的对应关系，然后构建哈弗曼树。同样Decompressing是实际的解压缩过程，它不断读取哈弗曼二进制位，然后从哈弗曼树根节点开始往下走，直到到达一个叶子节点，则解析出一个字符，如此循环，直到解析完所有二进制位。\n1 2 3 4 5 6 7 8 void HuffmanCode::Decompress(string src, string dest) { ifstream is(src, ios::binary); ofstream os(dest, ios::binary); ConstructHuffmanTreeFromFile(is); Decompressing(is, os); is.close(); os.close(); } 完整项目可以查看我的Github项目HZip，Windows版可执行程序请点此下载。\n压缩命令为：\n1 HZip.exe -c original_file_path compressed_file_path 解压缩命令为：\n1 HZip.exe -x compressed_file_path decompressed_file_path 下面是一些测试结果。\n//还没有统计好。。。\n//看来还是7Z道高一尺。\n我后面发现HZip甚至可以压缩/解压缩中文txt、pdf、图片、视频等（其实只要是ASCII编码的应该都可以吧？）。但是中文压缩效率较低，图片视频等压缩之后的大小几乎和没压缩是一样的:-(其实这很好理解，因为哈弗曼编码是根据字符频率的差异来编码的，英文只有26个字母加上一些符号，压缩效率肯定很高，而中文是以字为单位存储的，所以当以char读取来编码的时候，不同char的数量肯定更多，导致压缩效率较低。图片和视频就不得而知了。\n在测试的时候我发现压缩和解压缩大文件的时候，速度极其的慢，简直到了不能忍的地步，下一步我将分析性能瓶颈，争取把速度提高到可以接受的范围。\n","permalink":"http://localhost:1313/posts/2016-08-18-the-implementation-of-huffman-code/","summary":"\u003cp\u003e哈弗曼编码是一个很经典的压缩算法，压缩率能达到50%，甚至更低。它的基本原理包括四个步骤：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e统计文件中每个字符出现的频率。\u003c/li\u003e\n\u003cli\u003e构建一个哈弗曼树。建树的过程是不断的合并频率最小的两个节点，父亲节点的频率为两个孩子节点的频率之和。如此循环直到合并成一个根节点。叶子节点为不同的字符及其频率。\u003c/li\u003e\n\u003cli\u003e生成哈弗曼编码。从树根开始对树进行编码，比如进入左孩子的边标记为0，进入右孩子的边标记为1，这里的0和1都是二进制位。这样之后，每个叶子节点都有一个唯一的二进制编码，这就是哈弗曼编码。频率越低的字符哈弗曼编码越长，频率越高的字符哈弗曼编码越短，这样就能起到压缩的效果。\u003c/li\u003e\n\u003cli\u003e第二遍扫描文件，把字符转换为对应的哈弗曼编码，保存成压缩文件。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e解压缩的过程就是解析二进制位，然后查找哈弗曼树，每找到一个叶子节点，就解析出一个字符，直到解析完所有二进制位。下面详细解释我的C++实现。\u003c/p\u003e\n\u003cp\u003e首先定义一个哈弗曼编码类，对外只提供压缩Compress和解压缩Decompress两个接口。值得注意的是有一个Node结构体，用于构成哈弗曼树的节点。此外count_node的key是字符频率，value是所在节点，且是multimap类型的，所以count_node会自动按字符频率有小到大排序，在构建哈弗曼树时，每次只需要取count_node的前两个节点进行合并即可。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\n\u003ctable style=\"border-spacing:0;padding:0;margin:0;border:0;\"\u003e\u003ctr\u003e\u003ctd style=\"vertical-align:top;padding:0;margin:0;border:0;\"\u003e\n\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 1\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 2\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 3\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 4\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 5\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 6\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 7\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 8\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 9\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e10\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e11\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e12\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e13\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e14\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e15\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e16\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e17\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e18\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e19\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e20\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e21\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e22\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e23\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e24\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e25\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e26\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e27\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e28\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e29\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e30\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e31\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e32\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e33\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e34\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e35\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e36\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e37\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd style=\"vertical-align:top;padding:0;margin:0;border:0;;width:100%\"\u003e\n\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-cpp\" data-lang=\"cpp\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eclass\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eHuffmanCode\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003epublic\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    HuffmanCode();\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003evoid\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eCompress\u003c/span\u003e(string src, string dest);\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003evoid\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eDecompress\u003c/span\u003e(string src, string dest);\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003evirtual\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e~\u003c/span\u003eHuffmanCode();\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eprivate\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003evoid\u003c/span\u003e CountLetter(string src);\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003evoid\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eConstructHuffmanTree\u003c/span\u003e();\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003evoid\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eGenerateHuffmanCode\u003c/span\u003e();\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003evoid\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eWriteHuffmanCode\u003c/span\u003e(ofstream \u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u003c/span\u003eos);\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003evoid\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eCompressing\u003c/span\u003e(string src, string dest);\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003evoid\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eInsertIntoHuffmanTree\u003c/span\u003e(\u003cspan style=\"color:#66d9ef\"\u003echar\u003c/span\u003e letter, string \u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u003c/span\u003ecode, \u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u003c/span\u003ek);\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003evoid\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eConstructHuffmanTreeFromFile\u003c/span\u003e(ifstream \u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u003c/span\u003eis);\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003evoid\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eDecompressing\u003c/span\u003e(ifstream \u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u003c/span\u003eis, ofstream \u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u003c/span\u003eos);\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    map\u003cspan style=\"color:#f92672\"\u003e\u0026lt;\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003echar\u003c/span\u003e, \u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e\u0026gt;\u003c/span\u003e letter_count;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003etypedef\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eNode\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e id;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003ebool\u003c/span\u003e is_leaf;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003echar\u003c/span\u003e letter;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e parent, lchild, rchild;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        Node() {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        Node(\u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e i, \u003cspan style=\"color:#66d9ef\"\u003ebool\u003c/span\u003e il, \u003cspan style=\"color:#66d9ef\"\u003echar\u003c/span\u003e lt, \u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e p, \u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e lc, \u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e rc) \u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            id(i), is_leaf(il), letter(lt), parent(p), lchild(lc), rchild(rc) {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    };\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    multimap\u003cspan style=\"color:#f92672\"\u003e\u0026lt;\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e, Node\u003cspan style=\"color:#f92672\"\u003e\u0026gt;\u003c/span\u003e count_node;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    vector\u003cspan style=\"color:#f92672\"\u003e\u0026lt;\u003c/span\u003eNode\u003cspan style=\"color:#f92672\"\u003e\u0026gt;\u003c/span\u003e huffman_tree;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    map\u003cspan style=\"color:#f92672\"\u003e\u0026lt;\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003echar\u003c/span\u003e, vector\u003cspan style=\"color:#f92672\"\u003e\u0026lt;\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003echar\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e\u0026gt;\u0026gt;\u003c/span\u003e letter_hcode; \u003cspan style=\"color:#75715e\"\u003e// hufman code for each letter\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e};\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e压缩函数Compress串起压缩的整个流程，包括统计字符频率、构建哈弗曼树、生成哈弗曼编码以及最后将原始文件转换成哈弗曼编码的二进制文件。\u003c/p\u003e","title":"Huffman编码压缩算法及其实现"},{"content":"之前写了七篇博客详细介绍了搜索引擎的工作原理。彼时的搜索引擎主要讲查询和网页的相关性匹配，是动态的、在线的、实时的。相关性匹配有一个问题，网页很容易作弊，比如可以在一个网页中写满诸如“免费”、“美容”之类的垃圾关键词，进而提升查询相关性。但是用户在查询时，一定希望返回的网页比较权威可信，比如同样搜索“苹果电脑”，排名第一的应该是Apple的官网，而不应该是中关村在线之类的第三方网站。\n权威性是一个静态的（或者说变化较慢的）衡量网页重要性的指标。但是应该怎样度量权威性呢，HITS算法使用authority来度量，即指向自身的网页数量越多，则自身的authority值越大。谷歌的PageRank算法是用PageRank值来衡量权威性的。HITS和PageRank一个比较大的区别是HITS和查询有关，而PageRank和查询无关，所以PageRank可以离线计算。下面主要介绍PageRank算法。\nPageRank’s thesis is that a webpage is important if it is pointed to by other important pages.\n我先不加解释的给出PageRank的公式，然后带领大家一步步推导出这个公式。\n$$\\pi^T=\\pi^T(\\alpha S+(1-\\alpha)E)$$我们首先明确目标：PageRank计算的是网页的静态权威度（PR值），也就是如果给定了一个网络结构，则每个网页的PR值就可以通过PageRank算法计算出。假设网页\\(P_i\\)的PR值为\\(r(P_i)\\)，则\\(r(P_i)\\)等于所有指向\\(P_i\\)的网页的PR值之和，即\n$$\\begin{equation}r(P_i)=\\sum\\limits_{P_j\\in B_{P_i}}\\frac{r(P_j)}{|P_j|}\\end{equation}$$其中\\(B_{P_i}\\)为指向\\(P_i\\)的网页集合，\\(|P_j|\\)为\\(P_j\\)的出边的数量。这个式子很好理解，包括两方面内容：1）\\(\\sum\\limits_{P_j\\in B_{P_i}}\\)表示如果指向\\(P_i\\)的网页数量越多，说明网页\\(P_i\\)越重要；2）\\(\\frac{r(P_j)}{|P_j|}\\)表示如果\\(P_j\\)指向的页面数量越少，但有一个指向了\\(P_i\\)，说明网页\\(P_i\\)越重要（如果一个大牛写了很多推荐信（\\(|P_j|\\)大），则这些推荐信的效力就下降了，如果大牛只给你写了推荐信（\\(|P_j|=1\\)），则这封推荐信的效力一定很高）。\n(1)式有一个问题，初始给定一个网络结构时，并不知道\\(r(P_i), r(P_j)\\)，如何计算呢？Brin和Page利用递归的思想求解，初始假设所有网页的PR值相等，都为\\(\\frac{1}{n}\\)，其中\\(n\\)为网络中网页的数量。则第\\(k+1\\)轮的PR计算公式为：\n$$\\begin{equation}r_{k+1}(P_i)=\\sum\\limits_{P_j\\in B_{P_i}}\\frac{r_k(P_j)}{|P_j|}\\end{equation}$$初始对所有网页\\(P_i\\)有\\(r_0(P_i)=\\frac{1}{n}\\)，迭代\\(k\\)步之后，可以计算出所有网页的PR值，然后按PR值从大到小排序，就可以知道每个网页的重要性了。\n对于上图的小网络，我们可以计算出其每一步的PR值：\n可以看到经过2次迭代之后，节点4的PR值最大，从图中也可以看出，节点4的出入边较多，它可能比较重要。\n注意到对于(2)式，当\\(i,j\\)之间有边时，\\(\\frac{1}{|P_j|}\\)相当于对\\(P_j\\)出度的归一化，设矩阵\\(H\\)为图的邻接矩阵的行归一化矩阵，对于上图，为\n设行向量\\(\\pi^{(k)T}\\)为第\\(k\\)轮迭代时所有网页的PR值，则式(2)可以转换为如下的矩阵形式：\n$$\\begin{equation}\\pi^{(k+1)T}=\\pi^{(k)T}H\\end{equation}$$初始有\\(\\pi^{(0)T}=\\frac{1}{n}e^T\\)，\\(e^T\\)为全1的行向量。我们可以从(3)式观测出几点信息：\n(3)式的每一轮计算涉及到向量和矩阵的乘法，复杂度为\\(O(n^2)\\)，\\(n\\)为矩阵\\(H\\)的大小 \\(H\\)是一个稀疏矩阵，因为大部分网页只和很少的网页有链接关系，所以上述向量和矩阵的乘法复杂度还可以降低 \\(H\\)有点像马尔科夫链中的随机转移矩阵，但又不完全是，因为如果有dangling nodes，则这一行就是全0，所以\\(H\\)被称为substochastic matrix 上图中的节点3就是一个dangling node，它只有入边，没有出边，也就是说，每一轮迭代，PR值只会流入3号节点，不会从3号节点流出，久而久之，3就像一个水槽(sink)一样，吸走了大部分的PR，导致PR值虚高。\n所以问题随之而来，怎样保证(3)式一定能够收敛到一个平稳概率分布\\(\\pi^T\\)，\\(\\pi^T\\)和\\(\\pi^{(0)T}\\)有关吗，怎样解决dangling nodes问题，等等。此时需要引入一点马尔科夫链理论的知识。\n在马尔科夫理论呢中，如果一个矩阵\\(P\\)是随机的（stochastic）、不可约的（irreducible）和非周期的（aperiodic），则对于任意的起始向量，都能收敛到一个唯一的平稳正向量。所以如果PageRank矩阵\\(H\\)满足上述三个条件，则可以用幂法（Power Method）找到一个平稳概率分布\\(\\pi^T\\)。幂法是用来计算最大特征值的特征向量。因为\\(H\\)的最大特征值为1，所以可以用幂法找到稳态时（\\(\\pi^T=\\pi^TH\\)）的概率分布\\(\\pi^T\\)。\n下面我们就将矩阵\\(H\\)调整为随机的（stochastic）、不可约的（irreducible）和非周期的（aperiodic）。\n行随机矩阵是指行和为1的非负矩阵。如果图中含有dangling nodes，则\\(H\\)不是随机的，比如上面的例子，第二行为全0。所以第一个调整是对于所有dangling nodes，都加上一个随机跳转向量\\(e^T/n\\)，含义就是如果进入死胡同（dangling nodes），则随机跳转到网络中的任意一个网页。定义向量\\(a\\)：\n$$\\begin{equation}a_i=\\begin{cases}1\\quad\\text{if page}~i\\text{ is a dangling node}\\\\0\\quad\\text{otherwise}\\end{cases}\\end{equation}$$则新的Google矩阵为：\n$$\\begin{equation}S=H+a\\frac{1}{n}e^T\\end{equation}$$新矩阵\\(S\\)就是一个行随机矩阵了。对于上图的例子，有\n为了保证矩阵\\(S\\)满足不可约性（irreducible）和非周期性（aperiodic），必须使\\(S\\)对应的图是强连通的且每个节点有自回路。所以再次调整为：\n$$\\begin{equation}G=\\alpha S+(1-\\alpha)\\frac{1}{n}ee^T\\end{equation}$$令\n$$\\begin{equation}E=\\frac{1}{n}ee^T\\end{equation}$$则得到本博客开头的Google矩阵公式：\n$$\\begin{equation}G=\\alpha S+(1-\\alpha)E\\end{equation}$$\\(E\\)即为随机平均游走矩阵。矩阵\\(G\\)也很好解释，大家上网的时候以\\(\\alpha\\)的概率沿着某个网页里面的链接一步步深入进去（\\(S\\)），当沿着链接走累的时候，以\\(1-\\alpha\\)的概率在地址栏输入一个新地址，随机跳走了（\\(E\\)）。\n此时的矩阵\\(G\\)满足随机性（stochastic）、不可约性（irreducible）和非周期性（aperiodic），所以可以根据幂法（Power Method）找到一个平稳概率分布\\(\\pi^T\\)，\\(\\pi^T_i\\)就衡量了网页\\(P_i\\)的重要性或者权威性。\n此时只剩下参数\\(\\alpha\\)了，\\(\\alpha\\)平衡了网络结构和随机游走。如果\\(\\alpha\\)很小，则\\(1-\\alpha\\)大，\\(G\\)就退化成一个人造随机网络，不能很好的反应真实的网络结构。如果\\(\\alpha\\)很大，则有可能不能得到一个稳态分布，或者幂法会失效。当\\(\\alpha\\approx 1\\)时，幂法失效，且\\(\\pi^T(\\alpha)\\)对\\(H\\)的微小扰动很敏感。Google的选择是\\(\\alpha=0.85\\)。\n将(5)式带入(6)式，得到\n$$\\begin{equation}G=\\alpha H+(\\alpha a+(1-\\alpha)e)\\frac{1}{n}e^T\\end{equation}$$(9)式就非常好计算了，只涉及到向量和矩阵的乘法，而且矩阵\\(H\\)还是稀疏矩阵，复杂度还可以降低。\n幂法（Power Method）求解PageRank稳态分布就是不断计算下面的等式：\n$$\\begin{equation}\\pi^{(k+1)T}=\\pi^{(k)T}G=\\alpha \\pi^{(k)T}H+(\\alpha\\pi^{(k)T}a+1-\\alpha)e^T/n\\end{equation}$$当前后两次的\\(\\pi^{(k+1)T}\\)和\\(\\pi^{(k)T}\\)变化小于某个阈值时，算法收敛，所以算法实现是非常容易的。Brin and Page在他们1998年的论文中提到，只需要50-100次迭代运算就可以收敛了。\n对于上图的例子，令\\(\\alpha=0.9\\)，解得\n利用幂法解得稳态分布为\n所以这6个网页的排名为4\u0026gt;6\u0026gt;5\u0026gt;2\u0026gt;3\u0026gt;1。\n真正的搜索引擎应该综合了网页的静态权威性（如PageRank值）和查询的相关性，每个网站都有一个PR值，具体可以点此查询。\n本博客主要内容参考Google’s PageRank and Beyond: The Science of Search Engine Rankings[1]，插图即为该书封面；如果想快速了解PageRank，可以参考[2]；[3]的讲解也很详细。\nhttp://geza.kzoo.edu/~erdi/patent/langvillebook.pdf http://www.cs.cmu.edu/~elaw/pagerank.pdf http://www.ams.org/samplings/feature-column/fcarc-pagerank ","permalink":"http://localhost:1313/posts/2016-08-04-googles-pagerank-and-beyond/","summary":"\u003cp\u003e之前写了\u003ca href=\"https://bitjoy.net/categories/%E5%92%8C%E6%88%91%E4%B8%80%E8%B5%B7%E6%9E%84%E5%BB%BA%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/\"\u003e七篇博客\u003c/a\u003e详细介绍了搜索引擎的工作原理。彼时的搜索引擎主要讲查询和网页的\u003cstrong\u003e相关性\u003c/strong\u003e匹配，是动态的、在线的、实时的。相关性匹配有一个问题，网页很容易作弊，比如可以在一个网页中写满诸如“免费”、“美容”之类的垃圾关键词，进而提升查询相关性。但是用户在查询时，一定希望返回的网页比较\u003cstrong\u003e权威可信\u003c/strong\u003e，比如同样搜索“苹果电脑”，排名第一的应该是Apple的官网，而不应该是中关村在线之类的第三方网站。\u003c/p\u003e\n\u003cp\u003e权威性是一个静态的（或者说变化较慢的）衡量网页重要性的指标。但是应该怎样度量权威性呢，\u003ca href=\"https://en.wikipedia.org/wiki/HITS_algorithm\"\u003eHITS算法\u003c/a\u003e使用authority来度量，即指向自身的网页数量越多，则自身的authority值越大。谷歌的\u003ca href=\"https://en.wikipedia.org/wiki/PageRank\"\u003ePageRank算法\u003c/a\u003e是用PageRank值来衡量权威性的。\u003ca href=\"http://blog.sina.com.cn/s/blog_72995dcc01013bkb.html\"\u003eHITS和PageRank一个比较大的区别是HITS和查询有关，而PageRank和查询无关，所以PageRank可以离线计算。\u003c/a\u003e下面主要介绍PageRank算法。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://i0.wp.com/press.princeton.edu/images/k8216.gif\"\u003e\u003c/p\u003e\n\u003cp\u003ePageRank’s thesis is that a webpage is important if it is pointed to by other important pages.\u003c/p\u003e\n\u003cp\u003e我先不加解释的给出PageRank的公式，然后带领大家一步步推导出这个公式。\u003c/p\u003e\n$$\\pi^T=\\pi^T(\\alpha S+(1-\\alpha)E)$$\u003cp\u003e我们首先明确目标：PageRank计算的是网页的静态权威度（PR值），也就是如果给定了一个网络结构，则每个网页的PR值就可以通过PageRank算法计算出。假设网页\\(P_i\\)的PR值为\\(r(P_i)\\)，则\\(r(P_i)\\)等于所有指向\\(P_i\\)的网页的PR值之和，即\u003c/p\u003e\n$$\\begin{equation}r(P_i)=\\sum\\limits_{P_j\\in B_{P_i}}\\frac{r(P_j)}{|P_j|}\\end{equation}$$\u003cp\u003e其中\\(B_{P_i}\\)为指向\\(P_i\\)的网页集合，\\(|P_j|\\)为\\(P_j\\)的出边的数量。这个式子很好理解，包括两方面内容：1）\\(\\sum\\limits_{P_j\\in B_{P_i}}\\)表示如果指向\\(P_i\\)的网页数量越多，说明网页\\(P_i\\)越重要；2）\\(\\frac{r(P_j)}{|P_j|}\\)表示如果\\(P_j\\)指向的页面数量越少，但有一个指向了\\(P_i\\)，说明网页\\(P_i\\)越重要（如果一个大牛写了很多推荐信（\\(|P_j|\\)大），则这些推荐信的效力就下降了，如果大牛只给你写了推荐信（\\(|P_j|=1\\)），则这封推荐信的效力一定很高）。\u003c/p\u003e\n\u003cp\u003e(1)式有一个问题，初始给定一个网络结构时，并不知道\\(r(P_i), r(P_j)\\)，如何计算呢？Brin和Page利用递归的思想求解，初始假设所有网页的PR值相等，都为\\(\\frac{1}{n}\\)，其中\\(n\\)为网络中网页的数量。则第\\(k+1\\)轮的PR计算公式为：\u003c/p\u003e\n$$\\begin{equation}r_{k+1}(P_i)=\\sum\\limits_{P_j\\in B_{P_i}}\\frac{r_k(P_j)}{|P_j|}\\end{equation}$$\u003cp\u003e初始对所有网页\\(P_i\\)有\\(r_0(P_i)=\\frac{1}{n}\\)，迭代\\(k\\)步之后，可以计算出所有网页的PR值，然后按PR值从大到小排序，就可以知道每个网页的重要性了。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"pr-1\" loading=\"lazy\" src=\"/posts/2016-08-04-googles-pagerank-and-beyond/pr-1.png\"\u003e\n对于上图的小网络，我们可以计算出其每一步的PR值：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"pr-2\" loading=\"lazy\" src=\"/posts/2016-08-04-googles-pagerank-and-beyond/pr-2.png\"\u003e\n可以看到经过2次迭代之后，节点4的PR值最大，从图中也可以看出，节点4的出入边较多，它可能比较重要。\u003c/p\u003e\n\u003cp\u003e注意到对于(2)式，当\\(i,j\\)之间有边时，\\(\\frac{1}{|P_j|}\\)相当于对\\(P_j\\)出度的归一化，设矩阵\\(H\\)为图的邻接矩阵的行归一化矩阵，对于上图，为\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"pr-3\" loading=\"lazy\" src=\"/posts/2016-08-04-googles-pagerank-and-beyond/pr-3.png\"\u003e\n设行向量\\(\\pi^{(k)T}\\)为第\\(k\\)轮迭代时所有网页的PR值，则式(2)可以转换为如下的矩阵形式：\u003c/p\u003e\n$$\\begin{equation}\\pi^{(k+1)T}=\\pi^{(k)T}H\\end{equation}$$\u003cp\u003e初始有\\(\\pi^{(0)T}=\\frac{1}{n}e^T\\)，\\(e^T\\)为全1的行向量。我们可以从(3)式观测出几点信息：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e(3)式的每一轮计算涉及到向量和矩阵的乘法，复杂度为\\(O(n^2)\\)，\\(n\\)为矩阵\\(H\\)的大小\u003c/li\u003e\n\u003cli\u003e\\(H\\)是一个稀疏矩阵，因为大部分网页只和很少的网页有链接关系，所以上述向量和矩阵的乘法复杂度还可以降低\u003c/li\u003e\n\u003cli\u003e\\(H\\)有点像马尔科夫链中的随机转移矩阵，但又不完全是，因为如果有dangling nodes，则这一行就是全0，所以\\(H\\)被称为substochastic matrix\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"pr-4\" loading=\"lazy\" src=\"/posts/2016-08-04-googles-pagerank-and-beyond/pr-4.png\"\u003e\n上图中的节点3就是一个dangling node，它只有入边，没有出边，也就是说，每一轮迭代，PR值只会流入3号节点，不会从3号节点流出，久而久之，3就像一个水槽(sink)一样，吸走了大部分的PR，导致PR值虚高。\u003c/p\u003e\n\u003cp\u003e所以问题随之而来，怎样保证(3)式一定能够收敛到一个平稳概率分布\\(\\pi^T\\)，\\(\\pi^T\\)和\\(\\pi^{(0)T}\\)有关吗，怎样解决dangling nodes问题，等等。此时需要引入一点马尔科夫链理论的知识。\u003c/p\u003e\n\u003cp\u003e在马尔科夫理论呢中，如果一个矩阵\\(P\\)是随机的（stochastic）、不可约的（irreducible）和非周期的（aperiodic），则对于任意的起始向量，都能收敛到一个唯一的平稳正向量。所以如果PageRank矩阵\\(H\\)满足上述三个条件，则可以用幂法（Power Method）找到一个平稳概率分布\\(\\pi^T\\)。\u003ca href=\"https://en.wikipedia.org/wiki/Power_iteration\"\u003e幂法\u003c/a\u003e是用来计算最大特征值的特征向量。因为\\(H\\)的最大特征值为1，所以可以用幂法找到稳态时（\\(\\pi^T=\\pi^TH\\)）的概率分布\\(\\pi^T\\)。\u003c/p\u003e\n\u003cp\u003e下面我们就将矩阵\\(H\\)调整为随机的（stochastic）、不可约的（irreducible）和非周期的（aperiodic）。\u003c/p\u003e\n\u003cp\u003e行随机矩阵是指行和为1的非负矩阵。如果图中含有dangling nodes，则\\(H\\)不是随机的，比如上面的例子，第二行为全0。所以第一个调整是对于所有dangling nodes，都加上一个随机跳转向量\\(e^T/n\\)，含义就是如果进入死胡同（dangling nodes），则随机跳转到网络中的任意一个网页。定义向量\\(a\\)：\u003c/p\u003e\n$$\\begin{equation}a_i=\\begin{cases}1\\quad\\text{if page}~i\\text{ is a dangling node}\\\\0\\quad\\text{otherwise}\\end{cases}\\end{equation}$$\u003cp\u003e则新的Google矩阵为：\u003c/p\u003e\n$$\\begin{equation}S=H+a\\frac{1}{n}e^T\\end{equation}$$\u003cp\u003e新矩阵\\(S\\)就是一个行随机矩阵了。对于上图的例子，有\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"pr-5\" loading=\"lazy\" src=\"/posts/2016-08-04-googles-pagerank-and-beyond/pr-5.png\"\u003e\n为了保证矩阵\\(S\\)满足\u003ca href=\"http://mathworld.wolfram.com/ReducibleMatrix.html\"\u003e不可约性（irreducible）\u003c/a\u003e和\u003ca href=\"https://en.wikipedia.org/wiki/Aperiodic_graph\"\u003e非周期性（aperiodic）\u003c/a\u003e，必须使\\(S\\)对应的图是强连通的且每个节点有自回路。所以再次调整为：\u003c/p\u003e\n$$\\begin{equation}G=\\alpha S+(1-\\alpha)\\frac{1}{n}ee^T\\end{equation}$$\u003cp\u003e令\u003c/p\u003e\n$$\\begin{equation}E=\\frac{1}{n}ee^T\\end{equation}$$\u003cp\u003e则得到本博客开头的Google矩阵公式：\u003c/p\u003e\n$$\\begin{equation}G=\\alpha S+(1-\\alpha)E\\end{equation}$$\u003cp\u003e\\(E\\)即为随机平均游走矩阵。矩阵\\(G\\)也很好解释，大家上网的时候以\\(\\alpha\\)的概率沿着某个网页里面的链接一步步深入进去（\\(S\\)），当沿着链接走累的时候，以\\(1-\\alpha\\)的概率在地址栏输入一个新地址，随机跳走了（\\(E\\)）。\u003c/p\u003e\n\u003cp\u003e此时的矩阵\\(G\\)满足随机性（stochastic）、不可约性（irreducible）和非周期性（aperiodic），所以可以根据幂法（Power Method）找到一个平稳概率分布\\(\\pi^T\\)，\\(\\pi^T_i\\)就衡量了网页\\(P_i\\)的重要性或者权威性。\u003c/p\u003e","title":"还原谷歌PageRank算法真相"},{"content":"$$\\begin{equation}Pr(|\\hat{p}-p|\\geq 5\\%)\\leq 5\\%\\end{equation}$$上一回我们讲到当\\(p\\)本身很小的时候，容易被5%（绝对误差）给淹没掉，导致结果的不可信。我们可以引入相对误差，把(1)式转换为如下的不等式\n$$\\begin{equation}Pr(|\\hat{p}-p|\\geq\\delta p)\\leq\\epsilon\\end{equation}$$同理，我们可以用\n$$\\begin{equation}\\hat{p}=\\frac{x_1+x_2+…+x_n}{n}\\end{equation}$$代替\\(\\hat{p}\\)（建议先看上一篇博客），转换为\n$$\\begin{equation}Pr(|X-np|\\geq\\delta np)\\end{equation}$$类似的，\\(X=x_1+x_2+…+x_n\\)，\\(E(X)=\\mu=np\\)，所以(4)式等价为\n$$\\begin{equation}Pr(|X-\\mu|\\geq\\delta\\mu)\\end{equation}$$这个时候，因为不等号右边和均值\\(\\mu\\)有关，不能再用切比雪夫不等式了，我们需要另外一个武器：Chernoff bound。它有两种形式：\n$$\\begin{equation}Pr(X\\geq (1+\\delta)\\mu)\\leq[\\frac{e^\\delta}{(1+\\delta)^{1+\\delta}}]^\\mu\\leq e^{-\\frac{\\mu}{3}\\delta^2}\\quad\\forall\\delta\u003e0\\end{equation}$$$$\\begin{equation}Pr(X\\leq (1-\\delta)\\mu)\\leq[\\frac{e^{-\\delta}}{(1-\\delta)^{1-\\delta}}]^\\mu\\leq e^{-\\frac{\\mu}{2}\\delta^2}\\quad\\forall 0\u003c\\delta\u003c1\\end{equation}$$Chernoff bound的证明需要用到马尔可夫不等式，有一点技巧。以上两种形式可以统一成\n$$\\begin{equation}Pr(|X-\\mu|\\geq\\delta\\mu)\\leq 2e^{-\\frac{\\mu}{3}\\delta^2}\\end{equation}$$也是一个很漂亮的不等式。\n利用Chernoff bound求解(5)式：\n$$\\begin{equation}Pr(|X-\\mu|\\geq\\delta\\mu)\\leq 2e^{-\\frac{\\mu}{3}\\delta^2}\\\\=2e^{-\\frac{np}{3}\\delta^2}\\leq\\epsilon\\end{equation}$$解得\n$$\\begin{equation}n\\geq\\left\\lceil\\frac{3ln\\frac{2}{\\epsilon}}{p\\delta^2}\\right\\rceil\\end{equation}$$这个结果看起来就很复杂了。也就是说，如果要设计调查问卷使满足(2)式的精度，抽样的样本数必须满足(10)式。从(10)式可知，当要求的精度越高（即\\(\\delta\\)和\\(\\epsilon\\)越小），所需的样本数越大。并且结果还和真实值\\(p\\)有关。\n","permalink":"http://localhost:1313/posts/2016-07-23-the-validity-of-the-questionnaire-2/","summary":"$$\\begin{equation}Pr(|\\hat{p}-p|\\geq 5\\%)\\leq 5\\%\\end{equation}$$\u003cp\u003e\u003ca href=\"https://bitjoy.net/posts/2016-07-23-the-validity-of-the-questionnaire-1/\"\u003e上一回\u003c/a\u003e我们讲到当\\(p\\)本身很小的时候，容易被5%（绝对误差）给淹没掉，导致结果的不可信。我们可以引入相对误差，把(1)式转换为如下的不等式\u003c/p\u003e\n$$\\begin{equation}Pr(|\\hat{p}-p|\\geq\\delta p)\\leq\\epsilon\\end{equation}$$\u003cp\u003e同理，我们可以用\u003c/p\u003e\n$$\\begin{equation}\\hat{p}=\\frac{x_1+x_2+…+x_n}{n}\\end{equation}$$\u003cp\u003e代替\\(\\hat{p}\\)（建议先看\u003ca href=\"https://bitjoy.net/posts/2016-07-23-the-validity-of-the-questionnaire-1/\"\u003e上一篇博客\u003c/a\u003e），转换为\u003c/p\u003e\n$$\\begin{equation}Pr(|X-np|\\geq\\delta np)\\end{equation}$$\u003cp\u003e类似的，\\(X=x_1+x_2+…+x_n\\)，\\(E(X)=\\mu=np\\)，所以(4)式等价为\u003c/p\u003e\n$$\\begin{equation}Pr(|X-\\mu|\\geq\\delta\\mu)\\end{equation}$$\u003cp\u003e这个时候，因为不等号右边和均值\\(\\mu\\)有关，不能再用切比雪夫不等式了，我们需要另外一个武器：\u003ca href=\"https://en.wikipedia.org/wiki/Chernoff_bound\"\u003eChernoff bound\u003c/a\u003e。它有两种形式：\u003c/p\u003e\n$$\\begin{equation}Pr(X\\geq (1+\\delta)\\mu)\\leq[\\frac{e^\\delta}{(1+\\delta)^{1+\\delta}}]^\\mu\\leq e^{-\\frac{\\mu}{3}\\delta^2}\\quad\\forall\\delta\u003e0\\end{equation}$$$$\\begin{equation}Pr(X\\leq (1-\\delta)\\mu)\\leq[\\frac{e^{-\\delta}}{(1-\\delta)^{1-\\delta}}]^\\mu\\leq e^{-\\frac{\\mu}{2}\\delta^2}\\quad\\forall 0\u003c\\delta\u003c1\\end{equation}$$\u003cp\u003eChernoff bound的证明需要用到马尔可夫不等式，有一点技巧。以上两种形式可以统一成\u003c/p\u003e\n$$\\begin{equation}Pr(|X-\\mu|\\geq\\delta\\mu)\\leq 2e^{-\\frac{\\mu}{3}\\delta^2}\\end{equation}$$\u003cp\u003e也是一个很漂亮的不等式。\u003c/p\u003e\n\u003cp\u003e利用Chernoff bound求解(5)式：\u003c/p\u003e\n$$\\begin{equation}Pr(|X-\\mu|\\geq\\delta\\mu)\\leq 2e^{-\\frac{\\mu}{3}\\delta^2}\\\\=2e^{-\\frac{np}{3}\\delta^2}\\leq\\epsilon\\end{equation}$$\u003cp\u003e解得\u003c/p\u003e\n$$\\begin{equation}n\\geq\\left\\lceil\\frac{3ln\\frac{2}{\\epsilon}}{p\\delta^2}\\right\\rceil\\end{equation}$$\u003cp\u003e这个结果看起来就很复杂了。也就是说，如果要设计调查问卷使满足(2)式的精度，抽样的样本数必须满足(10)式。从(10)式可知，当要求的精度越高（即\\(\\delta\\)和\\(\\epsilon\\)越小），所需的样本数越大。并且结果还和真实值\\(p\\)有关。\u003c/p\u003e","title":"调查问卷的有效性（2）相对误差"},{"content":"每年春晚过后，央视又要吹嘘说今年春晚收视率创新高了，但是我们总感觉央视在骗我们，因为我是越长大越不看春晚了[笑cry]，所以收视率到底是怎么统计出来的，央视的说法是否靠谱呢？\n最近的美国大选真是热闹，很多机构都会发放一些调查问卷，然后统计出希拉里或者唐纳德的民众支持率是多少，但是我并没有收到调查问卷，凭什么就得出了民众支持率了，意思是把我排除在民众之外咯？所以引出这样一个问题，调查问卷是否可信，即调查问卷的有效性。\n其实，央视统计收视率并不要问全中国14亿人口有多少人看了春晚，他只需要从14亿人口里面随机抽\\(n\\)个人，问一下这\\(n\\)个人里有多少人看了春晚，然后把看的人数除以总数就大概估计出全国的收视率了。同理调查民众支持率也是一样，只需要随机调查\\(n\\)个人的意向，把支持希拉里的人数除以总数就大概得到了希拉里的支持率。\n但是你要问了，通过抽样调查出来的收视率和支持率靠谱吗，需要随机抽样多少人才能得到一个比较好的全局近似解呢？今天我们就来解决这个问题。\n假设我们随机抽样了\\(n\\)个人，分别是\\(x_1,x_2,…,x_n\\)。如果第\\(i\\)个人看了春晚，则\\(x_i=1\\)，否则\\(x_i=0\\)。那么通过这\\(n\\)个人的收视情况，我们可以估计出一个收视率\n$$\\begin{equation}\\hat{p}=\\frac{x_1+x_2+…+x_n}{n}\\end{equation}$$假设全国的真实收视率是\\(p\\)，那么平均到每一个人，他看了春晚的概率就是\\(p\\)，也即\\(Pr(x_i=1)=p\\)，所以有\n$$\\begin{equation}E(x_i)=p\\quad E(x_i^2)=p\\quad Var(x_i)=p(1-p)\\end{equation}$$我们的目的就是希望通过\\(n\\)个人估计出来的\\(\\hat{p}\\)和\\(p\\)越接近越好。换句话说，我们希望\\(\\hat{p}\\)和\\(p\\)相差大于5%的概率要小于5%。再换句话说就是有至少95%的概率，\\(\\hat{p}\\)和\\(p\\)相差在5%以内，即\\(\\hat{p}\\)和\\(p\\)很接近。注意这里的两个5%都是可以换成任意你想要的精度。用数学语言表示就是，\\(n\\)至少为多少时，以下不等式可以被满足。\n$$\\begin{equation}Pr(|\\hat{p}-p|\\geq 5\\%)\\leq 5\\%\\end{equation}$$把(1)式代入(3)式，用\\(\\frac{1}{20}\\)代替5%，得到等价形式：\n$$\\begin{equation}Pr(|(\\frac{x_1+x_2+…+x_n}{n})-p|\\geq\\frac{1}{20})\\\\ \\Longleftrightarrow~Pr(|X-np|\\geq\\frac{n}{20})\\end{equation}$$其中\\(X=x_1+x_2+…+x_n\\)。根据期望的线性可加性，有\n$$\\begin{equation}E(X)=E(x_1+x_2+…+x_n)=E(x_1)+E(x_2)+…+E(x_n)=np\\end{equation}$$所以(4)又等价于\n$$\\begin{equation}Pr(|X-E(X)|\\geq\\frac{n}{20})\\end{equation}$$我们需要利用著名的切比雪夫不等式来求解上式，切比雪夫不等式如下：\n$$\\begin{equation}Pr(|X-E(X)|\\geq~c)\\leq\\frac{Var(X)}{c^2}\\end{equation}$$切比雪夫不等式可以直接由马尔可夫不等式得到，马尔可夫不等式的证明也不难，略过。\n利用切比雪夫不等式求解(6)式\n$$\\begin{equation}Pr(|X-E(X)|\\geq\\frac{n}{20})\\leq\\frac{Var(X)}{n^2}*400\\\\ =\\frac{n*Var(x_i)}{n^2}*400\\\\ =\\frac{p(1-p)}{n}*400\\\\ \\leq\\frac{1/4}{n}*400=\\frac{100}{n} \\end{equation}$$第一个等号是因为\\(n\\)个变量是独立同分布的，所以方差也有类似于(5)式的线性性质。最后一个不等号是因为\\(p(1-p)\\)是一个开口向下的抛物线，在\\(p=1/2\\)时取到极值\\(1/4\\)。\n回到最初的不等式(3)，则(8)式要满足\\(\\frac{100}{n}\\leq 5\\%\\)，解得\\(n\\geq 2000\\)。注意到求出的\\(n\\)和总体人数是无关的，也就是说，虽然全中国有十几亿人口，但是央视只要随机抽样调查2000个人的收视情况，就能以比较高的概率准确估计出全国的收视率。\n这个结论还是很漂亮的，但是这种方法有两个限制条件：\n采样满足独立同分布，即这\\(n\\)个人是独立同分布的，不能针对某一特定人群调查 (3)式的5%是一个绝对误差，当\\(p\\)本身很小的时候，容易被5%淹没 对于第1个问题，稍微好处理一点，抽样的时候尽量随机一点。对于第2个问题，比较好的解决办法是引入相对误差，即把(3)式转换为如下的不等式\n$$\\begin{equation}Pr(|\\hat{p}-p|\\geq\\delta p)\\leq\\epsilon\\end{equation}$$(9)式的求解就比较复杂了，得出的结论也没有上面那么简单，具体的求解方法请听下回分解。\n","permalink":"http://localhost:1313/posts/2016-07-23-the-validity-of-the-questionnaire-1/","summary":"\u003cp\u003e每年春晚过后，央视又要吹嘘说今年春晚收视率创新高了，但是我们总感觉央视在骗我们，因为我是越长大越不看春晚了[笑cry]，所以收视率到底是怎么统计出来的，央视的说法是否靠谱呢？\u003c/p\u003e\n\u003cp\u003e最近的美国大选真是热闹，很多机构都会发放一些调查问卷，然后统计出希拉里或者唐纳德的民众支持率是多少，但是我并没有收到调查问卷，凭什么就得出了民众支持率了，意思是把我排除在民众之外咯？所以引出这样一个问题，调查问卷是否可信，即调查问卷的有效性。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://i0.wp.com/www.carp.ca/wp-content/uploads/2012/08/questionnaire1.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e其实，央视统计收视率并不要问全中国14亿人口有多少人看了春晚，他只需要从14亿人口里面随机抽\\(n\\)个人，问一下这\\(n\\)个人里有多少人看了春晚，然后把看的人数除以总数就大概估计出全国的收视率了。同理调查民众支持率也是一样，只需要随机调查\\(n\\)个人的意向，把支持希拉里的人数除以总数就大概得到了希拉里的支持率。\u003c/p\u003e\n\u003cp\u003e但是你要问了，通过抽样调查出来的收视率和支持率靠谱吗，需要随机抽样多少人才能得到一个比较好的全局近似解呢？今天我们就来解决这个问题。\u003c/p\u003e\n\u003cp\u003e假设我们随机抽样了\\(n\\)个人，分别是\\(x_1,x_2,…,x_n\\)。如果第\\(i\\)个人看了春晚，则\\(x_i=1\\)，否则\\(x_i=0\\)。那么通过这\\(n\\)个人的收视情况，我们可以估计出一个收视率\u003c/p\u003e\n$$\\begin{equation}\\hat{p}=\\frac{x_1+x_2+…+x_n}{n}\\end{equation}$$\u003cp\u003e假设全国的真实收视率是\\(p\\)，那么平均到每一个人，他看了春晚的概率就是\\(p\\)，也即\\(Pr(x_i=1)=p\\)，所以有\u003c/p\u003e\n$$\\begin{equation}E(x_i)=p\\quad E(x_i^2)=p\\quad Var(x_i)=p(1-p)\\end{equation}$$\u003cp\u003e我们的目的就是希望通过\\(n\\)个人估计出来的\\(\\hat{p}\\)和\\(p\\)越接近越好。换句话说，我们希望\\(\\hat{p}\\)和\\(p\\)相差大于5%的概率要小于5%。再换句话说就是有至少95%的概率，\\(\\hat{p}\\)和\\(p\\)相差在5%以内，即\\(\\hat{p}\\)和\\(p\\)很接近。注意这里的两个5%都是可以换成任意你想要的精度。用数学语言表示就是，\\(n\\)至少为多少时，以下不等式可以被满足。\u003c/p\u003e\n$$\\begin{equation}Pr(|\\hat{p}-p|\\geq 5\\%)\\leq 5\\%\\end{equation}$$\u003cp\u003e把(1)式代入(3)式，用\\(\\frac{1}{20}\\)代替5%，得到等价形式：\u003c/p\u003e\n$$\\begin{equation}Pr(|(\\frac{x_1+x_2+…+x_n}{n})-p|\\geq\\frac{1}{20})\\\\ \\Longleftrightarrow~Pr(|X-np|\\geq\\frac{n}{20})\\end{equation}$$\u003cp\u003e其中\\(X=x_1+x_2+…+x_n\\)。根据期望的线性可加性，有\u003c/p\u003e\n$$\\begin{equation}E(X)=E(x_1+x_2+…+x_n)=E(x_1)+E(x_2)+…+E(x_n)=np\\end{equation}$$\u003cp\u003e所以(4)又等价于\u003c/p\u003e\n$$\\begin{equation}Pr(|X-E(X)|\\geq\\frac{n}{20})\\end{equation}$$\u003cp\u003e我们需要利用著名的\u003ca href=\"https://en.wikipedia.org/wiki/Chebyshev%27s_inequality\"\u003e切比雪夫不等式\u003c/a\u003e来求解上式，切比雪夫不等式如下：\u003c/p\u003e\n$$\\begin{equation}Pr(|X-E(X)|\\geq~c)\\leq\\frac{Var(X)}{c^2}\\end{equation}$$\u003cp\u003e切比雪夫不等式可以直接由\u003ca href=\"https://en.wikipedia.org/wiki/Markov%27s_inequality\"\u003e马尔可夫不等式\u003c/a\u003e得到，马尔可夫不等式的证明也不难，略过。\u003c/p\u003e\n\u003cp\u003e利用切比雪夫不等式求解(6)式\u003c/p\u003e\n$$\\begin{equation}Pr(|X-E(X)|\\geq\\frac{n}{20})\\leq\\frac{Var(X)}{n^2}*400\\\\ =\\frac{n*Var(x_i)}{n^2}*400\\\\ =\\frac{p(1-p)}{n}*400\\\\ \\leq\\frac{1/4}{n}*400=\\frac{100}{n} \\end{equation}$$\u003cp\u003e第一个等号是因为\\(n\\)个变量是独立同分布的，所以方差也有类似于(5)式的线性性质。最后一个不等号是因为\\(p(1-p)\\)是一个开口向下的抛物线，在\\(p=1/2\\)时取到极值\\(1/4\\)。\u003c/p\u003e\n\u003cp\u003e回到最初的不等式(3)，则(8)式要满足\\(\\frac{100}{n}\\leq 5\\%\\)，解得\\(n\\geq 2000\\)。注意到求出的\\(n\\)和总体人数是无关的，也就是说，虽然全中国有十几亿人口，但是央视只要随机抽样调查2000个人的收视情况，就能以比较高的概率准确估计出全国的收视率。\u003c/p\u003e\n\u003cp\u003e这个结论还是很漂亮的，但是这种方法有两个限制条件：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e采样满足独立同分布，即这\\(n\\)个人是独立同分布的，不能针对某一特定人群调查\u003c/li\u003e\n\u003cli\u003e(3)式的5%是一个绝对误差，当\\(p\\)本身很小的时候，容易被5%淹没\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e对于第1个问题，稍微好处理一点，抽样的时候尽量随机一点。对于第2个问题，比较好的解决办法是引入相对误差，即把(3)式转换为如下的不等式\u003c/p\u003e\n$$\\begin{equation}Pr(|\\hat{p}-p|\\geq\\delta p)\\leq\\epsilon\\end{equation}$$\u003cp\u003e(9)式的求解就比较复杂了，得出的结论也没有上面那么简单，具体的求解方法请听下回分解。\u003c/p\u003e","title":"调查问卷的有效性（1）绝对误差"},{"content":"你是否想过如下问题：怎样向色盲证明两只袜子的颜色是不一样的？怎样证明两个图是不同构的？怎样证明一个数是二次非剩余的？\n咋听起来觉得很有意思吧，色盲是区分不了颜色的，怎么能让他相信两只袜子的颜色不一样呢。图同构问题目前既没有被证明属于P，也没有被证明属于NP-Complete。二次非剩余问题也没有被证明属于NP。\n这些听起来很“难”的问题，却可以通过交互式证明进行证明，下面先通过“向色盲证明两只袜子的颜色不同”这个有趣的例子一窥交互式证明的强大。\n向色盲证明两只袜子的颜色不同 P有一只红袜子和黄袜子，她的一个色盲朋友V不相信P的袜子颜色不同，P如何才能让V相信这是真的呢？一个简单的办法如下：\nP把两只袜子给V，V每只手拿了一只袜子 P转过身背对V V抛一枚硬币，如果头面朝上，则保持两只袜子不动，否则交换左右手的袜子 P转过身，V问P是否交换过袜子 如果P回答错误，则V不相信；否则，重复100次实验，如果P都回答正确，则V相信这两只袜子是不同颜色的 如果两只袜子的颜色确实不一样，则P通过区分两只袜子的颜色能正确回答V有没有交换过袜子。但是如果两只袜子颜色一样，则不管V有没有交换过，P都无法分辨这两只袜子，所以只好猜V有没有交换，而猜对的概率只有1/2，重复100次，都猜对的概率只有\\((1/2)^{100}\\)，这是一个非常小的数，可以认为几乎不会发生，即出错的概率极低。\n这就是交互式证明的一个例子，上述证明有三个特点：1）交互过程，整个证明需要P和V进行交互才能完成；2）具有随机性，即V需要抛一枚硬币，来决定是否交换袜子；3）零知识，虽然V最终相信了这两只袜子是不同颜色的，但V还是不知道这两只袜子是什么颜色的。\n下面我们给出交互式证明的形式化定义。\n交互式证明（Interactive Proofs, IP） 令\\(k\\)是\\(N\\rightarrow N\\)的一个函数，我们称语言\\(L\\)属于\\(IP[k]\\)，如果存在一个\\(k(|x|)\\)多项式时间概率图灵机TM \\(V\\)，使得：\n$$ \\begin{equation} \\begin{cases} x\\in L \\Longrightarrow\\exists P\\quad Pr[V \\text{ accepts }x, V(x)=1]\\geq 2/3 \\\\ x\\notin L \\Longrightarrow\\forall P\\quad Pr[V \\text{ accepts }x, V(x)=1]\\leq 1/3 \\end{cases} \\end{equation} $$定义\n$$IP=\\underset{c}{\\bigcup} IP[n^c]$$上述定义的第一条称为“完备性”（Completeness）：如果\\(x\\in L\\)，则存在一个证明者P（prover），使得验证者V（verfier）能以多项式时间接受\\(x\\)，且接受的概率大于2/3；第二条称为“可靠性”（Soundness），如果\\(x\\notin L\\)，则对于所有证明者P，V接受\\(x\\)的概率都不会超过1/3。\n对应到上面的例子，完备性：当两只袜子的颜色确实不同时，V接受的概率为1\u0026gt;2/3；可靠性：当两只袜子的颜色相同时，重复100次实验，V接受的概率只有\\((1/2)^{100}\u003c1/3\\)。\nIP这个复杂性类就是所有IP[k]的并集。在IP中，P的能力是无穷的，但它不一定是诚实的；V能力较弱，只能进行多项式时间的计算。\n下面我们给出另外两个交互式证明的协议。\n图不同构（Graph Non-isomorphism, GNI）的交互式证明 如果图\\(G_1\\)和\\(G_2\\)可以通过对顶点进行恰当标记来将它们转换为同一个图，则称\\(G_1\\)和\\(G_2\\)同构，记为\\(G_1\\cong G_2\\)。换句话说，如果\\(G_1\\)和\\(G_2\\)同构，则在\\(G_1\\)的所有顶点标签上存在一个置换\\(\\pi\\)使得\\(\\pi (G_1)=G_2\\)，其中\\(\\pi (G_1)\\)是将\\(\\pi\\)作用到\\(G_1\\)的各个顶点上之后得到的图。下图就是两个同构图，右边给出了置换\\(\\pi\\)。\n图同构的补集为图不同构（Graph Non-isomorphism, GNI），即判定给定的两个图是否不同构。下面是GNI的一个交互式证明过程。\n给定两个图\\(G_1\\)和\\(G_2\\)，证明者P想要向验证者V证明\\(G_1\\ncong G_2\\)。\nV：随机选一个\\(i\\in \\{1,2\\}\\)，对\\(G_i\\)做一个随机的置换，得到新图\\(H\\)，则有\\(H\\cong G_i\\)，将\\(H\\)发送给P P：发送\\(j\\)给V V：如果\\(i\\neq j\\)，则拒绝；否则重复100次实验，都有\\(i==j\\)，则相信\\(G_1\\ncong G_2\\) 完备性：如果\\(G_1\\ncong G_2\\)，则\\(H\\)只和\\(G_1, G_2\\)中的一个图同构，P因为能力无穷，一定能找出和\\(H\\)同构的图\\(G_j\\)，且满足\\(j==i\\)。\n可靠性：如果\\(G_1\\cong G_2\\)，则\\(H\\)和\\(G_1, G_2\\)都同构，所以P无法区分，只好猜一个\\(j\\)，所以\\(j==i\\)的概率只有1/2，重复100次实验，P都猜对的概率只有\\((1/2)^{100}\u003c1/3\\)。\n零知识：虽然V相信了\\(G_1\\ncong G_2\\)，但V对于P怎样证出来的一无所知。\nP.S.\n有趣的是，关于图同构问题，芝加哥大学的科学家László Babai最近给出了一个伪多项式时间的算法，被称为是计算机理论界近10年最重要的成果。\nNew algorithm cracks graph problem A Quasipolynomial Time Algorithm for Graph Isomorphism: The Details Graph Isomorphism in Quasipolynomial Time 图同构在P/NP问题上重大突破，计算机理论10年最重要成果 二次非剩余（Quadratic non-residuosity, QNR）的交互式证明 如果存在整数\\(b\\)使得\\(a\\equiv b^2(\\mod p)\\)，则称整数\\(a\\)是模\\(p\\)的二次剩余，并称\\(b\\)是\\(a\\)模\\(p\\)的平方根。显然，\\(-b\\)是\\(a\\)模\\(p\\)的另一个平方根，而且\\(a\\)模\\(p\\)不存在其他平方根，因为\\(x^2-a=0\\)在域\\(GF(p)\\)上至多有两个解。\n类似的，如果不存在整数\\(b\\)使得\\(a\\equiv b^2(\\mod p)\\)，则称整数\\(a\\)是模\\(p\\)的二次非剩余（Quadratic non-residuosity, QNR），记为\\(\u003c a, p\u003e\\in QNR\\)。下面是QNR的一个交互式证明过程。\n给定一个素数\\(p\\)和另一个整数\\(a\\)，P要向V证明\\(\u003c a, p\u003e\\in QNR\\)。\nV：取模\\(p\\)的随机数\\(r(\\mod p)\\)和随机数\\(b\\in\\{0,1\\}\\)，如果\\(b=0\\)，发送\\(r^2(\\mod p)\\)给P；否则发送\\(a\\cdot r^2(\\mod p)\\)给P P：发送\\(b’\\)给V V：如果\\(b’\\neq b\\)，则拒绝；否则重复100次实验，都有\\(b’=b\\)，则相信\\(\u003c a, p\u003e\\in QNR\\) 完备性：如果\\(\u003c a, p\u003e\\in QNR\\)，则\\(\u003c a \\cdot r^2,p\u003e\\in QNR\\)，但\\(\u003c r^2, p\u003e\\notin QNR\\)，所以P能区分\\(a\\cdot r^2\\)和\\(r^2\\)，即总能回答正确使得\\(b’=b\\)。\n可靠性：\\(\u003c a, p\u003e\\notin QNR\\)，则\\(\u003c a \\cdot r^2,p\u003e\\notin QNR\\)，且\\(\u003c r^2, p\u003e\\notin QNR\\)，即\\(a\\cdot r^2\\)和\\(r^2\\)都是二次剩余，所以P无法区分，只能瞎猜，正确的概率为1/2，重复100次，都回答正确的概率只有\\((1/2)^{100}\u003c1/3\\)。\n零知识：虽然V相信了\\(\u003c a, p\u003e\\in QNR\\)，但V对于P怎样证出来的一无所知。\n交互式证明的零知识真是有趣，它是密码学中大量研究工作的基础。很多场合都可能会用到零知识证明，比如要向别人证明你有密码，但又不透露密码；要向别人证明你会解某道题，但又不透露解题过程；要让别人相信你知道怎样从甲地到乙地，但又不告诉别人从甲到乙的路……\n交互式证明是这学期选修《高级算法》时接触的，主要参考书目Computational Complexity: A Modern Approach\n","permalink":"http://localhost:1313/posts/2016-07-14-the-interesting-interactive-proofs/","summary":"\u003cp\u003e你是否想过如下问题：怎样向色盲证明两只袜子的颜色是不一样的？怎样证明两个图是不同构的？怎样证明一个数是二次非剩余的？\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://i0.wp.com/writtenbyrel.com/wp-content/uploads/2014/06/socks.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e咋听起来觉得很有意思吧，色盲是区分不了颜色的，怎么能让他相信两只袜子的颜色不一样呢。图同构问题目前既没有被证明属于P，也没有被证明属于NP-Complete。二次非剩余问题也没有被证明属于NP。\u003c/p\u003e\n\u003cp\u003e这些听起来很“难”的问题，却可以通过交互式证明进行证明，下面先通过“向色盲证明两只袜子的颜色不同”这个有趣的例子一窥交互式证明的强大。\u003c/p\u003e\n\u003ch1 id=\"向色盲证明两只袜子的颜色不同\"\u003e向色盲证明两只袜子的颜色不同\u003c/h1\u003e\n\u003cp\u003eP有一只红袜子和黄袜子，她的一个色盲朋友V不相信P的袜子颜色不同，P如何才能让V相信这是真的呢？一个简单的办法如下：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eP把两只袜子给V，V每只手拿了一只袜子\u003c/li\u003e\n\u003cli\u003eP转过身背对V\u003c/li\u003e\n\u003cli\u003eV抛一枚硬币，如果头面朝上，则保持两只袜子不动，否则交换左右手的袜子\u003c/li\u003e\n\u003cli\u003eP转过身，V问P是否交换过袜子\u003c/li\u003e\n\u003cli\u003e如果P回答错误，则V不相信；否则，重复100次实验，如果P都回答正确，则V相信这两只袜子是不同颜色的\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e如果两只袜子的颜色确实不一样，则P通过区分两只袜子的颜色能正确回答V有没有交换过袜子。但是如果两只袜子颜色一样，则不管V有没有交换过，P都无法分辨这两只袜子，所以只好猜V有没有交换，而猜对的概率只有1/2，重复100次，都猜对的概率只有\\((1/2)^{100}\\)，这是一个非常小的数，可以认为几乎不会发生，即出错的概率极低。\u003c/p\u003e\n\u003cp\u003e这就是交互式证明的一个例子，上述证明有三个特点：1）交互过程，整个证明需要P和V进行交互才能完成；2）具有随机性，即V需要抛一枚硬币，来决定是否交换袜子；3）零知识，虽然V最终相信了这两只袜子是不同颜色的，但V还是不知道这两只袜子是什么颜色的。\u003c/p\u003e\n\u003cp\u003e下面我们给出交互式证明的形式化定义。\u003c/p\u003e\n\u003ch1 id=\"交互式证明interactive-proofs-ip\"\u003e交互式证明（Interactive Proofs, IP）\u003c/h1\u003e\n\u003cp\u003e令\\(k\\)是\\(N\\rightarrow N\\)的一个函数，我们称语言\\(L\\)属于\\(IP[k]\\)，如果存在一个\\(k(|x|)\\)多项式时间概率图灵机TM \\(V\\)，使得：\u003c/p\u003e\n$$\n\\begin{equation}\n\\begin{cases}\nx\\in L \\Longrightarrow\\exists P\\quad Pr[V \\text{ accepts }x, V(x)=1]\\geq 2/3 \\\\\nx\\notin L \\Longrightarrow\\forall P\\quad Pr[V \\text{ accepts }x, V(x)=1]\\leq 1/3\n\\end{cases}\n\\end{equation}\n$$\u003cp\u003e定义\u003c/p\u003e\n$$IP=\\underset{c}{\\bigcup} IP[n^c]$$\u003cp\u003e上述定义的第一条称为“完备性”（Completeness）：如果\\(x\\in L\\)，则存在一个证明者P（prover），使得验证者V（verfier）能以多项式时间接受\\(x\\)，且接受的概率大于2/3；第二条称为“可靠性”（Soundness），如果\\(x\\notin L\\)，则对于所有证明者P，V接受\\(x\\)的概率都不会超过1/3。\u003c/p\u003e\n\u003cp\u003e对应到上面的例子，完备性：当两只袜子的颜色确实不同时，V接受的概率为1\u0026gt;2/3；可靠性：当两只袜子的颜色相同时，重复100次实验，V接受的概率只有\\((1/2)^{100}\u003c1/3\\)。\u003c/p\u003e\n\u003cp\u003eIP这个复杂性类就是所有IP[k]的并集。在IP中，P的能力是无穷的，但它不一定是诚实的；V能力较弱，只能进行多项式时间的计算。\u003c/p\u003e\n\u003cp\u003e下面我们给出另外两个交互式证明的协议。\u003c/p\u003e\n\u003ch1 id=\"图不同构graph-non-isomorphism-gni的交互式证明\"\u003e图不同构（Graph Non-isomorphism, GNI）的交互式证明\u003c/h1\u003e\n\u003cp\u003e如果图\\(G_1\\)和\\(G_2\\)可以通过对顶点进行恰当标记来将它们转换为同一个图，则称\\(G_1\\)和\\(G_2\\)同构，记为\\(G_1\\cong G_2\\)。换句话说，如果\\(G_1\\)和\\(G_2\\)同构，则在\\(G_1\\)的所有顶点标签上存在一个置换\\(\\pi\\)使得\\(\\pi (G_1)=G_2\\)，其中\\(\\pi (G_1)\\)是将\\(\\pi\\)作用到\\(G_1\\)的各个顶点上之后得到的图。下图就是两个同构图，右边给出了置换\\(\\pi\\)。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"isomorphism graph\" loading=\"lazy\" src=\"/posts/2016-07-14-the-interesting-interactive-proofs/isomorphism-graph.webp\"\u003e\u003c/p\u003e\n\u003cp\u003e图同构的补集为图不同构（Graph Non-isomorphism, GNI），即判定给定的两个图是否不同构。下面是GNI的一个交互式证明过程。\u003c/p\u003e\n\u003cp\u003e给定两个图\\(G_1\\)和\\(G_2\\)，证明者P想要向验证者V证明\\(G_1\\ncong G_2\\)。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eV：随机选一个\\(i\\in \\{1,2\\}\\)，对\\(G_i\\)做一个随机的置换，得到新图\\(H\\)，则有\\(H\\cong G_i\\)，将\\(H\\)发送给P\u003c/li\u003e\n\u003cli\u003eP：发送\\(j\\)给V\u003c/li\u003e\n\u003cli\u003eV：如果\\(i\\neq j\\)，则拒绝；否则重复100次实验，都有\\(i==j\\)，则相信\\(G_1\\ncong G_2\\)\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e完备性：如果\\(G_1\\ncong G_2\\)，则\\(H\\)只和\\(G_1, G_2\\)中的一个图同构，P因为能力无穷，一定能找出和\\(H\\)同构的图\\(G_j\\)，且满足\\(j==i\\)。\u003c/p\u003e","title":"有趣的交互式证明"},{"content":"\n\\(\\LaTeX\\)的强大我就不赘述了，这里简单介绍一下怎样在Windows快速配置一个完美好用的\\(\\LaTeX\\)环境。\n我大学刚接触\\(\\LaTeX\\)的时候，使用的是CTeX，CTeX是一个大礼包，整合了编译器编辑器等，但是由于久不更新，很多宏包和语法都变了，而且CTeX附带的WinEdt是商业软件，30天之后需要收费，我又不想用盗版，所以就打算自己配置\\(\\LaTeX\\)环境。\n目前使用的是MiKTeX+Texmaker的完美组合！MiKTeX是\\(\\LaTeX\\)编译器，Texmaker是\\(\\LaTeX\\)编辑器。两者都是开源软件。\nMiKTeX非常棒的地方在于“MiKTeX has the ability to install needed packages automatically (on-the-fly)”，就是说，你用MiKTeX时，不需要担心某个宏包是否存在，你只管用就是了，MiKTeX会在你第一次用到某个宏包时，自动从网上下载，非常方便。正因为这样，MiKTeX的安装包很小，只有175MB。当然，因为是on-the-fly的，所以必须联网使用，而且MiKTeX只有Windows版本。\nMiKTeX自带了一个TeXworks编辑器的，但是这软件用户体验并不好。我以前一直都用WinEdt，很好用，但是它是商业软件，我又不想盗版（说到底是没钱…），所以换了Texmaker。Texmaker可以媲美WinEdt，软件布局合理，各种快捷键用起来也很方便。不过在上手之前要简单配置一下。\n如果是写英文文章，点击“快速构建”左边的箭头（或者F1快捷键），就能一键编译并刷新pdf视图。但是默认的快速构建使用的引擎是PdfLaTeX，如果你是中文用户，使用了xeCJK宏包，则必须使用XeLaTeX引擎编译，所以依次点击“选项-\u0026gt;配置Texmaker-\u0026gt;（左边）快速构建”，选择快速构建命令为”XeLaTeX + View PDF”。\n构建好的PDF默认是以弹窗的形式展现的，我们可以设置让代码和PDF并排显示，这样方便在PDF和源代码之间切换，配置如下：\nTexmaker自带了一个PDF阅读器，当然你也可以使用外部阅读器，比如非常棒的Sumatra PDF，只需填入Sumatra PDF的路径跟上%.pdf，并选中External Viewer。\nTexmaker还有一个很好用的功能是“正向/反向搜索”。反向搜索是点击PDF某个位置，会跳到tex源代码对应位置，快捷方式是ctrl+click。正向搜索是点击tex源代码某个位置，会跳到PDF对应的位置，默认快捷方式ctrl+space，但是这个快捷方式好像用不了，可以自行配置成其他快捷方式，比如ctrl+1，我当时是打开下图的快捷方式窗口才发现这个问题的。\n正反向搜索都可以通过鼠标右键菜单实现，但是快捷键还是更方便的。最重要的一点是，源文件*.tex所在路径不能有中文！！！要不然正反向搜索不能用，这点很重要，我当时郁闷了好久。\n另外还可以配置一下编辑器的字体，勾选”Backup documents every 10 min”之类的。\nOK，大功告成，这种三段式的界面、F1快速构建以及正向/反向搜索，用起来真是太顺手了，Just Enjoy \\(\\LaTeX\\)~\n下面是我常用的\\(\\LaTeX\\)中文模板：\nLaTeXDemo.pdf\nLaTeXDemo.tex\n","permalink":"http://localhost:1313/posts/2016-05-16-an-easy-to-use-latex-toolkit/","summary":"\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://www.ctan.org/lion/ctan_lion_350x350.png\"\u003e\u003c/p\u003e\n\u003cp\u003e\\(\\LaTeX\\)的强大我就不赘述了，这里简单介绍一下怎样在Windows快速配置一个完美好用的\\(\\LaTeX\\)环境。\u003c/p\u003e\n\u003cp\u003e我大学刚接触\\(\\LaTeX\\)的时候，使用的是\u003ca href=\"http://www.ctex.org/HomePage\"\u003eCTeX\u003c/a\u003e，CTeX是一个大礼包，整合了编译器编辑器等，但是由于久不更新，很多宏包和语法都变了，而且CTeX附带的WinEdt是商业软件，30天之后需要收费，我又不想用盗版，所以就打算自己配置\\(\\LaTeX\\)环境。\u003c/p\u003e\n\u003cp\u003e目前使用的是\u003ca href=\"http://miktex.org/\"\u003eMiKTeX\u003c/a\u003e+\u003ca href=\"http://www.xm1math.net/texmaker/\"\u003eTexmaker\u003c/a\u003e的完美组合！MiKTeX是\\(\\LaTeX\\)编译器，Texmaker是\\(\\LaTeX\\)编辑器。两者都是开源软件。\u003c/p\u003e\n\u003cp\u003eMiKTeX非常棒的地方在于“MiKTeX has the ability to install needed packages automatically (on-the-fly)”，就是说，你用MiKTeX时，不需要担心某个宏包是否存在，你只管用就是了，MiKTeX会在你第一次用到某个宏包时，自动从网上下载，非常方便。正因为这样，MiKTeX的安装包很小，只有175MB。当然，因为是on-the-fly的，所以必须联网使用，而且MiKTeX只有Windows版本。\u003c/p\u003e\n\u003cp\u003eMiKTeX自带了一个\u003ca href=\"https://www.tug.org/texworks/\"\u003eTeXworks\u003c/a\u003e编辑器的，但是这软件用户体验并不好。我以前一直都用WinEdt，很好用，但是它是商业软件，我又不想盗版（说到底是没钱…），所以换了Texmaker。Texmaker可以媲美WinEdt，软件布局合理，各种快捷键用起来也很方便。不过在上手之前要简单配置一下。\u003c/p\u003e\n\u003cp\u003e如果是写英文文章，点击“快速构建”左边的箭头（或者F1快捷键），就能一键编译并刷新pdf视图。但是默认的快速构建使用的引擎是PdfLaTeX，如果你是中文用户，使用了xeCJK宏包，则必须使用XeLaTeX引擎编译，所以依次点击“选项-\u0026gt;配置Texmaker-\u0026gt;（左边）快速构建”，选择快速构建命令为”XeLaTeX + View PDF”。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"Texmaker-1\" loading=\"lazy\" src=\"/posts/2016-05-16-an-easy-to-use-latex-toolkit/Texmaker-1.png\"\u003e\u003c/p\u003e\n\u003cp\u003e构建好的PDF默认是以弹窗的形式展现的，我们可以设置让代码和PDF并排显示，这样方便在PDF和源代码之间切换，配置如下：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"Texmaker-2\" loading=\"lazy\" src=\"/posts/2016-05-16-an-easy-to-use-latex-toolkit/Texmaker-2.png\"\u003e\u003c/p\u003e\n\u003cp\u003eTexmaker自带了一个PDF阅读器，当然你也可以使用外部阅读器，比如非常棒的\u003ca href=\"http://www.sumatrapdfreader.org/free-pdf-reader.html\"\u003eSumatra PDF\u003c/a\u003e，只需填入Sumatra PDF的路径跟上%.pdf，并选中External Viewer。\u003c/p\u003e\n\u003cp\u003eTexmaker还有一个很好用的功能是“正向/反向搜索”。反向搜索是点击PDF某个位置，会跳到tex源代码对应位置，快捷方式是ctrl+click。正向搜索是点击tex源代码某个位置，会跳到PDF对应的位置，默认快捷方式ctrl+space，但是这个快捷方式好像用不了，可以自行配置成其他快捷方式，比如ctrl+1，我当时是打开下图的快捷方式窗口才发现这个问题的。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"Texmaker-3\" loading=\"lazy\" src=\"/posts/2016-05-16-an-easy-to-use-latex-toolkit/Texmaker-3.png\"\u003e\u003c/p\u003e\n\u003cp\u003e正反向搜索都可以通过鼠标右键菜单实现，但是快捷键还是更方便的。最重要的一点是，源文件*.tex所在路径不能有中文！！！要不然正反向搜索不能用，这点很重要，我当时郁闷了好久。\u003c/p\u003e\n\u003cp\u003e另外还可以配置一下编辑器的字体，勾选”Backup documents every 10 min”之类的。\u003c/p\u003e\n\u003cp\u003eOK，大功告成，这种三段式的界面、F1快速构建以及正向/反向搜索，用起来真是太顺手了，Just Enjoy \\(\\LaTeX\\)~\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://i0.wp.com/www.xm1math.net/texmaker/texmakertop_big.png\"\u003e\u003c/p\u003e\n\u003cp\u003e下面是我常用的\\(\\LaTeX\\)中文模板：\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"/posts/2016-05-16-an-easy-to-use-latex-toolkit/LaTeXDemo.pdf\"\u003eLaTeXDemo.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"/posts/2016-05-16-an-easy-to-use-latex-toolkit/LaTeXDemo.tex\"\u003eLaTeXDemo.tex\u003c/a\u003e\u003c/p\u003e","title":"LaTeX写作完美解决方案"},{"content":"SVM回顾 支持向量机（SVM）的一大特点是最大化间距（max margin）。对于如上图的二分类问题，虽然有很多线可以将左右两部分分开，但是只有中间的红线效果是最好的，因为它的可活动范围（margin）是最大的，从直观上来说很好理解。\n对于线性二分类问题，假设分类面为\n$$\\begin{equation} u=\\vec w \\cdot \\vec x-b \\end{equation}$$则margin为\n$$\\begin{equation} m=\\frac{1}{||w||_2} \\end{equation}$$根据max margin规则和约束条件，得到如下优化问题，我们要求的就是参数\\(\\vec w\\)和\\(b\\)：\n$$\\begin{equation} \\min\\limits_{\\vec w,b}\\frac{1}{2}||\\vec w||^2 \\quad\\text{subject to}\\quad y_i(\\vec w\\cdot \\vec x_i-b) \\geq 1, \\forall i,\\end{equation}$$对于正样本，类标号\\(y_i\\)为+1，反之则为-1。根据拉格朗日对偶，(3)可以转换为如下的二次规划（QP）问题，其中\\(\\alpha_i\\)为拉格朗日乘子。\n$$\\begin{equation} \\min\\limits_{\\vec \\alpha}\\Psi(\\vec\\alpha)=\\min\\limits_{\\vec \\alpha}\\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^Ny_iy_j(\\vec x_i\\cdot\\vec x_j)\\alpha_i\\alpha_j-\\sum_{i=1}^N\\alpha_i,\\end{equation}$$其中N为样本数量。上式还需满足如下两个约束条件：\n$$\\begin{equation} \\alpha_i\\geq 0, \\forall i,\\end{equation}$$$$\\begin{equation} \\sum_{i=1}^Ny_i\\alpha_i=0.\\end{equation}$$一旦求解出所有的拉格朗日乘子，则我们可以通过如下的公式得到分类面参数\\(\\vec w\\)和\\(b\\)。\n$$\\begin{equation}\\vec w=\\sum_{i=1}^Ny_i\\alpha_i\\vec x_i,\\quad b=\\vec w\\cdot\\vec x_k-y_k\\quad\\text{for some}\\quad\\alpha_k\u003e0.\\end{equation}$$当然并不是所有的数据都可以完美的线性划分，可能有少量数据就是混在对方阵营，这时可以通过引入松弛变量\\(\\xi_i\\)得到软间隔形式的SVM：\n$$\\begin{equation} \\min\\limits_{\\vec w,b,\\vec\\xi}\\frac{1}{2}||\\vec w||^2+C\\sum_{i=1}^N\\xi_i \\quad\\text{subject to}\\quad y_i(\\vec w\\cdot \\vec x_i-b) \\geq 1-\\xi_i, \\forall i,\\end{equation}$$其中的\\(\\xi_i\\)为松弛变量，能假装把错的样本分对，\\(C\\)对max margin和margin failures的trades off。对于这个新的优化问题，约束变成了一个box constraint：\n$$\\begin{equation}0\\leq\\alpha_i \\leq C,\\forall i.\\end{equation}$$而松弛变量\\(\\xi_i\\)不再出现在对偶公式中了。\n对于线性不可分的数据，可以用核函数\\(K\\)将其投影到高维空间，这样就可分了，由此得到一般的分类面公式：\n$$\\begin{equation}u=\\sum_{j=1}^Ny_j\\alpha_jK(\\vec x_j,\\vec x)-b,\\end{equation}$$终极优化问题就变成了下面这个样子：\n$$\\begin{equation} \\min\\limits_{\\vec \\alpha}\\Psi(\\vec\\alpha)=\\min\\limits_{\\vec \\alpha}\\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^Ny_iy_jK(\\vec x_i,\\vec x_j)\\alpha_i\\alpha_j-\\sum_{i=1}^N\\alpha_i,\\\\0\\leq\\alpha_i \\leq C,\\forall i,\\\\ \\sum_{i=1}^Ny_i\\alpha_i=0.\\end{equation}$$要满足的KKT条件为：\n$$ \\begin{equation} \\begin{cases} \\alpha_i = 0 \\Leftrightarrow y_iu_i \\geq 1,\\\\ 0 \u003c \\alpha_i \u003c C \\Leftrightarrow y_iu_i = 1,\\\\ \\alpha_i = C \\Leftrightarrow y_iu_i \\leq 1.\\\\ \\end{cases} \\end{equation} $$SMO算法 为了求解式(11)，SMO算法通过启发式方法选择两个\\(\\alpha_i,\\alpha_j\\)当变量，固定其他\\(\\alpha_k\\)，然后用解析的方法求解两个变量的二次规划问题。关于这两个变量的解应该更接近原始的二次规划问题，更重要的是，这时子问题可以通过解析方法求解，避免了矩阵运算，大大提高了整个算法的计算速度。如此，SMO算法将原问题不断分解为子问题并对子问题求解，进而达到求解原问题的目的。\n不失一般性，假设选择的两个拉格朗日乘子是\\(\\alpha_1,\\alpha_2\\)，因为\\(\\alpha_i\\)和变量\\(x_i\\)是一一对应的，所以也可以说选择了变量\\(x_1,x_2\\)。固定其他变量\\(\\alpha_i (i=3,4,…,N)\\)\n此时，式(11)的优化问题转换为如下的优化问题：\n$$\\begin{equation} \\min\\limits_{\\alpha_1,\\alpha_2}W(\\alpha_1,\\alpha_2)=\\frac{1}{2}K_{11}\\alpha_1^2+\\frac{1}{2}K_{22}\\alpha_2^2+y_1y_2K_{12}\\alpha_1\\alpha_2\\\\-(\\alpha_1+\\alpha_2)+y_1\\alpha_1\\sum_{i=3}^Ny_i\\alpha_iK_{i1}+y_2\\alpha_2\\sum_{i=3}^Ny_i\\alpha_iK_{i2}\\end{equation}$$满足\n$$\\begin{equation}\\alpha_1y_1+\\alpha_2y_2=-\\sum_{i=3}^Ny_i\\alpha_i=\\zeta\\end{equation}$$因为只有\\(\\alpha_1,\\alpha_2\\)是变量，其他\\(\\alpha_i (i=3,4,…,N)\\)是固定的（可以认为是常数），所以式(13)省略了不含\\(\\alpha_1,\\alpha_2\\)的常数项。又因为\\(y_i=\\pm 1\\)，\\(\\alpha_i\\)有限制(9)，所以\\(\\alpha_1,\\alpha_2\\)被限制在\\([0,C]\\times[0,C]\\)的盒子里，且位于对角线上，如图Figure 1.\n由于\\(\\alpha_2^{new}\\)需满足(9)，所以最优值\\(\\alpha_2^{new}\\)的取值范围必须满足条件\n$$\\begin{equation}L\\leq\\alpha_2^{new}\\leq H\\end{equation}$$其中L与H是\\(\\alpha_2^{new}\\)所在的对角线段端点的界。如果\\(y_1\\neq y_2\\)（Figure 1.左图），则\n$$\\begin{equation}L=max(0,\\alpha_2^{old}-\\alpha_1^{old}),\\quad H=min(C,C+\\alpha_2^{old}-\\alpha_1^{old}).\\end{equation}$$如果\\(y_1= y_2\\)（Figure 1.右图），则\n$$\\begin{equation}L=max(0,\\alpha_2^{old}+\\alpha_1^{old}-C),\\quad H=min(C,\\alpha_2^{old}+\\alpha_1^{old}).\\end{equation}$$令\n$$\\begin{equation}\\eta=K(\\vec x_1,\\vec x_1)+K(\\vec x_2,\\vec x_2)-2K(\\vec x_1,\\vec x_2).\\end{equation}$$因为\\(y_i=\\pm 1\\)，所以\\(y_i^2=1\\)，式(14)同乘以\\(y_1\\)，用\\(\\alpha_2\\)表示\\(\\alpha_1\\)并代入式(13)，得到只含一个变量\\(\\alpha_2\\)的表达式，该表达式对\\(\\alpha_2\\)求偏导并等于0，求出\\(\\alpha_2\\)的更新公式为：\n$$\\begin{equation}\\alpha_2^{new}=\\alpha_2^{old}+\\frac{y_2(E_1-E_2)}{\\eta},\\end{equation}$$其中\\(E_i=u_i-y_i\\)是第\\(i\\)个样本的训练误差。经过截断之后的\\(\\alpha_2^{new}\\)为：\n$$ \\begin{equation} \\alpha_2^{new, clipped} = \\begin{cases} H, \u0026 \\mbox{if }\\alpha_2^{new}\\geq H;\\\\ \\alpha_2^{new}, \u0026 \\mbox{if }L \u003c \\alpha_2^{new} \u003c H;\\\\ L, \u0026 \\mbox{if }\\alpha_2^{new}\\leq L. \\end{cases} \\end{equation} $$将\\(\\alpha_2^{new,clipped}\\)的结果代入式(14)，得到\\(\\alpha_1\\)的更新公式：\n$$\\begin{equation}\\alpha_1^{new}=\\alpha_1^{old}+y_1y_2(\\alpha_2^{old}-\\alpha_2^{new,clipped}).\\end{equation}$$当\\(0 \u003c \\alpha_1^{new} \u003c C\\)时，由式(12)中间的条件可以得到阈值\\(b_1\\)的更新公式：\n$$\\begin{equation}b_1^{new}=b^{old}-E_1-y_1K_{11}(\\alpha_1^{new}-\\alpha_1^{old})-y_2K_{21}(\\alpha_2^{new,clipped}-\\alpha_2^{old}),\\end{equation}$$同理，当\\(0 \u003c \\alpha_2^{new,clipped} \u003c C\\)时，得到阈值\\(b_2\\)的更新公式：\n$$\\begin{equation}b_2^{new}=b^{old}-E_2-y_1K_{12}(\\alpha_1^{new}-\\alpha_1^{old})-y_2K_{22}(\\alpha_2^{new,clipped}-\\alpha_2^{old}).\\end{equation}$$综合以上，阈值\\(b\\)的更新公式为：\n$$ \\begin{equation} b^{new}= \\begin{cases} b_1^{new}, \u0026 \\mbox{if } 0 \u003c \\alpha_1^{new} \u003c C; \\\\ b_2^{new}, \u0026 \\mbox{if } 0 \u003c \\alpha_2^{new,clipped} \u003c C;\\\\ (b_1^{new}+b_2^{new})/2, \u0026 \\mbox{otherwise}. \\end{cases} \\end{equation} $$至此，如果我们选定了两个变量\\(\\alpha_2,\\alpha_1\\)，则可以通过公式(19)和(21)来更新它们，并通过公式(24)更新阈值\\(b\\)，通过多次迭代逼近最优结果。但是怎样选择\\(\\alpha_2,\\alpha_1\\)呢，SMO通过启发式方法选择！\n对于第一个样本\\(\\alpha_2\\)，我们选择违反KKT条件式(12)（最严重）的样本\\(\\alpha_2\\)；由式(19)可知，\\(\\alpha_2^{new}\\)是依赖于\\(|E_1-E_2|\\)的，为了加快计算，一种简单的做法是选择\\(\\alpha_1\\)，使其对应的\\(|E_1-E_2|\\)最大。\n至此，我们有了启发式选择两个变量\\(\\alpha_2,\\alpha_1\\)的方法，以及求解这两个变量二次规划的解析方法，下面介绍SMO算法的具体实现。\nMATLAB代码实现 算法伪代码如下：\n输入：训练数据\\(T=\\{(\\vec x_1,y_1),(\\vec x_2,y_2),…,(\\vec x_N,y_N)\\}\\)，其中\\(\\vec x_i \\in R^n\\)，\\(y_i\\in\\{-1,+1\\}\\)，\\(i=1,2,…,N\\)，精度为\\(\\epsilon\\)。\n输出：拉格朗日乘子\\(\\vec\\alpha=\\{\\alpha_1,\\alpha_2,…,\\alpha_N\\}\\)和阈值\\(b\\)的近似解。\n初始化\\(\\vec \\alpha=\\vec 0, b=0\\) 选一个违反KKT条件的变量\\(\\alpha_2\\) 选一个使得\\(|E_1-E_2|\\)最大的变量\\(\\alpha_1\\) 根据公式(19)~(21)更新变量\\(\\alpha_2,\\alpha_1\\) 根据公式(22)~(24)更新阈值\\(b\\) 如果不满足结束条件，则转2；否则算法结束 算法的结束条件是：如果所有变量都已经检查过，且没有变量可以进一步优化时，算法结束。\n下面是SMO算法的MATLAB简化实现，省略了论文[1]的公式(19)。代码主流程参考论文[1]中的伪代码，部分实现细节参考[2]。\n本代码和MATLAB自带的seqminopt.m算法接口相同，可直接替换使用。下载代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 function [alphas, offset] = bitjoy_seqminopt(data, targetLabels, boxConstraints, ... kernelFunc, smoOptions) % https://bitjoy.net/posts/2016-05-02-svm-smo-algorithm/ % 参考文献: % [1] A Fast Algorithm for Training Support Vector Machines, % http://research.microsoft.com/pubs/69644/tr-98-14.pdf % [2] CSDN, http://blog.csdn.net/techq/article/details/6171688 N = length(data); % 样本数量 alphas = zeros([N,1]); % 所有拉格朗日乘子初始化为0 offset = 0.0; % 偏移量b也初始化为0 numChanged = 0; % 拉格朗日乘子改变的个数 examineAll = 1; % 是否需要检查所有拉格朗日乘子 % 主流程 while numChanged \u0026gt; 0 || examineAll numChanged = 0; if examineAll == 1 for i = 1 : N numChanged = numChanged + examineExample(i); end else for i = 1 : N if alphas(i) ~= 0 \u0026amp;\u0026amp; alphas(i) ~= boxConstraints(i) numChanged = numChanged + examineExample(i); end end end if examineAll == 1 examineAll = 0; elseif numChanged == 0 examineAll = 1; end end % 计算当前参数下第idx个样本的函数输出 function [svm_o] = wxpb(idx) svm_o = 0.0; for j = 1 : N svm_o = svm_o + alphas(j) * targetLabels(j) * kernelFunc(data(j,:),data(idx,:)); end svm_o = svm_o + offset; end % 选定第二个变量i2后，根据max|E1-E2|的启发式规则，选择i1； % 如果没有满足条件的i1，返回-1. function [i1] = selectSecondChoice(i2, E2) i1 = -1; maxDelta = -1; for j = 1 : N if j ~= i2 \u0026amp;\u0026amp; alphas(j) ~= 0 \u0026amp;\u0026amp; alphas(j) ~= boxConstraints(j) Ej = wxpb(j) - targetLabels(j); if abs(E2 - Ej) \u0026gt; maxDelta i1 = j; maxDelta = abs(E2 - Ej); end end end end % 根据选定的两个变量i1,i2，代入更新公式计算； % 最后还更新了偏移量offset，也就是y=wx+b中的b。 function [flag] = takeStep(i1, i2) alpha1 = alphas(i1); y1 = targetLabels(i1); E1 = wxpb(i1) - y1; alpha2 = alphas(i2); y2 = targetLabels(i2); E2 = wxpb(i2) - y2; s = y1 * y2; if y1 ~= y2 L = max(0, alpha2 - alpha1); H = min(boxConstraints(i2), boxConstraints(i1) + alpha2 - alpha1); else L = max(0, alpha2 + alpha1 - boxConstraints(i1)); H = min(boxConstraints(i2), alpha2 + alpha1); end if L == H flag = 0; return; end k11 = kernelFunc(data(i1,:),data(i1,:)); k12 = kernelFunc(data(i1,:),data(i2,:)); k22 = kernelFunc(data(i2,:),data(i2,:)); eta = k11 + k22 - 2 * k12; if eta \u0026gt; 0 a2 = alpha2 + y2 * (E1 - E2) / eta; %截断 if a2 \u0026lt; L a2 = L; elseif a2 \u0026gt; H a2 = H; end else % 并未处理该case，论文[1]公式(19)有更详细的方法 flag = 0; return; end if abs(a2 - alpha2) \u0026lt; eps * (a2 + alpha2 + eps) flag = 0; return; end a1 = alpha1 + s * (alpha2 - a2); alphas(i1) = a1; alphas(i2) = a2; % 更新offset b1 = offset - E1 - y1 * k11 * (a1 - alpha1) - y2 * k12 * (a2 - alpha2); b2 = offset - E2 - y1 * k12 * (a1 - alpha1) - y2 * k22 * (a2 - alpha2); if a1 \u0026gt; 0 \u0026amp;\u0026amp; a1 \u0026lt; boxConstraints(i1) offset = b1; elseif a2 \u0026gt; 0 \u0026amp;\u0026amp; a2 \u0026lt; boxConstraints(i2) offset = b2; else offset = (b1 + b2) / 2; end flag = 1; end % 检查样本。 % 首先判断i2是否满足KKT条件，如果不满足， % 则根据启发式规则再选择i1样本， % 然后更新i1和i2的拉格朗日乘子。 function [flag] = examineExample(i2) y2 = targetLabels(i2); alpha2 = alphas(i2); E2 = wxpb(i2) - y2; r2 = E2 * y2; if (r2 \u0026lt; -smoOptions.TolKKT \u0026amp;\u0026amp; alpha2 \u0026lt; boxConstraints(i2)) || (r2 \u0026gt; smoOptions.TolKKT \u0026amp;\u0026amp; alpha2 \u0026gt; 0) i1 = selectSecondChoice(i2, E2); if i1 == -1 i1 = floor(1 + rand() * N); % 随机选一个i1 while i1 == i2 i1 = floor(1 + rand() * N); end flag = takeStep(i1,i2); else flag = takeStep(i1,i2); end else flag = 0; end end end 参考资料\n[1]. J.C. Platt: A Fast Algorithm for Training Support Vector Machines\n[2]. CSDN, techq, SVM算法实现（一）\n[3]. 国科大叶齐祥老师机器学习方法与应用课程资料\n[4]. 支持向量机（SVM）的详细推导过程及注解（一）\n","permalink":"http://localhost:1313/posts/2016-05-02-svm-smo-algorithm/","summary":"\u003ch1 id=\"svm回顾\"\u003eSVM回顾\u003c/h1\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://upload.wikimedia.org/wikipedia/commons/2/20/SVM_Example_of_Hyperplanes.png\"\u003e\u003c/p\u003e\n\u003cp\u003e支持向量机（SVM）的一大特点是最大化间距（max margin）。对于如上图的二分类问题，虽然有很多线可以将左右两部分分开，但是只有中间的红线效果是最好的，因为它的可活动范围（margin）是最大的，从直观上来说很好理解。\u003c/p\u003e\n\u003cp\u003e对于线性二分类问题，假设分类面为\u003c/p\u003e\n$$\\begin{equation} u=\\vec w \\cdot \\vec x-b \\end{equation}$$\u003cp\u003e则margin为\u003c/p\u003e\n$$\\begin{equation} m=\\frac{1}{||w||_2} \\end{equation}$$\u003cp\u003e根据max margin规则和约束条件，得到如下优化问题，我们要求的就是参数\\(\\vec w\\)和\\(b\\)：\u003c/p\u003e\n$$\\begin{equation} \\min\\limits_{\\vec w,b}\\frac{1}{2}||\\vec w||^2 \\quad\\text{subject to}\\quad y_i(\\vec w\\cdot \\vec x_i-b) \\geq 1, \\forall i,\\end{equation}$$\u003cp\u003e对于正样本，类标号\\(y_i\\)为+1，反之则为-1。根据拉格朗日对偶，(3)可以转换为如下的二次规划（QP）问题，其中\\(\\alpha_i\\)为拉格朗日乘子。\u003c/p\u003e\n$$\\begin{equation} \\min\\limits_{\\vec \\alpha}\\Psi(\\vec\\alpha)=\\min\\limits_{\\vec \\alpha}\\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^Ny_iy_j(\\vec x_i\\cdot\\vec x_j)\\alpha_i\\alpha_j-\\sum_{i=1}^N\\alpha_i,\\end{equation}$$\u003cp\u003e其中N为样本数量。上式还需满足如下两个约束条件：\u003c/p\u003e\n$$\\begin{equation} \\alpha_i\\geq 0, \\forall i,\\end{equation}$$$$\\begin{equation} \\sum_{i=1}^Ny_i\\alpha_i=0.\\end{equation}$$\u003cp\u003e一旦求解出所有的拉格朗日乘子，则我们可以通过如下的公式得到分类面参数\\(\\vec w\\)和\\(b\\)。\u003c/p\u003e\n$$\\begin{equation}\\vec w=\\sum_{i=1}^Ny_i\\alpha_i\\vec x_i,\\quad b=\\vec w\\cdot\\vec x_k-y_k\\quad\\text{for some}\\quad\\alpha_k\u003e0.\\end{equation}$$\u003cp\u003e当然并不是所有的数据都可以完美的线性划分，可能有少量数据就是混在对方阵营，这时可以通过引入松弛变量\\(\\xi_i\\)得到软间隔形式的SVM：\u003c/p\u003e\n$$\\begin{equation} \\min\\limits_{\\vec w,b,\\vec\\xi}\\frac{1}{2}||\\vec w||^2+C\\sum_{i=1}^N\\xi_i \\quad\\text{subject to}\\quad y_i(\\vec w\\cdot \\vec x_i-b) \\geq 1-\\xi_i, \\forall i,\\end{equation}$$\u003cp\u003e其中的\\(\\xi_i\\)为松弛变量，能假装把错的样本分对，\\(C\\)对max margin和margin failures的trades off。对于这个新的优化问题，约束变成了一个box constraint：\u003c/p\u003e\n$$\\begin{equation}0\\leq\\alpha_i \\leq C,\\forall i.\\end{equation}$$\u003cp\u003e而松弛变量\\(\\xi_i\\)不再出现在对偶公式中了。\u003c/p\u003e","title":"SVM之序列最小最优化算法（SMO算法）"},{"content":"\nyn说最近在备考GMAT和托福，把手机都清理了只为专心学习。xx说TCP/IP大作业要用Qt做一个网络监控的软件，问我Qt好不好学。\nGRE遇见Qt，会擦出怎样的火花呢~没错，我用Qt写了一个强化背诵GRE单词的软件——Cracking 3000\n当时的一本GRE单词书有3000个单词，用杨鹏17天刷过之后，很多都记不住，于是想有没有办法把记不住的单词筛选出来，集中力量强化记忆。网上已经有3000的Excel表，所以我很自然的想到了把表格导入软件，用软件快速测试，并把不认识的单词筛选到新的Excel表格中。这样就可以把不认识的单词表打印出来，记完之后再导入软件进行新一轮的测试筛选，直到不认识的单词数为零。\n有了软件需求，代码实现起来就很快了。由于当时用Qt库比较多，所以直接拿来用了。软件实现这一块，主要是Excel表格的导入和导出，需要查一些文档，其他的就很简单了。\n虽然和GRE纠缠了一个多月，最终却没有考，但是想起当初早上6点爬起来背单词，晚上回宿舍抹黑写代码的情景，心情还是有一点小小的激动！以后类似的体验估计不会太多吧。\n最后祝yn GT考试顺利，xx大作业圆满完成！\nCracking_3000软件安装包及说明\n","permalink":"http://localhost:1313/posts/2016-03-16-hello-gre-do-you-like-me/","summary":"\u003cp\u003e\u003cimg alt=\"GRE3000\" loading=\"lazy\" src=\"/posts/2016-03-16-hello-gre-do-you-like-me/GRE3000.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003eyn说最近在备考GMAT和托福，把手机都清理了只为专心学习。xx说TCP/IP大作业要用Qt做一个网络监控的软件，问我Qt好不好学。\u003c/p\u003e\n\u003cp\u003eGRE遇见Qt，会擦出怎样的火花呢~没错，我用Qt写了一个强化背诵GRE单词的软件——Cracking 3000\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"Cracking-3000-1\" loading=\"lazy\" src=\"/posts/2016-03-16-hello-gre-do-you-like-me/Cracking-3000-1.png\"\u003e \u003cimg alt=\"Cracking-3000-2\" loading=\"lazy\" src=\"/posts/2016-03-16-hello-gre-do-you-like-me/Cracking-3000-2.png\"\u003e\u003c/p\u003e\n\u003cp\u003e当时的一本GRE单词书有3000个单词，用杨鹏17天刷过之后，很多都记不住，于是想有没有办法把记不住的单词筛选出来，集中力量强化记忆。网上已经有3000的Excel表，所以我很自然的想到了把表格导入软件，用软件快速测试，并把不认识的单词筛选到新的Excel表格中。这样就可以把不认识的单词表打印出来，记完之后再导入软件进行新一轮的测试筛选，直到不认识的单词数为零。\u003c/p\u003e\n\u003cp\u003e有了软件需求，代码实现起来就很快了。由于当时用Qt库比较多，所以直接拿来用了。软件实现这一块，主要是Excel表格的导入和导出，需要查一些文档，其他的就很简单了。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"GRE3000-2\" loading=\"lazy\" src=\"/posts/2016-03-16-hello-gre-do-you-like-me/GRE3000-2.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e虽然和GRE纠缠了一个多月，最终却没有考，但是想起当初早上6点爬起来背单词，晚上回宿舍抹黑写代码的情景，心情还是有一点小小的激动！以后类似的体验估计不会太多吧。\u003c/p\u003e\n\u003cp\u003e最后祝yn GT考试顺利，xx大作业圆满完成！\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"/posts/2016-03-16-hello-gre-do-you-like-me/Cracking_3000.zip\"\u003eCracking_3000软件安装包及说明\u003c/a\u003e\u003c/p\u003e","title":"和GRE纠缠的岁月"},{"content":"刚坐上去北京的列车，就收到了妈妈的微信语音：霖，早上收拾东西怎么忘了带上我给你洗好的鞋呀。我这才想起早上妈妈把洗好的鞋和叠好的衣服放在我房间，我却忘了带鞋。\n后来和爸妈在群里聊了起来。当我问爸爸什么时候返回学校时，他却说前天突然请假回家惹老板不高兴了，可能要被炒鱿鱼。是，老爸在那个学校当老师十几年了，我平时老数落他当老师工资那么低，为什么不改行，可突然听到这个消息，心里却不是滋味。\n其实老爸没必要请假回来的。前几天我发脾气，老爸好像真的决定转行搞种植业了，托我在淘宝买了好多枸杞树，自己带回了五十棵脐橙树苗，还准备去某个地方考察什么药材。\n离家前一天，妈妈特地跑到县城买了好多排骨回来，还煮了十个土鸡蛋要我带着路上吃。老爸买了好多苹果、香蕉、猕猴桃要我带着路上吃。今天早上收拾行李的时候，从来不动手的爸爸，也抢着往我包里塞各种牛奶和水果。\n二十多年了，经历了多少次的离家，从来没有像今天这样的不舍。二十多年了，我突然发现爸爸妈妈变矮了，爸爸的额头黑得发亮，妈妈的眼角也长出了好多鱼尾纹。\n今年难得有一个月的寒假，但我整天忙着看论文、书和电视剧，和爸妈的交流反而少了。有天吃过晚饭，发现妈妈独自坐在客厅戳着她的手机。我问过才发现原来妈妈想看哥哥和他女朋友的照片，但是怎么都弄不出来，我帮妈妈找出来之后，还教她怎么用微信和qq，妈妈说wifi图标像降落伞，我说你什么时候想上网就把降落伞打开，我说你如果想和哥哥聊天，就按住底部的按钮，等到出现小喇叭之后就可以说话了，说完放开手，听到“嗖“”的一声，说的话就发过去了，但是妈妈经常忘记打开降落伞，经常忘记按小喇叭。。。\n刚刷QQ空间的时候，看到一个同学的说说“马上又要去坐火车回武汉了，在家的时间越来越少了，没能好好陪陪父母，我不是称职的儿子。”\n坐在火车上，看着窗外闪过的霓虹灯，突然觉得这个世界好陌生好无情，每个人在时间面前是多么的渺小。\n2016年2月26日于z68列车上。\n","permalink":"http://localhost:1313/posts/2016-02-26-leave-home-again/","summary":"\u003cp\u003e刚坐上去北京的列车，就收到了妈妈的微信语音：霖，早上收拾东西怎么忘了带上我给你洗好的鞋呀。我这才想起早上妈妈把洗好的鞋和叠好的衣服放在我房间，我却忘了带鞋。\u003c/p\u003e\n\u003cp\u003e后来和爸妈在群里聊了起来。当我问爸爸什么时候返回学校时，他却说前天突然请假回家惹老板不高兴了，可能要被炒鱿鱼。是，老爸在那个学校当老师十几年了，我平时老数落他当老师工资那么低，为什么不改行，可突然听到这个消息，心里却不是滋味。\u003c/p\u003e\n\u003cp\u003e其实老爸没必要请假回来的。前几天我发脾气，老爸好像真的决定转行搞种植业了，托我在淘宝买了好多枸杞树，自己带回了五十棵脐橙树苗，还准备去某个地方考察什么药材。\u003c/p\u003e\n\u003cp\u003e离家前一天，妈妈特地跑到县城买了好多排骨回来，还煮了十个土鸡蛋要我带着路上吃。老爸买了好多苹果、香蕉、猕猴桃要我带着路上吃。今天早上收拾行李的时候，从来不动手的爸爸，也抢着往我包里塞各种牛奶和水果。\u003c/p\u003e\n\u003cp\u003e二十多年了，经历了多少次的离家，从来没有像今天这样的不舍。二十多年了，我突然发现爸爸妈妈变矮了，爸爸的额头黑得发亮，妈妈的眼角也长出了好多鱼尾纹。\u003c/p\u003e\n\u003cp\u003e今年难得有一个月的寒假，但我整天忙着看论文、书和电视剧，和爸妈的交流反而少了。有天吃过晚饭，发现妈妈独自坐在客厅戳着她的手机。我问过才发现原来妈妈想看哥哥和他女朋友的照片，但是怎么都弄不出来，我帮妈妈找出来之后，还教她怎么用微信和qq，妈妈说wifi图标像降落伞，我说你什么时候想上网就把降落伞打开，我说你如果想和哥哥聊天，就按住底部的按钮，等到出现小喇叭之后就可以说话了，说完放开手，听到“嗖“”的一声，说的话就发过去了，但是妈妈经常忘记打开降落伞，经常忘记按小喇叭。。。\u003c/p\u003e\n\u003cp\u003e刚刷QQ空间的时候，看到一个同学的说说“马上又要去坐火车回武汉了，在家的时间越来越少了，没能好好陪陪父母，我不是称职的儿子。”\u003c/p\u003e\n\u003cp\u003e坐在火车上，看着窗外闪过的霓虹灯，突然觉得这个世界好陌生好无情，每个人在时间面前是多么的渺小。\u003c/p\u003e\n\u003cp\u003e2016年2月26日于z68列车上。\u003c/p\u003e","title":"爸妈老了"},{"content":"现在是2016年2月4日，距离农历新年不到4天，结束了半年的国科大研一生活，躺在被窝里，松了一口气……\n来国科大之前，在贴吧上了解到国科大雁栖湖校区地处偏远农村，周边几乎没有娱乐场所；但同时学校的软硬件设施非常的棒：豪华单人间，研究员甚至院士亲自授课等等。所以对国科大雁栖湖校区满是憧憬。至今还清楚的记得坐校车从玉泉路过来时，沿途看到APEC主会场的鸟蛋、国科大桥、钟楼以及国科大正门几个大字时的激动心情~\n入住国科大，着实被UCAS的蓝天白云、青山绿水给迷住了。\n当然，凡事有利必有弊，因为这里远离市区，环境好，但正因为远离市区，几乎没有年轻人的娱乐活动，想要看个电影唱个歌少说也得跑城里，再要想感受下帝都奢靡的生活，必须各种倒车近2个小时到市里。\n研一这上学期，半年只进市里两次，一次是买山地车，一次是回所里开会。购物主要靠天猫超市。\n九十月份，大家都和大一新生似的，各种疯玩，野长城、雁栖湖、慕田峪、青龙峡、密云水库。进入十一月，新鲜劲过去了，又开始各种赶大小作业，复习考试。\n这是我这学期的课表，看着课好像不多，每天都有半天休息，但是真的感觉回到了大三呀！尤其数据挖掘、信息检索、矩阵论一周上两次课，当天上完的课如果没有及时复习，隔一天再学新内容完全跟不上啊，而且矩阵论每次课都有好多作业啊，这数学课不做练习完全消化不了呀。更神的课还要数周五的卜神算法，君不见，每到周四晚上，西A、西B两栋宿舍，灯火通明，大家都在熬夜赶算法作业啊，不熬个两三点都不好意思和别人说你熬夜了呀。大家可以感受一下我整理的卜神算法作业~~\n正是因为这奇葩的课程安排，这半年几乎没有12点前睡过觉，估计平均是1:30才睡觉，早上8点多才起，中午也没午休。想想大学的时候按时作息，真是惭愧。期间有一次听说搜狐一同届华科毕业生猝死，朋友圈传得沸沸扬扬，大伙都吓得要命，纷纷表示绝不熬夜，早睡早起，我那天也是吓坏了，决定早睡，11:30就爬床上了，但是不知道是因为紧张还是熬夜习惯了，辗转反侧，到12点多才睡着的。\n我们研一在国科大上课是有补助的，但是在帝都完全不够用啊，而且CS相关的几个所补助都比ICT高，so当时还公车上书，各种写联名信、起义，经过半年之久的持久战，所里终于答应从2016年开始给我们涨500块钱的工资。涨了之后差不多够吃饭了。\n虽然这半年课业繁重，但是也抽空锻炼了身体，天气不是很冷的时候，隔一天就会去夜跑；而且选了乒乓球课，从直拍转为了横拍，并且在课上结识了路路，打球好厉害的一个女生，每次老师来指导的时候，都叫路路温柔点 O__O “…\n另外花了一千多块钱买了一辆二手山地车，骑着到处转悠了一下。很有缘的是，认识了一位才女。本来我们骑行社一块去美利达准备买车，但是由于种种原因我和小欣都没买，然后我们一块坐小黑车回村，在车上聊着聊着就认识，没想到后来还成为了好朋友，小欣的台球和乒乓球都打得不错，琴棋书画样样精通。突然发现身边的学霸才子佳人好多，更加深刻感受到有些东西不是你努力就能够弥补的，天赋、眼界、才艺、品味、性格……\n来国科大的这半年，自我感觉变化最大的是自己变得爱说话了，而且带着一种zhuang bi气息，不知道是不是受某几个我一直崇拜的人的影响。有时候静下心来想想都不敢相信之前的话是我说的，和大学时的我完全判若两人。当然这种事情有利也有弊，还在慢慢找平衡点，可能正如CL说的“话怎么说是一回事，内心要知道自己想要的”。\n这半年突然害怕一个人上学，一个人吃饭，一个人自习了，更喜欢face-to-face的交谈，少了对网络的依赖，不知道是不是因为性格的变化、环境的变化、抑或是认识的人多了，有了念想。\n半年时光，认识了不多不少几个好朋友：良辰、发文章、牛牛、欣儿、路路，有你们真好，谢谢你们~\n2016猴赛雷，即将从研一的上课转入课题组工作，很关键的一年，加油！\n","permalink":"http://localhost:1313/posts/2016-02-04-half-year-experience-report-in-ucas/","summary":"\u003cp\u003e现在是2016年2月4日，距离农历新年不到4天，结束了半年的国科大研一生活，躺在被窝里，松了一口气……\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"ucas-2015-1\" loading=\"lazy\" src=\"/posts/2016-02-04-half-year-experience-report-in-ucas/ucas-2015-1.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e来国科大之前，在贴吧上了解到国科大雁栖湖校区地处偏远农村，周边几乎没有娱乐场所；但同时学校的软硬件设施非常的棒：豪华单人间，研究员甚至院士亲自授课等等。所以对国科大雁栖湖校区满是憧憬。至今还清楚的记得坐校车从玉泉路过来时，沿途看到APEC主会场的鸟蛋、国科大桥、钟楼以及国科大正门几个大字时的激动心情~\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"ucas-2015-7\" loading=\"lazy\" src=\"/posts/2016-02-04-half-year-experience-report-in-ucas/ucas-2015-7.jpg\"\u003e \u003cimg alt=\"ucas-2015-3\" loading=\"lazy\" src=\"/posts/2016-02-04-half-year-experience-report-in-ucas/ucas-2015-3.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e入住国科大，着实被UCAS的蓝天白云、青山绿水给迷住了。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"ucas-2015-2\" loading=\"lazy\" src=\"/posts/2016-02-04-half-year-experience-report-in-ucas/ucas-2015-2.jpg\"\u003e \u003cimg alt=\"ucas-2015-4\" loading=\"lazy\" src=\"/posts/2016-02-04-half-year-experience-report-in-ucas/ucas-2015-4.jpg\"\u003e \u003cimg alt=\"ucas-2015-5\" loading=\"lazy\" src=\"/posts/2016-02-04-half-year-experience-report-in-ucas/ucas-2015-5.jpg\"\u003e \u003cimg alt=\"ucas-2015-6\" loading=\"lazy\" src=\"/posts/2016-02-04-half-year-experience-report-in-ucas/ucas-2015-6.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e当然，凡事有利必有弊，因为这里远离市区，环境好，但正因为远离市区，几乎没有年轻人的娱乐活动，想要看个电影唱个歌少说也得跑城里，再要想感受下帝都奢靡的生活，必须各种倒车近2个小时到市里。\u003c/p\u003e\n\u003cp\u003e研一这上学期，半年只进市里两次，一次是买山地车，一次是回所里开会。购物主要靠天猫超市。\u003c/p\u003e\n\u003cp\u003e九十月份，大家都和大一新生似的，各种疯玩，野长城、雁栖湖、慕田峪、青龙峡、密云水库。进入十一月，新鲜劲过去了，又开始各种赶大小作业，复习考试。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"ucas-schedule-2015-fall\" loading=\"lazy\" src=\"/posts/2016-02-04-half-year-experience-report-in-ucas/ucas-schedule-2015-fall.png\"\u003e\u003c/p\u003e\n\u003cp\u003e这是我这学期的课表，看着课好像不多，每天都有半天休息，但是真的感觉回到了大三呀！尤其数据挖掘、信息检索、矩阵论一周上两次课，当天上完的课如果没有及时复习，隔一天再学新内容完全跟不上啊，而且矩阵论每次课都有好多作业啊，这数学课不做练习完全消化不了呀。更神的课还要数周五的卜神算法，君不见，每到周四晚上，西A、西B两栋宿舍，灯火通明，大家都在熬夜赶算法作业啊，不熬个两三点都不好意思和别人说你熬夜了呀。\u003ca href=\"https://bitjoy.net/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/\"\u003e大家可以感受一下我整理的卜神算法作业~~\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e正是因为这奇葩的课程安排，这半年几乎没有12点前睡过觉，估计平均是1:30才睡觉，早上8点多才起，中午也没午休。想想大学的时候按时作息，真是惭愧。期间有一次听说搜狐一同届华科毕业生猝死，朋友圈传得沸沸扬扬，大伙都吓得要命，纷纷表示绝不熬夜，早睡早起，我那天也是吓坏了，决定早睡，11:30就爬床上了，但是不知道是因为紧张还是熬夜习惯了，辗转反侧，到12点多才睡着的。\u003c/p\u003e\n\u003cp\u003e我们研一在国科大上课是有补助的，但是在帝都完全不够用啊，而且CS相关的几个所补助都比ICT高，so当时还公车上书，各种写联名信、起义，经过半年之久的持久战，所里终于答应从2016年开始给我们涨500块钱的工资。涨了之后差不多够吃饭了。\u003c/p\u003e\n\u003cp\u003e虽然这半年课业繁重，但是也抽空锻炼了身体，天气不是很冷的时候，隔一天就会去夜跑；而且选了乒乓球课，从直拍转为了横拍，并且在课上结识了路路，打球好厉害的一个女生，每次老师来指导的时候，都叫路路温柔点 O__O “…\u003c/p\u003e\n\u003cp\u003e另外花了一千多块钱买了一辆二手山地车，骑着到处转悠了一下。很有缘的是，认识了一位才女。本来我们骑行社一块去美利达准备买车，但是由于种种原因我和小欣都没买，然后我们一块坐小黑车回村，在车上聊着聊着就认识，没想到后来还成为了好朋友，小欣的台球和乒乓球都打得不错，琴棋书画样样精通。突然发现身边的学霸才子佳人好多，更加深刻感受到有些东西不是你努力就能够弥补的，天赋、眼界、才艺、品味、性格……\u003c/p\u003e\n\u003cp\u003e来国科大的这半年，自我感觉变化最大的是自己变得爱说话了，而且带着一种zhuang bi气息，不知道是不是受某几个我一直崇拜的人的影响。有时候静下心来想想都不敢相信之前的话是我说的，和大学时的我完全判若两人。当然这种事情有利也有弊，还在慢慢找平衡点，可能正如CL说的“话怎么说是一回事，内心要知道自己想要的”。\u003c/p\u003e\n\u003cp\u003e这半年突然害怕一个人上学，一个人吃饭，一个人自习了，更喜欢face-to-face的交谈，少了对网络的依赖，不知道是不是因为性格的变化、环境的变化、抑或是认识的人多了，有了念想。\u003c/p\u003e\n\u003cp\u003e半年时光，认识了不多不少几个好朋友：良辰、发文章、牛牛、欣儿、路路，有你们真好，谢谢你们~\u003c/p\u003e\n\u003cp\u003e2016猴赛雷，即将从研一的上课转入课题组工作，很关键的一年，加油！\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://i0.wp.com/image.thepaper.cn/www/image/4/753/520.jpg\"\u003e\u003c/p\u003e","title":"国科大半年体验报告"},{"content":"这学期选修了卜老师的算法课，都说这课是神课，上过之后果然是神课。同样是算法课，别人12月底就考完了，我们要1月底才考试。\n本课程主要讲了以下几个专题：\nDivide-and-conquer Dynamic programming Greedy Linear programming Linear programming: duality Network flow Problem hardness: Polynomial-time reduction NP-Completeness Approximation algorithm 前三个专题的算法大多数本科时学过的，但是经卜老师讲一遍还会有新的收获。后六个专题接触较少，学到了很多新算法。\n下图是卜老师每节课必讲的问题求解思路图：\n（待我回家把图画出来…）\n本课程最神的要数课后作业了，一般deadline是周五，每到周四晚上，大家都做好熬通宵赶作业的准备，没熬到两三点都不好意思睡觉，我同学有一次甚至熬到了第二天六点！\n每次作业大概有10题，前7题是算法设计，后3题是算法实现，每题都不是省油的灯，不过如果把每道题都理解消化，算法及编程能力会有很大的提高。\n下面是我整理出来的算法题目和个人解答，大家感受一下。（仅供完成作业之后交流使用，拒绝抄袭！）\nAssignment1_DandC.zip A1sol.pdf | A1sol.tex A1sol_supplement.pdf | A1sol_supplement.tex_.zip Assignment2_DP.zip A2sol.pdf | A2sol.tex_.zip A2sol_supplement.pdf | A2sol_supplement.tex Assignment3_Greedy.zip A3sol.pdf | A3sol.tex_.zip A3sol_supplement.pdf | A3sol_supplement.tex Assignment4_LP.zip A4sol.pdf | A4sol.tex A4sol_supplement.pdf | A4sol_supplement.tex Assignment5_NF.zip A5sol.pdf | A5sol.tex A5sol_supplement.pdf | A5sol_supplement.tex Assignment6_NP.pdf A6sol.pdf | A6sol.tex Assignment7_App.pdf A7sol.pdf | A7sol.tex ","permalink":"http://localhost:1313/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/","summary":"\u003cp\u003e这学期选修了\u003ca href=\"http://bioinfo.ict.ac.cn/~dbu/AlgorithmCourses/CS711008Z/CS711008Z_2015.html\"\u003e卜老师的算法课\u003c/a\u003e，都说这课是神课，上过之后果然是神课。同样是算法课，别人12月底就考完了，我们要1月底才考试。\u003c/p\u003e\n\u003cp\u003e本课程主要讲了以下几个专题：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDivide-and-conquer\u003c/li\u003e\n\u003cli\u003eDynamic programming\u003c/li\u003e\n\u003cli\u003eGreedy\u003c/li\u003e\n\u003cli\u003eLinear programming\u003c/li\u003e\n\u003cli\u003eLinear programming: duality\u003c/li\u003e\n\u003cli\u003eNetwork flow\u003c/li\u003e\n\u003cli\u003eProblem hardness: Polynomial-time reduction\u003c/li\u003e\n\u003cli\u003eNP-Completeness\u003c/li\u003e\n\u003cli\u003eApproximation algorithm\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e前三个专题的算法大多数本科时学过的，但是经卜老师讲一遍还会有新的收获。后六个专题接触较少，学到了很多新算法。\u003c/p\u003e\n\u003cp\u003e下图是卜老师每节课必讲的问题求解思路图：\u003c/p\u003e\n\u003cp\u003e（待我回家把图画出来…）\u003c/p\u003e\n\u003cp\u003e本课程最神的要数课后作业了，一般deadline是周五，每到周四晚上，大家都做好熬通宵赶作业的准备，没熬到两三点都不好意思睡觉，我同学有一次甚至熬到了第二天六点！\u003c/p\u003e\n\u003cp\u003e每次作业大概有10题，前7题是算法设计，后3题是算法实现，每题都不是省油的灯，不过如果把每道题都理解消化，算法及编程能力会有很大的提高。\u003c/p\u003e\n\u003cp\u003e下面是我整理出来的算法题目和个人解答，大家感受一下。（\u003cstrong\u003e仅供完成作业之后交流使用，拒绝抄袭！\u003c/strong\u003e）\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/Assignment1_DandC.zip\"\u003eAssignment1_DandC.zip\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/A1sol.pdf\"\u003eA1sol.pdf\u003c/a\u003e   |  \u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/A1sol.tex\"\u003eA1sol.tex\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/A1sol_supplement.pdf\"\u003eA1sol_supplement.pdf\u003c/a\u003e   |   \u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/A1sol_supplement.tex_.zip\"\u003eA1sol_supplement.tex_.zip\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/Assignment2_DP.zip\"\u003eAssignment2_DP.zip\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/A2sol.pdf\"\u003eA2sol.pdf\u003c/a\u003e   |   \u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/A2sol.tex_.zip\"\u003eA2sol.tex_.zip\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/A2sol_supplement.pdf\"\u003eA2sol_supplement.pdf\u003c/a\u003e   |   \u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/A2sol_supplement.tex\"\u003eA2sol_supplement.tex\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/Assignment3_Greedy.zip\"\u003eAssignment3_Greedy.zip\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/A3sol.pdf\"\u003eA3sol.pdf\u003c/a\u003e  |  \u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/A3sol.tex_.zip\"\u003eA3sol.tex_.zip\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/A3sol_supplement.pdf\"\u003eA3sol_supplement.pdf\u003c/a\u003e  |   \u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/A3sol_supplement.tex\"\u003eA3sol_supplement.tex\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/Assignment4_LP.zip\"\u003eAssignment4_LP.zip\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/A4sol.pdf\"\u003eA4sol.pdf\u003c/a\u003e   |   \u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/A4sol.tex\"\u003eA4sol.tex\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/A4sol_supplement.pdf\"\u003eA4sol_supplement.pdf\u003c/a\u003e   |   \u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/A4sol_supplement.tex\"\u003eA4sol_supplement.tex\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/Assignment5_NF.zip\"\u003eAssignment5_NF.zip\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/A5sol.pdf\"\u003eA5sol.pdf\u003c/a\u003e   |   \u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/A5sol.tex\"\u003eA5sol.tex\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/A5sol_supplement.pdf\"\u003eA5sol_supplement.pdf\u003c/a\u003e   |   \u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/A5sol_supplement.tex\"\u003eA5sol_supplement.tex\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/Assignment6_NP.pdf\"\u003eAssignment6_NP.pdf\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/A6sol.pdf\"\u003eA6sol.pdf\u003c/a\u003e   |   \u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/A6sol.tex\"\u003eA6sol.tex\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/Assignment7_App.pdf\"\u003eAssignment7_App.pdf\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/A7sol.pdf\"\u003eA7sol.pdf\u003c/a\u003e   |   \u003ca href=\"/posts/2016-01-29-algorithm-design-and-analysis-by-dbu/A7sol.tex\"\u003eA7sol.tex\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"卜神算法作业整理"},{"content":"至此，整个新闻搜索引擎构建完毕，总体效果令人满意，不过还是有很多可以改进的地方。下面总结一下本系统的优点和不足。\n优点\n倒排索引存储方式。因为不同词项的倒排记录表长度一般不同，所以没办法以常规的方式存入关系型数据库。通过将一个词项的倒排记录表序列化成一个字符串再存入数据库，读取的时候通过反序列化获得相关数据，整个结构类似于邻接表的形式。\n推荐阅读实现方式。利用特征提取的方法，用25个关键词表示一篇新闻，大大减小了文档词项矩阵规模，提高计算效率的同时不影响推荐新闻相关性。\n借用了Reddit的热度公式，融合了时间因素。\n不足\n构建索引时，为了降低索引规模，提高算法速度，我们将纯数字词项过滤了，同时忽略了词项大小写。虽然索引规模下降了，但是牺牲了搜索引擎的正确率。\n构建索引时，采用了jieba的精确分词模式，比如句子“我来到北京清华大学”的分词结果为“我/ 来到/ 北京/ 清华大学”，“清华大学”作为一个整体被当作一个词项，如果搜索关键词是“清华”，则该句子不能匹配，但显然这个句子和“清华”相关。所以后续可以采用结巴的搜索引擎分词模式，虽然索引规模增加了，但能提升搜索引擎的召回率。\n在推荐阅读模块，虽然进行了维度约减，但是当数据量较大时（数十万条新闻），得到的文档词项矩阵也是巨大的，会远远超过现有PC的内存大小。所以可以先对新闻进行粗略的聚类，再在类内计算两两cosine相似度，得到值得推荐的新闻。\n在热度公式中，虽然借用了Reddit的公式，大的方向是正确的，但是引入了参数\\(k_1\\)和\\(k_2\\)，而且将其简单的设置为1。如果能够由专家给出或者经过机器学习训练得到，则热度公式的效果会更好。\n完整可运行的新闻搜索引擎Demo请看我的Github项目news_search_engine。\n以下是系列博客：\n和我一起构建搜索引擎（一）简介\n和我一起构建搜索引擎（二）网络爬虫\n和我一起构建搜索引擎（三）构建索引\n和我一起构建搜索引擎（四）检索模型\n和我一起构建搜索引擎（五）推荐阅读\n和我一起构建搜索引擎（六）系统展示\n和我一起构建搜索引擎（七）总结展望\n","permalink":"http://localhost:1313/posts/2016-01-09-introduction-to-building-a-search-engine-7/","summary":"\u003cp\u003e至此，整个新闻搜索引擎构建完毕，总体效果令人满意，不过还是有很多可以改进的地方。下面总结一下本系统的优点和不足。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e优点\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e倒排索引存储方式。因为不同词项的倒排记录表长度一般不同，所以没办法以常规的方式存入关系型数据库。通过将一个词项的倒排记录表序列化成一个字符串再存入数据库，读取的时候通过反序列化获得相关数据，整个结构类似于邻接表的形式。\u003c/p\u003e\n\u003cp\u003e推荐阅读实现方式。利用特征提取的方法，用25个关键词表示一篇新闻，大大减小了文档词项矩阵规模，提高计算效率的同时不影响推荐新闻相关性。\u003c/p\u003e\n\u003cp\u003e借用了Reddit的热度公式，融合了时间因素。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e不足\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e构建索引时，为了降低索引规模，提高算法速度，我们将纯数字词项过滤了，同时忽略了词项大小写。虽然索引规模下降了，但是牺牲了搜索引擎的正确率。\u003c/p\u003e\n\u003cp\u003e构建索引时，采用了jieba的精确分词模式，比如句子“我来到北京清华大学”的分词结果为“我/ 来到/ 北京/ 清华大学”，“清华大学”作为一个整体被当作一个词项，如果搜索关键词是“清华”，则该句子不能匹配，但显然这个句子和“清华”相关。所以后续可以采用结巴的搜索引擎分词模式，虽然索引规模增加了，但能提升搜索引擎的召回率。\u003c/p\u003e\n\u003cp\u003e在推荐阅读模块，虽然进行了维度约减，但是当数据量较大时（数十万条新闻），得到的文档词项矩阵也是巨大的，会远远超过现有PC的内存大小。所以可以先对新闻进行粗略的聚类，再在类内计算两两cosine相似度，得到值得推荐的新闻。\u003c/p\u003e\n\u003cp\u003e在热度公式中，虽然借用了Reddit的公式，大的方向是正确的，但是引入了参数\\(k_1\\)和\\(k_2\\)，而且将其简单的设置为1。如果能够由专家给出或者经过机器学习训练得到，则热度公式的效果会更好。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e完整可运行的新闻搜索引擎Demo请看我的Github项目\u003ca href=\"https://github.com/01joy/news_search_engine\"\u003enews_search_engine\u003c/a\u003e。\u003c/p\u003e\n\u003cp\u003e以下是系列博客：\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://bitjoy.net/posts/2016-01-04-introduction-to-building-a-search-engine-1/\"\u003e和我一起构建搜索引擎（一）简介\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://bitjoy.net/posts/2016-01-04-introduction-to-building-a-search-engine-2/\"\u003e和我一起构建搜索引擎（二）网络爬虫\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://bitjoy.net/posts/2016-01-07-introduction-to-building-a-search-engine-3/\"\u003e和我一起构建搜索引擎（三）构建索引\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://bitjoy.net/posts/2016-01-07-introduction-to-building-a-search-engine-4/\"\u003e和我一起构建搜索引擎（四）检索模型\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://bitjoy.net/posts/2016-01-09-introduction-to-building-a-search-engine-5/\"\u003e和我一起构建搜索引擎（五）推荐阅读\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://bitjoy.net/posts/2016-01-09-introduction-to-building-a-search-engine-6/\"\u003e和我一起构建搜索引擎（六）系统展示\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://bitjoy.net/posts/2016-01-09-introduction-to-building-a-search-engine-7/\"\u003e和我一起构建搜索引擎（七）总结展望\u003c/a\u003e\u003c/p\u003e","title":"和我一起构建搜索引擎（七）总结展望"},{"content":"前几个博客已经介绍完搜索引擎的所有功能，为了实现更好的用户体验，需要一个web界面。这一部分是另一个队员做的，我这里借用他的代码。\n我们利用开源的Flask Web框架搭建了展示系统，搜索引擎只需要两个界面，一个是搜索界面，另一个是展示详细新闻的页面（实际搜索引擎没有这个页面）。编写好这两个模板页面并调用前面给出的接口，得到数据，展示出来就可以。\n这一部分没有太多需要讲解的算法，直接上效果图（点击图片可以查看大图）。\n图1. 搜索页面\n图2. 新闻详情页面\n由于数据量不大，只有1000条新闻，所以第一页中后面几个结果相关度就不是很高了。但是经过测试，在大数据量的情况下，不论是搜索的速度、准确率、召回率以及推荐阅读的相关度，都达到了不错的效果。\n完整可运行的新闻搜索引擎Demo请看我的Github项目news_search_engine。\n以下是系列博客：\n和我一起构建搜索引擎（一）简介\n和我一起构建搜索引擎（二）网络爬虫\n和我一起构建搜索引擎（三）构建索引\n和我一起构建搜索引擎（四）检索模型\n和我一起构建搜索引擎（五）推荐阅读\n和我一起构建搜索引擎（六）系统展示\n和我一起构建搜索引擎（七）总结展望\n","permalink":"http://localhost:1313/posts/2016-01-09-introduction-to-building-a-search-engine-6/","summary":"\u003cp\u003e前几个博客已经介绍完搜索引擎的所有功能，为了实现更好的用户体验，需要一个web界面。这一部分是另一个队员做的，我这里借用他的代码。\u003c/p\u003e\n\u003cp\u003e我们利用开源的\u003ca href=\"http://flask.pocoo.org/\"\u003eFlask Web框架\u003c/a\u003e搭建了展示系统，搜索引擎只需要两个界面，一个是搜索界面，另一个是展示详细新闻的页面（实际搜索引擎没有这个页面）。编写好这两个模板页面并调用前面给出的接口，得到数据，展示出来就可以。\u003c/p\u003e\n\u003cp\u003e这一部分没有太多需要讲解的算法，直接上效果图（点击图片可以查看大图）。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"图1. 搜索页面\" loading=\"lazy\" src=\"/posts/2016-01-09-introduction-to-building-a-search-engine-6/News-Search-Engine1.webp\"\u003e\n图1. 搜索页面\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"图2. 新闻详情页面\" loading=\"lazy\" src=\"/posts/2016-01-09-introduction-to-building-a-search-engine-6/News-Search-Engine2.webp\"\u003e\n图2. 新闻详情页面\u003c/p\u003e\n\u003cp\u003e由于数据量不大，只有1000条新闻，所以第一页中后面几个结果相关度就不是很高了。但是经过测试，在大数据量的情况下，不论是搜索的速度、准确率、召回率以及推荐阅读的相关度，都达到了不错的效果。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e完整可运行的新闻搜索引擎Demo请看我的Github项目\u003ca href=\"https://github.com/01joy/news_search_engine\"\u003enews_search_engine\u003c/a\u003e。\u003c/p\u003e\n\u003cp\u003e以下是系列博客：\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://bitjoy.net/posts/2016-01-04-introduction-to-building-a-search-engine-1/\"\u003e和我一起构建搜索引擎（一）简介\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://bitjoy.net/posts/2016-01-04-introduction-to-building-a-search-engine-2/\"\u003e和我一起构建搜索引擎（二）网络爬虫\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://bitjoy.net/posts/2016-01-07-introduction-to-building-a-search-engine-3/\"\u003e和我一起构建搜索引擎（三）构建索引\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://bitjoy.net/posts/2016-01-07-introduction-to-building-a-search-engine-4/\"\u003e和我一起构建搜索引擎（四）检索模型\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://bitjoy.net/posts/2016-01-09-introduction-to-building-a-search-engine-5/\"\u003e和我一起构建搜索引擎（五）推荐阅读\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://bitjoy.net/posts/2016-01-09-introduction-to-building-a-search-engine-6/\"\u003e和我一起构建搜索引擎（六）系统展示\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://bitjoy.net/posts/2016-01-09-introduction-to-building-a-search-engine-7/\"\u003e和我一起构建搜索引擎（七）总结展望\u003c/a\u003e\u003c/p\u003e","title":"和我一起构建搜索引擎（六）系统展示"},{"content":"虽然主要的检索功能实现了，但是我们还需要一个“推荐阅读”的功能。当用户浏览某条具体新闻时，我们在页面底端给出5条和该新闻相关的新闻，也就是一个最简单的推荐系统。\n搜狐新闻“相关新闻”模块\n推荐模块的思路是度量两两新闻之间的相似度，取相似度最高的前5篇新闻作为推荐阅读的新闻。\n我们前面讲过，一篇文档可以用一个向量表示，向量中的每个值是不同词项t在该文档d中的词频tf。但是一篇较短的文档（如新闻）的关键词并不多，所以我们可以提取每篇新闻的关键词，用这些关键词的tfidf值构成文档的向量表示，这样能够大大减少相似度计算量，同时保持较好的推荐效果。\njieba分词组件自带关键词提取功能，并能返回关键词的tfidf值。所以对每篇新闻，我们先提取tfidf得分最高的前25个关键词，用这25个关键词的tfidf值作为文档的向量表示。由此能够得到一个1000*m的文档词项矩阵M，矩阵每行表示一个文档，每列表示一个词项，m为1000个文档的所有互异的关键词（大概10000个）。矩阵M当然也是稀疏矩阵。\n得到文档词项矩阵M之后，我们利用sklearn的pairwise_distances函数计算M中行向量之间的cosine相似度，对每个文档，得到与其最相似的前5篇新闻id，并把结果写入数据库。\n推荐阅读模块的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 # -*- coding: utf-8 -*- \u0026#34;\u0026#34;\u0026#34; Created on Wed Dec 23 14:06:10 2015 @author: bitjoy.net \u0026#34;\u0026#34;\u0026#34; from os import listdir import xml.etree.ElementTree as ET import jieba import jieba.analyse import sqlite3 import configparser from datetime import * import math import pandas as pd import numpy as np from sklearn.metrics import pairwise_distances class RecommendationModule: stop_words = set() k_nearest = [] config_path = \u0026#39;\u0026#39; config_encoding = \u0026#39;\u0026#39; doc_dir_path = \u0026#39;\u0026#39; doc_encoding = \u0026#39;\u0026#39; stop_words_path = \u0026#39;\u0026#39; stop_words_encoding = \u0026#39;\u0026#39; idf_path = \u0026#39;\u0026#39; db_path = \u0026#39;\u0026#39; def __init__(self, config_path, config_encoding): self.config_path = config_path self.config_encoding = config_encoding config = configparser.ConfigParser() config.read(config_path, config_encoding) self.doc_dir_path = config[\u0026#39;DEFAULT\u0026#39;][\u0026#39;doc_dir_path\u0026#39;] self.doc_encoding = config[\u0026#39;DEFAULT\u0026#39;][\u0026#39;doc_encoding\u0026#39;] self.stop_words_path = config[\u0026#39;DEFAULT\u0026#39;][\u0026#39;stop_words_path\u0026#39;] self.stop_words_encoding = config[\u0026#39;DEFAULT\u0026#39;][\u0026#39;stop_words_encoding\u0026#39;] self.idf_path = config[\u0026#39;DEFAULT\u0026#39;][\u0026#39;idf_path\u0026#39;] self.db_path = config[\u0026#39;DEFAULT\u0026#39;][\u0026#39;db_path\u0026#39;] f = open(self.stop_words_path, encoding = self.stop_words_encoding) words = f.read() self.stop_words = set(words.split(\u0026#39;\\n\u0026#39;)) def write_k_nearest_matrix_to_db(self): conn = sqlite3.connect(self.db_path) c = conn.cursor() c.execute(\u0026#34;\u0026#39;DROP TABLE IF EXISTS knearest\u0026#39;\u0026#34;) c.execute(\u0026#34;\u0026#39;CREATE TABLE knearest(id INTEGER PRIMARY KEY, first INTEGER, second INTEGER, third INTEGER, fourth INTEGER, fifth INTEGER)\u0026#39;\u0026#34;) for docid, doclist in self.k_nearest: c.execute(\u0026#34;INSERT INTO knearest VALUES (?, ?, ?, ?, ?, ?)\u0026#34;, tuple([docid] + doclist)) conn.commit() conn.close() def is_number(self, s): try: float(s) return True except ValueError: return False def construct_dt_matrix(self, files, topK = 200): jieba.analyse.set_stop_words(self.stop_words_path) jieba.analyse.set_idf_path(self.idf_path) M = len(files) N = 1 terms = {} dt = [] for i in files: root = ET.parse(self.doc_dir_path + i).getroot() title = root.find(\u0026#39;title\u0026#39;).text body = root.find(\u0026#39;body\u0026#39;).text docid = int(root.find(\u0026#39;id\u0026#39;).text) tags = jieba.analyse.extract_tags(title + \u0026#39;。\u0026#39; + body, topK=topK, withWeight=True) #tags = jieba.analyse.extract_tags(title, topK=topK, withWeight=True) cleaned_dict = {} for word, tfidf in tags: word = word.strip().lower() if word == \u0026#39;\u0026#39; or self.is_number(word): continue cleaned_dict[word] = tfidf if word not in terms: terms[word] = N N += 1 dt.append([docid, cleaned_dict]) dt_matrix = [[0 for i in range(N)] for j in range(M)] i =0 for docid, t_tfidf in dt: dt_matrix[i][0] = docid for term, tfidf in t_tfidf.items(): dt_matrix[i][terms[term]] = tfidf i += 1 dt_matrix = pd.DataFrame(dt_matrix) dt_matrix.index = dt_matrix[0] print(\u0026#39;dt_matrix shape:(%d %d)\u0026#39;%(dt_matrix.shape)) return dt_matrix def construct_k_nearest_matrix(self, dt_matrix, k): tmp = np.array(1 – pairwise_distances(dt_matrix[dt_matrix.columns[1:]], metric = \u0026#34;cosine\u0026#34;)) similarity_matrix = pd.DataFrame(tmp, index = dt_matrix.index.tolist(), columns = dt_matrix.index.tolist()) for i in similarity_matrix.index: tmp = [int(i),[]] j = 0 while j \u0026lt;= k: max_col = similarity_matrix.loc[i].idxmax(axis = 1) similarity_matrix.loc[i][max_col] = -1 if max_col != i: tmp[1].append(int(max_col)) #max column name j += 1 self.k_nearest.append(tmp) def gen_idf_file(self): files = listdir(self.doc_dir_path) n = float(len(files)) idf = {} for i in files: root = ET.parse(self.doc_dir_path + i).getroot() title = root.find(\u0026#39;title\u0026#39;).text body = root.find(\u0026#39;body\u0026#39;).text seg_list = jieba.lcut(title + \u0026#39;。\u0026#39; + body, cut_all=False) seg_list = set(seg_list) – self.stop_words for word in seg_list: word = word.strip().lower() if word == \u0026#39;\u0026#39; or self.is_number(word): continue if word not in idf: idf[word] = 1 else: idf[word] = idf[word] + 1 idf_file = open(self.idf_path, \u0026#39;w\u0026#39;, encoding = \u0026#39;utf-8\u0026#39;) for word, df in idf.items(): idf_file.write(\u0026#39;%s %.9f\\n\u0026#39;%(word, math.log(n / df))) idf_file.close() def find_k_nearest(self, k, topK): self.gen_idf_file() files = listdir(self.doc_dir_path) dt_matrix = self.construct_dt_matrix(files, topK) self.construct_k_nearest_matrix(dt_matrix, k) self.write_k_nearest_matrix_to_db() if __name__ == \u0026#34;__main__\u0026#34;: print(\u0026#39;—–start time: %s—–\u0026#39;%(datetime.today())) rm = RecommendationModule(\u0026#39;../config.ini\u0026#39;, \u0026#39;utf-8\u0026#39;) rm.find_k_nearest(5, 25) print(\u0026#39;—–finish time: %s—–\u0026#39;%(datetime.today())) 这个模块的代码量最多，主要原因是需要构建文档词项矩阵，并且计算k邻居矩阵。矩阵数据结构的设计需要特别注意，否则会严重影响系统的效率。我刚开始把任务都扔给了pandas.DataFrame，后来发现当两个文档向量合并时，需要join连接操作，当数据量很大时，非常耗时，所以改成了先用python原始的list存储，最后一次性构造一个完整的pandas.DataFrame，速度比之前快了不少。\n完整可运行的新闻搜索引擎Demo请看我的Github项目news_search_engine。\n以下是系列博客：\n和我一起构建搜索引擎（一）简介\n和我一起构建搜索引擎（二）网络爬虫\n和我一起构建搜索引擎（三）构建索引\n和我一起构建搜索引擎（四）检索模型\n和我一起构建搜索引擎（五）推荐阅读\n和我一起构建搜索引擎（六）系统展示\n和我一起构建搜索引擎（七）总结展望\n","permalink":"http://localhost:1313/posts/2016-01-09-introduction-to-building-a-search-engine-5/","summary":"\u003cp\u003e虽然主要的检索功能实现了，但是我们还需要一个“推荐阅读”的功能。当用户浏览某条具体新闻时，我们在页面底端给出5条和该新闻相关的新闻，也就是一个最简单的推荐系统。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"搜狐新闻“相关新闻”模块\" loading=\"lazy\" src=\"/posts/2016-01-09-introduction-to-building-a-search-engine-5/sohu-news3.webp\"\u003e\n搜狐新闻“相关新闻”模块\u003c/p\u003e\n\u003cp\u003e推荐模块的思路是度量两两新闻之间的相似度，取相似度最高的前5篇新闻作为推荐阅读的新闻。\u003c/p\u003e\n\u003cp\u003e我们前面讲过，一篇文档可以用一个向量表示，向量中的每个值是不同词项t在该文档d中的词频tf。但是一篇较短的文档（如新闻）的关键词并不多，所以我们可以提取每篇新闻的关键词，用这些关键词的tfidf值构成文档的向量表示，这样能够大大减少相似度计算量，同时保持较好的推荐效果。\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/fxsjy/jieba#3-%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E5%8F%96\"\u003ejieba分词组件自带关键词提取功能\u003c/a\u003e，并能返回关键词的tfidf值。所以对每篇新闻，我们先提取tfidf得分最高的前25个关键词，用这25个关键词的tfidf值作为文档的向量表示。由此能够得到一个1000*m的文档词项矩阵M，矩阵每行表示一个文档，每列表示一个词项，m为1000个文档的所有互异的关键词（大概10000个）。矩阵M当然也是稀疏矩阵。\u003c/p\u003e\n\u003cp\u003e得到文档词项矩阵M之后，我们利用\u003ca href=\"http://sklearn.metrics.pairwise.pairwise_distances/\"\u003esklearn的pairwise_distances函数\u003c/a\u003e计算M中行向量之间的cosine相似度，对每个文档，得到与其最相似的前5篇新闻id，并把结果写入数据库。\u003c/p\u003e\n\u003cp\u003e推荐阅读模块的代码如下：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\n\u003ctable style=\"border-spacing:0;padding:0;margin:0;border:0;\"\u003e\u003ctr\u003e\u003ctd style=\"vertical-align:top;padding:0;margin:0;border:0;\"\u003e\n\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e  1\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e  2\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e  3\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e  4\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e  5\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e  6\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e  7\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e  8\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e  9\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 10\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 11\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 12\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 13\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 14\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 15\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 16\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 17\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 18\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 19\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 20\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 21\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 22\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 23\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 24\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 25\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 26\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 27\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 28\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 29\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 30\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 31\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 32\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 33\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 34\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 35\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 36\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 37\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 38\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 39\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 40\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 41\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 42\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 43\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 44\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 45\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 46\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 47\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 48\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 49\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 50\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 51\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 52\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 53\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 54\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 55\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 56\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 57\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 58\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 59\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 60\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 61\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 62\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 63\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 64\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 65\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 66\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 67\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 68\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 69\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 70\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 71\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 72\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 73\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 74\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 75\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 76\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 77\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 78\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 79\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 80\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 81\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 82\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 83\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 84\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 85\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 86\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 87\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 88\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 89\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 90\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 91\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 92\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 93\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 94\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 95\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 96\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 97\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 98\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 99\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e100\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e101\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e102\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e103\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e104\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e105\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e106\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e107\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e108\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e109\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e110\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e111\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e112\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e113\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e114\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e115\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e116\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e117\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e118\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e119\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e120\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e121\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e122\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e123\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e124\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e125\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e126\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e127\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e128\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e129\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e130\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e131\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e132\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e133\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e134\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e135\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e136\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e137\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e138\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e139\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e140\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e141\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e142\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e143\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e144\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e145\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e146\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e147\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e148\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e149\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e150\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e151\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e152\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e153\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e154\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e155\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e156\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e157\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e158\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd style=\"vertical-align:top;padding:0;margin:0;border:0;;width:100%\"\u003e\n\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# -*- coding: utf-8 -*-\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u0026#34;\u0026#34;\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003eCreated on Wed Dec 23 14:06:10 2015\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e@author: bitjoy.net\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u0026#34;\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e os \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e listdir\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e xml.etree.ElementTree \u003cspan style=\"color:#66d9ef\"\u003eas\u003c/span\u003e ET\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e jieba\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e jieba.analyse\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e sqlite3\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e configparser\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e datetime \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e*\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e math\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e pandas \u003cspan style=\"color:#66d9ef\"\u003eas\u003c/span\u003e pd\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e numpy \u003cspan style=\"color:#66d9ef\"\u003eas\u003c/span\u003e np\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e sklearn.metrics \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e pairwise_distances\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eclass\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eRecommendationModule\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    stop_words \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e set()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    k_nearest \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e []\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    config_path \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    config_encoding \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    doc_dir_path \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    doc_encoding \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    stop_words_path \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    stop_words_encoding \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    idf_path \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    db_path \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003e__init__\u003c/span\u003e(self, config_path, config_encoding):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003econfig_path \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e config_path\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003econfig_encoding \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e config_encoding\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        config \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e configparser\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eConfigParser()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eread(config_path, config_encoding)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003edoc_dir_path \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e config[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;DEFAULT\u0026#39;\u003c/span\u003e][\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;doc_dir_path\u0026#39;\u003c/span\u003e]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003edoc_encoding \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e config[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;DEFAULT\u0026#39;\u003c/span\u003e][\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;doc_encoding\u0026#39;\u003c/span\u003e]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003estop_words_path \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e config[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;DEFAULT\u0026#39;\u003c/span\u003e][\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;stop_words_path\u0026#39;\u003c/span\u003e]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003estop_words_encoding \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e config[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;DEFAULT\u0026#39;\u003c/span\u003e][\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;stop_words_encoding\u0026#39;\u003c/span\u003e]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eidf_path \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e config[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;DEFAULT\u0026#39;\u003c/span\u003e][\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;idf_path\u0026#39;\u003c/span\u003e]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003edb_path \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e config[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;DEFAULT\u0026#39;\u003c/span\u003e][\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;db_path\u0026#39;\u003c/span\u003e]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        f \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e open(self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003estop_words_path, encoding \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003estop_words_encoding)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        words \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eread()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003estop_words \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e set(words\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003esplit(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e\\n\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ewrite_k_nearest_matrix_to_db\u003c/span\u003e(self):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        conn \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e sqlite3\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003econnect(self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003edb_path)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        c \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e conn\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ecursor()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        c\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eexecute(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u0026#39;DROP TABLE IF EXISTS knearest\u0026#39;\u0026#34;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        c\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eexecute(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u0026#39;CREATE TABLE knearest(id INTEGER PRIMARY KEY, first INTEGER, second INTEGER, third INTEGER, fourth INTEGER, fifth INTEGER)\u0026#39;\u0026#34;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e docid, doclist \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ek_nearest:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            c\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eexecute(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;INSERT INTO knearest VALUES (?, ?, ?, ?, ?, ?)\u0026#34;\u003c/span\u003e, tuple([docid] \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e doclist))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        conn\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ecommit()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        conn\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eclose()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eis_number\u003c/span\u003e(self, s):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003etry\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            float(s)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eTrue\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003eexcept\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eValueError\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eFalse\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003econstruct_dt_matrix\u003c/span\u003e(self, files, topK \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e200\u003c/span\u003e):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        jieba\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eanalyse\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eset_stop_words(self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003estop_words_path)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        jieba\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eanalyse\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eset_idf_path(self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eidf_path)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        M \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e len(files)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        N \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        terms \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e {}\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        dt \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e []\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e i \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e files:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            root \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e ET\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eparse(self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003edoc_dir_path \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e i)\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003egetroot()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            title \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e root\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efind(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;title\u0026#39;\u003c/span\u003e)\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etext\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            body \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e root\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efind(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;body\u0026#39;\u003c/span\u003e)\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etext\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            docid \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e int(root\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efind(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;id\u0026#39;\u003c/span\u003e)\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etext)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            tags \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e jieba\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eanalyse\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eextract_tags(title \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;。\u0026#39;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e body, topK\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003etopK, withWeight\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eTrue\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            \u003cspan style=\"color:#75715e\"\u003e#tags = jieba.analyse.extract_tags(title, topK=topK, withWeight=True)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            cleaned_dict \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e {}\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e word, tfidf \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e tags:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                word \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e word\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003estrip()\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003elower()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e word \u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u0026#39;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003eor\u003c/span\u003e self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eis_number(word):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                    \u003cspan style=\"color:#66d9ef\"\u003econtinue\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                cleaned_dict[word] \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e tfidf\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e word \u003cspan style=\"color:#f92672\"\u003enot\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e terms:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                    terms[word] \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e N\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                    N \u003cspan style=\"color:#f92672\"\u003e+=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                    dt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eappend([docid, cleaned_dict])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                    dt_matrix \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [[\u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e i \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e range(N)] \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e j \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e range(M)]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        i \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e docid, t_tfidf \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e dt:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            dt_matrix[i][\u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e] \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e docid\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e term, tfidf \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e t_tfidf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eitems():\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                dt_matrix[i][terms[term]] \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e tfidf\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                i \u003cspan style=\"color:#f92672\"\u003e+=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        dt_matrix \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e pd\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eDataFrame(dt_matrix)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        dt_matrix\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eindex \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e dt_matrix[\u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        print(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;dt_matrix shape:(\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e%d\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e \u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e%d\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e)\u0026#39;\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e%\u003c/span\u003e(dt_matrix\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eshape))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e dt_matrix\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003econstruct_k_nearest_matrix\u003c/span\u003e(self, dt_matrix, k):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        tmp \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e np\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003earray(\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e \u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e–\u003c/span\u003e pairwise_distances(dt_matrix[dt_matrix\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ecolumns[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e:]], metric \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;cosine\u0026#34;\u003c/span\u003e))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        similarity_matrix \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e pd\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eDataFrame(tmp, index \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e dt_matrix\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eindex\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etolist(), columns \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e dt_matrix\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eindex\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etolist())\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e i \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e similarity_matrix\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eindex:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            tmp \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [int(i),[]]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            j \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            \u003cspan style=\"color:#66d9ef\"\u003ewhile\u003c/span\u003e j \u003cspan style=\"color:#f92672\"\u003e\u0026lt;=\u003c/span\u003e k:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                max_col \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e similarity_matrix\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eloc[i]\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eidxmax(axis \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                similarity_matrix\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eloc[i][max_col] \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e-\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e max_col \u003cspan style=\"color:#f92672\"\u003e!=\u003c/span\u003e i:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                    tmp[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eappend(int(max_col)) \u003cspan style=\"color:#75715e\"\u003e#max column name\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                    j \u003cspan style=\"color:#f92672\"\u003e+=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                    self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ek_nearest\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eappend(tmp)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003egen_idf_file\u003c/span\u003e(self):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        files \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e listdir(self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003edoc_dir_path)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        n \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e float(len(files))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        idf \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e {}\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e i \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e files:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            root \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e ET\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eparse(self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003edoc_dir_path \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e i)\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003egetroot()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            title \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e root\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efind(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;title\u0026#39;\u003c/span\u003e)\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etext\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            body \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e root\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efind(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;body\u0026#39;\u003c/span\u003e)\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etext\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            seg_list \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e jieba\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003elcut(title \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;。\u0026#39;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e body, cut_all\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eFalse\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            seg_list \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e set(seg_list) \u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e–\u003c/span\u003e self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003estop_words\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e word \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e seg_list:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                word \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e word\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003estrip()\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003elower()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e word \u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u0026#39;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003eor\u003c/span\u003e self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eis_number(word):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                    \u003cspan style=\"color:#66d9ef\"\u003econtinue\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e word \u003cspan style=\"color:#f92672\"\u003enot\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e idf:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                    idf[word] \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                \u003cspan style=\"color:#66d9ef\"\u003eelse\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                    idf[word] \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e idf[word] \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                idf_file \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e open(self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eidf_path, \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;w\u0026#39;\u003c/span\u003e, encoding \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;utf-8\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e word, df \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e idf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eitems():\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                    idf_file\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ewrite(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e%s\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e \u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e%.9f\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e\\n\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e%\u003c/span\u003e(word, math\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003elog(n \u003cspan style=\"color:#f92672\"\u003e/\u003c/span\u003e df)))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                idf_file\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eclose()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003efind_k_nearest\u003c/span\u003e(self, k, topK):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003egen_idf_file()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        files \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e listdir(self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003edoc_dir_path)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        dt_matrix \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003econstruct_dt_matrix(files, topK)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003econstruct_k_nearest_matrix(dt_matrix, k)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ewrite_k_nearest_matrix_to_db()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e __name__ \u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;__main__\u0026#34;\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    print(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;—–start time: \u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e%s\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e—–\u0026#39;\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e%\u003c/span\u003e(datetime\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etoday()))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    rm \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e RecommendationModule(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;../config.ini\u0026#39;\u003c/span\u003e, \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;utf-8\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    rm\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efind_k_nearest(\u003cspan style=\"color:#ae81ff\"\u003e5\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e25\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    print(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;—–finish time: \u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e%s\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e—–\u0026#39;\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e%\u003c/span\u003e(datetime\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etoday()))\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e这个模块的代码量最多，主要原因是需要构建文档词项矩阵，并且计算k邻居矩阵。矩阵数据结构的设计需要特别注意，否则会严重影响系统的效率。我刚开始把任务都扔给了pandas.DataFrame，后来发现当两个文档向量合并时，需要join连接操作，当数据量很大时，非常耗时，所以改成了先用python原始的list存储，最后一次性构造一个完整的pandas.DataFrame，速度比之前快了不少。\u003c/p\u003e","title":"和我一起构建搜索引擎（五）推荐阅读"},{"content":"构建好倒排索引之后，就可以开始检索了。\n检索模型有很多，比如向量空间模型、概率模型、语言模型等。其中最有名的、检索效果最好的是基于概率的BM25模型。\n给定一个查询Q和一篇文档d，d对Q的BM25得分公式为\n$$BM25_{score}(Q,d)=\\sum_{t\\in Q}w(t,d)$$$$w(t,d)=\\frac{qtf}{k_3+qtf}\\times \\frac{k_1\\times tf}{tf+k_1(1-b+b\\times l_d/avg\\_l)}\\times log_2\\frac{N-df+0.5}{df+0.5}$$公式中变量含义如下：\n\\(qtf\\)：查询中的词频 \\(tf\\)：文档中的词频 \\(l_d\\)：文档长度 \\(avg\\_l\\)：平均文档长度 \\(N\\)：文档数量 \\(df\\)：文档频率 \\(b,k_1,k_3\\)：可调参数 这个公式看起来很复杂，我们把它分解一下，其实很容易理解。第一个公式是外部公式，一个查询Q可能包含多个词项，比如“苹果手机”就包含“苹果”和“手机”两个词项，我们需要分别计算“苹果”和“手机”对某个文档d的贡献分数w(t,d)，然后将他们加起来就是整个文档d相对于查询Q的得分。\n第二个公式就是计算某个词项t在文档d中的得分，它包括三个部分。第一个部分是词项t在查询Q中的得分，比如查询“中国人说中国话”中“中国”出现了两次，此时qtf=2，说明这个查询希望找到的文档和“中国”更相关，“中国”的权重应该更大，但是通常情况下，查询Q都很短，而且不太可能包含相同的词项，所以这个因子是一个常数，我们在实现的时候可以忽略。\n第二部分类似于TFIDF模型中的TF项。也就是说某个词项t在文档d中出现次数越多，则t越重要，但是文档长度越长，tf也倾向于变大，所以使用文档长度除以平均长度\\(l_d/avg\\_l\\)起到某种归一化的效果，\\(k_1\\)和\\(b\\)是可调参数。\n第三部分类似于TFIDF模型中的IDF项。也就是说虽然“的”、“地”、“得”等停用词在某文档d中出现的次数很多，但是他们在很多文档中都出现过，所以这些词对d的贡献分并不高，接近于0；反而那些很稀有的词如”糖尿病“能够很好的区分不同文档，这些词对文档的贡献分应该较高。\n所以根据BM25公式，我们可以很快计算出不同文档t对查询Q的得分情况，然后按得分高低排序给出结果。\n下面是给定一个查询句子sentence，根据BM25公式给出文档排名的函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 def result_by_BM25(self, sentence): seg_list = jieba.lcut(sentence, cut_all=False) n, cleaned_dict = self.clean_list(seg_list) BM25_scores = {} for term in cleaned_dict.keys(): r = self.fetch_from_db(term) if r is None: continue df = r[1] w = math.log2((self.N - df + 0.5) / (df + 0.5)) docs = r[2].split(\u0026#39;\\n\u0026#39;) for doc in docs: docid, date_time, tf, ld = doc.split(\u0026#39;\\t\u0026#39;) docid = int(docid) tf = int(tf) ld = int(ld) s = (self.K1 * tf * w) / (tf + self.K1 * (1 - self.B + self.B * ld / self.AVG_L)) if docid in BM25_scores: BM25_scores[docid] = BM25_scores[docid] + s else: BM25_scores[docid] = s BM25_scores = sorted(BM25_scores.items(), key = operator.itemgetter(1)) BM25_scores.reverse() if len(BM25_scores) == 0: return 0, [] else: return 1, BM25_scores 首先将句子分词得到所有查询词项，然后从数据库中取出词项对应的倒排记录表，对记录表中的所有文档，计算其BM25得分，最后按得分高低排序作为查询结果。\n类似的，我们还可以对所有文档按时间先后顺序排序，越新鲜的新闻排名越高；还可以按新闻的热度排序，越热门的新闻排名越高。\n关于热度公式，我们认为一方面要兼顾相关度，另一方面也要考虑时间因素，所以是BM25打分和时间打分的一个综合。\n比较有名的热度公式有两个，一个是Hacker News的，另一个是Reddit的，他们的公式分别为：\n图1. hacker news ranking algorithm [1]\n图2. reddit ranking algorithm [2]\n可以看出，他们都是将新闻/评论的一个原始得分和时间组合起来，只是一个用除法，一个用加法。所以我们也依葫芦画瓢，”自创“了一个简单的热度公式：\n$$hot_{score}=k_1log(BM25_{score})+\\frac{k_2}{t_{now}-t_{news}}$$用BM25得分加上新闻时间和当前时间的差值的倒数，\\(k_1\\)和\\(k_2\\)也是可调参数。\n按时间排序和按热度排序的函数和按BM25打分排序的函数类似，这里就不贴出来了，详细情况可以看我的Github项目News_IR_Demo。\n至此，搜索引擎的搜索功能已经实现了，你可以试着修改./web/search_engine.py的第167行的关键词，看看搜索结果是否和你预想的排序是一样的。不过由于我们的数据量只有1000个新闻，并不能涵盖所有关键词，更多的测试可以留给大家线下完成。\n[1]. http://amix.dk/blog/post/19574\n[2]. http://amix.dk/blog/post/19588\n完整可运行的新闻搜索引擎Demo请看我的Github项目news_search_engine。\n以下是系列博客：\n和我一起构建搜索引擎（一）简介\n和我一起构建搜索引擎（二）网络爬虫\n和我一起构建搜索引擎（三）构建索引\n和我一起构建搜索引擎（四）检索模型\n和我一起构建搜索引擎（五）推荐阅读\n和我一起构建搜索引擎（六）系统展示\n和我一起构建搜索引擎（七）总结展望\n","permalink":"http://localhost:1313/posts/2016-01-07-introduction-to-building-a-search-engine-4/","summary":"\u003cp\u003e构建好倒排索引之后，就可以开始检索了。\u003c/p\u003e\n\u003cp\u003e检索模型有很多，比如向量空间模型、概率模型、语言模型等。其中最有名的、检索效果最好的是基于概率的BM25模型。\u003c/p\u003e\n\u003cp\u003e给定一个查询Q和一篇文档d，d对Q的BM25得分公式为\u003c/p\u003e\n$$BM25_{score}(Q,d)=\\sum_{t\\in Q}w(t,d)$$$$w(t,d)=\\frac{qtf}{k_3+qtf}\\times \\frac{k_1\\times tf}{tf+k_1(1-b+b\\times l_d/avg\\_l)}\\times log_2\\frac{N-df+0.5}{df+0.5}$$\u003cp\u003e公式中变量含义如下：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\\(qtf\\)：查询中的词频\u003c/li\u003e\n\u003cli\u003e\\(tf\\)：文档中的词频\u003c/li\u003e\n\u003cli\u003e\\(l_d\\)：文档长度\u003c/li\u003e\n\u003cli\u003e\\(avg\\_l\\)：平均文档长度\u003c/li\u003e\n\u003cli\u003e\\(N\\)：文档数量\u003c/li\u003e\n\u003cli\u003e\\(df\\)：文档频率\u003c/li\u003e\n\u003cli\u003e\\(b,k_1,k_3\\)：可调参数\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e这个公式看起来很复杂，我们把它分解一下，其实很容易理解。第一个公式是外部公式，一个查询Q可能包含多个词项，比如“苹果手机”就包含“苹果”和“手机”两个词项，我们需要分别计算“苹果”和“手机”对某个文档d的贡献分数w(t,d)，然后将他们加起来就是整个文档d相对于查询Q的得分。\u003c/p\u003e\n\u003cp\u003e第二个公式就是计算某个词项t在文档d中的得分，它包括三个部分。第一个部分是词项t在查询Q中的得分，比如查询“中国人说中国话”中“中国”出现了两次，此时qtf=2，说明这个查询希望找到的文档和“中国”\u003cstrong\u003e更\u003c/strong\u003e相关，“中国”的权重应该更大，但是通常情况下，查询Q都很短，而且不太可能包含相同的词项，所以这个因子是一个常数，我们在实现的时候可以忽略。\u003c/p\u003e\n\u003cp\u003e第二部分类似于\u003ca href=\"https://en.wikipedia.org/wiki/Tf%E2%80%93idf\"\u003eTFIDF模型\u003c/a\u003e中的TF项。也就是说某个词项t在文档d中出现次数越多，则t越重要，但是文档长度越长，tf也倾向于变大，所以使用文档长度除以平均长度\\(l_d/avg\\_l\\)起到某种归一化的效果，\\(k_1\\)和\\(b\\)是可调参数。\u003c/p\u003e\n\u003cp\u003e第三部分类似于\u003ca href=\"https://en.wikipedia.org/wiki/Tf%E2%80%93idf\"\u003eTFIDF模型\u003c/a\u003e中的IDF项。也就是说虽然“的”、“地”、“得”等停用词在某文档d中出现的次数很多，但是他们在很多文档中都出现过，所以这些词对d的贡献分并不高，接近于0；反而那些很稀有的词如”糖尿病“能够很好的区分不同文档，这些词对文档的贡献分应该较高。\u003c/p\u003e\n\u003cp\u003e所以根据BM25公式，我们可以很快计算出不同文档t对查询Q的得分情况，然后按得分高低排序给出结果。\u003c/p\u003e\n\u003cp\u003e下面是给定一个查询句子sentence，根据BM25公式给出文档排名的函数\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\n\u003ctable style=\"border-spacing:0;padding:0;margin:0;border:0;\"\u003e\u003ctr\u003e\u003ctd style=\"vertical-align:top;padding:0;margin:0;border:0;\"\u003e\n\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 1\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 2\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 3\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 4\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 5\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 6\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 7\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 8\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 9\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e10\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e11\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e12\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e13\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e14\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e15\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e16\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e17\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e18\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e19\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e20\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e21\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e22\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e23\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e24\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e25\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e26\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e27\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd style=\"vertical-align:top;padding:0;margin:0;border:0;;width:100%\"\u003e\n\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eresult_by_BM25\u003c/span\u003e(self, sentence):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\tseg_list \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e jieba\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003elcut(sentence, cut_all\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eFalse\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\tn, cleaned_dict \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eclean_list(seg_list)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\tBM25_scores \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e {}\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e term \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e cleaned_dict\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ekeys():\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\tr \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efetch_from_db(term)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\t\u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e r \u003cspan style=\"color:#f92672\"\u003eis\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eNone\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\t\t\u003cspan style=\"color:#66d9ef\"\u003econtinue\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\tdf \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e r[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\tw \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e math\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003elog2((self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eN \u003cspan style=\"color:#f92672\"\u003e-\u003c/span\u003e df \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0.5\u003c/span\u003e) \u003cspan style=\"color:#f92672\"\u003e/\u003c/span\u003e (df \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0.5\u003c/span\u003e))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\tdocs \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e r[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003esplit(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e\\n\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\t\u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e doc \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e docs:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\t\tdocid, date_time, tf, ld \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e doc\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003esplit(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e\\t\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\t\tdocid \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e int(docid)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\t\ttf \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e int(tf)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\t\tld \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e int(ld)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\t\ts \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e (self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eK1 \u003cspan style=\"color:#f92672\"\u003e*\u003c/span\u003e tf \u003cspan style=\"color:#f92672\"\u003e*\u003c/span\u003e w) \u003cspan style=\"color:#f92672\"\u003e/\u003c/span\u003e (tf \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eK1 \u003cspan style=\"color:#f92672\"\u003e*\u003c/span\u003e (\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e-\u003c/span\u003e self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eB \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eB \u003cspan style=\"color:#f92672\"\u003e*\u003c/span\u003e ld \u003cspan style=\"color:#f92672\"\u003e/\u003c/span\u003e self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eAVG_L))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\t\t\u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e docid \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e BM25_scores:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\t\t\tBM25_scores[docid] \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e BM25_scores[docid] \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e s\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\t\t\u003cspan style=\"color:#66d9ef\"\u003eelse\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\t\t\tBM25_scores[docid] \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e s\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\tBM25_scores \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e sorted(BM25_scores\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eitems(), key \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e operator\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eitemgetter(\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\tBM25_scores\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ereverse()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e len(BM25_scores) \u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\t\u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e, []\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\u003cspan style=\"color:#66d9ef\"\u003eelse\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\t\u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e, BM25_scores\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e首先将句子分词得到所有查询词项，然后从数据库中取出词项对应的倒排记录表，对记录表中的所有文档，计算其BM25得分，最后按得分高低排序作为查询结果。\u003c/p\u003e","title":"和我一起构建搜索引擎（四）检索模型"},{"content":"目前正是所谓的“大数据”时代，数据量多到难以计数，怎样结构化的存储以便于分析计算，是当前的一大难题。上一篇博客我们简单抓取了1000个搜狐新闻数据，搜索的过程就是从这1000个新闻中找出和关键词相关的新闻来，那么怎样快速搜索呢，总不可能依次打开xml文件一个字一个字的找吧，这时就需要借助倒排索引这个强大的数据结构。\n在讲倒排索引之前，我们先介绍一下布尔检索。布尔检索只是简单返回包含某个关键词的文档，比如查询“苹果手机”，则返回所有包含“苹果”和“手机”关键词的文档，布尔检索并不对返回结果排序，所以有可能返回的第一个文档是“某个男孩边吃苹果边玩手机…“。\n实现布尔检索并不难，我们需要构建一个如下图的词项文档矩阵：\n图1. 布尔检索中的词项文档矩阵\n每行对应一个词项，每列对应一个文档，如果该值为1，表示该行词项出现在该列文档中。比如词项”苹果“出现在doc1和doc3文档中，如果我们要找同时出现”苹果“和”手机“的文档，只需把他们对应的向量取出来进行”与“操作，此为101\u0026amp;011=001，所以doc3同时出现了”苹果“和”手机“两个关键词，我们将其返回。\n布尔检索虽然很快，但是它也有很多缺陷，比如不能对结果排序，词项只有出现和不出现两种状态，但是一篇文档中出现10次“苹果“和只出现1次”苹果“，他们的相关度肯定是不相同的。所以需要对布尔检索进行改进。\n在扫描文档时，不但记录某词项出现与否，还记录该词项出现的次数，即词项频率(tf)；同时我们记录该文档的长度(ld)，以及某词项在不同文档中出现的次数，即文档频率(df)。\n图2. 倒排索引结构图\n这样我们就得到了如上图的倒排索引。左边部分被称为词典，存储的是1000个新闻中所有不同的词项；右边部分被称为倒排记录表，存储的是出现Term_i的那些文档信息。倒排索引中存储的变量都是为了给后续检索模型使用。\n讲到这里，我们需要解决如下几个问题。\n怎样得到一篇文档中的所有词项。给我们一篇新闻稿子，人类很容易分辨出”苹果“和”手机“是两个不同的词项，但是计算机怎么知道是这两个词呢？为什么不是”苹”、”国手“和”机“呢？这就需要进行中文分词，我们可以借助开源的jieba中文分词组件来完成，jieba分词能够将一个中文句子切成一个个词项，这样我们就可以统计tf, df了。 有些词，如”的“、”地“、”得“、”如果“等，几乎每篇文档都会出现，他们起不到很好的区分文档的效果，这类词被称为”停用词“，我们需要把他们去掉。去停词的步骤可以在jieba分词之后完成。 怎样存储倒排记录表。假设1000个文档共有20000个不同的词项，如果用类似图1的矩阵形式存储，需要耗费100020000=210^7个存储单元，但是图1往往是一个稀疏矩阵，因为一个文档中可能只出现了200个不同的词项，剩余的19800个词项都是空的。用矩阵方式存储时空效率都不高。所以我们可以采用图2的方式，词典用B-树或hash存储，倒排记录表用邻接链表存储方式，这样能大大减少存储空间。如果我们要将图2保存到数据库，可以对倒排记录表序列化成一个长的字符串，写入到一个单元格，读取的时候再反序列化。比如每个Doc内部用’\\t’连接，Doc之间用’\\n’连接，读取的时候split即可。 倒排索引构建算法使用内存式单遍扫描索引构建方法（SPIMI），其实就是依次对每篇新闻进行分词，如果出现新的词项则插入到词典中，否则将该文档的信息追加到词项对应的倒排记录表中。SPIMI的伪代码如下：\n图3. SPIMI算法伪代码\n下面是构建索引的所有代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 # -*- coding: utf-8 -*- \u0026#34;\u0026#34;\u0026#34; Created on Sat Dec 5 23:31:22 2015 @author: bitjoy.net \u0026#34;\u0026#34;\u0026#34; from os import listdir import xml.etree.ElementTree as ET import jieba import sqlite3 import configparser class Doc: docid = 0 date_time = \u0026#39;\u0026#39; tf = 0 ld = 0 def __init__(self, docid, date_time, tf, ld): self.docid = docid self.date_time = date_time self.tf = tf self.ld = ld def __repr__(self): return(str(self.docid) + \u0026#39;\\t\u0026#39; + self.date_time + \u0026#39;\\t\u0026#39; + str(self.tf) + \u0026#39;\\t\u0026#39; + str(self.ld)) def __str__(self): return(str(self.docid) + \u0026#39;\\t\u0026#39; + self.date_time + \u0026#39;\\t\u0026#39; + str(self.tf) + \u0026#39;\\t\u0026#39; + str(self.ld)) class IndexModule: stop_words = set() postings_lists = {} config_path = \u0026#39;\u0026#39; config_encoding = \u0026#39;\u0026#39; def __init__(self, config_path, config_encoding): self.config_path = config_path self.config_encoding = config_encoding config = configparser.ConfigParser() config.read(config_path, config_encoding) f = open(config[\u0026#39;DEFAULT\u0026#39;][\u0026#39;stop_words_path\u0026#39;], encoding = config[\u0026#39;DEFAULT\u0026#39;][\u0026#39;stop_words_encoding\u0026#39;]) words = f.read() self.stop_words = set(words.split(\u0026#39;\\n\u0026#39;)) def is_number(self, s): try: float(s) return True except ValueError: return False def clean_list(self, seg_list): cleaned_dict = {} n = 0 for i in seg_list: i = i.strip().lower() if i != \u0026#39;\u0026#39; and not self.is_number(i) and i not in self.stop_words: n = n + 1 if i in cleaned_dict: cleaned_dict[i] = cleaned_dict[i] + 1 else: cleaned_dict[i] = 1 return n, cleaned_dict def write_postings_to_db(self, db_path): conn = sqlite3.connect(db_path) c = conn.cursor() c.execute(\u0026#34;\u0026#39;DROP TABLE IF EXISTS postings\u0026#39;\u0026#34;) c.execute(\u0026#34;\u0026#39;CREATE TABLE postings(term TEXT PRIMARY KEY, df INTEGER, docs TEXT)\u0026#39;\u0026#34;) for key, value in self.postings_lists.items(): doc_list = \u0026#39;\\n\u0026#39;.join(map(str,value[1])) t = (key, value[0], doc_list) c.execute(\u0026#34;INSERT INTO postings VALUES (?, ?, ?)\u0026#34;, t) conn.commit() conn.close() def construct_postings_lists(self): config = configparser.ConfigParser() config.read(self.config_path, self.config_encoding) files = listdir(config[\u0026#39;DEFAULT\u0026#39;][\u0026#39;doc_dir_path\u0026#39;]) AVG_L = 0 for i in files: root = ET.parse(config[\u0026#39;DEFAULT\u0026#39;][\u0026#39;doc_dir_path\u0026#39;] + i).getroot() title = root.find(\u0026#39;title\u0026#39;).text body = root.find(\u0026#39;body\u0026#39;).text docid = int(root.find(\u0026#39;id\u0026#39;).text) date_time = root.find(\u0026#39;datetime\u0026#39;).text seg_list = jieba.lcut(title + \u0026#39;。\u0026#39; + body, cut_all=False) ld, cleaned_dict = self.clean_list(seg_list) AVG_L = AVG_L + ld for key, value in cleaned_dict.items(): d = Doc(docid, date_time, value, ld) if key in self.postings_lists: self.postings_lists[key][0] = self.postings_lists[key][0] + 1 # df++ self.postings_lists[key][1].append(d) else: self.postings_lists[key] = [1, [d]] # [df, [Doc]] AVG_L = AVG_L / len(files) config.set(\u0026#39;DEFAULT\u0026#39;, \u0026#39;N\u0026#39;, str(len(files))) config.set(\u0026#39;DEFAULT\u0026#39;, \u0026#39;avg_l\u0026#39;, str(AVG_L)) with open(self.config_path, ‘w’, encoding = self.config_encoding) as configfile: config.write(configfile) self.write_postings_to_db(config[‘DEFAULT’][‘db_path’]) if __name__ == \u0026#34;__main__\u0026#34;: im = IndexModule(\u0026#39;../config.ini\u0026#39;, \u0026#39;utf-8\u0026#39;) im.construct_postings_lists() 运行之后会在./data/下生成一个ir.db数据库文件，这就是构建好的索引数据库。\n完整可运行的新闻搜索引擎Demo请看我的Github项目news_search_engine。\n以下是系列博客：\n和我一起构建搜索引擎（一）简介\n和我一起构建搜索引擎（二）网络爬虫\n和我一起构建搜索引擎（三）构建索引\n和我一起构建搜索引擎（四）检索模型\n和我一起构建搜索引擎（五）推荐阅读\n和我一起构建搜索引擎（六）系统展示\n和我一起构建搜索引擎（七）总结展望\n","permalink":"http://localhost:1313/posts/2016-01-07-introduction-to-building-a-search-engine-3/","summary":"\u003cp\u003e目前正是所谓的“大数据”时代，数据量多到难以计数，怎样结构化的存储以便于分析计算，是当前的一大难题。上一篇博客我们简单抓取了1000个搜狐新闻数据，搜索的过程就是从这1000个新闻中找出和关键词相关的新闻来，那么怎样快速搜索呢，总不可能依次打开xml文件一个字一个字的找吧，这时就需要借助倒排索引这个强大的数据结构。\u003c/p\u003e\n\u003cp\u003e在讲倒排索引之前，我们先介绍一下布尔检索。布尔检索只是简单返回包含某个关键词的文档，比如查询“苹果手机”，则返回所有包含“苹果”和“手机”关键词的文档，布尔检索并不对返回结果排序，所以有可能返回的第一个文档是“某个男孩边吃苹果边玩手机…“。\u003c/p\u003e\n\u003cp\u003e实现布尔检索并不难，我们需要构建一个如下图的词项文档矩阵：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"图1. 布尔检索中的词项文档矩阵\" loading=\"lazy\" src=\"/posts/2016-01-07-introduction-to-building-a-search-engine-3/td_matrix.png\"\u003e\n图1. 布尔检索中的词项文档矩阵\u003c/p\u003e\n\u003cp\u003e每行对应一个词项，每列对应一个文档，如果该值为1，表示该行词项出现在该列文档中。比如词项”苹果“出现在doc1和doc3文档中，如果我们要找同时出现”苹果“和”手机“的文档，只需把他们对应的向量取出来进行”与“操作，此为101\u0026amp;011=001，所以doc3同时出现了”苹果“和”手机“两个关键词，我们将其返回。\u003c/p\u003e\n\u003cp\u003e布尔检索虽然很快，但是它也有很多缺陷，比如不能对结果排序，词项只有出现和不出现两种状态，但是一篇文档中出现10次“苹果“和只出现1次”苹果“，他们的相关度肯定是不相同的。所以需要对布尔检索进行改进。\u003c/p\u003e\n\u003cp\u003e在扫描文档时，不但记录某词项出现与否，还记录该词项出现的次数，即词项频率(tf)；同时我们记录该文档的长度(ld)，以及某词项在不同文档中出现的次数，即文档频率(df)。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"图2. 倒排索引结构图\" loading=\"lazy\" src=\"/posts/2016-01-07-introduction-to-building-a-search-engine-3/inverted-index.png\"\u003e\n图2. 倒排索引结构图\u003c/p\u003e\n\u003cp\u003e这样我们就得到了如上图的倒排索引。左边部分被称为词典，存储的是1000个新闻中所有不同的词项；右边部分被称为倒排记录表，存储的是出现Term_i的那些文档信息。倒排索引中存储的变量都是为了给后续检索模型使用。\u003c/p\u003e\n\u003cp\u003e讲到这里，我们需要解决如下几个问题。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e怎样得到一篇文档中的所有词项。给我们一篇新闻稿子，人类很容易分辨出”苹果“和”手机“是两个不同的词项，但是计算机怎么知道是这两个词呢？为什么不是”苹”、”国手“和”机“呢？这就需要进行中文分词，我们可以借助开源的\u003ca href=\"https://github.com/fxsjy/jieba\"\u003ejieba中文分词组件\u003c/a\u003e来完成，jieba分词能够将一个中文句子切成一个个词项，这样我们就可以统计tf, df了。\u003c/li\u003e\n\u003cli\u003e有些词，如”的“、”地“、”得“、”如果“等，几乎每篇文档都会出现，他们起不到很好的区分文档的效果，这类词被称为”停用词“，我们需要把他们去掉。去停词的步骤可以在jieba分词之后完成。\u003c/li\u003e\n\u003cli\u003e怎样存储倒排记录表。假设1000个文档共有20000个不同的词项，如果用类似图1的矩阵形式存储，需要耗费1000\u003cem\u003e20000=2\u003c/em\u003e10^7个存储单元，但是图1往往是一个稀疏矩阵，因为一个文档中可能只出现了200个不同的词项，剩余的19800个词项都是空的。用矩阵方式存储时空效率都不高。所以我们可以采用图2的方式，词典用B-树或hash存储，倒排记录表用邻接链表存储方式，这样能大大减少存储空间。如果我们要将图2保存到数据库，可以对倒排记录表序列化成一个长的字符串，写入到一个单元格，读取的时候再反序列化。比如每个Doc内部用’\\t’连接，Doc之间用’\\n’连接，读取的时候split即可。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e倒排索引构建算法使用内存式单遍扫描索引构建方法（SPIMI），其实就是依次对每篇新闻进行分词，如果出现新的词项则插入到词典中，否则将该文档的信息追加到词项对应的倒排记录表中。SPIMI的伪代码如下：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"图3. SPIMI算法伪代码\" loading=\"lazy\" src=\"/posts/2016-01-07-introduction-to-building-a-search-engine-3/SPIMI-algo.png\"\u003e\n图3. SPIMI算法伪代码\u003c/p\u003e\n\u003cp\u003e下面是构建索引的所有代码：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\n\u003ctable style=\"border-spacing:0;padding:0;margin:0;border:0;\"\u003e\u003ctr\u003e\u003ctd style=\"vertical-align:top;padding:0;margin:0;border:0;\"\u003e\n\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e  1\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e  2\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e  3\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e  4\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e  5\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e  6\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e  7\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e  8\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e  9\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 10\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 11\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 12\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 13\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 14\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 15\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 16\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 17\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 18\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 19\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 20\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 21\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 22\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 23\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 24\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 25\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 26\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 27\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 28\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 29\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 30\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 31\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 32\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 33\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 34\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 35\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 36\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 37\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 38\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 39\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 40\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 41\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 42\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 43\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 44\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 45\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 46\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 47\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 48\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 49\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 50\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 51\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 52\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 53\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 54\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 55\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 56\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 57\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 58\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 59\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 60\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 61\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 62\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 63\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 64\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 65\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 66\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 67\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 68\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 69\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 70\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 71\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 72\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 73\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 74\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 75\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 76\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 77\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 78\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 79\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 80\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 81\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 82\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 83\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 84\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 85\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 86\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 87\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 88\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 89\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 90\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 91\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 92\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 93\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 94\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 95\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 96\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 97\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 98\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 99\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e100\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e101\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e102\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e103\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e104\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e105\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e106\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e107\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e108\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e109\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e110\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e111\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e112\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e113\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e114\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd style=\"vertical-align:top;padding:0;margin:0;border:0;;width:100%\"\u003e\n\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# -*- coding: utf-8 -*-\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u0026#34;\u0026#34;\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003eCreated on Sat Dec 5 23:31:22 2015\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e@author: bitjoy.net\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u0026#34;\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e os \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e listdir\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e xml.etree.ElementTree \u003cspan style=\"color:#66d9ef\"\u003eas\u003c/span\u003e ET\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e jieba\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e sqlite3\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e configparser\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eclass\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eDoc\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    docid \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    date_time \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    tf \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    ld \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003e__init__\u003c/span\u003e(self, docid, date_time, tf, ld):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003edocid \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e docid\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003edate_time \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e date_time\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etf \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e tf\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eld \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e ld\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003e__repr__\u003c/span\u003e(self):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e(str(self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003edocid) \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e\\t\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003edate_time \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e\\t\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e str(self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etf) \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e\\t\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e str(self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eld))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003e__str__\u003c/span\u003e(self):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e(str(self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003edocid) \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e\\t\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003edate_time \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e\\t\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e str(self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etf) \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e\\t\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e str(self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eld))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eclass\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eIndexModule\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    stop_words \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e set()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    postings_lists \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e {}\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    config_path \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    config_encoding \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003e__init__\u003c/span\u003e(self, config_path, config_encoding):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003econfig_path \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e config_path\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003econfig_encoding \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e config_encoding\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        config \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e configparser\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eConfigParser()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eread(config_path, config_encoding)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        f \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e open(config[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;DEFAULT\u0026#39;\u003c/span\u003e][\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;stop_words_path\u0026#39;\u003c/span\u003e], encoding \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e config[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;DEFAULT\u0026#39;\u003c/span\u003e][\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;stop_words_encoding\u0026#39;\u003c/span\u003e])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        words \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eread()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003estop_words \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e set(words\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003esplit(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e\\n\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eis_number\u003c/span\u003e(self, s):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003etry\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            float(s)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eTrue\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003eexcept\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eValueError\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eFalse\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eclean_list\u003c/span\u003e(self, seg_list):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        cleaned_dict \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e {}\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        n \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e i \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e seg_list:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            i \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e i\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003estrip()\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003elower()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e i \u003cspan style=\"color:#f92672\"\u003e!=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u0026#39;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003eand\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003enot\u003c/span\u003e self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eis_number(i) \u003cspan style=\"color:#f92672\"\u003eand\u003c/span\u003e i \u003cspan style=\"color:#f92672\"\u003enot\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003estop_words:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                n \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e n \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e i \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e cleaned_dict:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                cleaned_dict[i] \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e cleaned_dict[i] \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            \u003cspan style=\"color:#66d9ef\"\u003eelse\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                cleaned_dict[i] \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e n, cleaned_dict\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ewrite_postings_to_db\u003c/span\u003e(self, db_path):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        conn \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e sqlite3\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003econnect(db_path)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        c \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e conn\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ecursor()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        c\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eexecute(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u0026#39;DROP TABLE IF EXISTS postings\u0026#39;\u0026#34;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        c\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eexecute(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u0026#39;CREATE TABLE postings(term TEXT PRIMARY KEY, df INTEGER, docs TEXT)\u0026#39;\u0026#34;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e key, value \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003epostings_lists\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eitems():\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            doc_list \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e\\n\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ejoin(map(str,value[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            t \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e (key, value[\u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e], doc_list)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            c\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eexecute(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;INSERT INTO postings VALUES (?, ?, ?)\u0026#34;\u003c/span\u003e, t)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        conn\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ecommit()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        conn\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eclose()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003econstruct_postings_lists\u003c/span\u003e(self):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        config \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e configparser\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eConfigParser()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eread(self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003econfig_path, self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003econfig_encoding)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        files \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e listdir(config[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;DEFAULT\u0026#39;\u003c/span\u003e][\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;doc_dir_path\u0026#39;\u003c/span\u003e])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        AVG_L \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e i \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e files:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            root \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e ET\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eparse(config[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;DEFAULT\u0026#39;\u003c/span\u003e][\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;doc_dir_path\u0026#39;\u003c/span\u003e] \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e i)\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003egetroot()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            title \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e root\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efind(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;title\u0026#39;\u003c/span\u003e)\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etext\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            body \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e root\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efind(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;body\u0026#39;\u003c/span\u003e)\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etext\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            docid \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e int(root\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efind(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;id\u0026#39;\u003c/span\u003e)\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etext)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            date_time \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e root\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efind(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;datetime\u0026#39;\u003c/span\u003e)\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etext\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            seg_list \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e jieba\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003elcut(title \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;。\u0026#39;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e body, cut_all\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eFalse\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            ld, cleaned_dict \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eclean_list(seg_list)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            AVG_L \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e AVG_L \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e ld\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e key, value \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e cleaned_dict\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eitems():\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                d \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e Doc(docid, date_time, value, ld)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e key \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003epostings_lists:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                    self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003epostings_lists[key][\u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e] \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003epostings_lists[key][\u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e] \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e \u003cspan style=\"color:#75715e\"\u003e# df++\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                    self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003epostings_lists[key][\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eappend(d)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                \u003cspan style=\"color:#66d9ef\"\u003eelse\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                    self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003epostings_lists[key] \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e, [d]] \u003cspan style=\"color:#75715e\"\u003e# [df, [Doc]]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                    AVG_L \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e AVG_L \u003cspan style=\"color:#f92672\"\u003e/\u003c/span\u003e len(files)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                    config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eset(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;DEFAULT\u0026#39;\u003c/span\u003e, \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;N\u0026#39;\u003c/span\u003e, str(len(files)))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                    config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eset(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;DEFAULT\u0026#39;\u003c/span\u003e, \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;avg_l\u0026#39;\u003c/span\u003e, str(AVG_L))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003ewith\u003c/span\u003e open(self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003econfig_path, \u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e‘\u003c/span\u003ew\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e’\u003c/span\u003e, encoding \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003econfig_encoding) \u003cspan style=\"color:#66d9ef\"\u003eas\u003c/span\u003e configfile:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ewrite(configfile)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ewrite_postings_to_db(config[\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e‘\u003c/span\u003eDEFAULT\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e’\u003c/span\u003e][\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e‘\u003c/span\u003edb_path\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e’\u003c/span\u003e])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e __name__ \u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;__main__\u0026#34;\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    im \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e IndexModule(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;../config.ini\u0026#39;\u003c/span\u003e, \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;utf-8\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    im\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003econstruct_postings_lists()\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e运行之后会在./data/下生成一个ir.db数据库文件，这就是构建好的索引数据库。\u003c/p\u003e","title":"和我一起构建搜索引擎（三）构建索引"},{"content":"网络爬虫又称网络蜘蛛、Web采集器等，它是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本。\n我们在设计网络爬虫的时候需要注意两点：\n鲁棒性。Web中有些服务器会制造采集器陷阱（spider traps），这些陷阱服务器实际上是Web页面的生成器，它能在某个域下生成无数网页，从而使采集器陷入到一个无限的采集循环中去。采集器必须能从这些陷阱中跳出来。当然，这些陷阱倒不一定都是恶意的，有时可能是网站设计疏忽所导致的结果。\n礼貌性。Web服务器具有一些隐式或显式的政策来控制采集器访问它们的频率。设计采集器时必须要遵守这些代表礼貌性的访问政策。\n采集器的基本架构如下图所示。\n基本上是“抓取→分析→得到新的URL→再抓取→再分析”这样一个死循环过程。\n以上内容摘自王斌老师翻译的《信息检索导论》课本。\n由于我们要做的是一个新闻搜索引擎，所以抓取的是新闻数据，对于爬虫，网上也有很多的开源程序，如nutch等，Github上还有人专门开发了抓取新闻的组件newspaper，可以很方便的提取新闻标题、正文、时间等信息。不过用python写爬虫也是分分钟的事情，下面我们一起来试一试。\n首先找一个新闻网站，为简单起见，要找那种结构清晰、html代码便于解析的门户网站，比如搜狐新闻、参考消息等。\n搜狐新闻的国内要闻列表如下：\n结构非常清楚，左边是带URL的标题，右边括号里有新闻时间。这一页列表就有200条新闻，如果我们要获取1000条，只要不断模拟点击下一页即可。下一页的URL也只是在首页的基础上加上_xxx.shtml，xxx就是不同的页码。\n查看列表的html源码，得知列表都在类名为newsblue1的td中，所以只需要解析html源码就可以得到新闻标题、URL和时间，python解析html可以用BeautifulSoup包，非常方便。\n进入到新闻详细页面，正文部分如下：\n查看html源码，正文位于类名为text clear的div中，据此可以很方便的提取新闻正文。\n得到一条新闻的所有数据之后，我们需要将之结构化成xml文件，借助相应的xml包可以很方便的完成这项工作。xml格式定义如下：\n注意爬虫需要访问网络，难免会出现一些异常，所以捕获异常是非常有必要的。另外，搜狐每篇新闻正文后面都会有一段’//’开始的注释，这个需要过滤掉，短于140个字的新闻我也过滤掉了。整个搜索系统的配置参数都存储在config.ini文件中。\n下面是完整的python 3.4+代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 # -*- coding: utf-8 -*- \u0026#34;\u0026#34;\u0026#34; Created on Sat Dec 19 11:57:01 2015 @author: bitjoy.net \u0026#34;\u0026#34;\u0026#34; from bs4 import BeautifulSoup import urllib.request import xml.etree.ElementTree as ET import configparser def get_news_pool(root, start, end): news_pool = [] for i in range(start,end,-1): page_url = \u0026#39;\u0026#39; if i != start: page_url = root +\u0026#39;_%d.shtml\u0026#39;%(i) else: page_url = root + \u0026#39;.shtml\u0026#39; try: response = urllib.request.urlopen(page_url) except Exception as e: print(\u0026#34;—–%s: %s—–\u0026#34;%(type(e), page_url)) continue html = response.read() soup = BeautifulSoup(html) td = soup.find(\u0026#39;td\u0026#39;, class_ = \u0026#34;newsblue1\u0026#34;) a = td.find_all(\u0026#39;a\u0026#39;) span = td.find_all(\u0026#39;span\u0026#39;) for i in range(len(a)): date_time = span[i].string url = a[i].get(\u0026#39;href\u0026#39;) title = a[i].string news_info = [\u0026#39;2016-\u0026#39;+date_time[1:3]+\u0026#39;-\u0026#39;+date_time[4:-1]+\u0026#39;:00\u0026#39;,url,title] news_pool.append(news_info) return(news_pool) def crawl_news(news_pool, min_body_len, doc_dir_path, doc_encoding): i = 1 for news in news_pool: try: response = urllib.request.urlopen(news[1]) except Exception as e: print(\u0026#34;—–%s: %s—–\u0026#34;%(type(e), news[1])) continue html = response.read() soup = BeautifulSoup(html) try: body = soup.find(\u0026#39;div\u0026#39;, class_ = \u0026#34;text clear\u0026#34;).find(\u0026#39;div\u0026#39;).get_text() except Exception as e: print(\u0026#34;—–%s: %s—–\u0026#34;%(type(e), news[1])) continue if \u0026#39;//\u0026#39; in body: body = body[:body.index(\u0026#39;//\u0026#39;)] body = body.replace(\u0026#34; \u0026#34;, \u0026#34;\u0026#34;) if len(body) \u0026lt;= min_body_len: continue doc = ET.Element(\u0026#34;doc\u0026#34;) ET.SubElement(doc, \u0026#34;id\u0026#34;).text = \u0026#34;%d\u0026#34;%(i) ET.SubElement(doc, \u0026#34;url\u0026#34;).text = news[1] ET.SubElement(doc, \u0026#34;title\u0026#34;).text = news[2] ET.SubElement(doc, \u0026#34;datetime\u0026#34;).text = news[0] ET.SubElement(doc, \u0026#34;body\u0026#34;).text = body tree = ET.ElementTree(doc) tree.write(doc_dir_path + \u0026#34;%d.xml\u0026#34;%(i), encoding = doc_encoding, xml_declaration = True) i += 1 if __name__ == \u0026#39;__main__\u0026#39;: config = configparser.ConfigParser() config.read(\u0026#39;../config.ini\u0026#39;, \u0026#39;utf-8\u0026#39;) root = \u0026#39;http://news.sohu.com/1/0903/61/subject212846158\u0026#39; news_pool = get_news_pool(root, 854, 849) crawl_news(news_pool, 140, config[\u0026#39;DEFAULT\u0026#39;][\u0026#39;doc_dir_path\u0026#39;], config[\u0026#39;DEFAULT\u0026#39;][\u0026#39;doc_encoding\u0026#39;]) print(\u0026#39;done!\u0026#39;) 完整可运行的新闻搜索引擎Demo请看我的Github项目news_search_engine。\n以下是系列博客：\n和我一起构建搜索引擎（一）简介\n和我一起构建搜索引擎（二）网络爬虫\n和我一起构建搜索引擎（三）构建索引\n和我一起构建搜索引擎（四）检索模型\n和我一起构建搜索引擎（五）推荐阅读\n和我一起构建搜索引擎（六）系统展示\n和我一起构建搜索引擎（七）总结展望\n","permalink":"http://localhost:1313/posts/2016-01-04-introduction-to-building-a-search-engine-2/","summary":"\u003cp\u003e网络爬虫又称网络蜘蛛、Web采集器等，它是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本。\u003c/p\u003e\n\u003cp\u003e我们在设计网络爬虫的时候需要注意两点：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e鲁棒性\u003c/strong\u003e。Web中有些服务器会制造采集器陷阱（spider traps），这些陷阱服务器实际上是Web页面的生成器，它能在某个域下生成无数网页，从而使采集器陷入到一个无限的采集循环中去。采集器必须能从这些陷阱中跳出来。当然，这些陷阱倒不一定都是恶意的，有时可能是网站设计疏忽所导致的结果。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e礼貌性\u003c/strong\u003e。Web服务器具有一些隐式或显式的政策来控制采集器访问它们的频率。设计采集器时必须要遵守这些代表礼貌性的访问政策。\u003c/p\u003e\n\u003cp\u003e采集器的基本架构如下图所示。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"the basic crawler architecture\" loading=\"lazy\" src=\"/posts/2016-01-04-introduction-to-building-a-search-engine-2/the-basic-crawler-architecture.png\"\u003e\u003c/p\u003e\n\u003cp\u003e基本上是“抓取→分析→得到新的URL→再抓取→再分析”这样一个死循环过程。\u003c/p\u003e\n\u003cp\u003e以上内容摘自王斌老师翻译的《信息检索导论》课本。\u003c/p\u003e\n\u003cp\u003e由于我们要做的是一个新闻搜索引擎，所以抓取的是新闻数据，对于爬虫，网上也有很多的开源程序，如nutch等，Github上还有人专门开发了抓取新闻的组件\u003ca href=\"https://github.com/codelucas/newspaper\"\u003enewspaper\u003c/a\u003e，可以很方便的提取新闻标题、正文、时间等信息。不过用python写爬虫也是分分钟的事情，下面我们一起来试一试。\u003c/p\u003e\n\u003cp\u003e首先找一个新闻网站，为简单起见，要找那种结构清晰、html代码便于解析的门户网站，比如\u003ca href=\"http://news.sohu.com/1/0903/61/subject212846158.shtml\"\u003e搜狐新闻\u003c/a\u003e、\u003ca href=\"http://www.cankaoxiaoxi.com/china/szyw/\"\u003e参考消息\u003c/a\u003e等。\u003c/p\u003e\n\u003cp\u003e搜狐新闻的国内要闻列表如下：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"sohu news1\" loading=\"lazy\" src=\"/posts/2016-01-04-introduction-to-building-a-search-engine-2/sohu-news1.png\"\u003e\u003c/p\u003e\n\u003cp\u003e结构非常清楚，左边是带URL的标题，右边括号里有新闻时间。这一页列表就有200条新闻，如果我们要获取1000条，只要不断模拟点击下一页即可。下一页的URL也只是在首页的基础上加上_xxx.shtml，xxx就是不同的页码。\u003c/p\u003e\n\u003cp\u003e查看列表的html源码，得知列表都在类名为newsblue1的td中，所以只需要解析html源码就可以得到新闻标题、URL和时间，python解析html可以用BeautifulSoup包，非常方便。\u003c/p\u003e\n\u003cp\u003e进入到新闻详细页面，正文部分如下：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"sohu news2\" loading=\"lazy\" src=\"/posts/2016-01-04-introduction-to-building-a-search-engine-2/sohu-news2.png\"\u003e\u003c/p\u003e\n\u003cp\u003e查看html源码，正文位于类名为text clear的div中，据此可以很方便的提取新闻正文。\u003c/p\u003e\n\u003cp\u003e得到一条新闻的所有数据之后，我们需要将之结构化成xml文件，借助相应的xml包可以很方便的完成这项工作。xml格式定义如下：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"xml format\" loading=\"lazy\" src=\"/posts/2016-01-04-introduction-to-building-a-search-engine-2/xml-format.png\"\u003e\u003c/p\u003e\n\u003cp\u003e注意爬虫需要访问网络，难免会出现一些异常，所以捕获异常是非常有必要的。另外，搜狐每篇新闻正文后面都会有一段’//’开始的注释，这个需要过滤掉，短于140个字的新闻我也过滤掉了。整个搜索系统的配置参数都存储在config.ini文件中。\u003c/p\u003e\n\u003cp\u003e下面是完整的python 3.4+代码。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\n\u003ctable style=\"border-spacing:0;padding:0;margin:0;border:0;\"\u003e\u003ctr\u003e\u003ctd style=\"vertical-align:top;padding:0;margin:0;border:0;\"\u003e\n\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 1\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 2\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 3\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 4\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 5\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 6\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 7\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 8\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 9\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e10\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e11\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e12\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e13\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e14\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e15\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e16\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e17\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e18\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e19\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e20\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e21\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e22\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e23\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e24\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e25\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e26\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e27\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e28\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e29\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e30\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e31\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e32\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e33\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e34\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e35\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e36\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e37\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e38\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e39\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e40\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e41\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e42\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e43\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e44\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e45\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e46\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e47\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e48\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e49\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e50\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e51\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e52\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e53\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e54\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e55\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e56\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e57\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e58\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e59\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e60\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e61\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e62\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e63\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e64\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e65\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e66\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e67\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e68\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e69\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e70\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e71\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e72\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e73\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e74\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e75\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd style=\"vertical-align:top;padding:0;margin:0;border:0;;width:100%\"\u003e\n\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# -*- coding: utf-8 -*-\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u0026#34;\u0026#34;\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003eCreated on Sat Dec 19 11:57:01 2015\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e@author: bitjoy.net\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u0026#34;\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e bs4 \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e BeautifulSoup\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e urllib.request\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e xml.etree.ElementTree \u003cspan style=\"color:#66d9ef\"\u003eas\u003c/span\u003e ET\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e configparser\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eget_news_pool\u003c/span\u003e(root, start, end):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    news_pool \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e []\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e i \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e range(start,end,\u003cspan style=\"color:#f92672\"\u003e-\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        page_url \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e i \u003cspan style=\"color:#f92672\"\u003e!=\u003c/span\u003e start:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            page_url \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e root \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;_\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e%d\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e.shtml\u0026#39;\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e%\u003c/span\u003e(i)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003eelse\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            page_url \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e root \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;.shtml\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003etry\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            response \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e urllib\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003erequest\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eurlopen(page_url)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003eexcept\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eException\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eas\u003c/span\u003e e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            print(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;—–\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e%s\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e: \u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e%s\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e—–\u0026#34;\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e%\u003c/span\u003e(type(e), page_url))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            \u003cspan style=\"color:#66d9ef\"\u003econtinue\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        html \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e response\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eread()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        soup \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e BeautifulSoup(html)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        td \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e soup\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efind(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;td\u0026#39;\u003c/span\u003e, class_ \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;newsblue1\u0026#34;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        a \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e td\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efind_all(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;a\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        span \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e td\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efind_all(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;span\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e i \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e range(len(a)):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            date_time \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e span[i]\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003estring\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            url \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e a[i]\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eget(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;href\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            title \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e a[i]\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003estring\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            news_info \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;2016-\u0026#39;\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003edate_time[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e:\u003cspan style=\"color:#ae81ff\"\u003e3\u003c/span\u003e]\u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;-\u0026#39;\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003edate_time[\u003cspan style=\"color:#ae81ff\"\u003e4\u003c/span\u003e:\u003cspan style=\"color:#f92672\"\u003e-\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]\u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;:00\u0026#39;\u003c/span\u003e,url,title]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            news_pool\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eappend(news_info)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e(news_pool)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ecrawl_news\u003c/span\u003e(news_pool, min_body_len, doc_dir_path, doc_encoding):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    i \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e news \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e news_pool:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003etry\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            response \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e urllib\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003erequest\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eurlopen(news[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003eexcept\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eException\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eas\u003c/span\u003e e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            print(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;—–\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e%s\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e: \u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e%s\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e—–\u0026#34;\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e%\u003c/span\u003e(type(e), news[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            \u003cspan style=\"color:#66d9ef\"\u003econtinue\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        html \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e response\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eread()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        soup \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e BeautifulSoup(html)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003etry\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            body \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e soup\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efind(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;div\u0026#39;\u003c/span\u003e, class_ \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;text clear\u0026#34;\u003c/span\u003e)\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efind(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;div\u0026#39;\u003c/span\u003e)\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eget_text()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003eexcept\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eException\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eas\u003c/span\u003e e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            print(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;—–\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e%s\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e: \u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e%s\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e—–\u0026#34;\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e%\u003c/span\u003e(type(e), news[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            \u003cspan style=\"color:#66d9ef\"\u003econtinue\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;//\u0026#39;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e body:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            body \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e body[:body\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eindex(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;//\u0026#39;\u003c/span\u003e)]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            body \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e body\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ereplace(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34; \u0026#34;\u003c/span\u003e, \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u0026#34;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e len(body) \u003cspan style=\"color:#f92672\"\u003e\u0026lt;=\u003c/span\u003e min_body_len:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            \u003cspan style=\"color:#66d9ef\"\u003econtinue\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        doc \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e ET\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eElement(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;doc\u0026#34;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        ET\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eSubElement(doc, \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;id\u0026#34;\u003c/span\u003e)\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etext \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e%d\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e%\u003c/span\u003e(i)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        ET\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eSubElement(doc, \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;url\u0026#34;\u003c/span\u003e)\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etext \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e news[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        ET\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eSubElement(doc, \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;title\u0026#34;\u003c/span\u003e)\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etext \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e news[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        ET\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eSubElement(doc, \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;datetime\u0026#34;\u003c/span\u003e)\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etext \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e news[\u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        ET\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eSubElement(doc, \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;body\u0026#34;\u003c/span\u003e)\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etext \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e body\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        tree \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e ET\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eElementTree(doc)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        tree\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ewrite(doc_dir_path \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e%d\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e.xml\u0026#34;\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e%\u003c/span\u003e(i), encoding \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e doc_encoding, xml_declaration \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eTrue\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        i \u003cspan style=\"color:#f92672\"\u003e+=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e __name__ \u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;__main__\u0026#39;\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    config \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e configparser\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eConfigParser()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eread(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;../config.ini\u0026#39;\u003c/span\u003e, \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;utf-8\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    root \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;http://news.sohu.com/1/0903/61/subject212846158\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    news_pool \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e get_news_pool(root, \u003cspan style=\"color:#ae81ff\"\u003e854\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e849\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    crawl_news(news_pool, \u003cspan style=\"color:#ae81ff\"\u003e140\u003c/span\u003e, config[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;DEFAULT\u0026#39;\u003c/span\u003e][\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;doc_dir_path\u0026#39;\u003c/span\u003e], config[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;DEFAULT\u0026#39;\u003c/span\u003e][\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;doc_encoding\u0026#39;\u003c/span\u003e])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    print(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;done!\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003chr\u003e\n\u003cp\u003e完整可运行的新闻搜索引擎Demo请看我的Github项目\u003ca href=\"https://github.com/01joy/news_search_engine\"\u003enews_search_engine\u003c/a\u003e。\u003c/p\u003e","title":"和我一起构建搜索引擎（二）网络爬虫"},{"content":"我们上网用得最多的一项服务应该是搜索，不管大事小情，都喜欢百度一下或谷歌一下，那么百度和谷歌是怎样从浩瀚的网络世界中快速找到你想要的信息呢，这就是搜索引擎的艺术，属于信息检索的范畴。\n这学期学习了《现代信息检索》课程，使用的是Stanford的教材Introduction to Information Retrieval，网上有电子版，大家可以参考。\n本课程的大作业是完成一个新闻搜索引擎，要求是这样的：定向采集3-4个新闻网站，实现这些网站信息的抽取、索引和检索。网页数目不少于10万条。能按相关度、时间和热度（需要自己定义）进行排序，能实现相似新闻的自动聚类。\n截止日期12月31日，我们已经在规定时间完成了该系统，自认为检索效果不错，所以在此把过程记录如下，欢迎讨论。\n网上有很多开源的全文搜索引擎，比如Lucene、Sphinx、Whoosh等，都提供了很好的API，开发者只需要调用相关接口就可以实现一个全功能的搜索引擎。不过既然学习了IR这门课，自然要把相关技术实践一下，所以我们打算自己实现一个搜索引擎。\n这是简介部分，主要介绍整个搜索引擎的思路和框架。\n上图为本搜索引擎的框架图。首先爬虫程序从特定的几个新闻网站抓取新闻数据，然后过滤网页中的图片、视频、广告等无关元素，抽取新闻的主体内容，得到结构化的xml数据。然后一方面使用内存式单遍扫描索引构建方法（SPIMI）构建倒排索引，供检索模型使用；另一方面根据向量空间模型计算两两新闻之间的余弦相似度，供推荐模块使用。最后利用概率检索模型中的BM25公式计算给定关键词下的文档相关性评分，BM25打分结合时间因素得到热度评分，根据评分给出排序结果。\n在后续博文中，我会详细介绍每个部分的实现。\n完整可运行的新闻搜索引擎Demo请看我的Github项目news_search_engine。\n以下是系列博客：\n和我一起构建搜索引擎（一）简介\n和我一起构建搜索引擎（二）网络爬虫\n和我一起构建搜索引擎（三）构建索引\n和我一起构建搜索引擎（四）检索模型\n和我一起构建搜索引擎（五）推荐阅读\n和我一起构建搜索引擎（六）系统展示\n和我一起构建搜索引擎（七）总结展望\n","permalink":"http://localhost:1313/posts/2016-01-04-introduction-to-building-a-search-engine-1/","summary":"\u003cp\u003e我们上网用得最多的一项服务应该是搜索，不管大事小情，都喜欢百度一下或谷歌一下，那么百度和谷歌是怎样从浩瀚的网络世界中快速找到你想要的信息呢，这就是搜索引擎的艺术，属于信息检索的范畴。\u003c/p\u003e\n\u003cp\u003e这学期学习了《现代信息检索》课程，使用的是Stanford的教材\u003ca href=\"http://nlp.stanford.edu/IR-book/\"\u003eIntroduction to Information Retrieval\u003c/a\u003e，网上有电子版，大家可以参考。\u003c/p\u003e\n\u003cp\u003e本课程的大作业是完成一个新闻搜索引擎，要求是这样的：定向采集3-4个新闻网站，实现这些网站信息的抽取、索引和检索。网页数目不少于10万条。能按相关度、时间和热度（需要自己定义）进行排序，能实现相似新闻的自动聚类。\u003c/p\u003e\n\u003cp\u003e截止日期12月31日，我们已经在规定时间完成了该系统，自认为检索效果不错，所以在此把过程记录如下，欢迎讨论。\u003c/p\u003e\n\u003cp\u003e网上有很多开源的全文搜索引擎，比如Lucene、Sphinx、Whoosh等，都提供了很好的API，开发者只需要调用相关接口就可以实现一个全功能的搜索引擎。不过既然学习了IR这门课，自然要把相关技术实践一下，所以我们打算自己实现一个搜索引擎。\u003c/p\u003e\n\u003cp\u003e这是简介部分，主要介绍整个搜索引擎的思路和框架。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"search engine outline\" loading=\"lazy\" src=\"/posts/2016-01-04-introduction-to-building-a-search-engine-1/search-engine-architecture.png\"\u003e\u003c/p\u003e\n\u003cp\u003e上图为本搜索引擎的框架图。首先爬虫程序从特定的几个新闻网站抓取新闻数据，然后过滤网页中的图片、视频、广告等无关元素，抽取新闻的主体内容，得到结构化的xml数据。然后一方面使用内存式单遍扫描索引构建方法（SPIMI）构建倒排索引，供检索模型使用；另一方面根据向量空间模型计算两两新闻之间的余弦相似度，供推荐模块使用。最后利用概率检索模型中的BM25公式计算给定关键词下的文档相关性评分，BM25打分结合时间因素得到热度评分，根据评分给出排序结果。\u003c/p\u003e\n\u003cp\u003e在后续博文中，我会详细介绍每个部分的实现。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e完整可运行的新闻搜索引擎Demo请看我的Github项目\u003ca href=\"https://github.com/01joy/news_search_engine\"\u003enews_search_engine\u003c/a\u003e。\u003c/p\u003e\n\u003cp\u003e以下是系列博客：\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://bitjoy.net/posts/2016-01-04-introduction-to-building-a-search-engine-1/\"\u003e和我一起构建搜索引擎（一）简介\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://bitjoy.net/posts/2016-01-04-introduction-to-building-a-search-engine-2/\"\u003e和我一起构建搜索引擎（二）网络爬虫\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://bitjoy.net/posts/2016-01-07-introduction-to-building-a-search-engine-3/\"\u003e和我一起构建搜索引擎（三）构建索引\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://bitjoy.net/posts/2016-01-07-introduction-to-building-a-search-engine-4/\"\u003e和我一起构建搜索引擎（四）检索模型\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://bitjoy.net/posts/2016-01-09-introduction-to-building-a-search-engine-5/\"\u003e和我一起构建搜索引擎（五）推荐阅读\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://bitjoy.net/posts/2016-01-09-introduction-to-building-a-search-engine-6/\"\u003e和我一起构建搜索引擎（六）系统展示\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://bitjoy.net/posts/2016-01-09-introduction-to-building-a-search-engine-7/\"\u003e和我一起构建搜索引擎（七）总结展望\u003c/a\u003e\u003c/p\u003e","title":"和我一起构建搜索引擎（一）简介"},{"content":"突然发现，从小到大，自己做事都做得很慢，别人一会做完的作业，我可能要花好几个小时。但拿作业一对比，明显能看出差距，自己精雕细琢的作品不是别人随随便便就能比的。\n最近几次和同学合作完成大作业也遇到了类似的情况，数据抓取的同学给我的数据，不是格式不对就是内容缺胳膊少腿，质量极其差，还不愿修改，曰：只是做一个演示系统，有数据就行了。他不知道他这样的数据给我，我们后面做得再好，最终的演示效果也不会好，他这样的随意，后面的人不知要多花多少时间来弥补。我也无意跟他多费口舌，自己挽起袖子重做了他的工作。\n类似的事情，我遇到的不在少数，和别人沟通的时间远远超过了自己完成任务的时间。所以往往一个很简单的工作，我要花比别人多两到三倍的时间。这个过程就像工匠在雕琢自己的作品，是不计时间的，直到自己认为完美为止。这大概就是老罗所说的工匠精神吧。\n在一个完美主义者的眼里，这是一个千疮百孔的世界。\n糟糕的文档排版，错别字和错误标点一堆，一群人并排走挡了后面或对面的人，开水房离宿舍十万八千里，蚊香的设计，电脑接口位置的设计，U盘接口的设计，凸出的摄像头，插队，说脏话。。。\n当然也有同学劝我，这些东西差不多就行了，何必花这么多时间做这么好干什么，还不如去看个电影打个球。也经常听人说Take it easy，别太认真，认真你就输了。\n但是我始终相信，态度决定一切。你一天认真做了，别人不一定看得到，但坚持一个月甚至一年，总会有志同道合的人发现你，而你的坚持也将一点点的改变这个行业这个世界。就像老罗做手机，虽然销量不怎么样，但他的工匠精神、他的情怀，值得每一个人尊敬。T2统一听筒和各种传感器的位置、消失的电源键、消失的SIM卡插槽、消失的金属中框断点完全是超出iPhone的美好设计。希望老罗的情怀之路能够坚持下去、越走越远。\n","permalink":"http://localhost:1313/posts/2016-01-04-attitude-is-everything/","summary":"\u003cp\u003e突然发现，从小到大，自己做事都做得很慢，别人一会做完的作业，我可能要花好几个小时。但拿作业一对比，明显能看出差距，自己精雕细琢的作品不是别人随随便便就能比的。\u003c/p\u003e\n\u003cp\u003e最近几次和同学合作完成大作业也遇到了类似的情况，数据抓取的同学给我的数据，不是格式不对就是内容缺胳膊少腿，质量极其差，还不愿修改，曰：只是做一个演示系统，有数据就行了。他不知道他这样的数据给我，我们后面做得再好，最终的演示效果也不会好，他这样的随意，后面的人不知要多花多少时间来弥补。我也无意跟他多费口舌，自己挽起袖子重做了他的工作。\u003c/p\u003e\n\u003cp\u003e类似的事情，我遇到的不在少数，和别人沟通的时间远远超过了自己完成任务的时间。所以往往一个很简单的工作，我要花比别人多两到三倍的时间。这个过程就像工匠在雕琢自己的作品，是不计时间的，直到自己认为完美为止。这大概就是老罗所说的工匠精神吧。\u003c/p\u003e\n\u003cp\u003e在一个完美主义者的眼里，这是一个千疮百孔的世界。\u003c/p\u003e\n\u003cp\u003e糟糕的文档排版，错别字和错误标点一堆，一群人并排走挡了后面或对面的人，开水房离宿舍十万八千里，蚊香的设计，电脑接口位置的设计，U盘接口的设计，凸出的摄像头，插队，说脏话。。。\u003c/p\u003e\n\u003cp\u003e当然也有同学劝我，这些东西差不多就行了，何必花这么多时间做这么好干什么，还不如去看个电影打个球。也经常听人说Take it easy，别太认真，认真你就输了。\u003c/p\u003e\n\u003cp\u003e但是我始终相信，态度决定一切。你一天认真做了，别人不一定看得到，但坚持一个月甚至一年，总会有志同道合的人发现你，而你的坚持也将一点点的改变这个行业这个世界。就像老罗做手机，虽然销量不怎么样，但他的工匠精神、他的情怀，值得每一个人尊敬。T2统一听筒和各种传感器的位置、消失的电源键、消失的SIM卡插槽、消失的金属中框断点完全是超出iPhone的美好设计。希望老罗的情怀之路能够坚持下去、越走越远。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"smartisan-T2-2015\" loading=\"lazy\" src=\"/posts/2016-01-04-attitude-is-everything/smartisan-T2-2015.jpg\"\u003e\u003c/p\u003e","title":"认真你就赢了"},{"content":"2015年过得好快，梳理一下，2015年的时间线大概是这样的：\n3月来北京计算所做毕设→5月返回武大修改论文→5月30公开答辩→6月毕业季→7月回北京计算所→8月回家陪父母→9月国科大开学→持续高强度的学习→2016元旦还在图书馆研究NPC问题。\n2015年给我的总体感受是很忙，但忙的事情都很琐碎，并没有什么大的里程碑事件，不过以下三件事情我认为值得一提。\n本科四年修成正果，研究生三年新的起航 买了一辆属于自己的山地车，1k2，虽然是二手的，但足够我骑着它去看世界了:-) 也许是在城市里待久了，我特别享受这种亲近大自然的感觉，蓝天、白云、草原、大海这些美景永远也看不够。\n在国科大认识了两个好基友，虽然都是单身汪，但至少想看电影吃火锅的时候还可以有个伴。（此处居然少了三人合照） 2015年共写了14篇博客，包含3篇技术博客，bitjoy.net 历史累计PV1039，UV520，IP502。\n展望2016年，大的方向基本都确定了，目标如下：\n完成国科大下学期的课程任务 接手pLink软件 刷完LeetCode所有题目 读10本书 去电影院看10场电影（2015下半年在怀柔村里没看一部电影/(ㄒoㄒ)/~~） 改正坐姿 大家一起见证！\n","permalink":"http://localhost:1313/posts/2016-01-03-2016-happy-new-year/","summary":"\u003cp\u003e2015年过得好快，梳理一下，2015年的时间线大概是这样的：\u003c/p\u003e\n\u003cp\u003e3月来北京计算所做毕设→5月返回武大修改论文→5月30公开答辩→6月毕业季→7月回北京计算所→8月回家陪父母→9月国科大开学→持续高强度的学习→2016元旦还在图书馆研究NPC问题。\u003c/p\u003e\n\u003cp\u003e2015年给我的总体感受是很忙，但忙的事情都很琐碎，并没有什么大的里程碑事件，不过以下三件事情我认为值得一提。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e本科四年修成正果，研究生三年新的起航\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg alt=\"whu_certificate\" loading=\"lazy\" src=\"/posts/2016-01-03-2016-happy-new-year/whu_certificate.jpg\"\u003e\n\u003cimg alt=\"ucas_admission\" loading=\"lazy\" src=\"/posts/2016-01-03-2016-happy-new-year/ucas_admission.jpg\"\u003e\u003c/p\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e买了一辆属于自己的山地车，1k2，虽然是二手的，但足够我骑着它去看世界了:-)\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg alt=\"bike\" loading=\"lazy\" src=\"/posts/2016-01-03-2016-happy-new-year/bike.jpg\"\u003e\n\u003cimg alt=\"2015_cycling_1\" loading=\"lazy\" src=\"/posts/2016-01-03-2016-happy-new-year/2015_cycling_1.jpg\"\u003e\n\u003cimg alt=\"2015_cycling_2\" loading=\"lazy\" src=\"/posts/2016-01-03-2016-happy-new-year/2015_cycling_2.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e也许是在城市里待久了，我特别享受这种亲近大自然的感觉，蓝天、白云、草原、大海这些美景永远也看不够。\u003c/p\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003e在国科大认识了两个好基友，虽然都是单身汪，但至少想看电影吃火锅的时候还可以有个伴。（此处居然少了三人合照）\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e2015年共写了14篇博客，包含3篇技术博客，bitjoy.net 历史累计PV1039，UV520，IP502。\u003c/p\u003e\n\u003cp\u003e展望2016年，大的方向基本都确定了，目标如下：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e完成国科大下学期的课程任务\u003c/li\u003e\n\u003cli\u003e接手pLink软件\u003c/li\u003e\n\u003cli\u003e刷完LeetCode所有题目\u003c/li\u003e\n\u003cli\u003e读10本书\u003c/li\u003e\n\u003cli\u003e去电影院看10场电影（2015下半年在怀柔村里没看一部电影/(ㄒoㄒ)/~~）\u003c/li\u003e\n\u003cli\u003e改正坐姿\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e大家一起见证！\u003c/p\u003e","title":"2016新年快乐"},{"content":"\n第一次在北方过冬，今年北京11月6日就下雪了，然而我在广州的小伙伴还穿着短袖吃着冰棍呢。。。\n北京2015年的第一场雪，比以往时候来的更早一些\n今天又下起了第二场雪，下了整整两天的大雪，然而我房间的暖气却不暖了，大叔来修了两次，无功而返，说是一楼的宿舍暖气都有问题，当初设计有缺陷(╯‵□′)╯︵┻━┻\n这样也好，给了自己去图书馆的理由❉\n","permalink":"http://localhost:1313/posts/2015-11-22-snow-in-beijing/","summary":"\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://upload.wikimedia.org/wikipedia/commons/f/fd/Von_Koch_curve.gif\"\u003e\u003c/p\u003e\n\u003cp\u003e第一次在北方过冬，今年北京11月6日就下雪了，然而我在广州的小伙伴还穿着短袖吃着冰棍呢。。。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"2015_11_06_beijing_snow\" loading=\"lazy\" src=\"/posts/2015-11-22-snow-in-beijing/2015_11_06_beijing_snow.jpg\"\u003e\n北京2015年的第一场雪，比以往时候来的更早一些\u003c/p\u003e\n\u003cp\u003e今天又下起了第二场雪，下了整整两天的大雪，然而我房间的暖气却不暖了，大叔来修了两次，无功而返，说是一楼的宿舍暖气都有问题，当初设计有缺陷(╯‵□′)╯︵┻━┻\u003c/p\u003e\n\u003cp\u003e这样也好，给了自己去图书馆的理由❉\u003c/p\u003e","title":"北国的雪"},{"content":"安装WIN10一个月以来，校园有线网经常间歇性断网，通常是20分钟不到就断了，需要重启或者把有线连接关闭再打开才可以。在微博上问过微软客服也无果，后来Google到某国外的解决办法，现记录如下。\n说到底WIN10断网的问题还是和驱动有关，先看一下我的有线网卡Broadcom NetLink (TM) Gigabit Ethernet，驱动信息是这样的：\n还是13年的驱动，版本号是15.6.0.14，于是第一想到的是更新驱动。点击驱动右键选更新-\u0026gt;自动搜索更新的驱动程序软件-\u0026gt;提示“已安装适合设备的最佳驱动程序软件”，但这明明不是最新的驱动啊！\n于是在Broadcom的官网上找到了最新驱动win_b57_x64-17.2.0.2，版本号是17.2.0.2，更新日期2015-10-27，原来这才是最新的驱动。\n（2018.1.25更新：上面的地址已失效，最新地址请点击此处，并选择DOWNLOADS→Software→NetLink®/NetXtreme® I Desktop/Mobile/Server (x64)，也可以从本站下载。）\n在安装最新驱动之前，我们需要关闭WIN10的自动更新驱动功能，因为WIN10会认为它的15.6.0.14版本是最新的，在windows update时把实际最新的17.2.0.2版本替换掉。具体做法是在Cortana中搜索“更改设备安装设置”并打开，选择否，从不安装来自Windows更新的驱动程序软件，如下。\n然后重启进入安全模式，再次在设备管理器中右键点击网卡驱动，选择更新-\u0026gt;浏览计算机以查找驱动程序软件-\u0026gt;从计算机的设备驱动程序列表中选取-\u0026gt;点击从磁盘安装按钮-\u0026gt;浏览找到你之前在网上下载的最新驱动（*.inf格式）-\u0026gt;选中-\u0026gt;依次确定。刷新之后再次查看驱动信息如下：\n可以看到驱动已经更新到最新的版本了。再次重启进入正常模式，目前用了两天了也没有再断过网。\n其他WIN10驱动问题应该也可以用类似的方法解决。\n（话说我的WIN10偶尔会死机，就是用着用着突然鼠标和键盘完全动不了了，只能强制重启，有谁知道这是怎么回事吗？）\n","permalink":"http://localhost:1313/posts/2015-11-13-solution-to-win10s-network-problem/","summary":"\u003cp\u003e安装WIN10一个月以来，校园有线网经常间歇性断网，通常是20分钟不到就断了，需要重启或者把有线连接关闭再打开才可以。在微博上问过微软客服也无果，\u003ca href=\"http://www.pcadvisor.co.uk/forum/windows-29/windows-10-no-internet-trough-ethernet-4540238/\"\u003e后来Google到某国外的解决办法\u003c/a\u003e，现记录如下。\u003c/p\u003e\n\u003cp\u003e说到底WIN10断网的问题还是和驱动有关，先看一下我的有线网卡Broadcom NetLink (TM) Gigabit Ethernet，驱动信息是这样的：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"bcm-driver-before\" loading=\"lazy\" src=\"/posts/2015-11-13-solution-to-win10s-network-problem/bcm-driver-before.png\"\u003e\u003c/p\u003e\n\u003cp\u003e还是13年的驱动，版本号是15.6.0.14，于是第一想到的是更新驱动。点击驱动右键选更新-\u0026gt;自动搜索更新的驱动程序软件-\u0026gt;提示“已安装适合设备的最佳驱动程序软件”，但这明明不是最新的驱动啊！\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.broadcom.com/support/ethernet-nic-netxtreme-i-desktop-mobile\"\u003e于是在Broadcom的官网上找到了最新驱动win_b57_x64-17.2.0.2\u003c/a\u003e，版本号是17.2.0.2，更新日期2015-10-27，原来这才是最新的驱动。\u003c/p\u003e\n\u003cp\u003e（\u003cstrong\u003e2018.1.25\u003c/strong\u003e更新：上面的地址已失效，\u003ca href=\"https://www.broadcom.cn/products/ethernet-connectivity/controllers/bcm5720#downloads\"\u003e最新地址请点击此处\u003c/a\u003e，并选择DOWNLOADS→Software→NetLink®/NetXtreme® I Desktop/Mobile/Server (x64)，\u003ca href=\"/posts/2015-11-13-solution-to-win10s-network-problem/win_b57_x64-17.2.0.2.zip\"\u003e也可以从本站下载\u003c/a\u003e。）\u003c/p\u003e\n\u003cp\u003e在安装最新驱动之前，我们需要关闭WIN10的自动更新驱动功能，因为WIN10会认为它的15.6.0.14版本是最新的，在windows update时把实际最新的17.2.0.2版本替换掉。具体做法是在Cortana中搜索“\u003cstrong\u003e更改设备安装设置\u003c/strong\u003e”并打开，选择否，从不安装来自Windows更新的驱动程序软件，如下。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"change-device-installation\" loading=\"lazy\" src=\"/posts/2015-11-13-solution-to-win10s-network-problem/change-device-installation.png\"\u003e\u003c/p\u003e\n\u003cp\u003e然后\u003ca href=\"http://jingyan.baidu.com/article/fea4511a72cb38f7ba912543.html\"\u003e重启进入安全模式\u003c/a\u003e，再次在设备管理器中右键点击网卡驱动，选择更新-\u0026gt;浏览计算机以查找驱动程序软件-\u0026gt;从计算机的设备驱动程序列表中选取-\u0026gt;点击从磁盘安装按钮-\u0026gt;浏览找到你之前在网上下载的最新驱动（*.inf格式）-\u0026gt;选中-\u0026gt;依次确定。刷新之后再次查看驱动信息如下：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"bcm-driver-after\" loading=\"lazy\" src=\"/posts/2015-11-13-solution-to-win10s-network-problem/bcm-driver-after.png\"\u003e\u003c/p\u003e\n\u003cp\u003e可以看到驱动已经更新到最新的版本了。再次重启进入正常模式，目前用了两天了也没有再断过网。\u003c/p\u003e\n\u003cp\u003e其他WIN10驱动问题应该也可以用类似的方法解决。\u003c/p\u003e\n\u003cp\u003e（话说我的WIN10偶尔会死机，就是用着用着突然鼠标和键盘完全动不了了，只能强制重启，有谁知道这是怎么回事吗？）\u003c/p\u003e","title":"解决Win10间歇性断网的问题"},{"content":"大家好，施一公老师的26篇博客大概可以分为四类：1）讲述个人生活经历2）评论社会问题3）讨论国家科技和人才引进政策4）介绍学习方法。这些博客比较全面地反应了施一公的求学经历、由学生到教授的转变过程以及回国之后为中国人才引进所做出的努力。\n给我感触最深的有3点：1）环境对人的影响很大2）坚持总会有所收获3）做一个有担当、有社会责任感的科研人。\n1）环境对人的影响很大 《从\u0026lt;高考1977\u0026gt;说起》这篇博客详细介绍了施一公高考前的家庭情况，施一公的父亲是哈工大毕业，母亲是北京矿业学院（今中国矿业大学）毕业，在上世纪五六十年代，父母都是名校大学毕业，可谓是少有的知识分子家庭。施一公还有两个姐姐、一个哥哥、一个表哥和一个表姐，哥哥姐姐们刻苦的学习、父亲悉心的辅导以及不错的高考成绩对施一公产生了很大的影响，争强好胜的施一公自然不甘示弱，以84年全国数学联赛省第一名的成绩保送清华。诚然，施一公的成绩和他自己的刻苦努力分不开，但是从小良好的家庭氛围也功不可没。\n2）坚持总会有所收获 这可以从施一公的两个例子中看出。\n《今天3000米》讲到施一公从82年跑步的“倒数第一“、“颜面尽失”之后开始坚持长跑，直到89年从未间断，在85年的清华新生运动会3000米竞走中，以16分10秒轻松获得第一名。\n跑步这件事我也深有体会，我高中几乎没有体育锻炼，大一刚入学的体能测试中，1000米项目跑了4’15’’，小组倒数第一，跑完全程脸都发白，当时真的担心大学因体育挂科毕不了业。后来大三下的时候，开始坚持跑步，一开始每晚跑3圈，一个月后加一圈，最后稳定在每晚跑5圈，一直坚持到毕业。在毕业体能测试中，还是1000米项目，我居然跑了3’42’’，小组顺数第一名，跑完之后虽然有点累，但并不感觉难受，连我自己都不太相信。\n《如何做一名优秀的博士生：（一）时间的付出》中，施一公讲到他在留学期间的时间付出。“留学的第一年，我情绪波动很大，内心浮躁而迷茫，根本无心念书。”“第二年，每周五天、每天从上午9点做实验到晚上7、8点，周末也会去两个半天。””到了第三年，晚上常常干到11点多，赶最后一班校车从霍普金斯医学院回Homewood campus（我住在附近）。””研究生阶段后期，我的刻苦在实验室是出了名的。每天晚上做实验到半夜三点左右，回到住处躺下来睡觉时常常已是四点以后；但每天早晨八点都会被窗外纽约第一大道(First Avenue)上的汽车喧闹声吵醒，九点左右又回到实验室开始了新的一天…”\n施一公几年如一日的坚持没有白费，他顺利毕业并获得名校终生教职席位。\n其实正如H老师所说“以大多数人努力的程度，根本还没到拼智商的时候。” 坚持做一件事，点滴积累，做到极致。无论什么事情，坚持做下去，一定能有所收获，对于体力活更是如此。\n3）做一个有担当、有社会责任感的科研人 在读施一公博客的时候，心潮澎湃，热血沸腾，无论是施一公自己排除万难坚持回国的行动，还是施一公回国之后号召海龟回国的倡议，亦或是施一公为人才引进，千人计划建言献策的付出，都真真切切的体现了他的强烈的爱国热情。\n施一公回国后的去私心、敢担当、有作为，坚持职业操守，“我申请基金的时候一定不和评委在评审前或评审后做任何形式的私下沟通；我当评委的时候一定不和申请人在评审前或评审后做任何形式的私下沟通”等都在用切身行动一点点改善国内的科研环境。\n在pFind组，H老师也时常教导我们要对学术保留一点敬畏之心，做好科研，尽自己一份力改善国际社会对中国学术界的看法。\n总的来说，施一公老师的博客内容丰富，让我受益匪浅，也给了我很多启发，关于如何做一名合格的研究生，我还完全是门外汉，前面的师兄师姐都给出了很多方法论的解读，我也把施一公关于如何做一名优秀的博士生的几个要点罗列如下，希望用此标准来要求自己。\n如何一名优秀的博士生：\n时间的付出 方法论的转变 正确分析负面结果 耗费时间的完美主义阻碍创新进取 科研文献与学术讲座的取与舍 挑战传统思维 祝大家工作顺利！\n-bitJoy\n","permalink":"http://localhost:1313/posts/2015-10-31-review-about-shiyigongs-blogs/","summary":"\u003cp\u003e大家好，\u003ca href=\"http://blog.sciencenet.cn/home.php?mod=space\u0026amp;uid=46212\u0026amp;do=blog\u0026amp;view=me\u0026amp;from=space\"\u003e施一公老师的26篇博客\u003c/a\u003e大概可以分为四类：1）讲述个人生活经历2）评论社会问题3）讨论国家科技和人才引进政策4）介绍学习方法。这些博客比较全面地反应了施一公的求学经历、由学生到教授的转变过程以及回国之后为中国人才引进所做出的努力。\u003c/p\u003e\n\u003cp\u003e给我感触最深的有3点：1）环境对人的影响很大2）坚持总会有所收获3）做一个有担当、有社会责任感的科研人。\u003c/p\u003e\n\u003ch1 id=\"1环境对人的影响很大\"\u003e1）环境对人的影响很大\u003c/h1\u003e\n\u003cp\u003e《从\u0026lt;高考1977\u0026gt;说起》这篇博客详细介绍了施一公高考前的家庭情况，施一公的父亲是哈工大毕业，母亲是北京矿业学院（今中国矿业大学）毕业，在上世纪五六十年代，父母都是名校大学毕业，可谓是少有的知识分子家庭。施一公还有两个姐姐、一个哥哥、一个表哥和一个表姐，哥哥姐姐们刻苦的学习、父亲悉心的辅导以及不错的高考成绩对施一公产生了很大的影响，争强好胜的施一公自然不甘示弱，以84年全国数学联赛省第一名的成绩保送清华。诚然，施一公的成绩和他自己的刻苦努力分不开，但是从小良好的家庭氛围也功不可没。\u003c/p\u003e\n\u003ch1 id=\"2坚持总会有所收获\"\u003e2）坚持总会有所收获\u003c/h1\u003e\n\u003cp\u003e这可以从施一公的两个例子中看出。\u003c/p\u003e\n\u003cp\u003e《今天3000米》讲到施一公从82年跑步的“倒数第一“、“颜面尽失”之后开始坚持长跑，直到89年从未间断，在85年的清华新生运动会3000米竞走中，以16分10秒轻松获得第一名。\u003c/p\u003e\n\u003cp\u003e跑步这件事我也深有体会，我高中几乎没有体育锻炼，大一刚入学的体能测试中，1000米项目跑了4’15’’，小组倒数第一，跑完全程脸都发白，当时真的担心大学因体育挂科毕不了业。后来大三下的时候，开始坚持跑步，一开始每晚跑3圈，一个月后加一圈，最后稳定在每晚跑5圈，一直坚持到毕业。在毕业体能测试中，还是1000米项目，我居然跑了3’42’’，小组顺数第一名，跑完之后虽然有点累，但并不感觉难受，连我自己都不太相信。\u003c/p\u003e\n\u003cp\u003e《如何做一名优秀的博士生：（一）时间的付出》中，施一公讲到他在留学期间的时间付出。“留学的第一年，我情绪波动很大，内心浮躁而迷茫，根本无心念书。”“第二年，每周五天、每天从上午9点做实验到晚上7、8点，周末也会去两个半天。””到了第三年，晚上常常干到11点多，赶最后一班校车从霍普金斯医学院回Homewood campus（我住在附近）。””研究生阶段后期，我的刻苦在实验室是出了名的。每天晚上做实验到半夜三点左右，回到住处躺下来睡觉时常常已是四点以后；但每天早晨八点都会被窗外纽约第一大道(First Avenue)上的汽车喧闹声吵醒，九点左右又回到实验室开始了新的一天…”\u003c/p\u003e\n\u003cp\u003e施一公几年如一日的坚持没有白费，他顺利毕业并获得名校终生教职席位。\u003c/p\u003e\n\u003cp\u003e其实正如H老师所说“\u003cstrong\u003e以大多数人努力的程度，根本还没到拼智商的时候。\u003c/strong\u003e” 坚持做一件事，点滴积累，做到极致。无论什么事情，坚持做下去，一定能有所收获，对于体力活更是如此。\u003c/p\u003e\n\u003ch1 id=\"3做一个有担当有社会责任感的科研人\"\u003e3）做一个有担当、有社会责任感的科研人\u003c/h1\u003e\n\u003cp\u003e在读施一公博客的时候，心潮澎湃，热血沸腾，无论是施一公自己排除万难坚持回国的行动，还是施一公回国之后号召海龟回国的倡议，亦或是施一公为人才引进，千人计划建言献策的付出，都真真切切的体现了他的强烈的爱国热情。\u003c/p\u003e\n\u003cp\u003e施一公回国后的去私心、敢担当、有作为，坚持职业操守，“我申请基金的时候一定不和评委在评审前或评审后做任何形式的私下沟通；我当评委的时候一定不和申请人在评审前或评审后做任何形式的私下沟通”等都在用切身行动一点点改善国内的科研环境。\u003c/p\u003e\n\u003cp\u003e在pFind组，H老师也时常教导我们要\u003cstrong\u003e对学术保留一点敬畏之心\u003c/strong\u003e，做好科研，尽自己一份力改善国际社会对中国学术界的看法。\u003c/p\u003e\n\u003cp\u003e总的来说，施一公老师的博客内容丰富，让我受益匪浅，也给了我很多启发，关于如何做一名合格的研究生，我还完全是门外汉，前面的师兄师姐都给出了很多方法论的解读，我也把施一公关于如何做一名优秀的博士生的几个要点罗列如下，希望用此标准来要求自己。\u003c/p\u003e\n\u003cp\u003e如何一名优秀的博士生：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e时间的付出\u003c/li\u003e\n\u003cli\u003e方法论的转变\n\u003col\u003e\n\u003cli\u003e正确分析负面结果\u003c/li\u003e\n\u003cli\u003e耗费时间的完美主义阻碍创新进取\u003c/li\u003e\n\u003cli\u003e科研文献与学术讲座的取与舍\u003c/li\u003e\n\u003cli\u003e挑战传统思维\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e祝大家工作顺利！\u003c/p\u003e\n\u003cp\u003e-bitJoy\u003c/p\u003e","title":"读施一公博客有感"},{"content":"进入研究生生涯完成的第一个新生培训作业是“2.5亿个浮点数的外部排序算法”，前后折腾了将近一个月，结果是在i7处理器上，限制512MB内存，排序用时250秒左右。\n这个作业的常规思路大部分人都能想到，按块读取文件-\u0026gt;atof转换为double-\u0026gt;内部快速排序或基数排序-\u0026gt;dtoa转换为char*-\u0026gt;按块写入文件。这里面中间的三个过程都很耗时，特别是atof和dtoa，因为精度只要求保留9位小数，所以可以自己实现atof和dtoa来加速，也可以使用多线程加速。\n整个作业都是基于对IEEE754浮点数的深刻理解展开的，所以下面详细讲解浮点数的一些知识。\nIEEE754双精度浮点数 目前大多数CPU内浮点数的表示都遵循IEEE754标准，IEEE754双精度浮点数（double）表示如下图所示。\nIEEE754 double在内存中的形式[1]\nsign bit：符号位，1位，用来表示正负号，0表示非负；1表示负 exponent：指数位，11位，用来表示次方数，是一个无符号数 fraction：尾数位，52位，用来表示精确度，也是一个无符号数，有些资料也叫做mantissa或significand 这种表示形式有两点需要注意。\n第一，既然exponent是无符号的，那么怎样表示负指数呢？\nIEEE754规定，二进制串中算得的e需要减去一个偏移量bias，对于double，bias=1023，即e’=e-bias。因为\\(e\\in[0,2^{11}-1]\\)，所以最终\\(e’\\in[-2^{10}+1,2^{10}]\\)。但是如果把e本身看作有符号数e”，则\\(e”\\in[-2^{10},2^{10}-1]\\)，既然e”和e’相差微小，为什么不直接把e看成有符号数，而非要把它看成无符号数，再减去一个偏移量bias呢？\n这是因为如果把e看成无符号数再减偏移量，浮点数大小比较速度更快。引用维基百科的一段话：\nBy arranging the fields so that the sign bit is in the most significant bit position, the biased exponent in the middle, then the mantissa in the least significant bits, the resulting value will be ordered properly, whether it’s interpreted as a floating point or integer value. This allows high speed comparisons of floating point numbers using fixed point hardware.\n对于两个正浮点数a和b，如果a\u0026gt;b，则a的二进制字符串的字典序也相应的在b的后面；对于负数则正好相反。也就是说，无论是把这个数看成浮点数还是整数，都可以通过只比较两个数的二进制串得出大小关系，而不需要通过公式计算其十进制值再比较大小，这显然加快了比较速度。\n浮点数的这个特性使得对浮点数排序也可以使用基数排序！很神奇吧，具体是这样的：先对二进制串进行分组，按先低位组后高位组对其进行基数排序；当到最高位组时，把负数放到正数的前面逆序排列，正数常规排列，得到的就是有序的排列。\n比如，假设把数看成无符号数时，会得到下面的基数排序结果，此时需要调整顺序，把正数统一移到后面，就是代码第50行：index += negatives；把负数移到前面的同时逆序排列，相当于在0的上面画一条线，然后-1,-2,-7以这条线做一个翻折对称，所以新的负数的下标变成了第48行的：index = n – index – 1。\n0　:　0000 1　:　0001 2　:　0010 4　:　0100 -1　:　1001 -2　:　1010 -7　:　1111　变成：\n-7　:　1111　-2　:　1010 -1　:　1001 0　:　0000 1　:　0001 2　:　0010 4　:　0100 具体的实现可以看这个讨论，下面是我实现的C++版本。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 void RadixSort(std::vector\u0026lt;double\u0026gt; \u0026amp;nums) { int n = nums.size(); vector\u0026lt;LL\u0026gt; t(n), a(n); for (int i = 0; i \u0026lt; n; i++) a[i] = *(LL*)(\u0026amp;nums[i]); //将double的二进制转换为long long int groupLength = 16; //可自定义 int bitLength = 64; int len = 1 \u0026lt;\u0026lt; groupLength; vector\u0026lt;int\u0026gt; count(len), pref(len); int groups = bitLength / groupLength; int mask = len - 1; int negatives = 0, positives = 0; for (int c = 0, shift = 0; c \u0026lt; groups; c++, shift += groupLength) { // reset count array fill(count.begin(), count.end(), 0); // counting elements of the c-th group for (int i = 0; i \u0026lt; n; i++) { ++count[(a[i] \u0026gt;\u0026gt; shift) \u0026amp; mask]; // additionally count all negative // values in first round if (c == 0 \u0026amp;\u0026amp; a[i] \u0026lt; 0) ++negatives; } if (c == 0) positives = n - negatives; // calculating prefixes pref[0] = 0; for (int i = 1; i \u0026lt; len; i++) pref[i] = pref[i - 1] + count[i - 1]; // from a[] to t[] elements ordered by c-th group for (int i = 0; i \u0026lt; n; i++) { // Get the right index to sort the number in int index = pref[(a[i] \u0026gt;\u0026gt; shift) \u0026amp; mask]++; if (c == groups - 1) { // We\u0026#39;re in the last (most significant) group, if the // number is negative, order them inversely in front // of the array, pushing positive ones back. if (a[i] \u0026lt; 0) index = n - index - 1; else index += negatives; } t[index] = a[i]; } // a[]=t[] and start again until the last group if (c != groups - 1) { for (int j = 0; j \u0026lt; n; j++) a[j] = t[j]; } } // Convert back the ints to the double array for (int i = 0; i \u0026lt; n; i++) nums[i] = *(double*)(\u0026amp;t[i]); //重新把long long 的二进制转换为double } 浮点数的基数排序肯定会比快速排序快，至于快多少我就没有测试了。\n二，IEEE754浮点数都是规格化浮点数。\n规格化（normalized）浮点数是指尾数f的最高位非0。如果指数e的范围是无限的，则可以通过对尾数f移位并调整指数e的大小对v进行规格化；如果e的范围是有限的，则有些数并不能被规格化（f移位过多，导致调整后的e超出其范围）。有最小指数的不可规格化浮点数称为非规格化数（denormals）。[3]\n当所有的数都是以规格化数或非规格化数表示时，他们是唯一的。[3]\nIEEE754也能表示非规格化浮点数，但不在本文的讨论范围。\n既然IEEE754浮点数都是规格化浮点数，则他们的f最高位都是1（非0），所以可以省略这一位。也就是说IEEE754双精度浮点数的尾数实际上有53位，只是最高位都是1，所以都省略掉了。\n了解了这两点之后，我们就可以理解为什么将IEEE754双精度浮点数转换为十进制数的公式是下面这个样子了。\n[1]\n或者\n[1]\n在接下来的讨论中，假设一个浮点数为v，其尾数为\\(f_v\\)，指数为\\(e_v\\)，基为b（通常为2），则有\\(v=f_v\\times b^{e_v}\\)。对于IEEE754 double，因为尾数省略了最高位1，所以有\\(hidden=2^{52}\\)，二进制串中的尾数为\\(f_{IEEE}\\)，真正的尾数为\\(f_v=hidden + f_{IEEE}\\)，真正的指数为\\(e_v=e_{IEEE}-bias\\)，所以有\\(v=f_v\\times 2^{e_v}\\)。\n舍入机制 因为浮点数并不能表示所有的实数，所以将实数映射到浮点数的时候，需要一个舍入机制，有两种舍入机制：\nup：向上进位，使用\\([x]^\\uparrow\\)表示； even：选择偶数，使用\\([x]^\\Box\\)表示，比如在十进制中，1.5→2、0.5→0；这是IEEE的默认策略。 当四舍五入的策略不重要时，使用\\([x]^*\\)表示。我们使用\\(\\widetilde x=[x]_p^s\\)来表示规格化浮点数\\(\\widetilde x\\)（x上一根波浪线）的尾数位数（精度）为p，在规格化的过程中使用了s的四舍五入策略。\nULP ULP的全称为unit in the last place，可以理解为尾数相差一个单位时，浮点数的差值。因为x被四舍五入到最接近x的值\\(\\widetilde x\\)，所以有\\(|\\widetilde x-x|\\leqslant 0.5\\times b^e=0.5ulp\\)。\n邻居和边界 令\\(v=f_v\\times b^{e_v}\\)是一个正浮点数，则v的前驱节点\\(v^-\\)是v的上一个可以表示的浮点数；v的后继节点\\(v^+\\)是v的下一个可以表示的浮点数。如果v是最小值，则\\(v^-=0\\)；如果v是最大值，则\\(v^+=v+(v-v^-)\\)。\\(v^-\\)和\\(v^+\\)都是v的邻居，他们和v具有相同的距离。\n两个相邻的数\\(v_1\\)和\\(v_2\\)的边界为他们的算术平均\\(m=(v_1+v_2)/2\\)。根据定义，边界值是不能被表示的。每个浮点数v都有2个边界：\\(m^-=(v^-+v)/2\\)、\\(m^+=(v^++v)/2\\)。明显的，任何实数\\(m^- \u003c w \u003c m^+\\)都将四舍五入到v，也就是说在\\((m^-,m^+)\\)之间的实数是无法用计算机表示的。\nGrisu原是1970年代意大利动画片中的主角，它是一条想成为消防员的小龙，配图是动画片VCD的封面[2]\n下面开始介绍Grisu算法，参考论文Printing Floating-Point Numbers Quickly and Accurately with Integers[3]。\nGrisu算法 自定义数据结构 本文使用整数来实现浮点数的转换，数据结构如下：\n1 2 3 4 typedef struct diy_fp{ uint64_t f; int e; }diy_fp; diy_fp中的f表示尾数，e表示指数。f的精度为q=64，高于IEEE754双精度浮点数的精度p=53。\ndiy_fp有两种运算，减法和乘法。减法为指数相等，尾数相减，结果可能没有规格化；乘法如下：\n$$x\\otimes y=[(f_x\\times f_y)/2^q ]^\\uparrow \\times 2^{e_x+e_y+q}$$乘法结果要四舍五入到64位，所以会有一些错误，但是错误不超过0.5ulp，结果可能没有规格化。\n预计算10的幂 Grisu算法需要用到10的幂的规格化结果，提前计算好这些结果能加速Grisu运行。函数diy_fp cached_power(int k);能够直接返回\\(10^k\\)的规格化浮点数。\n假设输入浮点数为v，其指数为e，需要寻找的10的幂即为\\(\\widetilde{c_k}=f_{c_k }\\times 2^{e_{c_k}}=[10^k ]_q^*\\)，且指数满足\\(\\alpha \\leqslant e_{c_k}+e \\leqslant \\gamma\\)。推导过程为：同时对\\(\\widetilde{c_k}\\)两边取\\(log_{10}\\)得到\\(k=log_{10}(f_{c_k }\\times 2^{e_{c_k}})\\)，将\\(e_{c_k}\\)的下界\\(e_{c_k}\\geqslant\\alpha-e\\)代入，得到\\(k=\\lceil log_{10}(f_{c_k}\\times 2^{\\alpha -e})\\rceil\\)，又因为\\(\\widetilde{c_k}\\)所表示的10的幂的尾数精度为\\(q\\)，所以\\(f_{c_k}\\)的下界为\\(2^{q-1}\\)，代入前一个式子得到下式：\n$$k=\\lceil log_{10}2^{\\alpha -e+q-1}\\rceil=\\lceil (\\alpha -e+q-1)\\times 1/log_{2}10\\rceil$$Grisu算法描述 假设浮点数v的指数是负数，则v可表示为\\(\\frac{f_v}{2^{-e_v}}\\)，如果能找到一个t，使得\\(1\\leqslant \\frac{f_v\\times 10^t}{2^{-e_v}}\u003c10\\)，则v的十进制尾数为\\(\\frac{f_v\\times 10^t}{2^{-e_v}}\\)，十进制指数为-t；我们可以很容易获取\\(\\frac{f_v\\times 10^t}{2^{-e_v}}\\)的各位数字。\n所以Grisu要解决的问题就是怎样快速的将\\(f_v\\times 2^{e_v}\\)转换为\\(D\\times 10^k\\)的形式，并且D尽量小。这样我们可以很容易的获取D的各位数字，和其十进制指数k。问题进一步转换为求k，使得\\(D=v\\times 10^{-k}=f_v\\times 2^{e_v}\\times f_{c_{-k}}\\times 2^{e_{c_{-k}}}\\)尽量的小，所以要让\\(e_{c_{-k}}\\)和\\(e_v\\)能尽量的抵消掉，这就是为什么在预计算10的幂中要求\\(\\alpha \\leqslant e_{c_k}+e \\leqslant \\gamma\\)，且\\(\\alpha\\)和\\(\\gamma\\)都比较小，但是论文表明\\(\\alpha\\)和\\(\\gamma\\)并不是越小越好。\n下面是Grisu算法的具体描述\n输入：精度为p的正浮点数v 前提：diy_fp的精度q≥p+2，且\\(\\widetilde{c_k}=[10^k ]_q^*\\)已经提前计算好了。 输出：十进制字符串V，且满足\\([V]_p^\\Box=v\\)，也就是说再次读取字符串V时，能四舍五入成浮点数v。 过程：\n求v的规格化浮点数表示diy_fp w 寻找满足\\(\\alpha \\leqslant e_c+e_w+q\\leqslant \\gamma\\)的10的幂\\(\\widetilde{c_{-k}}=f_c\\times 2^{e_c}=[10^{-k}]_q^*\\) 计算乘积\\(\\widetilde D=f_D\\times 2^{e_D}=w\\otimes\\widetilde{c_{-k}}\\) 定义\\(V=\\widetilde D\\times 10^k\\)，输出\\(\\widetilde D\\)的十进制表示，字符\u0026rsquo;e\u0026rsquo;和k的十进制表示。 Grisu算法中，\\(\\widetilde D\\)相当于v的十进制尾数，k相当于v的十进制指数。\nGrisu2算法 Grisu算法虽然快，但是得到的结果并不是最短的，比如Grisu可能会把1.0打印成10000000000000000000e-19。Grisu2算法使用了额外的二进制位使得对于99%的输入都能输出最短的字符串表示。\n主要长度 令v是一个正实数，n, l和s是整数，有\\(l\\geqslant 1, 10^{l-1}\\leqslant s\\leqslant 10^l, v=s\\times 10^{n-l}\\)，并且l越小越好，则s的前l个数字是v的主要数字（leading digits），l就是v的主要长度（leading length）。\n通俗的说就是把V的不必要的前导和后尾0去掉后的长度，比如\\(1.23=123\\times 10^{-2}\\)=\\(1230\\times 10^{-3}\\)，但是\\(1230\\times 10^{-3}\\)就多了一个不必要的后尾0，所以1.23的主要长度是3。\n定理6.2 令x和y是2个实数，且\\(x\\leqslant y\\)。令k是满足y mod \\(10^k\\leqslant y-x\\)的最大整数，则有\\(V=\\lfloor \\frac{y}{10^k}\\rfloor \\times 10^k\\)满足\\(x\\leqslant V\\leqslant y\\)。并且V的主要长度（leading length）是所有在[x,y]范围内最小的。\nGrisu2算法正是在Grisu的基础上，利用定理6.2输出了最短的长度。\nGrisu2算法描述 输入：同Grisu算法 前提：diy_fp的精度q≥p+3，且\\(\\widetilde {c_k}=[10^k ]_q^*\\)已经提前计算好了。 输出：十进制数字\\(d_i\\)，i属于[0,n]，和整数\\(\\kappa\\)使得\\(V=d_0 … d_n\\times 10^\\kappa\\)满足\\([V]_p^\\Box =v\\) 过程：\n计算v的边界\\(m^-\\)和\\(m^+\\)（\\(v\\mp 0.5ulp\\)） diy_fp \\(w^+=m^+\\); diy_fp \\(w^-=m^-;\\) 且\\(e_w^-=e_w^+\\) 寻找满足\\(\\alpha \\leqslant e_c+e_w^++q\\leqslant \\gamma\\)的10的幂\\(\\widetilde{c_{-k}}=f_c\\times 2^{e_c}=[10^{-k}]_q^*\\) 计算\\(\\widetilde{M^-}=w^- \\otimes \\widetilde{c_{-k}}\\)；\\(\\widetilde{M^+}=w^+ \\otimes \\widetilde{c_{-k}}\\)；\\(M_{\\uparrow }^-=\\widetilde{M^-}+1ulp\\)；\\(M_{\\downarrow }^+=\\widetilde{M^+}-1ulp\\)；\\(\\delta =M_{\\downarrow }^+-M_{\\uparrow }^-\\) 找到最大的\\(\\kappa\\)使得\\(M_{\\downarrow }^+ mod 10^{\\kappa }\\leqslant \\delta\\)，并且定义\\(P=\\lfloor \\frac{M_{\\downarrow }^+}{10^{\\kappa }}\\rfloor\\) 定义\\(V=P\\times 10^{k+\\kappa }\\)，输出P的十进制数字和\\(K=k+\\kappa\\) Grisu2算法的前三步工作和Grisu算法类似，4,5步的工作近似求Grisu算法的\\(\\widetilde D\\)的最短表示，利用的正是定理6.2，所以最终的指数是由k和\\(\\kappa\\)两部分构成的。\n该论文表示，Grisu2算法比sprintf快四倍左右，根据milo的测试[4] ，经过优化的Grisu2算法milo比sprintf快九倍，据说Google的V8 JavaScript引擎就是使用了Grisu算法，速度才很快的。\ndtoa-benchmark，grisu2是sprintf的5.7倍，milo（优化过的grisu2算法）是sprintf的9.1倍[4]\n至于milo是怎么优化Grisu的，可以参考他的博客，完整的代码可以参考他的Github项目[4]。\n关于完整全面的浮点数介绍，可以参考文献[5]。\n参考：\n[1]. https://en.wikipedia.org/wiki/Double-precision_floating-point_format\n[2]. http://miloyip.com/images/grisu.jpg\n[3]. Printing Floating-Point Numbers Quickly and Accurately with Integers第2节\n[4]. dtoa-benchmark\n[5]. What Every Computer Scientist Should Know About Floating-Point Arithmetic\n","permalink":"http://localhost:1313/posts/2015-08-30-introduction-to-floating-point-numbers-and-grisu-algorithm/","summary":"\u003cp\u003e进入研究生生涯完成的第一个新生培训作业是“2.5亿个浮点数的外部排序算法”，前后折腾了将近一个月，结果是在i7处理器上，限制512MB内存，排序用时250秒左右。\u003c/p\u003e\n\u003cp\u003e这个作业的常规思路大部分人都能想到，按块读取文件-\u0026gt;atof转换为double-\u0026gt;内部快速排序或基数排序-\u0026gt;dtoa转换为char*-\u0026gt;按块写入文件。这里面中间的三个过程都很耗时，特别是atof和dtoa，因为精度只要求保留9位小数，所以可以自己实现atof和dtoa来加速，也可以使用多线程加速。\u003c/p\u003e\n\u003cp\u003e整个作业都是基于对IEEE754浮点数的深刻理解展开的，所以下面详细讲解浮点数的一些知识。\u003c/p\u003e\n\u003ch1 id=\"ieee754双精度浮点数\"\u003eIEEE754双精度浮点数\u003c/h1\u003e\n\u003cp\u003e目前大多数CPU内浮点数的表示都遵循IEEE754标准，IEEE754双精度浮点数（double）表示如下图所示。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"IEEE754 double在内存中的形式[1]\" loading=\"lazy\" src=\"https://upload.wikimedia.org/wikipedia/commons/a/a9/IEEE_754_Double_Floating_Point_Format.svg\"\u003e\nIEEE754 double在内存中的形式[1]\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003esign bit：符号位，1位，用来表示正负号，0表示非负；1表示负\u003c/li\u003e\n\u003cli\u003eexponent：指数位，11位，用来表示次方数，是一个无符号数\u003c/li\u003e\n\u003cli\u003efraction：尾数位，52位，用来表示精确度，也是一个无符号数，有些资料也叫做mantissa或significand\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e这种表示形式有两点需要注意。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e第一，既然exponent是无符号的，那么怎样表示负指数呢？\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIEEE754规定，二进制串中算得的e需要减去一个偏移量bias，对于double，bias=1023，即e’=e-bias。因为\\(e\\in[0,2^{11}-1]\\)，所以最终\\(e’\\in[-2^{10}+1,2^{10}]\\)。但是如果把e本身看作有符号数e”，则\\(e”\\in[-2^{10},2^{10}-1]\\)，既然e”和e’相差微小，为什么不直接把e看成有符号数，而非要把它看成无符号数，再减去一个偏移量bias呢？\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"http://stackoverflow.com/questions/2612775/why-ieee-floating-point-number-calculate-exponent-using-a-biased-form\"\u003e这是因为如果把e看成无符号数再减偏移量，浮点数大小比较速度更快。\u003c/a\u003e引用\u003ca href=\"https://en.wikipedia.org/wiki/Exponent_bias\"\u003e维基百科\u003c/a\u003e的一段话：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eBy arranging the fields so that the sign bit is in the most significant bit position, the biased exponent in the middle, then the mantissa in the least significant bits, the resulting value will be ordered properly, whether it’s interpreted as a floating point or integer value. This allows high speed comparisons of floating point numbers using fixed point hardware.\u003c/p\u003e","title":"浮点数知识及Grisu算法介绍"},{"content":"去年暑假在北大计算所实习的时候，任务之一就是批量下载百度图片。当时没学python，用c#实现了一个简易版本的批量下载器，如下图。\nC#版本百度图片批量下载器（抓的是百度的wap站点，现在好像不能用了）\n当时“时间紧，任务重“，既没仔细研究百度图片API，也没处理好界面线程阻塞的问题。这个问题其实很有意思，趁着暑假在家，实现了一个比较完美的python版本，先上效果图。\npython3版本百度图片批量下载器\n新版使用了python-3.4.3.amd64.msi + PyQt5-5.5-gpl-Py3.4-Qt5.5.0-x64.exe + eric6-6.0.8.zip + cx_Freeze-4.3.4-cp34-none-win_amd64.whl，完整项目在我的GitHub上。大致有如下几点工作：\n研究百度图片API，获取原始图片URL列表 使用python3进行多线程下载 利用pyqt5实现界面 利用cx_Freeze4打包整个程序 下面记录每个步骤的要点，供后人参考。\n百度图片API 正常使用百度图片搜索的时候，URL是这样的：\nhttp://image.baidu.com/search/index?ct=201326592\u0026z=0\u0026tn=baiduimage\u0026ipn=r\u0026word=%E6%AD%A6%E6%B1%89%E5%A4%A7%E5%AD%A6\u0026pn=0\u0026istype=2\u0026ie=utf-8\u0026oe=utf-8\u0026cl=2\u0026lm=-1\u0026st=-1\u0026fr=\u0026fmq=1439374041843_R\u0026ic=0\u0026se=\u0026sme=\u0026width=0\u0026height=0\u0026face=0\n里面有很多参数，有些我们并不需要，精简之后大概是这样的：\nhttp://image.baidu.com/i?tn=baiduimage\u0026ie=utf-8\u0026word=%E7%BE%8E%E5%A5%B3\u0026pn=\u0026rn=\u0026z=\nword为搜索关键词；pn为page number当前是第几页，实际含义是image id，表示第几张图片，从0开始；rn为每一页的图片数量，最大为60；z表示图片尺寸，z=9特大尺寸，z=3大尺寸，z=2中等尺寸，z=1小尺寸，z=0所有尺寸。\n但是这个URL是给”人“看的，下一页的图片是动态加载的，其html代码的图片URL数量固定。一番查询之后发现，将tn=baiduimage换成tn=resultjson_com能获取到所有图片URL的json，json当然是给”猴“看的，这样就能轻松获取到所有图片的URL。\n慢着，仔细看看json中的objURL，是一串连”猴“都看不懂的字符串，原来百度把图片真实URL加密了，好在加密方法是简单的字符映射，参考这篇博客成功解密。\n更新：tn=resultjson_com的objURL是加密了，但是tn=resultjson的objURL并没有加密，所以采用tn=resultjson最佳。\n通过控制pn和rn就能获取指定数量的图片URL，但是我发现rn最大只能为60，并且不同的pn可能会有相同的图片url（比如pn=0和pn=1都有ippr_z2C$qAzdH3FAzdH3Fooo_z\u0026amp;e3Bd8vs7k_z\u0026amp;e3Bv54_z\u0026amp;e3BvgAzdH3F7rs5w1utsjAzdH3Fda8nAzdH3Fa080AzdH3Fda8na080aldm9bb8m_z\u0026amp;e3B3r2这个objURL），所以使用python的集合（set）去重。\n更新：pn实际上指图片的id，pn=0、rn=60能获取到从0~59这60个URL列表，pn=1、rn=60能获取到从1~60这60个URL列表，所以pn=0和pn=1的列表中当然有59个是重复的。正确的做法是pn=0、rn=60获取0~59这60个URL列表，然后pn=60、rn=60获取60~119这60个列表，以此类推，这样获取到的URL就不会有重复的了。\n获取图片URL列表的简要代码如下：\n1 2 3 4 5 6 7 8 9 10 11 def ParseJSON(self, pn, rn, st): url = \u0026#39;http://image.baidu.com/i?tn=resultjson_com\u0026amp;amp;amp;ie=utf-8\u0026amp;amp;amp;word=%s\u0026amp;amp;amp;pn=%d\u0026amp;amp;amp;rn=%d\u0026amp;amp;amp;z=%d\u0026#39;%(self.word, pn, rn, self.size) #print(url) request = urllib.request.Request(url = url, headers = my_header) html = urllib.request.urlopen(request).read() hjson = json.loads(html.decode(\u0026#39;gbk\u0026#39;)) for i in range(0, len(hjson[\u0026#39;data\u0026#39;])-1):#最后一个数据为空 img_url = self.DecodeURL(hjson[\u0026#39;data\u0026#39;][i][\u0026#39;objURL\u0026#39;]) if img_url not in st: st.add(img_url)#去重 self.progressBar_updated_signal.emit()#更新进度条 DecodeURL是解密函数。很奇怪，json最后一个数据是空的。\n更新：文章末尾的最新代码已经不需要set去重和DecodeURL解密了。\npython3多线程下载 多线程下载图片主要参考了这个例子，只是将其转换为python3的形式，不得不感叹python的易用性，创建线程和下载图片一两行代码就可以完成，太方便了。这个例子有点像单生产者多消费者模型，创建了4个线程之后，并不需要告诉a线程下载哪几张图片，这4个线程会自定从队列里获取，互斥变量的访问也不会出错，减轻了程序员很多任务。\n关于python抓取网络资源的介绍，这篇博客介绍得很全面。有些URL并不是图片的真正地址，访问之后还会进行跳转，这种情况在使用urlretrieve下载图片时可能会抛出URLError异常。其他还可能遇到timeout、HTTPError、OSError等异常，可以使用下面的方式一次性捕获所有异常。\n1 2 3 4 try: urllib.request.urlretrieve(img_url, self.dir + \u0026#39;/\u0026#39; + img_url.split(\u0026#39;/\u0026#39;)[-1]) except Exception as e: print(\u0026#34;—–%s: %s—–n\u0026#34;%(type(e), img_url)) pyqt5实现界面 大二大三的时候接触过c++ qt4 gui编程，现在改python了，不过基本思想差不多，pyqt和c++qt的api基本相同，所以借助eric6实现了python和qt的联接。\n关于eric的使用教程，网上很多，这个讲解很详细，不过如果在windows上，安装没那么复杂，安装eric之前先安装好python3和pyqt5就行了，不用任何配置。eric熟练之后很方便了，直接拖拽控件画界面。\n在使用pyqt5的时候有一些坑需要注意，尤其是我使用的是最新版的python3和qt5，网上的资料不是很多。我遇到的两个主要坑是qt的信号和槽以及界面线程阻塞的问题。\n1 2 3 4 5 6 def on_download_pushButton_clicked(self): if self.check_option() == 1: de = DownloadEngine(self.word_lineEdit.text(), self.size_radio_group.checkedId(), self.num_spinBox.value(), self.dir_lineEdit.text(), self.thread_spinBox.value(),self.progressBar) de.Run() msg_box = QMessageBox(QMessageBox.Information, \u0026#34;提示\u0026#34;, \u0026#34;下载完毕\u0026#34;) msg_box.exec_() 上面这一段是我最开始的按钮槽函数，点击下载按钮之后，实例化一个DownloadEngine，然后de.Run()开始下载，要等到下载完毕de.Run()返回后，流程才会往下走，弹出提示框。但是下载过程耗时较长，这样整个界面线程阻塞，程序出现假死状态。\n后来参考A、B两个例子，令DownloadEngine继承QThread，用de.start()开启一个新的下载线程，界面线程继续往下走，当de下载完毕后，发送download_done_signal信号，界面接收到该信号后弹出提示框。第二版程序大概如下：\n1 2 3 4 5 def on_download_pushButton_clicked(self): if self.check_option() == 1: de = DownloadEngine(self.word_lineEdit.text(), self.size_radio_group.checkedId(), self.num_spinBox.value(), self.dir_lineEdit.text(), self.thread_spinBox.value(), self.progressBar) de.start() de.download_done_signal.connect(self.download_done_slot) 一切似乎很正确，但是点击下载按钮后程序崩溃，提示pythonw.exe已停止工作，我开始以为是python或者pyqt5的问题，重装一遍问题依旧。百思不得其解之后，用命令行运行py程序，cmd提示QThread: Destroyed while thread is still running，原来de是该函数的局部变量，当de.start()后，函数继续往下走直到结束，但是de的下载任务可能还没完成，所以导致上面的错误。解决办法就是将de变为该类的成员变量，将de改为self.de。\n有了这一个编写信号和槽函数的经验之后，准备实现进度条的功能，同样要保证界面线程不阻塞，所以创建了progressBar_updated_signal信号和相应槽函数。\n但是因为界面是直接和DownloadEngine联系的，但真正的下载工作是在ImageDownloadThread完成，所以progressBar_updated_signal信号最原始的发出地是ImageDownloadThread。这里面的信号传递关系如下图所示：\n“进度条更新”信号传递关系\npython3多线程下载代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 # -*- coding: utf-8 -*- import urllib.request import json import socket import queue from PyQt5.QtCore import * global my_header my_header = {\u0026#39;User-Agent\u0026#39;:\u0026#39;Mozilla/5.0\u0026#39;} global bad bad = 0 class ImageDownloadThread(QThread): sub_progressBar_updated_signal = pyqtSignal() def __init__(self,queue_in, dir_in): #进程间通过队列通信，所以每个进程需要用到同一个队列初始化 super(ImageDownloadThread,self).__init__() self.my_queue=queue_in self.dir = dir_in #self.setDaemon(True) #守护线程 self.start() #启动线程 #使用队列实现进程间通信 def run(self): while (True): global bad img_url = self.my_queue.get() socket.setdefaulttimeout(5)#这里对整个socket层设置超时时间。后续连接中如果再使用到socket，不必再设置 try: urllib.request.urlretrieve(img_url, self.dir + \u0026#39;/\u0026#39; + img_url.split(\u0026#39;/\u0026#39;)[-1]) except Exception as e: print(\u0026#34;—–%s: %s—–n\u0026#34;%(type(e), img_url)) bad += 1 self.sub_progressBar_updated_signal.emit() if self.my_queue.empty(): break self.my_queue.task_done() #当使用者线程调用 task_done() 以表示检索了该项目、并完成了所有的工作时，那么未完成的任务的总数就会减少。 class DownloadEngine(QThread): download_done_signal = pyqtSignal(int) status_changed_signal = pyqtSignal(str) progressBar_updated_signal = pyqtSignal() def __init__(self, word_in, size_in, num_in, dir_in, thread_num_in): super(DownloadEngine,self).__init__() self.word = urllib.parse.quote(word_in) self.size = size_in self.num = num_in self.dir = dir_in self.thread_num = thread_num_in def ParseJSON(self, pn, rn, qe): url = \u0026#39;http://image.baidu.com/i?tn=resultjson\u0026amp;ie=utf-8\u0026amp;word=%s\u0026amp;pn=%d\u0026amp;rn=%d\u0026amp;z=%d\u0026#39;%(self.word, pn, rn, self.size) #print(url) request = urllib.request.Request(url = url, headers = my_header) html = urllib.request.urlopen(request).read() hjson = json.loads(html.decode(\u0026#39;gbk\u0026#39;)) for i in range(0, len(hjson[‘data’])-1):#最后一个数据为空 qe.put(hjson[\u0026#39;data\u0026#39;][i][\u0026#39;objURL\u0026#39;]) self.progressBar_updated_signal.emit()#更新进度条 def GetImgUrlQueue(self): img_url_queue = queue.Queue(0) if self.num \u0026lt;= 60: self.ParseJSON(0, self.num, img_url_queue) else: n = self.num / 60 n = int(n) for i in range(n): self.ParseJSON(i * 60, 60, img_url_queue) self.ParseJSON(n * 60, self.num – n * 60, img_url_queue) return img_url_queue def sub_update_progressBar(self): self.progressBar_updated_signal.emit() def run(self): global bad bad = 0 self.status_changed_signal.emit(\u0026#39;获取URL\u0026#39;) img_url_queue = self.GetImgUrlQueue() threads = [] self.status_changed_signal.emit(‘下载图片’) #多线程爬去图片 for i in range(self.thread_num): thread=ImageDownloadThread(img_url_queue, self.dir) thread.sub_progressBar_updated_signal.connect(self.sub_update_progressBar) threads.append(thread) #合并进程，当子进程结束时，主进程才可以执行 for thread in threads: thread.wait() self.status_changed_signal.emit(\u0026#39;下载完成\u0026#39;) self.download_done_signal.emit(bad) pyqt5界面代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 # -*- coding: utf-8 -*- \u0026#34;\u0026#34;\u0026#34; Module implementing MainDialog. \u0026#34;\u0026#34;\u0026#34; from PyQt5.QtCore import * from PyQt5.QtWidgets import * from Ui_main import Ui_Dialog from DownloadEngine import DownloadEngine import webbrowser class MainDialog(QDialog, Ui_Dialog): \u0026#34;\u0026#34;\u0026#34; Class documentation goes here. \u0026#34;\u0026#34;\u0026#34; def __init__(self, parent=None): \u0026#34;\u0026#34;\u0026#34; Constructor @param parent reference to the parent widget (QWidget) \u0026#34;\u0026#34;\u0026#34; super(MainDialog, self).__init__(parent) self.setupUi(self) self.size_radio_group = QButtonGroup() self.size_radio_group.addButton(self.total_radioButton, 0) self.size_radio_group.addButton(self.XL_radioButton, 9) self.size_radio_group.addButton(self.L_radioButton, 3) self.size_radio_group.addButton(self.M_radioButton, 2) self.size_radio_group.addButton(self.S_radioButton, 1) self.count = 0 def check_option(self): if self.word_lineEdit.text() == \u0026#34;\u0026#34;: msg_box = QMessageBox(QMessageBox.Warning, \u0026#34;警告\u0026#34;, \u0026#34;请输入搜索关键词！\u0026#34;) msg_box.exec_() return 0 if self.dir_lineEdit.text() == \u0026#34;\u0026#34;: msg_box = QMessageBox(QMessageBox.Warning, \u0026#34;警告\u0026#34;, \u0026#34;请选择图片存储目录！\u0026#34;) msg_box.exec_() return 0 return 1 @pyqtSlot() def on_dir_pushButton_clicked(self): \u0026#34;\u0026#34;\u0026#34; Slot documentation goes here. \u0026#34;\u0026#34;\u0026#34; # TODO: not implemented yet dir = QFileDialog.getExistingDirectory(self, \u0026#34;选择图片存储目录\u0026#34;,\u0026#34;.\u0026#34;) self.dir_lineEdit.setText(dir) @pyqtSlot() def on_download_pushButton_clicked(self): \u0026#34;\u0026#34;\u0026#34; Slot documentation goes here. \u0026#34;\u0026#34;\u0026#34; # TODO: not implemented yet self.progressBar.setValue(0) if self.check_option() == 1: self.progressBar.setMaximum(self.num_spinBox.value()) self.download_pushButton.setEnabled(False) self.de = DownloadEngine(self.word_lineEdit.text(), self.size_radio_group.checkedId(), self.num_spinBox.value(), self.dir_lineEdit.text(), self.thread_spinBox.value()) self.de.start() self.de.status_changed_signal.connect(self.status_changed_slot) self.de.download_done_signal.connect(self.download_done_slot) self.de.progressBar_updated_signal.connect(self.progressBar_updated_slot) @pyqtSlot() def on_src_pushButton_clicked(self): \u0026#34;\u0026#34;\u0026#34; Slot documentation goes here. \u0026#34;\u0026#34;\u0026#34; # TODO: not implemented yet webbrowser.open(\u0026#34;https://github.com/Beeder/BaiduImageDownloader\u0026#34;) def progressBar_updated_slot(self): self.count += 1 self.progressBar.setValue(self.count) def status_changed_slot(self, tip): self.status_label.setText(tip) self.count = 0 if tip != \u0026#39;下载完成\u0026#39;: self.progressBar.setValue(0) def download_done_slot(self, bad): msg_box = QMessageBox(QMessageBox.Information, \u0026#34;提示\u0026#34;, \u0026#34;下载完毕n成功%d,失败%d\u0026#34;%(self.num_spinBox.value() – bad, bad)) msg_box.exec_() self.download_pushButton.setEnabled(True) if __name__ == \u0026#34;__main__\u0026#34;: import sys app = QApplication(sys.argv) Dialog = MainDialog() Dialog.show() sys.exit(app.exec_()) cx_Freeze4打包 目前有好几个python打包程序，但是只有cx_Freeze明确表示支持python3，所以非他莫属了。\n在sourceforge下载cx_Freeze-4.3.3.win-amd64-py3.4.msi，安装；根据官方指南编写setup.py代码，将setup.py放到工程根目录下，执行python setup.py bdist_msi；报错`AttributeError:’module’object has no attribute ‘fix_up_module’。原来这是cx_Freeze-4.3.3版本的一个bug，利用替换的方法，安装4.3.4版本，问题解决。\n打包完成之后生成一个BaiduImageDownloader-0.1-amd64.msi文件，拷贝到其他电脑上也可正常运行。Winows7 64位用户可以点击下载BaiduImageDownloader-0.1-amd64.msi。\n（完）\n","permalink":"http://localhost:1313/posts/2015-08-13-baidu-image-downloader-python3-pyqt5-eric6-cx_freeze4/","summary":"\u003cp\u003e去年暑假在北大计算所实习的时候，任务之一就是批量下载百度图片。当时没学python，用c#实现了一个简易版本的批量下载器，如下图。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"C#版本百度图片批量下载器（抓的是百度的wap站点，现在好像不能用了）\" loading=\"lazy\" src=\"/posts/2015-08-13-baidu-image-downloader-python3-pyqt5-eric6-cx_freeze4/BaiduImageDownloader1.png\"\u003e\nC#版本百度图片批量下载器（抓的是百度的wap站点，现在好像不能用了）\u003c/p\u003e\n\u003cp\u003e当时“时间紧，任务重“，既没仔细研究百度图片API，也没处理好界面线程阻塞的问题。这个问题其实很有意思，趁着暑假在家，实现了一个比较完美的python版本，先上效果图。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"python3版本百度图片批量下载器\" loading=\"lazy\" src=\"/posts/2015-08-13-baidu-image-downloader-python3-pyqt5-eric6-cx_freeze4/BaiduImageDownloader2.png\"\u003e\npython3版本百度图片批量下载器\u003c/p\u003e\n\u003cp\u003e新版使用了\u003ca href=\"https://www.python.org/ftp/python/3.4.3/python-3.4.3.amd64.msi\"\u003epython-3.4.3.amd64.msi\u003c/a\u003e + \u003ca href=\"http://sourceforge.net/projects/pyqt/files/PyQt5/PyQt-5.5/PyQt5-5.5-gpl-Py3.4-Qt5.5.0-x64.exe\"\u003ePyQt5-5.5-gpl-Py3.4-Qt5.5.0-x64.exe\u003c/a\u003e + \u003ca href=\"http://downloads.sourceforge.net/project/eric-ide/eric6/stable/6.0.8/eric6-6.0.8.zip?r=http%3A%2F%2Fsourceforge.net%2Fprojects%2Feric-ide%2Ffiles%2Feric6%2Fstable%2F\u0026amp;ts=1439435222\u0026amp;use_mirror=nchc\"\u003eeric6-6.0.8.zip\u003c/a\u003e + \u003ca href=\"http://www.lfd.uci.edu/~gohlke/pythonlibs/3i673h27/cx_Freeze-4.3.4-cp34-none-win_amd64.whl\"\u003ecx_Freeze-4.3.4-cp34-none-win_amd64.whl\u003c/a\u003e，完整项目在\u003ca href=\"https://github.com/01joy/BaiduImageDownloader\"\u003e我的GitHub上\u003c/a\u003e。大致有如下几点工作：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e研究百度图片API，获取原始图片URL列表\u003c/li\u003e\n\u003cli\u003e使用python3进行多线程下载\u003c/li\u003e\n\u003cli\u003e利用pyqt5实现界面\u003c/li\u003e\n\u003cli\u003e利用cx_Freeze4打包整个程序\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e下面记录每个步骤的要点，供后人参考。\u003c/p\u003e\n\u003ch1 id=\"百度图片api\"\u003e百度图片API\u003c/h1\u003e\n\u003cp\u003e正常使用百度图片搜索的时候，URL是这样的：\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"http://image.baidu.com/search/index?ct=201326592\u0026amp;z=0\u0026amp;tn=baiduimage\u0026amp;ipn=r\u0026amp;word=%E6%AD%A6%E6%B1%89%E5%A4%A7%E5%AD%A6\u0026amp;pn=0\u0026amp;istype=2\u0026amp;ie=utf-8\u0026amp;oe=utf-8\u0026amp;cl=2\u0026amp;lm=-1\u0026amp;st=-1\u0026amp;fr=\u0026amp;fmq=1439374041843_R\u0026amp;ic=0\u0026amp;se=\u0026amp;sme=\u0026amp;width=0\u0026amp;height=0\u0026amp;face=0\"\u003ehttp://image.baidu.com/search/index?ct=201326592\u0026z=0\u0026tn=baiduimage\u0026ipn=r\u0026word=%E6%AD%A6%E6%B1%89%E5%A4%A7%E5%AD%A6\u0026pn=0\u0026istype=2\u0026ie=utf-8\u0026oe=utf-8\u0026cl=2\u0026lm=-1\u0026st=-1\u0026fr=\u0026fmq=1439374041843_R\u0026ic=0\u0026se=\u0026sme=\u0026width=0\u0026height=0\u0026face=0\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e里面有很多参数，有些我们并不需要，精简之后大概是这样的：\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"http://image.baidu.com/i?tn=baiduimage\u0026amp;ie=utf-8\u0026amp;word=%E7%BE%8E%E5%A5%B3\u0026amp;pn=\u0026amp;rn=\u0026amp;z=\"\u003ehttp://image.baidu.com/i?tn=baiduimage\u0026ie=utf-8\u0026word=%E7%BE%8E%E5%A5%B3\u0026pn=\u0026rn=\u0026z=\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eword为搜索关键词；pn为page number\u003cdel\u003e当前是第几页，\u003c/del\u003e\u003cstrong\u003e实际含义是image id\u003c/strong\u003e，表示第几张图片，从0开始；rn为每一页的图片数量，最大为60；z表示图片尺寸，z=9特大尺寸，z=3大尺寸，z=2中等尺寸，z=1小尺寸，z=0所有尺寸。\u003c/p\u003e\n\u003cp\u003e但是这个URL是给”人“看的，下一页的图片是动态加载的，其html代码的图片URL数量固定。一番查询之后发现，将tn=baiduimage换成tn=resultjson_com能获取到所有图片URL的json，json当然是给”猴“看的，这样就能轻松获取到所有图片的URL。\u003c/p\u003e\n\u003cp\u003e慢着，仔细看看json中的objURL，是一串连”猴“都看不懂的字符串，原来百度把图片真实URL加密了，好在加密方法是简单的字符映射，参考\u003ca href=\"http://blog.csdn.net/hbuxiaoshe/article/details/44780653\"\u003e这篇博客\u003c/a\u003e成功解密。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e更新：tn=resultjson_com的objURL是加密了，但是tn=resultjson的objURL并没有加密，所以采用tn=resultjson最佳。\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e通过控制pn和rn就能获取指定数量的图片URL，但是我发现rn最大只能为60，并且不同的pn可能会有相同的图片url（比如\u003ca href=\"http://image.baidu.com/i?tn=resultjson_com\u0026amp;ie=utf-8\u0026amp;word=mit\u0026amp;pn=0\u0026amp;rn=60\u0026amp;z=9\"\u003epn=0\u003c/a\u003e和\u003ca href=\"http://image.baidu.com/i?tn=resultjson_com\u0026amp;ie=utf-8\u0026amp;word=mit\u0026amp;pn=1\u0026amp;rn=60\u0026amp;z=9\"\u003epn=1\u003c/a\u003e都有ippr_z2C$qAzdH3FAzdH3Fooo_z\u0026amp;e3Bd8vs7k_z\u0026amp;e3Bv54_z\u0026amp;e3BvgAzdH3F7rs5w1utsjAzdH3Fda8nAzdH3Fa080AzdH3Fda8na080aldm9bb8m_z\u0026amp;e3B3r2这个objURL），所以使用python的集合（set）去重。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e更新：pn实际上指图片的id，pn=0、rn=60能获取到从0~59这60个URL列表，pn=1、rn=60能获取到从1~60这60个URL列表，所以pn=0和pn=1的列表中当然有59个是重复的。正确的做法是pn=0、rn=60获取0~59这60个URL列表，然后pn=60、rn=60获取60~119这60个列表，以此类推，这样获取到的URL就不会有重复的了。\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e获取图片URL列表的简要代码如下：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\n\u003ctable style=\"border-spacing:0;padding:0;margin:0;border:0;\"\u003e\u003ctr\u003e\u003ctd style=\"vertical-align:top;padding:0;margin:0;border:0;\"\u003e\n\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 1\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 2\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 3\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 4\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 5\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 6\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 7\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 8\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e 9\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e10\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e11\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd style=\"vertical-align:top;padding:0;margin:0;border:0;;width:100%\"\u003e\n\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eParseJSON\u003c/span\u003e(self, pn, rn, st):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    url \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;http://image.baidu.com/i?tn=resultjson_com\u0026amp;amp;amp;ie=utf-8\u0026amp;amp;amp;word=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e%s\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026amp;amp;amp;pn=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e%d\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026amp;amp;amp;rn=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e%d\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026amp;amp;amp;z=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e%d\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e%\u003c/span\u003e(self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eword, pn, rn, self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003esize)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#75715e\"\u003e#print(url)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    request \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e urllib\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003erequest\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eRequest(url \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e url, headers \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e my_header)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    html \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e urllib\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003erequest\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eurlopen(request)\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eread()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    hjson \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e json\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eloads(html\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003edecode(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;gbk\u0026#39;\u003c/span\u003e))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e i \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e range(\u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e, len(hjson[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;data\u0026#39;\u003c/span\u003e])\u003cspan style=\"color:#f92672\"\u003e-\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e):\u003cspan style=\"color:#75715e\"\u003e#最后一个数据为空\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        img_url \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eDecodeURL(hjson[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;data\u0026#39;\u003c/span\u003e][i][\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;objURL\u0026#39;\u003c/span\u003e])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e img_url \u003cspan style=\"color:#f92672\"\u003enot\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e st:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            st\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eadd(img_url)\u003cspan style=\"color:#75715e\"\u003e#去重\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            self\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eprogressBar_updated_signal\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eemit()\u003cspan style=\"color:#75715e\"\u003e#更新进度条\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003eDecodeURL是解密函数。很奇怪，json最后一个数据是空的。\u003c/p\u003e","title":"百度图片批量下载器（python3 + pyqt5 + eric6 + cx_Freeze4）"},{"content":"2015年6月27日，武汉大学在梅园操场举办了2015年毕业典礼。\n武汉大学2015年毕业典礼，正在发言的是雷军学长[1]\n武汉大学2015年毕业典礼[2]\n坐在台下，顿感恍惚，四年前同样在梅操，同样是这些人，我们举办开学典礼。\n武汉大学2011年开学典礼[3]\n原来梅操到梅操的距离只有四年。\n毕业典礼结束，下午集体收拾行李，大家都默默无语。晚上去红牛—-大一第一次聚餐的地方—-吃最后的晚餐，这次聚餐喝了两箱啤酒，6瓶白酒！白酒下肚，前一口酒落地又向上翻滚，和后一口酒相互撞击，四年的往事喷涌而出。离别之际，每个人都把自己的心声说出来了，说出了自己的家境、对某某的感情、一个宿舍的兄弟情，说出了自己的抱负、未来的理想，再互相拥抱、道一声珍重。\n山水一程，三生有幸[4]\n回到宿舍，所有人吐得一塌糊涂，昏睡过去。也许这就是离别的滋味，折磨着你，让你难受，只有把它吐出来，离开了，平静了，一切就好了。\n第二天醒来，发现隔壁宿舍的几个哥们已经走了，宿舍冷清了许多。去小卖部买了一些非必需品，只为把卡里的几十块钱用掉。打包行李，准备出发。\n毕业了，离开了，那些大一的迷茫、兼职，大二的信息安全竞赛，大三繁重的课业、为保研奋斗的数学建模竞赛，大四悠闲的生活也将躲藏在记忆的某个角落，不再被轻易的发现。武大的樱花、牌坊、樱顶、新图、青楼、梅操电影、珞珈之声、每天晚上在奥场穿着17号球衣跑步的女生、一起练笛的同学、在梅园食堂吃饭的一对情侣、幽默装逼的室友，这一幅幅画面，也将随着时间的车轮，慢慢消散。\n天下没有不散的筵席，我们来到这个世上，就注定要历经悲欢离合。在中国最美丽的大学，度过了我人生中最美好的年华，山水一程，三生有幸，感谢有你。\n别怕，梦的方向叫做闯，青春还没散场！\n参考：\n[1]. 武汉大学官方微博\n[2]. 武大新闻网：http://news.whu.edu.cn/info/1002/43788.htm\n[3]. 守望珞珈的新浪博客：http://blog.sina.com.cn/s/blog_4da93d1f0100t6v9.html\n[4]. 珞珈山水bbs毕业封面：http://bbs.whu.edu.cn/\n","permalink":"http://localhost:1313/posts/2015-06-28-farewell-to-whu/","summary":"\u003cp\u003e2015年6月27日，武汉大学在梅园操场举办了2015年毕业典礼。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"武汉大学2015年毕业典礼，正在发言的是雷军学长[1]\" loading=\"lazy\" src=\"https://i0.wp.com/ww1.sinaimg.cn/large/634fd979jw1etiecww24cj20hs0dctbj.jpg\"\u003e\n武汉大学2015年毕业典礼，正在发言的是雷军学长[1]\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"武汉大学2015年毕业典礼[2]\" loading=\"lazy\" src=\"https://i0.wp.com/news.whu.edu.cn/_mediafile/whu_news/2015/06/27/29kc177qza.jpg\"\u003e\n武汉大学2015年毕业典礼[2]\u003c/p\u003e\n\u003cp\u003e坐在台下，顿感恍惚，四年前同样在梅操，同样是这些人，我们举办开学典礼。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"武汉大学2011年开学典礼[3]\" loading=\"lazy\" src=\"https://i0.wp.com/ww3.sinaimg.cn/large/005Muw7zjw1etjl1cs943j30j60bpgpm.jpg\"\u003e\n武汉大学2011年开学典礼[3]\u003c/p\u003e\n\u003cp\u003e原来梅操到梅操的距离只有四年。\u003c/p\u003e\n\u003cp\u003e毕业典礼结束，下午集体收拾行李，大家都默默无语。晚上去红牛—-大一第一次聚餐的地方—-吃最后的晚餐，这次聚餐喝了两箱啤酒，6瓶白酒！白酒下肚，前一口酒落地又向上翻滚，和后一口酒相互撞击，四年的往事喷涌而出。离别之际，每个人都把自己的心声说出来了，说出了自己的家境、对某某的感情、一个宿舍的兄弟情，说出了自己的抱负、未来的理想，再互相拥抱、道一声珍重。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"whu_bbs_graduation_2015\" loading=\"lazy\" src=\"/posts/2015-06-28-farewell-to-whu/whu_bbs_graduation_2015.jpg\"\u003e\n山水一程，三生有幸[4]\u003c/p\u003e\n\u003cp\u003e回到宿舍，所有人吐得一塌糊涂，昏睡过去。也许这就是离别的滋味，折磨着你，让你难受，只有把它吐出来，离开了，平静了，一切就好了。\u003c/p\u003e\n\u003cp\u003e第二天醒来，发现隔壁宿舍的几个哥们已经走了，宿舍冷清了许多。去小卖部买了一些非必需品，只为把卡里的几十块钱用掉。打包行李，准备出发。\u003c/p\u003e\n\u003cp\u003e毕业了，离开了，那些大一的迷茫、兼职，大二的信息安全竞赛，大三繁重的课业、为保研奋斗的数学建模竞赛，大四悠闲的生活也将躲藏在记忆的某个角落，不再被轻易的发现。武大的樱花、牌坊、樱顶、新图、青楼、梅操电影、珞珈之声、每天晚上在奥场穿着17号球衣跑步的女生、一起练笛的同学、在梅园食堂吃饭的一对情侣、幽默装逼的室友，这一幅幅画面，也将随着时间的车轮，慢慢消散。\u003c/p\u003e\n\u003cp\u003e天下没有不散的筵席，我们来到这个世上，就注定要历经悲欢离合。在中国最美丽的大学，度过了我人生中最美好的年华，山水一程，三生有幸，感谢有你。\u003c/p\u003e\n\u003cp\u003e别怕，梦的方向叫做闯，青春还没散场！\u003c/p\u003e\n\u003cp\u003e参考：\u003c/p\u003e\n\u003cp\u003e[1]. 武汉大学官方微博\u003c/p\u003e\n\u003cp\u003e[2]. 武大新闻网：\u003ca href=\"http://news.whu.edu.cn/info/1002/43788.htm\"\u003ehttp://news.whu.edu.cn/info/1002/43788.htm\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e[3]. 守望珞珈的新浪博客：\u003ca href=\"http://blog.sina.com.cn/s/blog_4da93d1f0100t6v9.html\"\u003ehttp://blog.sina.com.cn/s/blog_4da93d1f0100t6v9.html\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e[4]. 珞珈山水bbs毕业封面：\u003ca href=\"http://bbs.whu.edu.cn/\"\u003ehttp://bbs.whu.edu.cn/\u003c/a\u003e\u003c/p\u003e","title":"再见武大"},{"content":"今天参加了【珞珈阅读广场第89期】《礼物》（影像阅读），感触很多，收获也很多，其中最大的收获就是体会到了交流的乐趣。\n【珞珈阅读广场第89期】《礼物》（影像阅读）[1]\n影片《礼物》讲述了一位功成名就的大叔和身为小偷的女生相互救赎的故事。大叔白手起家，一路打拼，最后坐拥万贯家财，却抛弃了妻子和女儿，导致妻子自杀；女生的父亲早逝，母亲生活又不检点，女生曾差点一刀把母亲捅死，为了偿还男朋友的债务，女生甚至当起了小偷。在一次行窃过程中被大叔抓住，大叔要求女生当他的司机和搬运工，带他去东京，给女儿送一个礼物。在去东京的路上，大叔走访了自己曾经到过的很多地方，但大多数都是激情满怀而去，失望而归。到达东京，当女生知道大叔要送给女儿的礼物是自己的心脏，自己的生命的时候，女生陷入了两难的境地。但是女生最终答应的大叔的请求，帮其送出了礼物，大叔得到了救赎，女生也因为大叔的一句“要好好活着”而坚强乐观的面对生活。\n90分钟的观影结束之后，主持人抛出了如下几个问题。\n关于《礼物》这部电影，主持人提出的若干问题\n因为上学期我也参加过珞珈阅读广场的观影活动，当时也体会到了与他人交流的乐趣，现在马上要毕业了，所以跃跃欲试，想和同学们交流一下。正好第一个问题主持人点名叫我谈一谈。我当时谈了一下我对大叔这种献出自己生命拯救外孙女的行为表示了理解，并表示自己也会做出类似的事情。在场的另外一个老师就表达了他的观点，他对日本这种“野蛮粗暴”的拯救方式不太理解，也不太赞同，大叔最后的死亡过程类似于日本武士的剖腹自尽。\n关于第三个问题，大家也畅所欲言，从很多个方面谈了自己的想法，大部分还是认为大叔想要给外孙女抽一个好彩头的观点。其实这个观点要到最后大叔把这个“大吉”签绑到外孙女的病床上才能感觉得到，在对后面内容不知道的情况下，我认为最合理的解释应该是这一行为体现了大叔好强甚至“蛮横”的性格，因为他抽签的时候说自己从白手起家到现在亿万富翁，就像中了头彩一样，那么我现在抽签，也要像我经商一样，取得最好的结果。有的同学甚至解读出了大叔“执念”这一层含义。\n对于第四个问题，好几个同学分享了自己的经历或者想法。我当时表达了“虽然你现在面临不幸，请不要过多的抱怨，珍惜当下，因为你现在所遭遇的，正是你将来所怀念的；当你再故地重游的时候，也许像这位大叔一样，再也找不到当初那种美好的感觉了。“，并顺带告诉学弟学妹们，珍惜在武大的美好时光，自己马上要毕业了，对武大的一花一木都非常的不舍。\n最后一个问题，主持人给出了很好的解答，并且阐明了要拯救一个身处绝望的人的困难性，很精彩。\n交流过程中很有意思的一件事情是，主持人给出了这样一个观点”婚姻或家庭不幸的人，其子女的性格往往也会偏离常态，并且子女的婚姻或家庭也很可能会不幸。”，对于这个观点，大家的反应比较激烈，特别是在场的那位老师，表达了他的反对意见。我因为自己的家庭环境原因，反而表示了积极的一面，就是父母婚姻不幸的人，其孩子有可能反而更加珍惜婚姻，珍惜家庭，所以家庭有可能比一般家庭更加幸福。当然也有同学表示对爱的人抓得太紧，有可能适得其反，导致婚姻的破裂。主持人讲了这样一段话，很好的表达了这个观点：\n让爱恰到好处－不让疯长的孤独烧毁世界，也不让泛滥的博爱窒息自由。\n电影从晚上7:00到8:30，讨论从8:30到10:00。讨论结束的时候，主持人把本期两本书分别赠送给了我和另一位硕士毕业生，我的赠书是《那一天》。\n赠书《那一天》[2]\n讨论结束，临走的时候大家还意犹未尽，主持人对大家的讨论表示感谢，此时有一位同学表示主持人的发言也很不错。确实，整个讨论环节，主持人很好的带动起了大家发言的兴趣和积极性，包括问题的设置，主持人的点名提问以及主持人自身精彩的解说，都非常好的带动了现场的气氛，打开了观众的话匣子。不久前我刚好参加过这位主持人主持的”周末艺苑·外院专场“演出，当时主持人随机应变的能力和绝妙的口才给我留下了深刻的印象，学弟不错，加油！\n这次观影交流达到了真正交流的目的，观众中有大一大二的新生，有即将毕业的本科生和研究生，也有已经成家的中年老师，大家基于各自的背景，表达自己的想法，聆听他人的观点，达到了很好的思维发散、观点碰撞的目的。此时我想到了高中背的萧伯纳讲过的一句话：\n两个人各有一个苹果，交换之后，每个人还是只有一个苹果；然而，当两个人各有一种思想，交换之后，每个人却拥有了两种思想。\n前几天观看了踪点剧社的两部毕业大戏《理想》和《禁闭》，两部很有深意的话剧，话剧结束的时候，也有一个短暂的交流会，也很精彩。\n人很多时候会沉浸在自我的世界中，产生很多偏见，此时不妨听一听他人的观点，也许会豁然开朗或眼前一亮，觉得世界真奇妙。最后用H老师的一句话结束：技术上要多钻研，技术外要多沟通，生存两个法则。\n希望每个人都能发现并享受交流的乐趣。\n参考：\n[1]. 珞珈阅读广场第89期公告：http://www.lib.whu.edu.cn/news/view.asp?id=3354\n[2]. 豆瓣读书《那一天》：http://book.douban.com/subject/25904481/\n","permalink":"http://localhost:1313/posts/2015-06-12-the-joy-of-communication/","summary":"\u003cp\u003e今天参加了\u003ca href=\"http://www.lib.whu.edu.cn/news/view.asp?id=3354\"\u003e【珞珈阅读广场第89期】《礼物》（影像阅读）\u003c/a\u003e，感触很多，收获也很多，其中最大的收获就是体会到了交流的乐趣。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"【珞珈阅读广场第89期】《礼物》（影像阅读）[1]\" loading=\"lazy\" src=\"https://i0.wp.com/www.lib.whu.edu.cn/news/tc/readSqua89.jpg\"\u003e\n【珞珈阅读广场第89期】《礼物》（影像阅读）[1]\u003c/p\u003e\n\u003cp\u003e影片\u003ca href=\"http://movie.douban.com/subject/25878911/\"\u003e《礼物》\u003c/a\u003e讲述了一位功成名就的大叔和身为小偷的女生相互救赎的故事。大叔白手起家，一路打拼，最后坐拥万贯家财，却抛弃了妻子和女儿，导致妻子自杀；女生的父亲早逝，母亲生活又不检点，女生曾差点一刀把母亲捅死，为了偿还男朋友的债务，女生甚至当起了小偷。在一次行窃过程中被大叔抓住，大叔要求女生当他的司机和搬运工，带他去东京，给女儿送一个礼物。在去东京的路上，大叔走访了自己曾经到过的很多地方，但大多数都是激情满怀而去，失望而归。到达东京，当女生知道大叔要送给女儿的礼物是自己的心脏，自己的生命的时候，女生陷入了两难的境地。但是女生最终答应的大叔的请求，帮其送出了礼物，大叔得到了救赎，女生也因为大叔的一句“要好好活着”而坚强乐观的面对生活。\u003c/p\u003e\n\u003cp\u003e90分钟的观影结束之后，主持人抛出了如下几个问题。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"关于《礼物》这部电影，主持人提出的若干问题\" loading=\"lazy\" src=\"/posts/2015-06-12-the-joy-of-communication/questions-about-gift.jpg\"\u003e\n关于《礼物》这部电影，主持人提出的若干问题\u003c/p\u003e\n\u003cp\u003e因为上学期我也参加过珞珈阅读广场的观影活动，当时也体会到了与他人交流的乐趣，现在马上要毕业了，所以跃跃欲试，想和同学们交流一下。正好第一个问题主持人点名叫我谈一谈。我当时谈了一下我对大叔这种献出自己生命拯救外孙女的行为表示了理解，并表示自己也会做出类似的事情。在场的另外一个老师就表达了他的观点，他对日本这种“野蛮粗暴”的拯救方式不太理解，也不太赞同，大叔最后的死亡过程类似于日本武士的剖腹自尽。\u003c/p\u003e\n\u003cp\u003e关于第三个问题，大家也畅所欲言，从很多个方面谈了自己的想法，大部分还是认为大叔想要给外孙女抽一个好彩头的观点。其实这个观点要到最后大叔把这个“大吉”签绑到外孙女的病床上才能感觉得到，在对后面内容不知道的情况下，我认为最合理的解释应该是这一行为体现了大叔好强甚至“蛮横”的性格，因为他抽签的时候说自己从白手起家到现在亿万富翁，就像中了头彩一样，那么我现在抽签，也要像我经商一样，取得最好的结果。有的同学甚至解读出了大叔“执念”这一层含义。\u003c/p\u003e\n\u003cp\u003e对于第四个问题，好几个同学分享了自己的经历或者想法。我当时表达了“虽然你现在面临不幸，请不要过多的抱怨，珍惜当下，因为你现在所遭遇的，正是你将来所怀念的；当你再故地重游的时候，也许像这位大叔一样，再也找不到当初那种美好的感觉了。“，并顺带告诉学弟学妹们，珍惜在武大的美好时光，自己马上要毕业了，对武大的一花一木都非常的不舍。\u003c/p\u003e\n\u003cp\u003e最后一个问题，主持人给出了很好的解答，并且阐明了要拯救一个身处绝望的人的困难性，很精彩。\u003c/p\u003e\n\u003cp\u003e交流过程中很有意思的一件事情是，主持人给出了这样一个观点”婚姻或家庭不幸的人，其子女的性格往往也会偏离常态，并且子女的婚姻或家庭也很可能会不幸。”，对于这个观点，大家的反应比较激烈，特别是在场的那位老师，表达了他的反对意见。我因为自己的家庭环境原因，反而表示了积极的一面，就是父母婚姻不幸的人，其孩子有可能反而更加珍惜婚姻，珍惜家庭，所以家庭有可能比一般家庭更加幸福。当然也有同学表示对爱的人抓得太紧，有可能适得其反，导致婚姻的破裂。主持人讲了这样一段话，很好的表达了这个观点：\u003c/p\u003e\n\u003cp\u003e让爱恰到好处－不让疯长的孤独烧毁世界，也不让泛滥的博爱窒息自由。\u003c/p\u003e\n\u003cp\u003e电影从晚上7:00到8:30，讨论从8:30到10:00。讨论结束的时候，主持人把本期两本书分别赠送给了我和另一位硕士毕业生，我的赠书是\u003ca href=\"http://book.douban.com/subject/25904481/\"\u003e《那一天》\u003c/a\u003e。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"赠书《那一天》[2]\" loading=\"lazy\" src=\"https://img1.doubanio.com/lpic/s27950209.jpg\"\u003e\n赠书《那一天》[2]\u003c/p\u003e\n\u003cp\u003e讨论结束，临走的时候大家还意犹未尽，主持人对大家的讨论表示感谢，此时有一位同学表示主持人的发言也很不错。确实，整个讨论环节，主持人很好的带动起了大家发言的兴趣和积极性，包括问题的设置，主持人的点名提问以及主持人自身精彩的解说，都非常好的带动了现场的气氛，打开了观众的话匣子。不久前我刚好参加过这位主持人主持的”周末艺苑·外院专场“演出，当时主持人随机应变的能力和绝妙的口才给我留下了深刻的印象，学弟不错，加油！\u003c/p\u003e\n\u003cp\u003e这次观影交流达到了真正交流的目的，观众中有大一大二的新生，有即将毕业的本科生和研究生，也有已经成家的中年老师，大家基于各自的背景，表达自己的想法，聆听他人的观点，达到了很好的思维发散、观点碰撞的目的。此时我想到了高中背的萧伯纳讲过的一句话：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e两个人各有一个苹果，交换之后，每个人还是只有一个苹果；然而，当两个人各有一种思想，交换之后，每个人却拥有了两种思想。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e前几天观看了踪点剧社的两部毕业大戏《理想》和《禁闭》，两部很有深意的话剧，话剧结束的时候，也有一个短暂的交流会，也很精彩。\u003c/p\u003e\n\u003cp\u003e人很多时候会沉浸在自我的世界中，产生很多偏见，此时不妨听一听他人的观点，也许会豁然开朗或眼前一亮，觉得世界真奇妙。最后用H老师的一句话结束：\u003cstrong\u003e技术上要多钻研，技术外要多沟通，生存两个法则。\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e希望每个人都能发现并享受交流的乐趣。\u003c/p\u003e\n\u003cp\u003e参考：\u003c/p\u003e\n\u003cp\u003e[1]. 珞珈阅读广场第89期公告：\u003ca href=\"http://www.lib.whu.edu.cn/news/view.asp?id=3354\"\u003ehttp://www.lib.whu.edu.cn/news/view.asp?id=3354\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e[2]. 豆瓣读书《那一天》：\u003ca href=\"http://book.douban.com/subject/25904481/\"\u003ehttp://book.douban.com/subject/25904481/\u003c/a\u003e\u003c/p\u003e","title":"交流的乐趣"},{"content":"前几天给毕设指导老师发邮件，麻烦老师写申优推荐理由，老师回复我说她的儿子这几天高考，她不在学院，最晚要9号才能帮我写。我才意识到又是一年高考时，距离自己参加高考已经过去了四个春秋，但高中生活的场景在脑海中却依稀可见，想来是要写一篇文章追忆那平凡或不平凡的高中生活。\n在我读初中的时候，县里只有一所高中－县一中，每年中考之前，县一中都会组织一次提前批考试，如果提前批考试被录取了，正式中考的时候只要过线就能上，和现在的大学自主招生有点类似。我当时考试成绩不错，大概是全县十名左右，被分到所谓的奥赛班了。正式中考完之后，县五中开始正式招生，五中是抚州市一个老板办的私立学校，据说办学模式借鉴临川一中。当时县五中为了抢占优质生源，承诺只要去五中读书，除了3年学费全免之外，还额外奖励3000块钱，而且如果高考考上清华北大，奖励10万，考上其他十大名牌大学，奖励3万。当时考虑到五中刚开始办学，又借鉴临川一中的办学模式，老师大多是抚州的“名师”，教学质量应该不错，而且去五中读书能省不少钱，爸爸建议我去五中。我当时其实是不太情愿的，毕竟一中奥赛班聚集了全县最优秀的老师和同学，不论是环境还是各项措施，都比刚办学的五中要好。不过我还是以“只要自己认真读，在哪个学校都能取得好成绩”的理由安慰自己，去了五中。\n说实话，五中学生的层次确实要比一中学生差。不过好在学校把几十个成绩比较好的安排在了一个班里，配备了更好的老师，实行特殊管理。\n在我的印象中，高中的三年过得都一样，高三并没有比高一高二累多少，或者说高一高二并没有比高三轻松多少。每天早上6点准时起床，洗漱完之后6:20做早操，高三的时候不用做早操，改早自习了。大概6:50吃早餐，7:10开始早读。因为是理科，早读的内容不外乎英语单词、英语作文、语文背诵诗词、语文作文。8:05开始正式上课，上午四节课一直上到11:40。下课之后回家吃饭，因为妈妈在校内陪读，所以午餐能在15分钟之内解决，然后马上回到教室做几道题或者看一两个作文素材。下午1点准时午休半个小时，2:05正式上课，下午三节课一直上到4:40，好像高三的时候改成了四节课，记不清了。和中午一样，快速解决晚餐，马上回到教室，首先复习或学习语文字词，包括拼音和常考成语，当时基本把《现代汉语词典》翻熟了；然后正式晚自习，一直到晚上11点才回家洗漱睡觉。当时学校规定其他班学生10点之后就必须离开教室，但是我们班特殊规定可以自习到11点。回家洗漱完之后大概11:30了，高三的时候，我还经常在睡之前打着小电筒复习一下白天学习的内容。\n学校每两个星期放1天假，再过两个星期放2天半假，大多数同学只有在2天半假的时候才回家一趟。放假期间，除了做一两套卷子，大多数时间是在看电视，另外会去书店逛一次，不过买的大多数是高考复习资料，仅有的算得上是课外读物的就是《疯狂阅读》或者《读者》之类的了，小县城的书店也没有其他的“闲书”。高考要求阅读的几篇经典名著，几乎没有完整阅读过纸质版，高三的时候为了应付高考，时间紧，任务重，直接从机房下载了《巴黎圣母院》、《堂吉诃德》等改编电影，这才稍微了解了一下主要内容。学校也没有像样的图书馆，在石城那个小县城，不可能买到这些“高大上”的书。我相信大城市的很多高中生肯定看过很多这类世界名著，周末或者放假的时候也是在忙着学琴棋书画。这可能就是所谓的城乡教育差别吧，虽然这种差别在高考的时候体现得并不明显，农村的孩子在高中稍微刻苦一下，也能上不错的大学；但是一旦到了大学，大城市的孩子和我这种从农村走出来的孩子的差别一下就能看出来。大城市的孩子不论是在交际、口才、学识、才艺等方面都能轻松碾压农村的孩子，农村孩子虽然你很刻苦，卷面成绩不错，但是知识面不够宽广，格局比较小，几乎没有才艺；并不是城里人歧视你，不和你玩，但是和你聊美术，你懂吗，和你聊莎士比亚剧作，你看过吗，和你排练音乐舞蹈，你会吗。来到武大之后，我对这种城乡读书孩子之间的差别真的深有体会，无论我多么努力，好像总达不到他们的高度，总是无法融入他们的生活。\n高中不像大学，每个班有固定的教师，每个人有固定的座位，有自己的“左邻右舍”，坐在座位上，真的感觉很温暖。每到下课的时候，班上都闹哄哄的，同班同学之间的交流也很多，班集体的荣誉感以及个人的归属感也很强。每次打扫卫生的时候，几乎要经过每个同学的座位，问一问有没有垃圾要处理的；每次发考卷的时候，也会左顾右盼，相互逗个乐。一年中要数元旦晚会最为热闹，犹记得高三那年元旦，我为了演唱“海阔天空”，每天回家吃饭的时候就听mp3，走在路上也会小声哼唱，当然对于五音不全的我，演唱效果并不是很好:-) 晚会当天下午开始布置场地，所有人把书搬回宿舍，清空教室，在玻璃窗上贴上气球，圣诞树贴纸，或者某个小画家直接在上面画一幅画，电风扇和墙上都会挂上彩带；在教室四周摆上课桌，课桌上摆上事先买好的瓜子、花生、糖果、饮料等；同学们借来音响话筒，老师也把自己的笔记本搬到教室，一场简朴晚会现场就布置好了。晚会的所有工作人员、演员、主持人都是自己班上的同学，大家欢聚一堂，过着小集体的节日，有时候在同学和主持人的怂恿下，老师们也会激情献唱一首。现在回想起来，这种小集体归属感真的很美好，高中毕业之后，我大概再也没有过这种感觉了。\n春节过后，就是高考的紧要关头了，每周一的班会课上，老师都会给我们加油鼓劲，告诉我们大学有多轻松美好。百日会战那天，班主任甚至亲自泼墨，写下“辛苦数日，幸福一生”的对联，贴在教室的后墙上。高三，每天就是不停的做卷子、刷题，日考、周考、月考，不断的考试，往往上一张考卷还没有讲评，下一次考试又到了。考得多了，对成绩也不那么看重了，不过也基本稳定在前三。\n图片来自[1]\n距离高考只剩一个星期的时候，题量开始下降，老师也变得温柔起来，开始提醒我们注意饮食，调整生物钟，保持充足睡眠等。考前3天，学校放假，让我们回家吃好喝好，放松心情。考前1天，看考场，当时坐我前面的一个同学找到我，叫我给他抄，并威胁我如果不给他抄，则影响我考试，碰到这样一个人渣，对我的心情还是有一定影响的，我也没敢把这件事告诉我妈。当天晚上英语老师找我谈话，宽慰我，跟我说考试的时候不要遮住试卷，他能不能抄到是他的事了，况且他最多只能抄到选择填空题，主观题还得靠真才实学。高考那两天，全校其他年级放假，为的是给所有考生创造一个安静舒适的校园环境，这一点给学校点赞。高考第一天和第二天上午还算顺利，正常发挥，第二天午休没有睡着，下午考英语的时候，听力几乎没有进入状态，哈欠连连，英语是我考得最差的一科了，当然英语本来就不是我的强项。\n考完之后，回到家中，妈妈给我和哥哥洗了两个甜瓜吃，寓意我们苦尽甘来:-) 高考完的那个暑假，妈妈说让我们好好在家待着休养生息，所以基本过着猪一样的生活。6月底高考成绩出来了，六百多吧，和估分差不多，纠结的是填志愿。当时也不像现在，互联网这么发达，基本上是通过《全国普通高等学校报考指南》了解每个学校，对提前批的情况也不甚了解。后来根据往年分数线以及自己的兴趣，报了武大、吉大、川大这几个学校，很幸运，录取了第一志愿第一专业WHUCS。说实话，在填志愿之前，我只知道清华北大这两个学校，对武大这所“全国最美丽的大学”一无所知，我不是狂妄自大，而是孤陋寡闻。\n高中真的很累、很辛苦，要想坚持下去，一定要找一个可靠的精神支柱，不论是做什么事都是这样，一直以来，支持我勇往直前的都是我的亲人和我想要改变命运的决心！要说高中3年的收获，那就是它磨砺了我的意志，增强了我忍受孤独的能力，当然高中并不是我最孤独的时候，至少有我前面提到的小集体归属感；高中三年，也认识了很要好的同学兼老乡WQ、WS和MZ。\n对了，高中那会每个人都会有一个座右铭，我也不例外，很大众化，汪国真的“既然选择了远方，便只顾风雨兼程”。惊闻汪老师于2015年4月26日逝世，令人嘘唏。\n参考：\n[1]. 永不过时的高考记忆\n","permalink":"http://localhost:1313/posts/2015-06-08-my-high-school-life/","summary":"\u003cp\u003e前几天给毕设指导老师发邮件，麻烦老师写申优推荐理由，老师回复我说她的儿子这几天高考，她不在学院，最晚要9号才能帮我写。我才意识到又是一年高考时，距离自己参加高考已经过去了四个春秋，但高中生活的场景在脑海中却依稀可见，想来是要写一篇文章追忆那平凡或不平凡的高中生活。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"classroom\" loading=\"lazy\" src=\"/posts/2015-06-08-my-high-school-life/classroom.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e在我读初中的时候，县里只有一所高中－县一中，每年中考之前，县一中都会组织一次提前批考试，如果提前批考试被录取了，正式中考的时候只要过线就能上，和现在的大学自主招生有点类似。我当时考试成绩不错，大概是全县十名左右，被分到所谓的奥赛班了。正式中考完之后，县五中开始正式招生，五中是抚州市一个老板办的私立学校，据说办学模式借鉴临川一中。当时县五中为了抢占优质生源，承诺只要去五中读书，除了3年学费全免之外，还额外奖励3000块钱，而且如果高考考上清华北大，奖励10万，考上其他十大名牌大学，奖励3万。当时考虑到五中刚开始办学，又借鉴临川一中的办学模式，老师大多是抚州的“名师”，教学质量应该不错，而且去五中读书能省不少钱，爸爸建议我去五中。我当时其实是不太情愿的，毕竟一中奥赛班聚集了全县最优秀的老师和同学，不论是环境还是各项措施，都比刚办学的五中要好。不过我还是以“只要自己认真读，在哪个学校都能取得好成绩”的理由安慰自己，去了五中。\u003c/p\u003e\n\u003cp\u003e说实话，五中学生的层次确实要比一中学生差。不过好在学校把几十个成绩比较好的安排在了一个班里，配备了更好的老师，实行特殊管理。\u003c/p\u003e\n\u003cp\u003e在我的印象中，高中的三年过得都一样，高三并没有比高一高二累多少，或者说高一高二并没有比高三轻松多少。每天早上6点准时起床，洗漱完之后6:20做早操，高三的时候不用做早操，改早自习了。大概6:50吃早餐，7:10开始早读。因为是理科，早读的内容不外乎英语单词、英语作文、语文背诵诗词、语文作文。8:05开始正式上课，上午四节课一直上到11:40。下课之后回家吃饭，因为妈妈在校内陪读，所以午餐能在15分钟之内解决，然后马上回到教室做几道题或者看一两个作文素材。下午1点准时午休半个小时，2:05正式上课，下午三节课一直上到4:40，好像高三的时候改成了四节课，记不清了。和中午一样，快速解决晚餐，马上回到教室，首先复习或学习语文字词，包括拼音和常考成语，当时基本把《现代汉语词典》翻熟了；然后正式晚自习，一直到晚上11点才回家洗漱睡觉。当时学校规定其他班学生10点之后就必须离开教室，但是我们班特殊规定可以自习到11点。回家洗漱完之后大概11:30了，高三的时候，我还经常在睡之前打着小电筒复习一下白天学习的内容。\u003c/p\u003e\n\u003cp\u003e学校每两个星期放1天假，再过两个星期放2天半假，大多数同学只有在2天半假的时候才回家一趟。放假期间，除了做一两套卷子，大多数时间是在看电视，另外会去书店逛一次，不过买的大多数是高考复习资料，仅有的算得上是课外读物的就是《疯狂阅读》或者《读者》之类的了，小县城的书店也没有其他的“闲书”。高考要求阅读的几篇经典名著，几乎没有完整阅读过纸质版，高三的时候为了应付高考，时间紧，任务重，直接从机房下载了《巴黎圣母院》、《堂吉诃德》等改编电影，这才稍微了解了一下主要内容。学校也没有像样的图书馆，在石城那个小县城，不可能买到这些“高大上”的书。我相信大城市的很多高中生肯定看过很多这类世界名著，周末或者放假的时候也是在忙着学琴棋书画。这可能就是所谓的城乡教育差别吧，虽然这种差别在高考的时候体现得并不明显，农村的孩子在高中稍微刻苦一下，也能上不错的大学；但是一旦到了大学，大城市的孩子和我这种从农村走出来的孩子的差别一下就能看出来。大城市的孩子不论是在交际、口才、学识、才艺等方面都能轻松碾压农村的孩子，农村孩子虽然你很刻苦，卷面成绩不错，但是知识面不够宽广，格局比较小，几乎没有才艺；并不是城里人歧视你，不和你玩，但是和你聊美术，你懂吗，和你聊莎士比亚剧作，你看过吗，和你排练音乐舞蹈，你会吗。来到武大之后，我对这种城乡读书孩子之间的差别真的深有体会，无论我多么努力，好像总达不到他们的高度，总是无法融入他们的生活。\u003c/p\u003e\n\u003cp\u003e高中不像大学，每个班有固定的教师，每个人有固定的座位，有自己的“左邻右舍”，坐在座位上，真的感觉很温暖。每到下课的时候，班上都闹哄哄的，同班同学之间的交流也很多，班集体的荣誉感以及个人的归属感也很强。每次打扫卫生的时候，几乎要经过每个同学的座位，问一问有没有垃圾要处理的；每次发考卷的时候，也会左顾右盼，相互逗个乐。一年中要数元旦晚会最为热闹，犹记得高三那年元旦，我为了演唱“海阔天空”，每天回家吃饭的时候就听mp3，走在路上也会小声哼唱，当然对于五音不全的我，演唱效果并不是很好:-) 晚会当天下午开始布置场地，所有人把书搬回宿舍，清空教室，在玻璃窗上贴上气球，圣诞树贴纸，或者某个小画家直接在上面画一幅画，电风扇和墙上都会挂上彩带；在教室四周摆上课桌，课桌上摆上事先买好的瓜子、花生、糖果、饮料等；同学们借来音响话筒，老师也把自己的笔记本搬到教室，一场简朴晚会现场就布置好了。晚会的所有工作人员、演员、主持人都是自己班上的同学，大家欢聚一堂，过着小集体的节日，有时候在同学和主持人的怂恿下，老师们也会激情献唱一首。现在回想起来，这种小集体归属感真的很美好，高中毕业之后，我大概再也没有过这种感觉了。\u003c/p\u003e\n\u003cp\u003e春节过后，就是高考的紧要关头了，每周一的班会课上，老师都会给我们加油鼓劲，告诉我们大学有多轻松美好。百日会战那天，班主任甚至亲自泼墨，写下“辛苦数日，幸福一生”的对联，贴在教室的后墙上。高三，每天就是不停的做卷子、刷题，日考、周考、月考，不断的考试，往往上一张考卷还没有讲评，下一次考试又到了。考得多了，对成绩也不那么看重了，不过也基本稳定在前三。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"图片来自[1]\" loading=\"lazy\" src=\"https://i0.wp.com/a3.att.hudong.com/66/83/300000908235130708833431958_950.jpg\"\u003e\n图片来自[1]\u003c/p\u003e\n\u003cp\u003e距离高考只剩一个星期的时候，题量开始下降，老师也变得温柔起来，开始提醒我们注意饮食，调整生物钟，保持充足睡眠等。考前3天，学校放假，让我们回家吃好喝好，放松心情。考前1天，看考场，当时坐我前面的一个同学找到我，叫我给他抄，并威胁我如果不给他抄，则影响我考试，碰到这样一个人渣，对我的心情还是有一定影响的，我也没敢把这件事告诉我妈。当天晚上英语老师找我谈话，宽慰我，跟我说考试的时候不要遮住试卷，他能不能抄到是他的事了，况且他最多只能抄到选择填空题，主观题还得靠真才实学。高考那两天，全校其他年级放假，为的是给所有考生创造一个安静舒适的校园环境，这一点给学校点赞。高考第一天和第二天上午还算顺利，正常发挥，第二天午休没有睡着，下午考英语的时候，听力几乎没有进入状态，哈欠连连，英语是我考得最差的一科了，当然英语本来就不是我的强项。\u003c/p\u003e\n\u003cp\u003e考完之后，回到家中，妈妈给我和哥哥洗了两个甜瓜吃，寓意我们苦尽甘来:-) 高考完的那个暑假，妈妈说让我们好好在家待着休养生息，所以基本过着猪一样的生活。6月底高考成绩出来了，六百多吧，和估分差不多，纠结的是填志愿。当时也不像现在，互联网这么发达，基本上是通过《全国普通高等学校报考指南》了解每个学校，对提前批的情况也不甚了解。后来根据往年分数线以及自己的兴趣，报了武大、吉大、川大这几个学校，很幸运，录取了第一志愿第一专业WHUCS。说实话，在填志愿之前，我只知道清华北大这两个学校，对武大这所“全国最美丽的大学”一无所知，我不是狂妄自大，而是孤陋寡闻。\u003c/p\u003e\n\u003cp\u003e高中真的很累、很辛苦，要想坚持下去，一定要找一个可靠的精神支柱，不论是做什么事都是这样，一直以来，支持我勇往直前的都是我的亲人和我想要改变命运的决心！要说高中3年的收获，那就是它磨砺了我的意志，增强了我忍受孤独的能力，当然高中并不是我最孤独的时候，至少有我前面提到的小集体归属感；高中三年，也认识了很要好的同学兼老乡WQ、WS和MZ。\u003c/p\u003e\n\u003cp\u003e对了，高中那会每个人都会有一个座右铭，我也不例外，很大众化，汪国真的“既然选择了远方，便只顾风雨兼程”。惊闻汪老师于2015年4月26日逝世，令人嘘唏。\u003c/p\u003e\n\u003cp\u003e参考：\u003c/p\u003e\n\u003cp\u003e[1]. \u003ca href=\"http://tupian.baike.com/84178/2.html\"\u003e永不过时的高考记忆\u003c/a\u003e\u003c/p\u003e","title":"我的高中生活"},{"content":"5月19号的中午吃完饭后随手刷了一下朋友圈，发现MS表哥分享了一个链接，说家乡发生了十多年未遇洪灾。仔细看了一下，发现这次洪灾真的很严重，然后就给妈妈打了个电话，妈妈说从昨天下午开始下大雨，到晚上下暴雨，我家后院有一座小山，也出现了滑坡；附近的一座桥也淹了，家门口的一片农田（不是我家的）也全被淹了。妈妈说她也是头一回看到这么大而持久的暴雨。\n后来看QQ空间，全是关于家乡灾情的状态，很多新闻媒体也报道了。县的下游地区受灾比较严重，隔壁有个叫横江的村镇，这个镇因为坐落在横江水旁边，受灾最严重，听说整个镇断水断电，都快成孤岛了。我有一个亲戚在横江，他们家一层楼就被淹了，很多人家养的鸡鸭鱼猪等都被冲走了，几乎所有的农田被淹，损失真的很严重。\n横江镇政府被淹情形[1]\n这是通往横江镇的公路，下坡后就是横江镇，可以看到整个村镇已经被淹[2]\n停在路边的小汽车都被冲走了！[2]\n整个村子一片汪洋[2]\n特写[2]\n估计我家后山的滑坡比这严重很多[1]\n我记得我小的时候（大概五六岁？），可能是1998年吧，也发生过一次特大洪水，当时也是晚上，爷爷把我和哥哥叫起来，爬到后山上去避难了。当时虽然洪水也大，但也就一晚上，第二天很快就退了，不像这次持续的特大暴雨。\n晚些时候我又打电话给妈妈，听妈妈说因为怕山体滑坡，已经去半山腰上的烤烟房里过夜了。那个烤烟房是我还没出生（或者我很小）的时候盖的土坯房，专门用来烤烟的。 后来一家人常年在外，也没怎么管它，很多瓦都碎了。前几年我爸回家补漏，现在是不会漏水了。但是毕竟年代久远了，而且是土坯房，又下那么大雨，还是不放心。想到妈妈一个人在家，晚上要住在一个没有水没有电的土坯房里，心里真不是滋味。以后有钱了应该把烤烟房改建成砖房，万一出现什么灾害，也有个落脚的地方。\n刚看了下天气预报，现在还在下雨，周六周一还有雷阵雨，希望不要再滑坡了。\n石城5月份历史天气，从15号开始连下了6天的大雨，以18,19,20为最[4]\n在这次灾害中，也要感谢当今发达的互联网，让全国各地的人实时了解家乡的情况，很多救援队也纷纷赶赴家乡展开救援。希望洪水快快退去，还家乡人民安宁的生活。\n此次特大灾害直播：http://mp.weixin.qq.com/s?__biz=MjM5MzEzODgyMA==\u0026amp;mid=206189476\u0026amp;idx=1\u0026amp;sn=3e2cc4f01b7ff42f933420063f4e5a74#rd\n520，对石城说“我爱你”：http://v.qq.com/boke/page/z/0/2/z0154dvf6d2.html\n灾后场景：http://mp.weixin.qq.com/s?__biz=MzAwNDUzMjg5OA==\u0026amp;mid=208435542\u0026amp;idx=1\u0026amp;sn=346f8e17448bf3a976c55591636b6e02\u0026amp;scene=1\u0026amp;from=singlemessage\u0026amp;isappinstalled=0#rd\n2015年5月21号石城新闻：http://v.qq.com/boke/page/w/0/4/w015442vnu4.html\n相关媒体报道：\nhttp://pic.people.com.cn/n/2015/0520/c1016-27031534.html?k=1\nhttp://news.163.com/15/0521/05/AQ48GSQU00014Q4P.html\nhttp://news.163.com/15/0521/06/AQ4CVUIF00014AEE.html\n参考：\n[1]. 赣江源头微信公众号文章\n[2]. 石城热线微信公众号文章\n[3]. 百度搜索“石城天气”，数据来源中国天气网\n[4]. 数据来源：http://15tianqi.cn/shicheng5yuetianqi/\n","permalink":"http://localhost:1313/posts/2015-05-21-severe-flooding-hits-my-hometown/","summary":"\u003cp\u003e5月19号的中午吃完饭后随手刷了一下朋友圈，发现MS表哥分享了一个\u003ca href=\"http://mp.weixin.qq.com/s?__biz=MzAwNDUzMjg5OA==\u0026amp;mid=208222165\u0026amp;idx=1\u0026amp;sn=8586e0f5d9830cfb4cf51921bfe1269a\u0026amp;scene=2\u0026amp;from=timeline\u0026amp;isappinstalled=0#rd\"\u003e链接\u003c/a\u003e，说家乡发生了十多年未遇洪灾。仔细看了一下，发现这次洪灾真的很严重，然后就给妈妈打了个电话，妈妈说从昨天下午开始下大雨，到晚上下暴雨，我家后院有一座小山，也出现了滑坡；附近的一座桥也淹了，家门口的一片农田（不是我家的）也全被淹了。妈妈说她也是头一回看到这么大而持久的暴雨。\u003c/p\u003e\n\u003cp\u003e后来看QQ空间，全是关于家乡灾情的状态，很多新闻媒体也报道了。县的下游地区受灾比较严重，隔壁有个叫横江的村镇，这个镇因为坐落在横江水旁边，受灾最严重，听说整个镇断水断电，都快成孤岛了。我有一个亲戚在横江，他们家一层楼就被淹了，很多人家养的鸡鸭鱼猪等都被冲走了，几乎所有的农田被淹，损失真的很严重。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"横江镇政府被淹情形[1]\" loading=\"lazy\" src=\"/posts/2015-05-21-severe-flooding-hits-my-hometown/flood201505-1.jpg\"\u003e\n横江镇政府被淹情形[1]\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"这是通往横江镇的公路，下坡后就是横江镇，可以看到整个村镇已经被淹[2]\" loading=\"lazy\" src=\"/posts/2015-05-21-severe-flooding-hits-my-hometown/flood201505-2.jpg\"\u003e\n这是通往横江镇的公路，下坡后就是横江镇，可以看到整个村镇已经被淹[2]\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"停在路边的小汽车都被冲走了！[2]\" loading=\"lazy\" src=\"/posts/2015-05-21-severe-flooding-hits-my-hometown/flood201505-3.jpg\"\u003e\n停在路边的小汽车都被冲走了！[2]\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"整个村子一片汪洋[2]\" loading=\"lazy\" src=\"/posts/2015-05-21-severe-flooding-hits-my-hometown/flood201505-4.jpg\"\u003e\n整个村子一片汪洋[2]\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"特写[2]\" loading=\"lazy\" src=\"/posts/2015-05-21-severe-flooding-hits-my-hometown/flood201505-5.jpg\"\u003e\n特写[2]\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"估计我家后山的滑坡比这严重很多[1]\" loading=\"lazy\" src=\"/posts/2015-05-21-severe-flooding-hits-my-hometown/flood201505-6.jpg\"\u003e\n估计我家后山的滑坡比这严重很多[1]\u003c/p\u003e\n\u003cp\u003e我记得我小的时候（大概五六岁？），可能是1998年吧，也发生过一次特大洪水，当时也是晚上，爷爷把我和哥哥叫起来，爬到后山上去避难了。当时虽然洪水也大，但也就一晚上，第二天很快就退了，不像这次持续的特大暴雨。\u003c/p\u003e\n\u003cp\u003e晚些时候我又打电话给妈妈，听妈妈说因为怕山体滑坡，已经去半山腰上的烤烟房里过夜了。那个烤烟房是我还没出生（或者我很小）的时候盖的土坯房，专门用来烤烟的。 后来一家人常年在外，也没怎么管它，很多瓦都碎了。前几年我爸回家补漏，现在是不会漏水了。但是毕竟年代久远了，而且是土坯房，又下那么大雨，还是不放心。想到妈妈一个人在家，晚上要住在一个没有水没有电的土坯房里，心里真不是滋味。以后有钱了应该把烤烟房改建成砖房，万一出现什么灾害，也有个落脚的地方。\u003c/p\u003e\n\u003cp\u003e刚看了下天气预报，现在还在下雨，周六周一还有雷阵雨，希望不要再滑坡了。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"石城5月份历史天气，从15号开始连下了6天的大雨，以18,19,20为最[4]\" loading=\"lazy\" src=\"/posts/2015-05-21-severe-flooding-hits-my-hometown/shicheng_history_weather.png\"\u003e\n石城5月份历史天气，从15号开始连下了6天的大雨，以18,19,20为最[4]\u003c/p\u003e\n\u003cp\u003e在这次灾害中，也要感谢当今发达的互联网，让全国各地的人实时了解家乡的情况，很多救援队也纷纷赶赴家乡展开救援。希望洪水快快退去，还家乡人民安宁的生活。\u003c/p\u003e\n\u003cp\u003e此次特大灾害直播：\u003ca href=\"http://mp.weixin.qq.com/s?__biz=MjM5MzEzODgyMA==\u0026amp;mid=206189476\u0026amp;idx=1\u0026amp;sn=3e2cc4f01b7ff42f933420063f4e5a74#rd\"\u003ehttp://mp.weixin.qq.com/s?__biz=MjM5MzEzODgyMA==\u0026amp;mid=206189476\u0026amp;idx=1\u0026amp;sn=3e2cc4f01b7ff42f933420063f4e5a74#rd\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e520，对石城说“我爱你”：\u003ca href=\"http://v.qq.com/boke/page/z/0/2/z0154dvf6d2.html\"\u003ehttp://v.qq.com/boke/page/z/0/2/z0154dvf6d2.html\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e灾后场景：\u003ca href=\"http://mp.weixin.qq.com/s?__biz=MzAwNDUzMjg5OA==\u0026amp;mid=208435542\u0026amp;idx=1\u0026amp;sn=346f8e17448bf3a976c55591636b6e02\u0026amp;scene=1\u0026amp;from=singlemessage\u0026amp;isappinstalled=0#rd\"\u003ehttp://mp.weixin.qq.com/s?__biz=MzAwNDUzMjg5OA==\u0026amp;mid=208435542\u0026amp;idx=1\u0026amp;sn=346f8e17448bf3a976c55591636b6e02\u0026amp;scene=1\u0026amp;from=singlemessage\u0026amp;isappinstalled=0#rd\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e2015年5月21号石城新闻：\u003ca href=\"http://v.qq.com/boke/page/w/0/4/w015442vnu4.html\"\u003ehttp://v.qq.com/boke/page/w/0/4/w015442vnu4.html\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e相关媒体报道：\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"http://pic.people.com.cn/n/2015/0520/c1016-27031534.html?k=1\"\u003ehttp://pic.people.com.cn/n/2015/0520/c1016-27031534.html?k=1\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"http://news.163.com/15/0521/05/AQ48GSQU00014Q4P.html\"\u003ehttp://news.163.com/15/0521/05/AQ48GSQU00014Q4P.html\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"http://news.163.com/15/0521/06/AQ4CVUIF00014AEE.html\"\u003ehttp://news.163.com/15/0521/06/AQ4CVUIF00014AEE.html\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e参考：\u003c/p\u003e\n\u003cp\u003e[1]. 赣江源头微信公众号文章\u003c/p\u003e\n\u003cp\u003e[2]. 石城热线微信公众号文章\u003c/p\u003e\n\u003cp\u003e[3]. 百度搜索“石城天气”，数据来源中国天气网\u003c/p\u003e\n\u003cp\u003e[4]. 数据来源：\u003ca href=\"http://15tianqi.cn/shicheng5yuetianqi/\"\u003ehttp://15tianqi.cn/shicheng5yuetianqi/\u003c/a\u003e\u003c/p\u003e","title":"家乡遭受几十年一遇的洪灾"},{"content":"其实在中学的时候就遇到过“刺猬困境”，只是那时候不知道这个名词，直接促使我了解这方面内容的原因是和XN的一次不愉快的交谈。\n那是半个多月以前的事情了，有一天中午我们一起吃完午饭回来，我们身后突然有一辆小车要启动，XN就一个劲叫我靠边走；但与此同时我边上迎面来了一辆电动车，于是我就和XN说我这边也有车，但是XN回我一句“叫你靠边走你不靠边走”，当时我听了很不舒服，还是告诉她我这边也有车，但是语气稍微重了点，我以为XN会到此为止，没想到她还是回了一句“你那么大声干嘛呀”……因为那天心情就不太好，还被她这么一说，那天我就没理她了。\n本来以为以XN的性格，这件事会很快过去，没想到XN一气之下不和我一起上下班了，也不和我一起打球吃饭了。我觉得事情还是有那么一点“严重”，这都还没正式入组，就和最熟悉的组员闹僵了，以后三年该怎么办呀，所以第二天晚上我还是诚恳的向XN道歉了。\n后来回想起这件事，确实是我的错。XN当时叫我靠边是一番好意，她多说了几句，我一个男生反倒先急了，确实是气度不够大。\n不过说实话，XN也并不是完全没有错，在我和她解释之后，她还不依不饶，似乎有点过了。她之前也跟我讲过自己有一次在班群里开某同学的玩笑，导致那个同学和她理论的事情。\n写到这的时候又让我想起了有一次教XN打乒乓球的时候，在公共场合批评她打球不够认真，哪里哪里打得不好之类的，当时我自己觉得不以为然，教她打球，当然要指出她的不对之处，但是后来XN告诉我她很生气，哪有我这样一直批评学生的老师啊。我仔细一想，对呀，我为什么在公共场合批评她打得不好呢，我是她的教练吗，我和她熟到能无话不谈吗，好像没有，所以这就是我没有把握好人际交往的一个度。我和XN只是同届同门师弟妹，我们之间应该保持一定的距离，距离太近了，说话做事无所顾忌，迟早会对某一方产生伤害，导致矛盾。\n刺猬困境是由叔本华提出的一个概念。寒冷的冬天，刺猬本想拥作一团、互相取暖，但一靠近便被彼此刺伤了；想分开避免扎伤，又觉得寒冷而想再彼此靠近。几个反复后，刺猬发现它们最好保持一点距离。\n与人交往也是这样，当两个人关系逐渐亲密起来，成为所谓的好基友、好闺蜜的时候，往往容易忽视对方的感受，说出一些伤人的话。\n高中的时候因为成绩还可以，班上的LL同学经常向我请教问题，我每次都会很耐心很热情的帮他解答，慢慢的关系比较好，他就经常和我一起上下课，课间跑到我的位置上和我聊天开玩笑，甚至左拍一下我右捏一下我。这让我感到很不舒服，感觉个人空间被入侵，后来我就慢慢的和他疏远，保持一个合理的距离。\n我和XN的那次不愉快交谈，就相当于刺猬间相互取暖导致彼此受伤的过程，不过我相信，经过几个回合，我们能慢慢的找到合适的距离，既相互取暖，又不至于受伤。\nEdward T. Hall’s personal reaction bubbles, showing radius in feet and meters[1]\n上图是爱德华·霍尔提出的人际交往的四个距离，从内到外依次是亲密距离-\u0026gt;个人距离-\u0026gt;社交距离-\u0026gt;公共距离。和朋友同事之间的距离应该保持在个人距离0.45米。\nP.S.希望能够找到那个和我共享亲密距离的人-:)\n参考：\n[1]. 维基百科“Personal space”条目：http://en.wikipedia.org/wiki/Personal_space\n","permalink":"http://localhost:1313/posts/2015-05-02-hedgehogs-dilemma-and-interpersonal-distance/","summary":"\u003cp\u003e其实在中学的时候就遇到过“刺猬困境”，只是那时候不知道这个名词，直接促使我了解这方面内容的原因是和XN的一次不愉快的交谈。\u003c/p\u003e\n\u003cp\u003e那是半个多月以前的事情了，有一天中午我们一起吃完午饭回来，我们身后突然有一辆小车要启动，XN就一个劲叫我靠边走；但与此同时我边上迎面来了一辆电动车，于是我就和XN说我这边也有车，但是XN回我一句“叫你靠边走你不靠边走”，当时我听了很不舒服，还是告诉她我这边也有车，但是语气稍微重了点，我以为XN会到此为止，没想到她还是回了一句“你那么大声干嘛呀”……因为那天心情就不太好，还被她这么一说，那天我就没理她了。\u003c/p\u003e\n\u003cp\u003e本来以为以XN的性格，这件事会很快过去，没想到XN一气之下不和我一起上下班了，也不和我一起打球吃饭了。我觉得事情还是有那么一点“严重”，这都还没正式入组，就和最熟悉的组员闹僵了，以后三年该怎么办呀，所以第二天晚上我还是诚恳的向XN道歉了。\u003c/p\u003e\n\u003cp\u003e后来回想起这件事，确实是我的错。XN当时叫我靠边是一番好意，她多说了几句，我一个男生反倒先急了，确实是气度不够大。\u003c/p\u003e\n\u003cp\u003e不过说实话，XN也并不是完全没有错，在我和她解释之后，她还不依不饶，似乎有点过了。她之前也跟我讲过自己有一次在班群里开某同学的玩笑，导致那个同学和她理论的事情。\u003c/p\u003e\n\u003cp\u003e写到这的时候又让我想起了有一次教XN打乒乓球的时候，在公共场合批评她打球不够认真，哪里哪里打得不好之类的，当时我自己觉得不以为然，教她打球，当然要指出她的不对之处，但是后来XN告诉我她很生气，哪有我这样一直批评学生的老师啊。我仔细一想，对呀，我为什么在公共场合批评她打得不好呢，我是她的教练吗，我和她熟到能无话不谈吗，好像没有，所以这就是我没有把握好人际交往的一个度。我和XN只是同届同门师弟妹，我们之间应该保持一定的距离，距离太近了，说话做事无所顾忌，迟早会对某一方产生伤害，导致矛盾。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"hedgehogs dilemma\" loading=\"lazy\" src=\"/posts/2015-05-02-hedgehogs-dilemma-and-interpersonal-distance/hedgehogs-dilemma.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e刺猬困境是由叔本华提出的一个概念。寒冷的冬天，刺猬本想拥作一团、互相取暖，但一靠近便被彼此刺伤了；想分开避免扎伤，又觉得寒冷而想再彼此靠近。几个反复后，刺猬发现它们最好保持一点距离。\u003c/p\u003e\n\u003cp\u003e与人交往也是这样，当两个人关系逐渐亲密起来，成为所谓的好基友、好闺蜜的时候，往往容易忽视对方的感受，说出一些伤人的话。\u003c/p\u003e\n\u003cp\u003e高中的时候因为成绩还可以，班上的LL同学经常向我请教问题，我每次都会很耐心很热情的帮他解答，慢慢的关系比较好，他就经常和我一起上下课，课间跑到我的位置上和我聊天开玩笑，甚至左拍一下我右捏一下我。这让我感到很不舒服，感觉个人空间被入侵，后来我就慢慢的和他疏远，保持一个合理的距离。\u003c/p\u003e\n\u003cp\u003e我和XN的那次不愉快交谈，就相当于刺猬间相互取暖导致彼此受伤的过程，不过我相信，经过几个回合，我们能慢慢的找到合适的距离，既相互取暖，又不至于受伤。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://i0.wp.com/upload.wikimedia.org/wikipedia/commons/thumb/3/35/Personal_Space.svg/640px-Personal_Space.svg.png\"\u003e\nEdward T. Hall’s personal reaction bubbles, showing radius in feet and meters[1]\u003c/p\u003e\n\u003cp\u003e上图是爱德华·霍尔提出的人际交往的四个距离，从内到外依次是亲密距离-\u0026gt;个人距离-\u0026gt;社交距离-\u0026gt;公共距离。和朋友同事之间的距离应该保持在个人距离0.45米。\u003c/p\u003e\n\u003cp\u003eP.S.希望能够找到那个和我共享亲密距离的人-:)\u003c/p\u003e\n\u003cp\u003e参考：\u003c/p\u003e\n\u003cp\u003e[1]. 维基百科“Personal space”条目：\u003ca href=\"http://en.wikipedia.org/wiki/Personal_space\"\u003ehttp://en.wikipedia.org/wiki/Personal_space\u003c/a\u003e\u003c/p\u003e","title":"“刺猬困境”与人际交往距离"},{"content":"其实很早之前就打算学习繁体字了，但是直接驱动我开始行动的还是上周末的一件事。\n上周末组内一起去天津蓟县盘山景区游玩，进入景区看到的第一个“景点”就是下面的乾隆御笔\n乾隆《游盘山记》\n当时JL师姐念了一遍，有几个繁体字不认识，在场的其他人也都模棱两可。我当时就后悔为什么不早点把繁体字学了呢。所以回所之后马上买了下面的这本《繁简字对照字典》，决定每天看一两页。\n《繁简字对照字典》[1]\n网上也有《游盘山记》的简体版，如下\n连太行，拱神京，放碣石，距沧溟，走蓟野，枕长城，盖蓟州之天作，俯临重壑，如众星拱北而莫敢与争者也。—-乾隆御笔\n对照图片中的繁体字，学习一下。\n有些繁体字和简体字不是一一对应的，比如同样是“汇”字，“汇聚”对应的繁体字为“匯聚”，而“词汇”对应的繁体字为“詞彙”，这一点需要注意，网上有开源的繁简字转换工具，可以看这里。\n关于繁简字的争论，网上已经很多了，我也不想评论，我只想说，学习繁体字完全是个人兴趣，我觉得繁体字很美，很有意思，一个字可以研究半天，外出游玩的时候也能顺带“和古人交流交流”，所以就学了-:)\n参考：\n[1]. 豆瓣读书《繁简字对照字典》：http://book.douban.com/subject/2234412/\n","permalink":"http://localhost:1313/posts/2015-04-21-learning-traditional-chinese-characters/","summary":"\u003cp\u003e其实很早之前就打算学习繁体字了，但是直接驱动我开始行动的还是上周末的一件事。\u003c/p\u003e\n\u003cp\u003e上周末组内一起去天津蓟县盘山景区游玩，进入景区看到的第一个“景点”就是下面的乾隆御笔\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"乾隆《游盘山记》\" loading=\"lazy\" src=\"/posts/2015-04-21-learning-traditional-chinese-characters/panshan.jpg\"\u003e\n乾隆《游盘山记》\u003c/p\u003e\n\u003cp\u003e当时JL师姐念了一遍，有几个繁体字不认识，在场的其他人也都模棱两可。我当时就后悔为什么不早点把繁体字学了呢。所以回所之后马上买了下面的这本《繁简字对照字典》，决定每天看一两页。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://img3.doubanio.com/lpic/s2988301.jpg\"\u003e\n《繁简字对照字典》[1]\u003c/p\u003e\n\u003cp\u003e网上也有《游盘山记》的简体版，如下\u003c/p\u003e\n\u003cp\u003e连太行，拱神京，放碣石，距沧溟，走蓟野，枕长城，盖蓟州之天作，俯临重壑，如众星拱北而莫敢与争者也。—-乾隆御笔\u003c/p\u003e\n\u003cp\u003e对照图片中的繁体字，学习一下。\u003c/p\u003e\n\u003cp\u003e有些繁体字和简体字不是一一对应的，比如同样是“汇”字，“汇聚”对应的繁体字为“匯聚”，而“词汇”对应的繁体字为“詞彙”，这一点需要注意，网上有开源的繁简字转换工具，可以看\u003ca href=\"http://opencc.byvoid.com/\"\u003e这里\u003c/a\u003e。\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"http://www.zhihu.com/question/25389359\"\u003e关于繁简字的争论，网上已经很多了\u003c/a\u003e，我也不想评论，我只想说，学习繁体字完全是个人兴趣，我觉得繁体字很美，很有意思，一个字可以研究半天，外出游玩的时候也能顺带“和古人交流交流”，所以就学了-:)\u003c/p\u003e\n\u003cp\u003e参考：\u003c/p\u003e\n\u003cp\u003e[1]. 豆瓣读书《繁简字对照字典》：\u003ca href=\"http://book.douban.com/subject/2234412/\"\u003ehttp://book.douban.com/subject/2234412/\u003c/a\u003e\u003c/p\u003e","title":"我学繁体字"},{"content":"师姐推荐了最新一期《人物周刊》上的一篇文章–“不求助的人”。这篇文章讲到，在上月末德国空难事件中，副驾驶卢比茨选择了坠毁飞机。调查人员随后了解到，他可能患有抑郁症，同时，他的弱视或许在持续恶化。视力和心理问题给卢比茨的职业前景笼上阴影，而他没有选择求助。\n“求助”似乎从来不是首选项。遇到难题自己解决，不行就上网搜搜方法，还不行，则“咬紧牙关熬过去”。不求助的表面理由是不麻烦别人，但更真实的担忧大概是“如果开口求助，别人会认为我能力低下，我会因此丧失各种机会”。本质原因在于，给自己定的目标是“在他人面前表现出众”。\n目标可细分为两种，“精熟型目标（mastery goal）”和“绩效型目标（performancegoal）”。精熟型目标更重视过程而非结果，认为目的是自我提升，不是获得肯定。哪怕现在还“做不到”，但通过不断努力也能有所进步。既然目标是“成为更好的自己”，那么遇到困难时，自然会寻求帮助。而绩效型目标只看最终结果，你要么“能做到”，要么“不能做到”，要么力压众人表现出色，要么挑战失败沦为笑柄。既然目的是“从他人那里获得肯定”，感觉上像是“示弱”的求助就不会被列入选项。\n“不求助之人”并不少见。不过，“绩效型目标”者不知道的是，求助他人时，其实会提升此人对你的评价。每个人都觉得自己智慧过人，可以为别人授业解惑，而“懂得向聪明的我询问智慧建言的人，一定也是聪明人”。沃顿商学院的研究者发现，脑力竞赛中接到“搭档”求助的人，赛后给搭档打了更高的能力分。2010年，美国西北大学研究发现，老板其实更喜欢那些遇到困境会主动求援的下属，某种意义上，“求指点迷津”可能是对老板最好的恭维。\n说到底，不管目标是获得成长还是赞赏，求助都是帮助达成目标的大道。越早寻求帮助，越有机会让自己成长，也越有可能掌握技能、成功解决问题，周遭人对你的评价也会因此上升。反倒是不求助的人，万一拖到事情无法收拾，自己的自信和风评都会落到极低。\n这篇文章讲得很有道理，我发现身边就有很多不求助的人。他们从小到大很少向别人求助，自己能做的事尽量自己做，遇到难题也尽量自己扛，给人一种能力很强、很自信的印象；同时他们也很鄙视那些经常向别人求助的人，认为这些人“就知道问别人，这么简单的都不会”。你可以称赞“不求助的人”独立自主、坚韧刻苦，但是从某种程度上这恰恰反映了他们内心的不自信，他们害怕自己的求助暴露了自己的智商，显得自己水平不够。他们属于绩效型人群，只看重结果，不看重过程，如果当上领导，下属的压力肯定不小，久而久之，就会产生类似上面的案例，宁愿选择坠毁，也不愿向他人求助。\n不求助的人因为很少向他人求助，他们的交际圈也很窄，他们经常把自己封锁起来，甚至把主动伸出援手的人拒之门外。长期的封闭往往导致一些心理和精神疾病，以至于做出一些病态的选择。\n其实，和”不求助的人“的想法相反，文中沃顿商学院的研究结果很有道理，遇到问题喜欢求助的人，反而会受到别人较高的评价，因为被求助者会潜意识的认为“懂得向聪明的我询问智慧建言的人，一定也是聪明人”，说不定双方还能由此发展出一段不错的关系；而且越早求助，就能越早解决问题。这一箭多雕的事情，恐怕是不求助的人没有想到的吧。\n从某种程度上来说，我自己也是一个“不求助的人”，H老师估计早就猜透了，我希望能够在读研期间“收获一点成就感、一点自信心”，从绩效型人群转移到精熟型人群。\n","permalink":"http://localhost:1313/posts/2015-04-18-someone-who-doesnt-ask-for-help/","summary":"\u003cp\u003e师姐推荐了最新一期《人物周刊》上的一篇文章–\u003ca href=\"https://mp.weixin.qq.com/s?__biz=MTY0MzI5NDcwMQ==\u0026amp;mid=206411797\u0026amp;idx=1\u0026amp;sn=c0da9db2ed5a6a5bdedbfb871e45c8e6#rd\"\u003e“不求助的人”\u003c/a\u003e。这篇文章讲到，在上月末德国空难事件中，副驾驶卢比茨选择了坠毁飞机。调查人员随后了解到，他可能患有抑郁症，同时，他的弱视或许在持续恶化。视力和心理问题给卢比茨的职业前景笼上阴影，\u003cstrong\u003e而他没有选择求助\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e“求助”似乎从来不是首选项。遇到难题自己解决，不行就上网搜搜方法，还不行，则“咬紧牙关熬过去”。不求助的表面理由是不麻烦别人，但更真实的担忧大概是“如果开口求助，别人会认为我能力低下，我会因此丧失各种机会”。本质原因在于，给自己定的目标是“在他人面前表现出众”。\u003c/p\u003e\n\u003cp\u003e目标可细分为两种，“精熟型目标（mastery goal）”和“绩效型目标（performancegoal）”。精熟型目标更重视过程而非结果，认为目的是自我提升，不是获得肯定。哪怕现在还“做不到”，但通过不断努力也能有所进步。既然目标是“成为更好的自己”，那么遇到困难时，自然会寻求帮助。而绩效型目标只看最终结果，你要么“能做到”，要么“不能做到”，要么力压众人表现出色，要么挑战失败沦为笑柄。既然目的是“从他人那里获得肯定”，感觉上像是“示弱”的求助就不会被列入选项。\u003c/p\u003e\n\u003cp\u003e“不求助之人”并不少见。不过，“绩效型目标”者不知道的是，求助他人时，其实会提升此人对你的评价。每个人都觉得自己智慧过人，可以为别人授业解惑，而“懂得向聪明的我询问智慧建言的人，一定也是聪明人”。沃顿商学院的研究者发现，脑力竞赛中接到“搭档”求助的人，赛后给搭档打了更高的能力分。2010年，美国西北大学研究发现，老板其实更喜欢那些遇到困境会主动求援的下属，某种意义上，“求指点迷津”可能是对老板最好的恭维。\u003c/p\u003e\n\u003cp\u003e说到底，不管目标是获得成长还是赞赏，求助都是帮助达成目标的大道。越早寻求帮助，越有机会让自己成长，也越有可能掌握技能、成功解决问题，周遭人对你的评价也会因此上升。反倒是不求助的人，万一拖到事情无法收拾，自己的自信和风评都会落到极低。\u003c/p\u003e\n\u003cp\u003e这篇文章讲得很有道理，我发现身边就有很多不求助的人。他们从小到大很少向别人求助，自己能做的事尽量自己做，遇到难题也尽量自己扛，给人一种能力很强、很自信的印象；同时他们也很鄙视那些经常向别人求助的人，认为这些人“就知道问别人，这么简单的都不会”。你可以称赞“不求助的人”独立自主、坚韧刻苦，但是从某种程度上这恰恰反映了他们内心的不自信，他们害怕自己的求助暴露了自己的智商，显得自己水平不够。他们属于绩效型人群，只看重结果，不看重过程，如果当上领导，下属的压力肯定不小，久而久之，就会产生类似上面的案例，宁愿选择坠毁，也不愿向他人求助。\u003c/p\u003e\n\u003cp\u003e不求助的人因为很少向他人求助，他们的交际圈也很窄，他们经常把自己封锁起来，甚至把主动伸出援手的人拒之门外。长期的封闭往往导致一些心理和精神疾病，以至于做出一些病态的选择。\u003c/p\u003e\n\u003cp\u003e其实，和”不求助的人“的想法相反，文中沃顿商学院的研究结果很有道理，遇到问题喜欢求助的人，反而会受到别人较高的评价，因为被求助者会潜意识的认为“懂得向聪明的我询问智慧建言的人，一定也是聪明人”，说不定双方还能由此发展出一段不错的关系；而且越早求助，就能越早解决问题。这一箭多雕的事情，恐怕是不求助的人没有想到的吧。\u003c/p\u003e\n\u003cp\u003e从某种程度上来说，我自己也是一个“不求助的人”，H老师估计早就猜透了，我希望能够在读研期间\u003ca href=\"http://pfind.net/people/hesimin/Chinese/Favorite%20Books.htm\"\u003e“收获一点成就感、一点自信心”\u003c/a\u003e，从绩效型人群转移到精熟型人群。\u003c/p\u003e","title":"不求助的人"},{"content":"趁着周末，看了韩寒导演的处女作《后会无期》，说来奇怪，看的过程中没有丝毫感觉，情节松散，直到听到了片尾曲”平凡之路“，内心为之一颤，想来应该写点什么纪念一下。\n影片中三个年轻人离开家乡小岛，一路向西，横穿中国大陆，路上落下了胡生，错过了假装”小姐“的”骗子“，告别了一直”恋爱“着的笔友，遇到了善恶莫测的奇怪旅人，送走了最好的朋友，只有流浪的小狗留在了身边。几番告白，几番告别，勾勒出几段截然不同的平凡人生之路。\n突然间，我从影片中看到了萧瑟冷漠的世界，看到了饱经沧桑的老人挣扎着，反抗着，但最终离开了。\n影片给我影响最深的两句话是：\n你连世界都没观过，你哪来的世界观。 如果要告别，一定要用力一点,因为任何多看一眼,都有可能成为最后一眼,多说一句,都可能是最后一句。 经常有人惊讶于我小小年纪就表现得如此成熟，不知道是不是因为从小跟着父母外出闯荡，经历得多了，世界观不一样了。\n很小的时候就跟着父母去了广东JY，当时父亲帮别人挖煤，后来当过老师，开过早餐店，开过出租车。挖煤的时候每天都要在臭气熏天的河里挖半天煤，然后用船运回去，又要顶着炎炎夏日做半天的煤。每天完事之后脚乌漆墨黑，老茧长得跟树皮一样。开早餐店的时候，每天凌晨三四点就要起床开始和面，做包子，熬豆浆，炸油条。忙完了早餐还要去学校上班。\n那一年有天晚上，爸爸妈妈正在收拾店铺，准备第二天早晨的面料，YT睡到半夜突然KTBM，脚一直在发抖，我被吵醒之后马上告诉了爸爸妈妈。当时都已经很晚了，地段也比较偏僻，路上少有行人，幸好隔壁开茶叶店的老板还没有走，他用摩托车把YT送到了医院。那一天晚上格外的冷，我只记得妈妈站在医院门口不停的祈祷着什么。后来几经折腾，转院到汕头的大医院，病床好像在走廊里，医院的快餐比家里的还好吃。\n一家人出门在外，父母的工资很低，在外读书，一学期的学费要几百块钱，再加上YT的那场大病，家里的经济压力着实不小。父母经常为一些事大吵大闹，有几次还大打出手，作为小孩子的我只能哭着求着他们不要再吵不要再打了，过往的事件历历在目，那都是血和泪的记忆。\n在外漂泊的日子过得很辛苦，对于大人如此，对于我们这些青少年也一样。走在路上经常会被一些本地的小混混打，晚自习回家一定要结伴而行，不要走人少的路。我记得有一次我和表哥一起走在街上，一个骑自行车的小混混从我们背后踢了我们两脚，当时表哥正要反击，我把他拉住了，因为我知道，外地人在这势单力薄，根本不是这些人的对手，自己吃点亏，能不惹麻烦尽量不惹麻烦。但是这个小事给我的印象很深。\n也许是在外打拼的日子太苦，初一下学期，我、YT和妈妈回老家了，爸爸继续在JY打拼着。回到家之后，去了一个稍微好一点的初中，妈妈在我们身边陪读。\n因为在JY的时候，家里很穷，但是过年的时候，父母总还是会给我们买新衣服，所以每年就给我们买便宜又得体的西装。回到老家之后，城里的同学看我们经常穿西装，索性给我们取了一个外号”西装“，这导致我后来对西装厌恶至极。\n有一天晚上，晚自习回家，我和YT刚走出校门的时候，有一群小混混和我们逆行，他们跑的时候不小心把水溅到我们身上了，我想想也就算了，但是YT不服，故意把水溅到他们身上。我当时暗想坏了，他们会不会回来找我们算账啊，果不其然，没过多久，一帮人就追着我们打，幸好当时有一个老师路过，我向她”求救“才得以脱险回家。\n这些小事反应到我的性格上来就是忍气吞声，处世中庸，”吃亏是福“。这种性格在某种程度上也是一件好事，高中三年给我省了很多麻烦，也能让我沉下心来，埋头苦干，高考的时候考了全县第十一名，考取WHU也算是对我那几年的一个回报。其实农村孩子这种”两耳不闻窗外事，一心只读圣贤书“的单一发展，也给我视野狭窄、其他技能缺失埋下了伏笔，这里暂时按下不表。\n我还在JY的时候，有一天妈妈说我们要马上回家看外公，外公病了。回到老家之后，我和YT在院子里玩耍，后来妈妈拉我去见了外公最后一面。那大概是我记忆中第一次亲人离别。后来妈妈告诉我，外公当时还怪我到家之后为什么没有马上去看他呢，对呀，我当时为什么没有马上去看外公而是在院子里玩耍呢，也许那时候还不知道什么是离别吧。\n后来又经历了曾祖母的离别。记忆最深的是爷爷的离别。那大概是一年前吧，我当时正在图书馆准备保研的事情，突然爷爷给我打了一个电话，爷爷很少给我打电话的，而且那时候我们好像还不知道对方的手机号码，爷爷说是从YT那知道我的号码的。他问了我一些近况，叫我要好好照顾自己的身体，不要担心他；他还说他给YT也打了电话，给CY打电话但是没有打通；末了，他说这个电话没别的意思，就这样吧，挂了。我可以明显的感受到电话那头爷爷凄凉孤独的心，这通电话听起来很怪，我马上给爸爸打了个电话，告诉了他情况，爸爸说爷爷一个人在家，也许是太孤单了，或者是犯了老年痴呆症，爸爸还说爷爷也经常打类似的电话给他。是啊，奶奶在我很小的时候就去世了，爷爷一个人孤苦伶仃生活了将近二十年，纵然有三个儿子一个女儿，但是几个儿子儿媳之间为了老人的赡养问题竟成陌路，小儿子老大不小了也还没有成家，是孤独的在这个世界苟活着，给儿子儿媳带来更多的麻烦还是默默的离开，给年轻人省去一个包袱，爷爷心里恐怕早已有了答案。\n几天之后，噩耗传来，没想到那竟成了我和爷爷最后的通话。\n给爷爷办后事的时候，几个叔叔姑姑都回来了，这竟是我记忆中唯一一次看到大家坐在一张桌子上吃饭。\n很多人都说我冷漠、沉默寡言，其实我小时候不是这样的，可能是这些年经历的事太多了，我对很多事情漠不关心，很多不必要的、无意义的话也不讲了，很多点头之交的朋友也不联系了，也变得不喜欢和人争辩了；我开始喜欢独处，喜欢一个人走在路上，看过往匆匆行人，喜欢看《文化苦旅》、《一九八四》、《百年孤独》、《活着》……\n身边很多同学喜欢三五成群出门，经常见他们和各种各样的朋友打招呼。有一次我和一个夏令营认识的同学打招呼，XN居然诧异的告诉我这是她第一次在ICT发现我也有认识的人。为什么要有那么多朋友呢，可能你会告诉我你的QQ好友都上千了，但是真正在你社交圈里的朋友，能够和你交心的朋友，超过10个吗？逢年过节，为了维系那990个你都不记得他/她的模样的朋友，群发着各种短信，朋友圈、QQ空间、微博里不停的给别人点赞，有必要吗？我已经厌倦了这些虚情假意。\n令我很感动的是，前几天，我正在实验室敲代码的时候，接到了WQ的一个电话，我跟他抱怨了一下在北京的各种不顺，他跟我说一个人出门在外，要好好照顾自己；同时另一个好友WS也经常跟我说想和我聊聊。这让我感到非常温暖，虽然我现在一无所有，但是有一两个至交，足以。\n我已经走过了二十多年，是时候走出去看看世界，说不准世界观就形成了呢。\n","permalink":"http://localhost:1313/posts/2015-04-12-my-ordinary-life/","summary":"\u003cp\u003e趁着周末，看了韩寒导演的处女作《后会无期》，说来奇怪，看的过程中没有丝毫感觉，情节松散，直到听到了片尾曲”平凡之路“，内心为之一颤，想来应该写点什么纪念一下。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"The-Continent1.jpg\" loading=\"lazy\" src=\"/posts/2015-04-12-my-ordinary-life/The-Continent1.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e影片中三个年轻人离开家乡小岛，一路向西，横穿中国大陆，路上落下了胡生，错过了假装”小姐“的”骗子“，告别了一直”恋爱“着的笔友，遇到了善恶莫测的奇怪旅人，送走了最好的朋友，只有流浪的小狗留在了身边。几番告白，几番告别，勾勒出几段截然不同的平凡人生之路。\u003c/p\u003e\n\u003cp\u003e突然间，我从影片中看到了萧瑟冷漠的世界，看到了饱经沧桑的老人挣扎着，反抗着，但最终离开了。\u003c/p\u003e\n\u003cp\u003e影片给我影响最深的两句话是：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e你连世界都没观过，你哪来的世界观。\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e如果要告别，一定要用力一点,因为任何多看一眼,都有可能成为最后一眼,多说一句,都可能是最后一句。\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e经常有人惊讶于我小小年纪就表现得如此成熟，不知道是不是因为从小跟着父母外出闯荡，经历得多了，世界观不一样了。\u003c/p\u003e\n\u003cp\u003e很小的时候就跟着父母去了广东JY，当时父亲帮别人挖煤，后来当过老师，开过早餐店，开过出租车。挖煤的时候每天都要在臭气熏天的河里挖半天煤，然后用船运回去，又要顶着炎炎夏日做半天的煤。每天完事之后脚乌漆墨黑，老茧长得跟树皮一样。开早餐店的时候，每天凌晨三四点就要起床开始和面，做包子，熬豆浆，炸油条。忙完了早餐还要去学校上班。\u003c/p\u003e\n\u003cp\u003e那一年有天晚上，爸爸妈妈正在收拾店铺，准备第二天早晨的面料，YT睡到半夜突然KTBM，脚一直在发抖，我被吵醒之后马上告诉了爸爸妈妈。当时都已经很晚了，地段也比较偏僻，路上少有行人，幸好隔壁开茶叶店的老板还没有走，他用摩托车把YT送到了医院。那一天晚上格外的冷，我只记得妈妈站在医院门口不停的祈祷着什么。后来几经折腾，转院到汕头的大医院，病床好像在走廊里，医院的快餐比家里的还好吃。\u003c/p\u003e\n\u003cp\u003e一家人出门在外，父母的工资很低，在外读书，一学期的学费要几百块钱，再加上YT的那场大病，家里的经济压力着实不小。父母经常为一些事大吵大闹，有几次还大打出手，作为小孩子的我只能哭着求着他们不要再吵不要再打了，过往的事件历历在目，那都是血和泪的记忆。\u003c/p\u003e\n\u003cp\u003e在外漂泊的日子过得很辛苦，对于大人如此，对于我们这些青少年也一样。走在路上经常会被一些本地的小混混打，晚自习回家一定要结伴而行，不要走人少的路。我记得有一次我和表哥一起走在街上，一个骑自行车的小混混从我们背后踢了我们两脚，当时表哥正要反击，我把他拉住了，因为我知道，外地人在这势单力薄，根本不是这些人的对手，自己吃点亏，能不惹麻烦尽量不惹麻烦。但是这个小事给我的印象很深。\u003c/p\u003e\n\u003cp\u003e也许是在外打拼的日子太苦，初一下学期，我、YT和妈妈回老家了，爸爸继续在JY打拼着。回到家之后，去了一个稍微好一点的初中，妈妈在我们身边陪读。\u003c/p\u003e\n\u003cp\u003e因为在JY的时候，家里很穷，但是过年的时候，父母总还是会给我们买新衣服，所以每年就给我们买便宜又得体的西装。回到老家之后，城里的同学看我们经常穿西装，索性给我们取了一个外号”西装“，这导致我后来对西装厌恶至极。\u003c/p\u003e\n\u003cp\u003e有一天晚上，晚自习回家，我和YT刚走出校门的时候，有一群小混混和我们逆行，他们跑的时候不小心把水溅到我们身上了，我想想也就算了，但是YT不服，故意把水溅到他们身上。我当时暗想坏了，他们会不会回来找我们算账啊，果不其然，没过多久，一帮人就追着我们打，幸好当时有一个老师路过，我向她”求救“才得以脱险回家。\u003c/p\u003e\n\u003cp\u003e这些小事反应到我的性格上来就是忍气吞声，处世中庸，”吃亏是福“。这种性格在某种程度上也是一件好事，高中三年给我省了很多麻烦，也能让我沉下心来，埋头苦干，高考的时候考了全县第十一名，考取WHU也算是对我那几年的一个回报。其实农村孩子这种”两耳不闻窗外事，一心只读圣贤书“的单一发展，也给我视野狭窄、其他技能缺失埋下了伏笔，这里暂时按下不表。\u003c/p\u003e\n\u003cp\u003e我还在JY的时候，有一天妈妈说我们要马上回家看外公，外公病了。回到老家之后，我和YT在院子里玩耍，后来妈妈拉我去见了外公最后一面。那大概是我记忆中第一次亲人离别。后来妈妈告诉我，外公当时还怪我到家之后为什么没有马上去看他呢，对呀，我当时为什么没有马上去看外公而是在院子里玩耍呢，也许那时候还不知道什么是离别吧。\u003c/p\u003e\n\u003cp\u003e后来又经历了曾祖母的离别。记忆最深的是爷爷的离别。那大概是一年前吧，我当时正在图书馆准备保研的事情，突然爷爷给我打了一个电话，爷爷很少给我打电话的，而且那时候我们好像还不知道对方的手机号码，爷爷说是从YT那知道我的号码的。他问了我一些近况，叫我要好好照顾自己的身体，不要担心他；他还说他给YT也打了电话，给CY打电话但是没有打通；末了，他说这个电话没别的意思，就这样吧，挂了。我可以明显的感受到电话那头爷爷凄凉孤独的心，这通电话听起来很怪，我马上给爸爸打了个电话，告诉了他情况，爸爸说爷爷一个人在家，也许是太孤单了，或者是犯了老年痴呆症，爸爸还说爷爷也经常打类似的电话给他。是啊，奶奶在我很小的时候就去世了，爷爷一个人孤苦伶仃生活了将近二十年，纵然有三个儿子一个女儿，但是几个儿子儿媳之间为了老人的赡养问题竟成陌路，小儿子老大不小了也还没有成家，是孤独的在这个世界苟活着，给儿子儿媳带来更多的麻烦还是默默的离开，给年轻人省去一个包袱，爷爷心里恐怕早已有了答案。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"The-Continent2.jpg\" loading=\"lazy\" src=\"/posts/2015-04-12-my-ordinary-life/The-Continent2.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e几天之后，噩耗传来，没想到那竟成了我和爷爷最后的通话。\u003c/p\u003e\n\u003cp\u003e给爷爷办后事的时候，几个叔叔姑姑都回来了，这竟是我记忆中唯一一次看到大家坐在一张桌子上吃饭。\u003c/p\u003e\n\u003cp\u003e很多人都说我冷漠、沉默寡言，其实我小时候不是这样的，可能是这些年经历的事太多了，我对很多事情漠不关心，很多不必要的、无意义的话也不讲了，很多点头之交的朋友也不联系了，也变得不喜欢和人争辩了；我开始喜欢独处，喜欢一个人走在路上，看过往匆匆行人，喜欢看《文化苦旅》、《一九八四》、《百年孤独》、《活着》……\u003c/p\u003e\n\u003cp\u003e身边很多同学喜欢三五成群出门，经常见他们和各种各样的朋友打招呼。有一次我和一个夏令营认识的同学打招呼，XN居然诧异的告诉我这是她第一次在ICT发现我也有认识的人。为什么要有那么多朋友呢，可能你会告诉我你的QQ好友都上千了，但是真正在你社交圈里的朋友，能够和你交心的朋友，超过10个吗？逢年过节，为了维系那990个你都不记得他/她的模样的朋友，群发着各种短信，朋友圈、QQ空间、微博里不停的给别人点赞，有必要吗？我已经厌倦了这些虚情假意。\u003c/p\u003e\n\u003cp\u003e令我很感动的是，前几天，我正在实验室敲代码的时候，接到了WQ的一个电话，我跟他抱怨了一下在北京的各种不顺，他跟我说一个人出门在外，要好好照顾自己；同时另一个好友WS也经常跟我说想和我聊聊。这让我感到非常温暖，虽然我现在一无所有，但是有一两个至交，足以。\u003c/p\u003e\n\u003cp\u003e我已经走过了二十多年，是时候走出去看看世界，说不准世界观就形成了呢。\u003c/p\u003e","title":"人生，平凡之路"},{"content":"2015年2月28日到达北京，到现在一月有余，是时候月度总结了。\n这是我第三次来北京 2014年的6月份第一次来北京，去北大计算所实习十天。感受了一下北大计算所p老师及其博士生z的冷漠。我还记得刚到的那天晚上一个人孤零零的走在北京的大街上寻找北大方正员工宿舍的场景。每天重复着朝九晚十的固定模式，每个人都像机器一样的工作，实验室只有敲击键盘的声音，偶尔看到p的时候他也是阴沉着脸，临走的时候还被z批评了。虽然p承诺说只要我通过夏令营面试就会要我，但是这明显就是废话呀；而且这段不算愉快的实习经历让我对p的实验室产生了厌恶。\n回学校之后开始准备期末考试和7月份的夏令营，并于2014年7月9日到达北京，这次的行程包括北大计算所和中科院计算所的夏令营。北大计算所因为机试和综合排名不占优势，败下阵来，不过现在想想当初幸好没有进p的实验室，要不然天天对着p的臭脸，估计要疯。\n中科院计算所的风格完全不像北大，中科院真正做到了海纳百川，一视同仁，不像北大看不起校外学生。来北京之前和ict的h老师沟通过很多次，发现我和h老师的性格很相似，我非常崇拜h老师严谨的处事风格，经过认真的准备，我也顺利通过了ict的夏令营，然后跑去深圳siat玩耍了。\n北京的物价真是贵 这次是来ict完成我的本科毕业设计的，大概要待到5月初。一来从家里不方便带太多东西，二来想想要在北京待三年，所以准备在北京重新置办生活用品。\n2月28刚到北京，去了师兄推荐的家乐福大超市。超市很大，有两层，不过里面的东西真是贵。也就买了被子、三件套、桶、盆，花了四五百，很可恨的是，很薄的春秋单人被子，居然要169，这还是最便宜的，床垫比被子还贵，要199。\n没必要的用品可以不买，但是饭不能不吃。以前在学校一天也就十几块，到北京后发现，一顿饭就十多块了。早餐一个鸡蛋要2块，一个小包子要1.5块，哎，想想以前自己家做早餐的时候1块钱4个大肉包子啊，当初怎么不多吃几个呢。\n餐厅里的饭菜确实贵，不过国科大食堂的饭菜既便宜又好吃，赞一个。\n北京的雾霾 来北京之前对北京的雾霾也略有耳闻，觉得那是北京人的小题大做，武汉也是扬尘满天飞，我也活得好好的啊；不过真来北京之后，确实受不了，放眼望去，街道上灰蒙蒙的一片，路上的特大广告牌都看不清。也许是雾霾加干燥的原因，刚来北京那一个星期，嗓子特别不舒服，每天早晨刷牙的时候都恶心干呕，不过后来慢慢好了。\n3月28那天，北京还遭遇了沙尘暴，那场景真像外星人袭击地球。所以来北京，口罩是必需品。\n3月28日北京的沙尘暴[1]\n北京的风景 来北京的前3个星期，忙于组内布置的任务，也是过着朝九晚十的生活，后来想想也不能天天这样，我应该出去透透气，于是选择了颐和园，3月份属于颐和园景区的淡季，加上学生证，门票不贵。颐和园不愧是皇家园林，里面的景色确实很漂亮，有万寿山、昆明湖，湖水还算干净。\n我去的那天天气很好，空气质量也不错；人虽多，但不算拥挤，部分原因是颐和园真是太大了。我在游玩的过程中看到了很多外国旅游团，听到过英语、法语、日语、韩语、粤语、中文，让我默默联想起了八国联军侵略中国的场景。\n在游玩的过程中遇到了一个很温馨的“外国小家庭”，妈妈是外国人，爸爸应该也是外国人，爸爸和妈妈聊天的时候是用英语，但是爸爸和儿子却是用中文，他们还有一个坐在婴儿车里的小女儿，儿子坐在湖边玩ipad，小女儿在车里哭个不停…\n虽然颐和园的风景很好，但是里面居然有很多蚊子（小虫子）！期间有一个虫子撞到我的嘴巴，还有一个钻进了我的耳朵。可能是春天到了，万物复苏，加上颐和园内潮湿，植物丰富，给虫子提供了很好的环境。\n下面放几张游玩时拍的照片。\n谁能告诉我这是什么乐器\n学太极的外国人\n这也是迎春花？\n这个角度的颐和园很美\n长廊\n准备回去的时候看到的，各种长枪大炮，据说是在抓拍一种珍稀鸟类。。。\n颐和园的风景虽好，但就自然风光来说，比不上南方早已复苏的大自然。\n家乡的油菜花，比颐和园的迎春花漂亮多了-:)\n武大樱花已经争奇斗艳了，北方还是萧瑟一片[2]\n后记 没来北京之前，我想着以后一定要在北京工作，还要争取在北京安家落户。虽然北京生活压力很大，但是机会和挑战也多，这不就是我要的生活吗；而且北京是全国的政治、经济和文化中心，可以很方便的去感受中国几千年的文化和历史。在北京生活一个月之后，我的想法变了，很重要的原因是北京的雾霾和气候。雾霾不是一个人一天两天能够解决的，你必须尽量减少不必要的出行，跑步健身什么的就更别提了；北京属于北温带季风气候，冬天很干燥，而且放眼望去看不到绿色，ict旁边种的树，光秃秃的只有树干。这种钢筋混凝土构筑起来的城市，我真的不喜欢。\n和南方的一些城市相比，北京真的不适宜居住，尤其对于南方人！\n参考 [1]. 新京报网：http://www.bjnews.com.cn/news/2015/03/28/358122.html\n[2]. 中新网：http://www.chinanews.com/tp/hd2011/2015/03-21/496005.shtml\n","permalink":"http://localhost:1313/posts/2015-03-30-one-month-in-beijing/","summary":"\u003cp\u003e2015年2月28日到达北京，到现在一月有余，是时候月度总结了。\u003c/p\u003e\n\u003ch1 id=\"这是我第三次来北京\"\u003e这是我第三次来北京\u003c/h1\u003e\n\u003cp\u003e2014年的6月份第一次来北京，去北大计算所实习十天。感受了一下北大计算所p老师及其博士生z的冷漠。我还记得刚到的那天晚上一个人孤零零的走在北京的大街上寻找北大方正员工宿舍的场景。每天重复着朝九晚十的固定模式，每个人都像机器一样的工作，实验室只有敲击键盘的声音，偶尔看到p的时候他也是阴沉着脸，临走的时候还被z批评了。虽然p承诺说只要我通过夏令营面试就会要我，但是这明显就是废话呀；而且这段不算愉快的实习经历让我对p的实验室产生了厌恶。\u003c/p\u003e\n\u003cp\u003e回学校之后开始准备期末考试和7月份的夏令营，并于2014年7月9日到达北京，这次的行程包括北大计算所和中科院计算所的夏令营。北大计算所因为机试和综合排名不占优势，败下阵来，不过现在想想当初幸好没有进p的实验室，要不然天天对着p的臭脸，估计要疯。\u003c/p\u003e\n\u003cp\u003e中科院计算所的风格完全不像北大，中科院真正做到了海纳百川，一视同仁，不像北大看不起校外学生。来北京之前和ict的h老师沟通过很多次，发现我和h老师的性格很相似，我非常崇拜h老师严谨的处事风格，经过认真的准备，我也顺利通过了ict的夏令营，然后跑去深圳siat玩耍了。\u003c/p\u003e\n\u003ch1 id=\"北京的物价真是贵\"\u003e北京的物价真是贵\u003c/h1\u003e\n\u003cp\u003e这次是来ict完成我的本科毕业设计的，大概要待到5月初。一来从家里不方便带太多东西，二来想想要在北京待三年，所以准备在北京重新置办生活用品。\u003c/p\u003e\n\u003cp\u003e2月28刚到北京，去了师兄推荐的家乐福大超市。超市很大，有两层，不过里面的东西真是贵。也就买了被子、三件套、桶、盆，花了四五百，很可恨的是，很薄的春秋单人被子，居然要169，这还是最便宜的，床垫比被子还贵，要199。\u003c/p\u003e\n\u003cp\u003e没必要的用品可以不买，但是饭不能不吃。以前在学校一天也就十几块，到北京后发现，一顿饭就十多块了。早餐一个鸡蛋要2块，一个小包子要1.5块，哎，想想以前自己家做早餐的时候1块钱4个大肉包子啊，当初怎么不多吃几个呢。\u003c/p\u003e\n\u003cp\u003e餐厅里的饭菜确实贵，不过国科大食堂的饭菜既便宜又好吃，赞一个。\u003c/p\u003e\n\u003ch1 id=\"北京的雾霾\"\u003e北京的雾霾\u003c/h1\u003e\n\u003cp\u003e来北京之前对北京的雾霾也略有耳闻，觉得那是北京人的小题大做，武汉也是扬尘满天飞，我也活得好好的啊；不过真来北京之后，确实受不了，放眼望去，街道上灰蒙蒙的一片，路上的特大广告牌都看不清。也许是雾霾加干燥的原因，刚来北京那一个星期，嗓子特别不舒服，每天早晨刷牙的时候都恶心干呕，不过后来慢慢好了。\u003c/p\u003e\n\u003cp\u003e3月28那天，北京还遭遇了沙尘暴，那场景真像外星人袭击地球。所以来北京，口罩是必需品。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"3月28日北京的沙尘暴\" loading=\"lazy\" src=\"https://i0.wp.com/y0.ifengimg.com/cmpp/2015/03/28/14/1120a1ac-4317-49ca-8114-5962823270e1_size48_w600_h400.jpg\"\u003e\n3月28日北京的沙尘暴[1]\u003c/p\u003e\n\u003ch1 id=\"北京的风景\"\u003e北京的风景\u003c/h1\u003e\n\u003cp\u003e来北京的前3个星期，忙于组内布置的任务，也是过着朝九晚十的生活，后来想想也不能天天这样，我应该出去透透气，于是选择了颐和园，3月份属于颐和园景区的淡季，加上学生证，门票不贵。颐和园不愧是皇家园林，里面的景色确实很漂亮，有万寿山、昆明湖，湖水还算干净。\u003c/p\u003e\n\u003cp\u003e我去的那天天气很好，空气质量也不错；人虽多，但不算拥挤，部分原因是颐和园真是太大了。我在游玩的过程中看到了很多外国旅游团，听到过英语、法语、日语、韩语、粤语、中文，让我默默联想起了八国联军侵略中国的场景。\u003c/p\u003e\n\u003cp\u003e在游玩的过程中遇到了一个很温馨的“外国小家庭”，妈妈是外国人，爸爸应该也是外国人，爸爸和妈妈聊天的时候是用英语，但是爸爸和儿子却是用中文，他们还有一个坐在婴儿车里的小女儿，儿子坐在湖边玩ipad，小女儿在车里哭个不停…\u003c/p\u003e\n\u003cp\u003e虽然颐和园的风景很好，但是里面居然有很多蚊子（小虫子）！期间有一个虫子撞到我的嘴巴，还有一个钻进了我的耳朵。可能是春天到了，万物复苏，加上颐和园内潮湿，植物丰富，给虫子提供了很好的环境。\u003c/p\u003e\n\u003cp\u003e下面放几张游玩时拍的照片。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"谁能告诉我这是什么乐器\" loading=\"lazy\" src=\"/posts/2015-03-30-one-month-in-beijing/Summer-Palace1.jpg\"\u003e\n谁能告诉我这是什么乐器\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"学太极的外国人\" loading=\"lazy\" src=\"/posts/2015-03-30-one-month-in-beijing/Summer-Palace2.jpg\"\u003e\n学太极的外国人\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"这也是迎春花？\" loading=\"lazy\" src=\"/posts/2015-03-30-one-month-in-beijing/Summer-Palace3.jpg\"\u003e\n这也是迎春花？\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"这个角度的颐和园很美\" loading=\"lazy\" src=\"/posts/2015-03-30-one-month-in-beijing/Summer-Palace4.jpg\"\u003e\n这个角度的颐和园很美\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"长廊\" loading=\"lazy\" src=\"/posts/2015-03-30-one-month-in-beijing/Summer-Palace5.jpg\"\u003e\n长廊\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"准备回去的时候看到的，各种长枪大炮，据说是在抓拍一种珍稀鸟类。。。\" loading=\"lazy\" src=\"/posts/2015-03-30-one-month-in-beijing/Summer-Palace6.jpg\"\u003e\n准备回去的时候看到的，各种长枪大炮，据说是在抓拍一种珍稀鸟类。。。\u003c/p\u003e\n\u003cp\u003e颐和园的风景虽好，但就自然风光来说，比不上南方早已复苏的大自然。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"家乡的油菜花，比颐和园的迎春花漂亮多了-:)\" loading=\"lazy\" src=\"/posts/2015-03-30-one-month-in-beijing/rape-flowers.jpg\"\u003e\n家乡的油菜花，比颐和园的迎春花漂亮多了-:)\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"武大樱花已经争奇斗艳了，北方还是萧瑟一片\" loading=\"lazy\" src=\"https://i0.wp.com/i2.chinanews.com/simg/hd/2015/03/21/7e9527ca232f4253bfb86eef15cee517.jpg\"\u003e\n武大樱花已经争奇斗艳了，北方还是萧瑟一片[2]\u003c/p\u003e\n\u003ch1 id=\"后记\"\u003e后记\u003c/h1\u003e\n\u003cp\u003e没来北京之前，我想着以后一定要在北京工作，还要争取在北京安家落户。虽然北京生活压力很大，但是机会和挑战也多，这不就是我要的生活吗；而且北京是全国的政治、经济和文化中心，可以很方便的去感受中国几千年的文化和历史。在北京生活一个月之后，我的想法变了，很重要的原因是北京的雾霾和气候。雾霾不是一个人一天两天能够解决的，你必须尽量减少不必要的出行，跑步健身什么的就更别提了；北京属于北温带季风气候，冬天很干燥，而且放眼望去看不到绿色，ict旁边种的树，光秃秃的只有树干。这种钢筋混凝土构筑起来的城市，我真的不喜欢。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e和南方的一些城市相比，北京真的不适宜居住，尤其对于南方人！\u003c/strong\u003e\u003c/p\u003e\n\u003ch1 id=\"参考\"\u003e参考\u003c/h1\u003e\n\u003cp\u003e[1]. 新京报网：\u003ca href=\"http://www.bjnews.com.cn/news/2015/03/28/358122.html\"\u003ehttp://www.bjnews.com.cn/news/2015/03/28/358122.html\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e[2]. 中新网：\u003ca href=\"http://www.chinanews.com/tp/hd2011/2015/03-21/496005.shtml\"\u003ehttp://www.chinanews.com/tp/hd2011/2015/03-21/496005.shtml\u003c/a\u003e\u003c/p\u003e","title":"One month in Beijing"},{"content":"在上一题POJ Problem 1837: Balance中，我们曾讲到，如果只有两个挂钩，问题会好办得多，就拿题目给的样例数据来说：\nSample Input 2 4 -2 3 3 4 5 8 Sample Output 2 如上图所示，给定重量为3,4,5,8的砝码，放在一个左右臂长分别为2和3的天平上，要使天平平衡，问有多少种方法。\n这个问题可以稍加转换，假设放在左边的重量为x，右边为y，则有如下方程组成立：\n$$ \\begin{cases} x+y=3+4+5+8=20\\\\ 2x=3y \\end{cases} $$马上解出x=12,y=8。这样就相当于把原问题转换为：已知序列3,4,5,8，问从中取若干个数使和为12（或8）的方案数有多少个？ 因为取出数字和为8，则剩余和为12，所以和为8和12的方案数是相等的。\n因为这里只有4个数字，一眼就能看出有(3,4,5)，(4,8)能使和为12，即只有两种方案。如果给的数字较多较大，该怎样写代码求出呢？可以使用动态规划求解。\n设dp[i][j]表示从前i个数中选若干个数使得和为j的方案数，则我们可以得到这样的状态转换方程：\n$$ \\begin{cases} dp[i][j]=1\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\text{if}i=0\\\u0026\\\u0026j=0\\\\ dp[i][j]=dp[i-1][j]\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\text{if}w[i]\u003ej\\\\ dp[i][j]=dp[i-1][j]+dp[i-1][j-w[i]]\\qquad\\quad\\text{if}w[i]\u003c=j \\end{cases} $$ 当i=0\u0026amp;\u0026amp;j=0时，dp[i][j]=1表示从0个数中取若干个数使得和为0，当然只有1种方案，那就是什么都不取 当w[i]\u0026gt;j时，第i个数用不上，因为你单个数字都超过j了，怎么使和为j呢，所以直接dp[i][j]=dp[i-1][j] 当w[i]\u0026lt;=j时，第i个数可以用了，这个时候分两种情况，用或者不用第i个数，如果不用，则和w[i]\u0026gt;j时一样dp[i][j]=dp[i-1][j]，如果用的话，则要从前i-1个数中取若干个数使和为j-w[i]，也就是dp[i-1][j-w[i]]，这样总的方案数就是用和不用第i个数的方案数之和，即dp[i][j]=dp[i-1][j]+dp[i-1][j-w[i]] 下面是针对这个例子我手算的一个图：\n以上面的内容设计一个OJ题如下：\n描述： 给定一个正整数数字序列，从中取出若干个数字，使得这些数字之和为某一个特定的值，求所有取法的方案数。 输入： 输入包含多个测试用例，每个测试用例的第一行有两个数N,S，N表示这个数字序列共有多少个数字；S表示取出的数字之和为S。后面一行包含N个正整数。 N,S为0程序结束 输出： 每个测试用例输出一行，表示从N个数中取若干个数使得和为S的方案总数。 样例输入： 4 8 3 4 5 8 4 12 3 4 5 8 10 10 10 9 8 7 6 5 4 3 2 1 0 0 样例输出： 2 2 10 知道了状态转换方程，我们可以很快的写出以上OJ的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 #include \u0026lt;algorithm\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; using namespace std; int main() { int n, s, sum; while (cin \u0026gt;\u0026gt; n \u0026gt;\u0026gt; s \u0026amp;\u0026amp; n \u0026amp;\u0026amp; s) { vector\u0026lt;int\u0026gt; w(n + 1); vector\u0026lt;int\u0026gt; dp(s + 1, 0); sum = 0; w[0] = 0; /* 额外添加的第0个数字为0 */ for (int i = 1; i \u0026lt;= n; i++) { cin \u0026gt;\u0026gt; w[i]; sum += w[i]; /* 所有数字之和 */ } if (sum \u0026lt; s) /* 如果所有数字加起来都小于s，则怎么取都不存在和为s的方案 */ { cout \u0026lt;\u0026lt; \u0026#34;0\u0026#34; \u0026lt;\u0026lt; endl; continue; } sort(w.begin(), w.end()); /* 首先对这些数字从小到大排序，因为取大的数字的时候会用到取小的数字的结果 */ dp[0] = 1; /* 相当于dp[0][0]=1; */ for (int i = 1; i \u0026lt;= n; i++) { for (int j = s; j \u0026gt;= 1; j – ) /* 从后往前测试，这样只需要一行空间 */ { if (w[i] \u0026lt;= j) dp[j] += dp[j - w[i]]; } } cout \u0026lt;\u0026lt; dp[s] \u0026lt;\u0026lt; endl; } return (0); } 代码中添加了几个操作，首先如果所有数字之和都小于s，则肯定无解；其次，我们先对数字序列从小到大排序，这样DP填表；最后我们填表的时候是从右往左填的，这样只需要一行空间dp[j]，而不是二维dp[i][j]。\n","permalink":"http://localhost:1313/posts/2014-11-15-subset-sum-problem/","summary":"\u003cp\u003e在上一题POJ Problem 1837: Balance中，我们曾讲到，如果只有两个挂钩，问题会好办得多，就拿题目给的样例数据来说：\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eSample Input\n2 4\n-2 3\n3 4 5 8\n\nSample Output\n2\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg alt=\"number-balance.png\" loading=\"lazy\" src=\"/posts/2014-11-15-subset-sum-problem/number-balance.png\"\u003e\n如上图所示，给定重量为3,4,5,8的砝码，放在一个左右臂长分别为2和3的天平上，要使天平平衡，问有多少种方法。\u003c/p\u003e\n\u003cp\u003e这个问题可以稍加转换，假设放在左边的重量为x，右边为y，则有如下方程组成立：\u003c/p\u003e\n$$\n\\begin{cases}\nx+y=3+4+5+8=20\\\\\n2x=3y\n\\end{cases}\n$$\u003cp\u003e马上解出x=12,y=8。这样就相当于把原问题转换为：\u003cstrong\u003e已知序列3,4,5,8，问从中取若干个数使和为12（或8）的方案数有多少个？\u003c/strong\u003e 因为取出数字和为8，则剩余和为12，所以和为8和12的方案数是相等的。\u003c/p\u003e\n\u003cp\u003e因为这里只有4个数字，一眼就能看出有(3,4,5)，(4,8)能使和为12，即只有两种方案。如果给的数字较多较大，该怎样写代码求出呢？可以使用动态规划求解。\u003c/p\u003e\n\u003cp\u003e设dp[i][j]表示从前i个数中选若干个数使得和为j的方案数，则我们可以得到这样的状态转换方程：\u003c/p\u003e\n$$\n\\begin{cases}\ndp[i][j]=1\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\text{if}i=0\\\u0026\\\u0026j=0\\\\\ndp[i][j]=dp[i-1][j]\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\text{if}w[i]\u003ej\\\\\ndp[i][j]=dp[i-1][j]+dp[i-1][j-w[i]]\\qquad\\quad\\text{if}w[i]\u003c=j\n\\end{cases}\n$$\u003col\u003e\n\u003cli\u003e当i=0\u0026amp;\u0026amp;j=0时，dp[i][j]=1表示从0个数中取若干个数使得和为0，当然只有1种方案，那就是什么都不取\u003c/li\u003e\n\u003cli\u003e当w[i]\u0026gt;j时，第i个数用不上，因为你单个数字都超过j了，怎么使和为j呢，所以直接dp[i][j]=dp[i-1][j]\u003c/li\u003e\n\u003cli\u003e当w[i]\u0026lt;=j时，第i个数可以用了，这个时候分两种情况，用或者不用第i个数，如果不用，则和w[i]\u0026gt;j时一样dp[i][j]=dp[i-1][j]，如果用的话，则要从前i-1个数中取若干个数使和为j-w[i]，也就是dp[i-1][j-w[i]]，这样总的方案数就是用和不用第i个数的方案数之和，即dp[i][j]=dp[i-1][j]+dp[i-1][j-w[i]]\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e下面是针对这个例子我手算的一个图：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"20141115_170507.jpg\" loading=\"lazy\" src=\"/posts/2014-11-15-subset-sum-problem/20141115_170507.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e以上面的内容设计一个OJ题如下：\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e描述：\n给定一个正整数数字序列，从中取出若干个数字，使得这些数字之和为某一个特定的值，求所有取法的方案数。\n\n输入：\n输入包含多个测试用例，每个测试用例的第一行有两个数N,S，N表示这个数字序列共有多少个数字；S表示取出的数字之和为S。后面一行包含N个正整数。\nN,S为0程序结束\n\n输出：\n每个测试用例输出一行，表示从N个数中取若干个数使得和为S的方案总数。\n\n样例输入：\n4 8\n3 4 5 8\n4 12\n3 4 5 8\n10 10\n10 9 8 7 6 5 4 3 2 1\n0 0\n\n样例输出：\n2\n2\n10\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e知道了状态转换方程，我们可以很快的写出以上OJ的代码：\u003c/p\u003e","title":"从一个数字序列中取若干个数字使得和为某个数，问共有多少种取数方案？"},{"content":"一、第一次使用Github的步骤： 在这个页面中填写Repo名称 不要勾选Initialize this repository with a README 点击Create repository 在本地使用Git命令行工具进入到和第1步填写Repo相同名称的文件夹中（此文件夹中已包含你要push到Github上的内容），执行以下几个命令： 1 2 3 4 5 6 git init touch README.md #optional git add . git commit -m \u0026#39;your comment\u0026#39; git remote add origin https://github.com/UserName/RepoName git push origin master 如果你在第2步中勾选了Initialize this repository with a README，那么在第4步中省略touch README.md并且在git add .之前，执行第5行代码，然后git pull origin master将远端（remote）的内容pull到本地 关于Git命令中的fetch和pull的区别，请看这篇博文 关于Git bash和Github的连接，请看这篇博文 二、Git命令中fetch和pull的区别（转载） Git中从远程的分支获取最新的版本到本地有这样2个命令：\ngit fetch：相当于是从远程获取最新版本到本地，不会自动merge 1 2 3 git fetch origin master git log -p master..origin/master git merge origin/master 以上命令的含义：首先从远程的origin的master主分支下载最新的版本到origin/master分支上，然后比较本地的master分支和origin/master分支的差别，最后进行合并。\n上述过程其实可以用以下更清晰的方式来进行：\n1 2 3 git fetch origin master:tmp git diff tmp git merge tmp 从远程获取最新的版本到本地的test分支上，之后再进行比较合并。\ngit pull：相当于是从远程获取最新版本并merge到本地 1 git pull origin master 上述命令其实相当于git fetch + git merge。\n在实际使用中，git fetch更安全一些，因为在merge前，我们可以查看更新情况，然后再决定是否合并。\n","permalink":"http://localhost:1313/posts/2014-11-11-git-notes/","summary":"\u003ch1 id=\"一第一次使用github的步骤\"\u003e一、第一次使用Github的步骤：\u003c/h1\u003e\n\u003col\u003e\n\u003cli\u003e在\u003ca href=\"https://github.com/new\"\u003e这个页面\u003c/a\u003e中填写Repo名称\u003c/li\u003e\n\u003cli\u003e不要勾选Initialize this repository with a README\u003c/li\u003e\n\u003cli\u003e点击Create repository\u003c/li\u003e\n\u003cli\u003e在本地使用Git命令行工具进入到和第1步填写Repo相同名称的文件夹中（此文件夹中已包含你要push到Github上的内容），执行以下几个命令：\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\n\u003ctable style=\"border-spacing:0;padding:0;margin:0;border:0;\"\u003e\u003ctr\u003e\u003ctd style=\"vertical-align:top;padding:0;margin:0;border:0;\"\u003e\n\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e1\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e2\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e3\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e4\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e5\n\u003c/span\u003e\u003cspan style=\"white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f\"\u003e6\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd style=\"vertical-align:top;padding:0;margin:0;border:0;;width:100%\"\u003e\n\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit init\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003etouch README.md \u003cspan style=\"color:#75715e\"\u003e#optional\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit add .\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit commit -m \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;your comment\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit remote add origin https://github.com/UserName/RepoName\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit push origin master\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003col start=\"5\"\u003e\n\u003cli\u003e如果你在第2步中勾选了Initialize this repository with a README，那么在第4步中省略touch README.md并且在git add .之前，执行第5行代码，然后git pull origin master将远端（remote）的内容pull到本地\u003c/li\u003e\n\u003cli\u003e关于Git命令中的fetch和pull的区别，请看\u003ca href=\"https://blog.csdn.net/wfdtxz/article/details/8632811\"\u003e这篇博文\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e关于Git bash和Github的连接，请看\u003ca href=\"https://www.cnblogs.com/fnng/archive/2011/08/25/2153807.html\"\u003e这篇博文\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch1 id=\"二git命令中fetch和pull的区别转载\"\u003e二、Git命令中fetch和pull的区别（\u003ca href=\"https://blog.csdn.net/wfdtxz/article/details/8632811\"\u003e转载\u003c/a\u003e）\u003c/h1\u003e\n\u003cp\u003eGit中从远程的分支获取最新的版本到本地有这样2个命令：\u003c/p\u003e","title":"Git相关笔记"}]